---
    - name: HDFS | Download hadoop
      unarchive:
        src: https://www.apache.org/dyn/mirrors/mirrors.cgi?action=download&filename=hadoop/common/hadoop-3.3.2/hadoop-3.3.2.tar.gz
        dest: /opt
        remote_src: yes
      tags:
        - hdfs

    - name: Remove Hadoop archive
      ansible.builtin.file:
        path: /opt/hadoop-3.3.2.tar.gz
        state: absent
      tags:
        - hdfs
    
    - name: HDFS | Insert Hadoop related Environment Variables at the end of a bashrc.
      blockinfile:
        path: "/home/{{ CLUSTER_USER }}/.bashrc"
        insertbefore: '.*'
        marker: "#<!-- {mark} Adding HDFS related Env Variables -->"
        block: |
          export JAVA_HOME=/usr/lib/jvm/jre-11-openjdk
          export HADOOP_HOME=/opt/hadoop-3.3.2
          export HADOOP_INSTALL=$HADOOP_HOME
          export HADOOP_MAPRED_HOME=$HADOOP_HOME
          export HADOOP_COMMON_HOME=$HADOOP_HOME
          export HADOOP_HDFS_HOME=$HADOOP_HOME
          export YARN_HOME=$HADOOP_HOME
          export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
          export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin
          export HADOOP_OPTS='-Djava.library.path=/opt/hadoop-3.3.2/lib/native'
          export HADOOP_OPTIONAL_TOOLS=hadoop-azure
          export ARROW_LIBHDFS_DIR=$HADOOP_COMMON_LIB_NATIVE_DIR
          export CLASSPATH=`$HADOOP_HOME/bin/hdfs classpath --glob`
      tags:
        - hdfs
    
    # Copy the bodo-azurefs-sas-token-provider jar to /opt/hadoop-3.3.2/share/hadoop/hdfs so that
    # it's in the CLASSPATH automatically when CLASSPATH=`$HADOOP_HOME/bin/hdfs classpath --glob`
    # is executed within bashrc
    - name: BODO | Copy bodo-azurefs-sas-token-provider jar to /opt/hadoop-3.3.2/share/hadoop/hdfs
      shell: |
        export PATH=/opt/conda/bin:$PATH
        JAR_LOC=`python -c "from bodo_azurefs_sas_token_provider import JAR_PATH; print(JAR_PATH)"`
        cp $JAR_LOC /opt/hadoop-3.3.2/share/hadoop/hdfs
      tags:
        - hdfs
