{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"About Bodo","text":"<p>Bodo is the first HPC-based compute engine for SQL and Python data processing.  With its new just-in-time (JIT) inferential compiler, Bodo brings supercomputing-style performance and scalability to native SQL and Python code automatically. Bodo significantly improves the performance of long-running data engineering workloads on popular data warehouses by typically saving more than 60% of the infrastructure cost. </p> <p>Bodo\u2019s compiler optimization and parallel runtime system technologies bring HPC levels of performance and efficiency to  large-scale data processing for the first time. Data warehouses focus on decades-old database techniques such as  indexing\u2014ensuring that a minimal amount of rows is scanned to match query filters that target small portions of the data. However, modern queries that require heavy computation on large data also need MPI parallelization and low-level code  optimization techniques to run efficiently. The Bodo Compute Engine brings these optimization techniques to data engineering without requiring any code change or tuning.</p> <p> <p></p> <p>Bodo operates on the data in your data warehouse or data lake without copy. Data always stays in your own VPC, so you can comply with the security standards that your organization may require. The Bodo Platform provides a simple, interactive workflow for development, deployment, and monitoring. Quickly get up and running with the most challenging workloads in your existing cloud account.</p> <p>This documentation covers the basics of using Bodo and provides a reference of supported SQL and Python features and APIs. To get started with Bodo using the Bodo Platform, refer to our Quick Start Guide. </p> <p>If you want to try the free community edition of Bodo on your local setup, you can follow the steps outlined here.</p>"},{"location":"dev_guide/","title":"Developer's Quick Start Guide","text":"<p>This page provides an introduction to programming with Bodo and explains its important concepts briefly.</p>","tags":["getting started"]},{"location":"dev_guide/#installation","title":"Installation","text":"<p>We recommend trying Bodo by signing up for a personalized 1:1 demo where you will get a step-by-step guide on how to use the Bodo cloud platform. If you prefer to do it yourself,  see how to get started with the Bodo platform</p> <p>If you prefer a local install, you can also use <code>pip</code>:</p> <pre><code>pip install bodo\n</code></pre> <p>Conda installation is available too:</p> <pre><code>conda create -n Bodo python=3.9 mamba -c conda-forge\nconda activate Bodo\nmamba install bodo -c bodo.ai -c conda-forge\n</code></pre> <p>This command installs Bodo Community Edition by default, which is free and works on up to 8 cores. You can also subscribe to Bodo Platform on AWS Marketplace or contact us for trial licenses. See the installation section for more details of setting up Bodo.</p>","tags":["getting started"]},{"location":"dev_guide/#data-transform-example-with-bodo","title":"Data Transform Example with Bodo","text":"<p>We use a simple data transformation example to discuss some of the key Bodo concepts.</p>","tags":["getting started"]},{"location":"dev_guide/#generate-data","title":"Generate data","text":"<p>Let's generate some example data and write to a Parquet file:</p> <pre><code>import pandas as pd\nimport numpy as np\n# 10m data points\ndf = pd.DataFrame(\n{\n\"A\": np.repeat(pd.date_range(\"2013-01-03\", periods=1000), 10_000),\n\"B\": np.arange(10_000_000),\n}\n)\n# set some values to NA\ndf.iloc[np.arange(1000) * 3, 0] = pd.NA\n# using row_group_size helps with efficient parallel read of data later\ndf.to_parquet(\"pd_example.pq\", row_group_size=100_000)\n</code></pre> <p>Save this code in <code>gen_data.py</code> and run in command line:</p> <pre><code>python gen_data.py\n</code></pre>","tags":["getting started"]},{"location":"dev_guide/#example_code_in_pandas","title":"Example Pandas Code","text":"<p>Here is a simple data transformation code in Pandas that processes a column of datetime values and creates two new columns:</p> <pre><code>import pandas as pd\nimport time\ndef data_transform():\nt0 = time.time()\ndf = pd.read_parquet(\"pd_example.pq\")\ndf[\"B\"] = df.apply(lambda r: \"NA\" if pd.isna(r.A) else \"P1\" if r.A.month &lt; 5 else \"P2\", axis=1)\ndf[\"C\"] = df.A.dt.month\ndf.to_parquet(\"pandas_output.pq\")\nprint(\"Total time: {:.2f}\".format(time.time() - t0))\nif __name__ == \"__main__\":\ndata_transform()\n</code></pre> <p>Save this code in <code>data_transform.py</code> and run in command line:</p> <pre><code>$ python data_transform.py\nTotal time: 166.18\n</code></pre> <p>Standard Python is quite slow for these data transforms since:</p> <ol> <li>The use of custom code inside <code>apply()</code> does not let Pandas run an     optimized prebuilt C library in its backend. Therefore, the Python     interpreter overheads dominate.</li> <li>Python uses a single CPU core and does not parallelize     computation.</li> </ol> <p>Bodo solves both of these problems as we demonstrate below.</p>","tags":["getting started"]},{"location":"dev_guide/#using-the-bodo-jit-decorator","title":"Using the Bodo JIT Decorator","text":"<p>Bodo optimizes and parallelizes data workloads by providing just-in-time (JIT) compilation. This code is identical to the original Pandas code, except that it annotates the <code>data_transform</code> function with the <code>bodo.jit</code> decorator:</p> <pre><code>import pandas as pd\nimport time\nimport bodo\n@bodo.jit\ndef data_transform():\nt0 = time.time()\ndf = pd.read_parquet(\"pd_example.pq\")\ndf[\"B\"] = df.apply(lambda r: \"NA\" if pd.isna(r.A) else \"P1\" if r.A.month &lt; 5 else \"P2\", axis=1)\ndf[\"C\"] = df.A.dt.month\ndf.to_parquet(\"bodo_output.pq\")\nprint(\"Total time: {:.2f}\".format(time.time()-t0))\nif __name__ == \"__main__\":\ndata_transform()\n</code></pre> <p>Save this code in <code>bodo_data_transform.py</code> and run on a single core from command line:</p> <pre><code>$ python bodo_data_transform.py\nTotal time: 1.78\n</code></pre> <p>This code is 94x faster with Bodo than Pandas even on a single core, because Bodo compiles the function into a native binary, eliminating the interpreter overheads in <code>apply</code>.</p> <p>Now let's run the code on 8 CPU cores using <code>mpiexec</code> in command line:</p> <pre><code>$ mpiexec -n 8 python bodo_data_transform.py\nTotal time: 0.38\n</code></pre> <p>Using 8 cores gets an additional ~5x speedup. The same program can be scaled to larger datasets and as many cores as necessary in compute clusters and cloud environments (e.g. <code>mpiexec -n 10000 python bodo_data_transform.py</code>).</p> <p>See the documentation on bodo parallelism basics for more details about Bodo's JIT compilation workflow and parallel computation model.</p>","tags":["getting started"]},{"location":"dev_guide/#compilation-time-and-caching","title":"Compilation Time and Caching","text":"<p>Bodo's JIT workflow compiles the function the first time it is called, but reuses the compiled version for subsequent calls. In the previous code, we added timers inside the function to avoid measuring compilation time. Let's move the timers outside and call the function twice:</p> <pre><code>import pandas as pd\nimport time\nimport bodo\n@bodo.jit\ndef data_transform():\ndf = pd.read_parquet(\"pd_example.pq\")\ndf[\"B\"] = df.apply(lambda r: \"NA\" if pd.isna(r.A) else \"P1\" if r.A.month &lt; 5 else \"P2\", axis=1)\ndf[\"C\"] = df.A.dt.month\ndf.to_parquet(\"bodo_output.pq\")\nif __name__ == \"__main__\":\nt0 = time.time()\ndata_transform()\nprint(\"Total time first call: {:.2f}\".format(time.time()-t0))\nt0 = time.time()\ndata_transform()\nprint(\"Total time second call: {:.2f}\".format(time.time()-t0))\n</code></pre> <p>Save this code in <code>data_transform2.py</code> and run in command line:</p> <pre><code>$ python data_transform2.py\nTotal time first call: 4.72\nTotal time second call: 1.92\n</code></pre> <p>The first call is slower due to compilation of the function, but the second call reuses the compiled version and runs faster.</p> <p>Compilation time can be avoided across program runs by using the <code>cache=True</code> flag:</p> <pre><code>import pandas as pd\nimport time\nimport bodo\n@bodo.jit(cache=True)\ndef data_transform():\ndf = pd.read_parquet(\"pd_example.pq\")\ndf[\"B\"] = df.apply(lambda r: \"NA\" if pd.isna(r.A) else \"P1\" if r.A.month &lt; 5 else \"P2\", axis=1)\ndf[\"C\"] = df.A.dt.month\ndf.to_parquet(\"bodo_output.pq\")\nif __name__ == \"__main__\":\nt0 = time.time()\ndata_transform()\nprint(\"Total time: {:.2f}\".format(time.time() - t0))\n</code></pre> <p>Save this code in <code>data_transform_cache.py</code> and run in command line twice:</p> <pre><code>$ python data_transform_cache.py\nTotal time: 4.70\n$ python data_transform_cache.py\nTotal time: 1.96\n</code></pre> <p>In this case, Bodo saves the compiled version of the function to a file and reuses it in the second run since the code has not changed. We plan to make caching default in the future. See caching for more information.</p>","tags":["getting started"]},{"location":"dev_guide/#parallel-python-processes","title":"Parallel Python Processes","text":"<p>Bodo uses the MPI parallelism model, which runs the full program on all cores from the beginning. Essentially, <code>mpiexec</code> launches identical Python processes but Bodo divides the data and computation in JIT functions to exploit parallelism.</p> <p>Let's try a simple example that demonstrates how chunks of data are loaded in parallel:</p> <pre><code>import pandas as pd\nimport bodo\ndef load_data_pandas():\ndf = pd.read_parquet(\"pd_example.pq\")\nprint(\"pandas dataframe: \", df)\n@bodo.jit\ndef load_data_bodo():\ndf = pd.read_parquet(\"pd_example.pq\")\nprint(\"Bodo dataframe: \", df)\nif __name__ == \"__main__\":\nload_data_pandas()\nload_data_bodo()\n</code></pre> <p>Save this code in <code>load_data.py</code> and run on two cores (output prints of the cores are mixed):</p>  Click to expand output <pre><code>$ mpiexec -n 2 python load_data.py\npandas dataframe:\n                 A        B\n0              NaT        0\n1       2013-01-03        1\n2       2013-01-03        2\n3              NaT        3\n4       2013-01-03        4\n...            ...      ...\n9999995 2015-09-29  9999995\n9999996 2015-09-29  9999996\n9999997 2015-09-29  9999997\n9999998 2015-09-29  9999998\n9999999 2015-09-29  9999999\n[10000000 rows x 2 columns]\npandas dataframe:\n                 A        B\n0              NaT        0\n1       2013-01-03        1\n2       2013-01-03        2\n3              NaT        3\n4       2013-01-03        4\n...            ...      ...\n9999995 2015-09-29  9999995\n9999996 2015-09-29  9999996\n9999997 2015-09-29  9999997\n9999998 2015-09-29  9999998\n9999999 2015-09-29  9999999\n[10000000 rows x 2 columns]\nBodo dataframe:\n                 A        B\n0       1970-01-01        0\n1       2013-01-03        1\n2       2013-01-03        2\n3       2013-01-03        3\n4       2013-01-03        4\n...            ...      ...\n4999995 2014-05-17  4999995\n4999996 2014-05-17  4999996\n4999997 2014-05-17  4999997\n4999998 2014-05-17  4999998\n4999999 2014-05-17  4999999\n[5000000 rows x 2 columns]\npandas dataframe:\n                 A        B\n5000000 2014-05-18  5000000\n5000001 2014-05-18  5000001\n5000002 2014-05-18  5000002\n5000003 2014-05-18  5000003\n5000004 2014-05-18  5000004\n...            ...      ...\n9999995 2015-09-29  9999995\n9999996 2015-09-29  9999996\n9999997 2015-09-29  9999997\n9999998 2015-09-29  9999998\n9999999 2015-09-29  9999999\n[5000000 rows x 2 columns]\n</code></pre> <p>The first two dataframes printed are regular Pandas dataframes which are replicated on both processes and have all 10 million rows. However, the last two dataframes printed are Bodo parallelized Pandas dataframes, with 5 million rows each. In this case, Bodo parallelizes <code>read_parquet</code> automatically and loads different chunks of data in different cores. Therefore, the non-JIT parts of the Python program are replicated across cores whereas Bodo JIT functions are parallelized.</p>","tags":["getting started"]},{"location":"dev_guide/#parallel-computation","title":"Parallel Computation","text":"<p>Bodo automatically divides computation and manages communication across cores as this example demonstrates:</p> <pre><code>import pandas as pd\nimport bodo\n@bodo.jit\ndef data_groupby():\ndf = pd.read_parquet(\"pd_example.pq\")\ndf2 = df.groupby(\"A\", as_index=False).sum()\ndf2.to_parquet(\"bodo_output.pq\")\nif __name__ == \"__main__\":\ndata_groupby()\n</code></pre> <p>Save this code as <code>data_groupby.py</code> and run from command line:</p> <pre><code>$ mpiexec -n 8 python data_groupby.py\n</code></pre> <p>This program uses <code>groupby</code> which requires rows with the same key to be aggregated together. Therefore, Bodo shuffles the data automatically under the hoods using MPI, and the user doesn't need to worry about parallelism challenges like communication.</p> <p></p> <p></p>","tags":["getting started"]},{"location":"dev_guide/#bodo-jit-requirements","title":"Bodo JIT Requirements","text":"<p>To take advantage of the Bodo JIT compiler and avoid errors, make sure only compute and data-intensive code is in JIT functions. Other Python code for setup and configuration should run in regular Python. For example, consider this simple script:</p> <pre><code>import os\nimport pandas as pd\ndata_path = os.environ[\"JOB_DATA_PATH\"]\ndf = pd.read_parquet(data_path)\nprint(df.A.sum())\n</code></pre> <p>The Bodo version performs the computation in JIT functions, but keeps the setup code (finding <code>data_path</code>) in regular Python:</p> <pre><code>import os\nimport pandas as pd\nimport bodo\ndata_path = os.environ[\"JOB_DATA_PATH\"]\n@bodo.jit\ndef f(path):\ndf = pd.read_parquet(path)\nprint(df.A.sum())\nf(data_path)\n</code></pre> <p>In addition, the Bodo version passes the file path <code>data_path</code> as an argument to the JIT function <code>f</code>, allowing Bodo to find the input dataframe schema which is necessary for type inference (more in Scalable Data I/O).</p> <p>Bodo JIT supports specific APIs in Pandas currently, and other APIs cannot be used inside JIT functions. For example:</p> <pre><code>import pandas as pd\nimport bodo\n@bodo.jit\ndef df_unsupported():\ndf = pd.DataFrame({\"A\": [1, 2, 3])\ndf2 = df.transpose()\nreturn df2\nif __name__ == \"__main__\":\ndf_unsupported()\n</code></pre> <p>Save this code as <code>df_unsupported.py</code> and run from command line:</p> <pre><code>$ python df_unsupported.py\n# bodo.utils.typing.BodoError: Dataframe.transpose not supported yet\n</code></pre> <p>As the error indicates, Bodo doesn't currently support the <code>transpose</code> call in JIT functions. In these cases, an alternative API should be used or this portion of the code should be either be in regular Python or in Bodo's Object Mode. See supported Pandas API for the complete list of supported Pandas operations.</p>","tags":["getting started"]},{"location":"dev_guide/#type-stability","title":"Type Stability","text":"<p>The main requirement of JIT compilation is being able to infer data types for all variables and values. In Bodo, column names are part of dataframe data types, so Bodo tries to infer column name related inputs in all operations. For example, key names in <code>groupby</code> are used to determine the output data type and need to be known to Bodo:</p> <pre><code>import pandas as pd\nimport bodo\n@bodo.jit\ndef groupby_keys(extra_keys):\ndf = pd.read_parquet(\"pd_example.pq\")\nkeys = [c for c in df.columns if c not in [\"B\", \"C\"]]\nif extra_keys:\nkeys.append(\"B\")\ndf2 = df.groupby(keys).sum()\nprint(df2)\nif __name__ == \"__main__\":\ngroupby_keys(False)\n</code></pre> <p>Save this code as <code>groupby_keys.py</code> and run from command line:</p> <pre><code>$ python groupby_keys.py\n# bodo.utils.typing.BodoError: groupby(): argument 'by' requires a constant value but variable 'keys' is updated inplace using 'append'\n</code></pre> <p>In this case, the list of groupby keys is determined using the runtime value of <code>extra_keys</code> in a way that Bodo is not able to infer it from the program during compilation time. The alternative is to compute the keys in a separate JIT function to make it easier for Bodo to infer:</p> <pre><code>import pandas as pd\nimport bodo\n@bodo.jit\ndef get_keys(df_columns, extra_keys):\nkeys = [c for c in df_columns if c not in [\"B\", \"C\"]]\nif extra_keys:\nkeys.append(\"B\")\nreturn keys\n@bodo.jit\ndef groupby_keys(extra_keys):\ndf = pd.read_parquet(\"pd_example.pq\")\nkeys = get_keys(df.columns, extra_keys)\ndf2 = df.groupby(keys).sum()\nprint(df2)\nif __name__ == \"__main__\":\nkeys = get_keys()\ngroupby_keys(False)\n</code></pre> <p>This program works since <code>get_keys</code> can be evaluated in compile time. It only uses <code>df.columns</code> and <code>extra_keys</code> values that can be constant at compile time, and does not use non-deterministic features like I/O.</p>","tags":["getting started"]},{"location":"dev_guide/#python-features","title":"Python Features","text":"<p>Bodo uses Numba for compiling regular Python features and some of Numba's requirements apply to Bodo as well. For example, values in data structures like lists should have the same data type. This example fails since list values are either integers or strings:</p> <pre><code>import bodo\n@bodo.jit\ndef create_list():\nout = []\nout.append(0)\nout.append(\"A\")\nout.append(1)\nout.append(\"B\")\nreturn out\nif __name__ == \"__main__\":\ncreate_list()\n</code></pre> <p>Using tuples can often solve these problems since tuples can hold values of different types:</p> <pre><code>import bodo\n@bodo.jit\ndef create_list():\nout = []\nout.append((0, \"A\"))\nout.append((1, \"B\"))\nreturn out\nif __name__ == \"__main__\":\ncreate_list()\n</code></pre> <p>Please refer to the Unsupported Python Programs documentation for more details.</p>","tags":["getting started"]},{"location":"dev_guide/#jupyter","title":"Using Bodo in Jupyter Notebooks","text":"<p>See Interactive Bodo Cluster Setup using IPyParallel for more information.</p>","tags":["getting started"]},{"location":"file_io/","title":"Scalable Data I/O","text":"<p>Efficient parallel data processing requires data I/O to be parallelized effectively as well. Bodo provides parallel file I/O for many different formats such as Parquet, CSV, JSON, Numpy binaries, HDF5 and SQL databases. This diagram demonstrates how chunks of data are partitioned among parallel execution engines by Bodo.</p> <p> </p> <p>Bodo automatically parallelizes I/O for any number of cores and cluster size without any additional API layers.</p>"},{"location":"file_io/#io_workflow","title":"I/O Workflow","text":"<p>Make sure I/O calls for large data are inside JIT functions to allow Bodo to parallelize I/O and divide the data across cores automatically (see below for supported formats and APIs).</p> <p>Warning</p> <p>Performing I/O in regular Python (outside JIT functions) replicates data on all Python processes, which can result in out-of-memory errors if the data is large. For example, a 1 GB dataframe replicated on 1000 cores consumes 1 TB of memory.</p> <p>Bodo looks at the schema of the input dataset during compilation time to infer the datatype of the resulting dataframe. This requires the dataset path to be available to the compiler. The path should be either a constant string value, an argument to the JIT function, or a simple combination of the two. For example, the following code passes the dataset path as an argument, allowing Bodo to infer the data type of <code>df</code>:</p> <pre><code>import os\nimport pandas as pd\nimport bodo\ndata_path = os.environ[\"JOB_DATA_PATH\"]\n@bodo.jit\ndef f(path):\ndf = pd.read_parquet(path)\nprint(df.A.sum())\nf(data_path)\n</code></pre> <p>Concatenating arguments and constant values also works:</p> <pre><code>import os\nimport pandas as pd\nimport bodo\ndata_root = os.environ[\"JOB_DATA_ROOT\"]\n@bodo.jit\ndef f(root):\ndf = pd.read_parquet(root + \"/table1.pq\")\nprint(df.A.sum())\nf(data_root)\n</code></pre> <p>In the rare case that the path should be a dynamic value inside JIT functions, the data types have to be specified manually (see Specifying I/O Data Types Manually). This is error-prone and should be avoided as much as possible.</p>"},{"location":"file_io/#supported-data-formats","title":"Supported Data Formats","text":"<p>Currently, Bodo supports I/O for Parquet, CSV, SQL, JSON, HDF5, and Numpy binaries formats. It can read these formats from multiple filesystems, including S3, HDFS and Azure Data Lake (ADLS) (see File Systems below for more information). Many databases and data warehouses such as Snowflake are supported as well.</p> <p>Also see supported pandas APIs for supported arguments of I/O functions.</p>"},{"location":"file_io/#parquet-section","title":"Parquet","text":"<p>Parquet is a commonly used file format in analytics due to its efficient columnar storage. Bodo supports the standard pandas API for reading Parquet: <code>pd.read_parquet(path)</code>, where path can be a parquet file, a directory with multiple parquet files (all are part of the same dataframe), a glob pattern, list of files or list of glob patterns:</p> <pre><code>import pandas as pd\nimport bodo\n@bodo.jit\ndef write_pq(df):\ndf.to_parquet(\"s3://bucket-name/example.pq\")\n@bodo.jit\ndef read_pq():\ndf = pd.read_parquet(\"s3://bucket-name/example.pq\")\nreturn df\n</code></pre> <p>Note</p> <p>Bodo reads datasets in parallel using multiple cores while ensuring that the number of rows read on all cores is roughly equal. The size and number of row groups can affect parallel read performance significantly. Currently, reading any number of rows in Bodo requires reading at least one row-group. To read even a single row from a parquet dataset, the entire row-group containing that row (and its corresponding metadata) needs to be read first, and then the required row is extracted from it. Therefore, for best parallel read performance, there must be sufficient row-groups to minimize the number of instances where multiple cores need to read from the same row group. This means there must be at least as many row groups as the number of cores, but ideally a lot more. At the same time, the size of the row-groups should not be too small since this can lead to overheads. For more details about parquet file format, refer to the format specification.</p> <p><code>to_parquet(name)</code> with distributed data writes to a folder called <code>name</code>. Each process writes one file into the folder, but if the data is not distributed, <code>to_parquet(name)</code> writes to a single file called <code>name</code>:</p> <pre><code>df = pd.DataFrame({\"A\": range(10)})\n@bodo.jit\ndef example1_pq(df):\ndf.to_parquet(\"example1.pq\")\n@bodo.jit(distributed={\"df\"})\ndef example2_pq(df):\ndf.to_parquet(\"example2.pq\")\nif bodo.get_rank() == 0:\nexample1_pq(df)\nexample2_pq(df)\n</code></pre> <p>Run the code above with 4 processors:</p> <pre><code>mpiexec -n 4 python example_pq.py\n</code></pre> <p><code>example1_pq(df)</code> writes 1 single file, and <code>example2_pq(df)</code> writes a folder containing 4 parquet files:</p> <pre><code>.\n\u251c\u2500\u2500 example1.pq\n\u251c\u2500\u2500 example2.pq\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 part-00.parquet\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 part-01.parquet\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 part-02.parquet\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 part-03.parquet\n</code></pre> <p>See <code>read_parquet()</code>, <code>to_parquet()</code> for supported arguments.</p>"},{"location":"file_io/#filter-pushdown-and-column-pruning","title":"Filter Pushdown and Column Pruning","text":"<p>Filter Pushdown and Column Pruning</p> <p>Bodo can detect filters used by the code and optimize the <code>read_parquet</code> call by pushing the filters down to the storage layer, so that only the rows required by the program are read. In addition, Bodo only reads the columns that are used in the program, and prunes the unused columns. These optimizations can significantly speed up I/O in many cases and can substantially reduce the program's memory footprint.</p> <p>For example, suppose we have a large dataset with many columns that spans many years, and we only need to read revenue data for a particular year:</p> <pre><code>@bodo.jit\ndef query():\ndf = pd.read_parquet(\"s3://my-bucket/data.pq\")\ndf = df[df[\"year\"] == 2021]\nreturn df.groupby(\"customer_key\")[\"revenue\"].max()\n</code></pre> <p>When compiling the above, Bodo detects the <code>df[df[\"year\"] == 2021]</code> filter and optimizes the <code>read_parquet</code> call so that it only reads data for year 2021 from S3. This requires the dataframe filtering operation to be in the same JIT function as <code>read_parquet</code>, and the dataframe variable shouldn't be used before filtering. Bodo also makes sure only <code>customer_key</code> and <code>revenue</code> columns are read since other columns are not used in the programs.</p> <p>In general, if the dataset is hive-partitioned and partition columns appear in filter expressions, only the files that contain relevant data are read, and the rest are discarded based on their path. For example, if <code>year</code> is a partition column above and we have a dataset:</p> <pre><code>.\n\u2514\u2500\u2500 data.pq/\n    \u2502   ...\n    \u251c\u2500\u2500\u2500year=2020/\n    \u2502   \u251c\u2500\u2500 part-00.parquet\n    \u2502   \u2514\u2500\u2500 part-01.parquet\n    \u2514\u2500\u2500\u2500year=2021/\n        \u251c\u2500\u2500 part-02.parquet\n        \u2514\u2500\u2500 part-03.parquet\n</code></pre> <p>Bodo will only read the files in the <code>year=2021</code> directory.</p> <p>For non-partition columns, Bodo may discard files entirely just by looking at their parquet metadata (depending on the filters and statistics contained in the metadata) or filter the rows during read.</p> <p>Note</p> <p>Filter pushdown is often a very important optimization and critical for having manageable memory footprint in big data workloads. Make sure filtering happens in the same JIT function right after dataset read (or JIT functions for I/O are inlined, see inlining).</p>"},{"location":"file_io/#exploring-large-data-without-full-read","title":"Exploring Large Data Without Full Read","text":"<p>Exploring Large Data Without Full Read</p> <p>Exploring large datasets often requires seeing its shape and a sample of the data. Bodo is able to provide this information quickly without loading the full Parquet dataset, which means there is no need for a large cluster with a lot of memory. For example:</p> <pre><code>@bodo.jit\ndef head_only_read():\ndf = pd.read_parquet(\"s3://my-bucket/example.pq\")\nprint(df.shape)\nprint(df.head())\n</code></pre> <p>In this example, Bodo provides the shape information for the full dataset in <code>df.shape</code>, but only loads the first few rows that are necessary for <code>df.head()</code>.</p>"},{"location":"file_io/#csv-section","title":"CSV","text":"<p>CSV is a common text format for data exchange. Bodo supports most of the standard pandas API to read CSV files:</p> <pre><code>import pandas as pd\nimport bodo\n@bodo.jit\ndef write_csv(df):\ndf.to_csv(\"s3://my-bucket/example.csv\")\n@bodo.jit\ndef read_csv():\ndf = pd.read_csv(\"s3://my-bucket/example.csv\")\nreturn df\n</code></pre> <p>Unlike <code>read_csv</code> in regular pandas, Bodo can read a directory that contains multiple partitioned CSV files as well. All files in the folder must have the same number and datatype of columns. They can have different number of rows.</p> <p>Usage:</p> <pre><code>@bodo.jit\ndef read_csv_folder():\ndf = pd.read_csv(\"s3://my-bucket/path/to/folder/foldername\")\ndoSomething(df)\n</code></pre> <p>Use <code>sep=\"n\"</code> to read text files line by line into a single-column dataframe (without creating separate columns, useful when text data is unstructured or there are too many columns to read efficiently):</p> <pre><code>@bodo.jit\ndef read_test():\ndf = pd.read_csv(\"example.csv\", sep=\"n\", names=[\"value\"], dtype={\"value\": \"str\"})\nreturn df\n</code></pre> <p>Note</p> <p>Bodo uses nullable integer types of pandas to ensure type stability (see integer NA issue in pandas for more details). Therefore, data types must be specified explicitly for accurate performance comparisons of Bodo and pandas for <code>read_csv</code>.</p> <p><code>to_csv(name)</code> has different behaviors for different file systems:</p> <ol> <li> <p>POSIX file systems: always writes to a single file, regardless of the number of processes and whether the data is     distributed, but writing is still done in parallel when more than 1 processor is used:</p> <pre><code>df = pd.DataFrame({\"A\": np.arange(n)})\n@bodo.jit\ndef example1_csv(df):\ndf.to_csv(\"example1.csv\")\n@bodo.jit(distributed={\"df\"})\ndef example2_csv(df):\ndf.to_csv(\"example2.csv\")\nif bodo.get_rank() == 0:\nexample1_csv(df)\nexample2_csv(df)\n</code></pre> <p>Run the code above with 4 processors:</p> <pre><code>mpiexec -n 4 python example_csv.py\n</code></pre> <p>each <code>example1_csv(df)</code> and <code>example2_csv(df)</code> writes to a single file:</p> <pre><code>.\n\u251c\u2500\u2500 example1.csv\n\u251c\u2500\u2500 example2.csv\n</code></pre> </li> <li> <p>S3 and HDFS: distributed data is written to a folder called <code>name</code>.     Each process writes one file into the folder, but if the data is not distributed,     <code>to_csv(name)</code> writes to a single file called <code>name</code>:</p> <pre><code>df = pd.DataFrame({\"A\": np.arange(n)})\n@bodo.jit\ndef example1_csv(df):\ndf.to_csv(\"s3://bucket-name/example1.csv\")\n@bodo.jit(distributed={\"df\"})\ndef example2_csv(df):\ndf.to_csv(\"s3://bucket-name/example2.csv\")\nif bodo.get_rank() == 0:\nexample1_csv(df)\nexample2_csv(df)\n</code></pre> <p>Run the code above with 4 processors:</p> <pre><code>mpiexec -n 4 python example_csv.py\n</code></pre> <p><code>example1_csv(df)</code> writes 1 single file, and <code>example2_csv(df)</code> writes a folder containing 4 csv files:</p> <pre><code>.\n\u251c\u2500\u2500 example1.csv\n\u251c\u2500\u2500 example2.csv\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 part-00.csv\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 part-01.csv\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 part-02.csv\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 part-03.csv\n</code></pre> </li> </ol> <p>See <code>read_csv()</code>, <code>to_csv()</code> for supported arguments.</p>"},{"location":"file_io/#json-section","title":"JSON","text":"<p>For JSON, the syntax is also the same as pandas.</p> <p>Usage:</p> <pre><code>@bodo.jit\ndef example_write_json(df, fname):\ndf.to_json(fname)\n@bodo.jit\ndef example_read_json_lines_format():\ndf = pd.read_json(\"example.json\", orient = \"records\", lines = True)\n@bodo.jit\ndef example_read_json_multi_lines():\ndf = pd.read_json(\"example_file.json\", orient = \"records\", lines = False,\ndtype={\"A\": float, \"B\": \"bool\", \"C\": int})\n</code></pre> <p>Note</p> <ul> <li>The <code>dtype</code> argument is required when reading a regular multi-line JSON     file.</li> <li>Bodo cannot read a directory containing multiple multi-line JSON     files</li> <li>Bodo's default values for <code>orient</code> and <code>lines</code> are <code>records</code> and <code>False</code> respectively.</li> </ul> <p><code>to_json(name)</code> has different behaviors for different file systems:</p> <ol> <li> <p>POSIX file systems: <code>to_json(name)</code> behavior depends on <code>orient</code> and <code>lines</code> arguments.</p> <ol> <li> <p><code>DataFrame.to_json(name, orient=\"records\", lines=True)</code>     (i.e. writing JSON Lines text file format) always writes to a single file,     regardless of the number of processes and whether the data is distributed,     but writing is still done in parallel when more than 1 processor is used:</p> <pre><code>df = pd.DataFrame({\"A\": np.arange(n)})\n@bodo.jit\ndef example1_json(df):\ndf.to_json(\"example1.json\", orient=\"records\", lines=True)\n@bodo.jit(distributed={\"df\"})\ndef example2_json(df):\ndf.to_json(\"example2.json\", orient=\"records\", lines=True)\nif bodo.get_rank() == 0:\nexample1_json(df)\nexample2_jsons(df)\n</code></pre> <p>Run the code above with 4 processors:</p> <pre><code>mpiexec -n 4 python example_json.py\n</code></pre> <p>each <code>example1_json(df)</code> and <code>example2_json(df)</code> writes to a single file:</p> <pre><code>.\n\u251c\u2500\u2500 example1.json\n\u251c\u2500\u2500 example2.json\n</code></pre> </li> <li> <p>All other combinations of values for <code>orient</code> and <code>lines</code> have the same behavior as S3 and HDFS explained below.</p> </li> </ol> </li> <li> <p>S3 and HDFS : distributed data is written to a folder called <code>name</code>.     Each process writes one file into the folder, but if the data is not distributed,     <code>to_json(name)</code> writes to a file called <code>name</code>:</p> <pre><code>df = pd.DataFrame({\"A\": np.arange(n)})\n@bodo.jit\ndef example1_json(df):\ndf.to_json(\"s3://bucket-name/example1.json\")\n@bodo.jit(distributed={\"df\"})\ndef example2_json(df):\ndf.to_json(\"s3://bucket-name/example2.json\")\nif bodo.get_rank() == 0:\nexample1_json(df)\nexample2_json(df)\n</code></pre> <p>Run the code above with 4 processors:</p> <pre><code>mpiexec -n 4 python example_json.py\n</code></pre> <p><code>example1_json(df)</code> writes 1 single file, and <code>example2_json(df)</code> writes a folder containing 4 json files:</p> <pre><code>.\n\u251c\u2500\u2500 example1.json\n\u251c\u2500\u2500 example2.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 part-00.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 part-01.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 part-02.json\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 part-03.json\n</code></pre> <p>See <code>read_json()][pandas-f-in], [</code>to_json()` for supported arguments.</p> </li> </ol>"},{"location":"file_io/#sql-section","title":"SQL","text":"<p>See Databases for the list of supported Relational Database Management Systems (RDBMS) with Bodo.</p> <p>For SQL, the syntax is also the same as pandas. For reading:</p> <pre><code>@bodo.jit\ndef example_read_sql():\ndf = pd.read_sql(\"select * from employees\", \"mysql+pymysql://&lt;username&gt;:&lt;password&gt;@&lt;host&gt;/&lt;db_name&gt;\")\n</code></pre> <p>See <code>read_sql()</code> for supported arguments.</p> <p>For writing:</p> <pre><code>@bodo.jit\ndef example_write_sql(df):\ndf.to_sql(\"table_name\", \"mysql+pymysql://&lt;username&gt;:&lt;password&gt;@&lt;host&gt;/&lt;db_name&gt;\")\n</code></pre> <p>See <code>to_sql()</code> for supported arguments.</p> <p>Note</p> <p><code>sqlalchemy</code> must be installed in order to use <code>pandas.read_sql</code>.</p>"},{"location":"file_io/#filter-pushdown-and-column-pruning_1","title":"Filter Pushdown and Column Pruning","text":"<p>Filter Pushdown and Column Pruning</p> <p>Similar to Parquet read, Bodo JIT compiler is able to push down filters to the data source and prune unused columns automatically. For example, this program reads data from a very large Snowflake table, but only needs limited rows and columns:</p> <pre><code>@bodo.jit\ndef filter_ex(conn, int_val):\ndf = pd.read_sql(\"SELECT * FROM LINEITEM\", conn)\ndf = df[(df[\"l_orderkey\"] &gt; 10) &amp; (int_val &gt;= df[\"l_linenumber\"])]\nresult = df[\"l_suppkey\"]\nprint(result)\nfilter_ex(conn, 2)\n</code></pre> <p>Bodo optimizes the query passed to <code>read_sql</code> to push filters down and prune unused columns. In this case, Bodo will replace <code>SELECT * FROM LINEITEM</code> with the optimized version automatically:</p> <pre><code>SELECT \"L_SUPPKEY\" FROM (SELECT * FROM LINEITEM) as TEMP\nWHERE  ( ( l_orderkey &gt; 10 ) AND ( l_linenumber &lt;= 2 ) )\n</code></pre>"},{"location":"file_io/#deltalake-section","title":"Delta Lake","text":"<p>Reading parquet files from Delta Lake is supported locally, from S3, and from Azure ADLS.</p> <ul> <li>The Delta Lake binding python packaged needs to be installed using pip:<code>pip install deltalake</code>.</li> <li>For S3, the <code>AWS_DEFAULT_REGION</code> environment variable should be set to the region of the bucket hosting     the Delta Lake table.</li> <li>For ADLS, the <code>AZURE_STORAGE_ACCOUNT</code> and <code>AZURE_STORAGE_KEY</code> environment variables need to be set.</li> </ul> <p>Example code for reading:</p> <pre><code>@bodo.jit\ndef example_read_deltalake():\ndf = pd.read_parquet(\"path/to/deltalake\")\n</code></pre> <p>Note</p> <p>Writing is currently not supported.</p>"},{"location":"file_io/#iceberg-section","title":"Iceberg","text":"<p>Bodo's support for Iceberg Tables is under active development and currently only supports basic read and write functionality.</p> <p>Bodo supports reading Iceberg tables stored in a directory on HDFS, either locally or from S3, through Pandas' <code>read_sql_table</code> API.</p> <ul> <li>Bodo's Iceberg Connector python package needs to be installed using conda:      <code>conda install bodo-iceberg-connector -c bodo.ai -c conda-forge</code>.</li> <li>For tables on S3, the credentials should be set either using environment variables,     or AWS configuration in <code>~/.aws</code> or using an instance profile on the EC2 instance.</li> </ul> <p>Iceberg connection strings vary by catalog, but in general are of the form <code>iceberg&lt;+conn&gt;://&lt;path&gt;&lt;?params&gt;</code> where  - <code>&lt;conn&gt;://&lt;path&gt;</code> is the location of the catalog or Iceberg warehouse - <code>params</code> is a list of properties to pass to the catalog. Each parameter must be of the form <code>&lt;key&gt;=&lt;value&gt;</code> and separated with <code>&amp;</code>, similar to HTTP URLs.</p> <p>The following parameters are officially supported: - <code>type</code>: Type of catalog. The supported values are listed below. When the connection string is ambiguous, this parameter is used to determine the type of catalog implementation. - <code>warehouse</code>: Location of the warehouse. Required when creating a new table using Glue, Nessie, or Hive catalog.</p> <p>The following catalogs are supported:</p> <ul> <li> <p>Hadoop Catalog on Local Filesystem:</p> <ul> <li>Used when <code>type=hadoop</code> is specified or when <code>&lt;conn&gt;</code> is <code>file</code> or empty</li> <li><code>&lt;path&gt;</code> is the absolute path to the warehouse (directory containing the database schema)</li> <li>Parameter <code>warehouse</code> will be ignored if specified</li> <li>E.g. <code>iceberg://&lt;ABSOLUTE PATH TO ICEBERG WAREHOUSE&gt;</code> or <code>iceberg+file://&lt;ABSOLUTE PATH TO ICEBERG WAREHOUSE&gt;</code></li> </ul> </li> <li> <p>Hadoop Catalog on S3</p> <ul> <li>Used when <code>type=hadoop-s3</code> is specified or when <code>&lt;conn&gt;</code> is <code>s3</code></li> <li><code>&lt;conn&gt;://&lt;path&gt;</code> is the S3 path to the warehouse (directory or bucket containing the database schema)</li> <li>Parameter <code>warehouse</code> will be ignored if specified</li> <li>E.g. <code>iceberg+s3://&lt;S3 PATH TO ICEBERG WAREHOUSE&gt;</code></li> </ul> </li> <li> <p>Dremio Arctic or Nessie Catalog</p> <ul> <li>Must specify <code>type=nessie</code> as a parameter to use this warehouse.</li> <li><code>&lt;conn&gt;://&lt;path&gt;</code> is the URL to the Nessie catalog, which can be found on Dremio's dashboard.<ul> <li>It will look like the following: <code>https://nessie.dremio.cloud/v1/projects/&lt;PROJECT ID&gt;</code></li> <li><code>&lt;PROJECT ID&gt;</code> is the Nessie project UUID</li> </ul> </li> <li>The following parameters are required:<ul> <li><code>authentication.type=BEARER</code></li> <li><code>authentication.token=&lt;AUTH TOKEN&gt;</code> where <code>&lt;AUTH TOKEN&gt;</code> is your personal Dremio authentication token and can be found on the dashboard</li> </ul> </li> <li>Parameter <code>warehouse</code> is required to create a table</li> <li>E.g. <code>iceberg+https://nessie.dremio.cloud/v1/projects/&lt;PROJECT ID&gt;?type=nessie&amp;authentication.type=BEARER&amp;authentication.token=&lt;AUTH TOKEN&gt;</code></li> </ul> </li> <li> <p>AWS Glue Catalog</p> <ul> <li>Connection string must be of the form <code>iceberg+glue?&lt;params&gt;</code></li> <li>Parameter <code>type</code> will be ignored if specified</li> <li>Parameter <code>warehouse</code> is required to create a table</li> <li>E.g. <code>iceberg+glue</code> or <code>iceberg+glue?warehouse=s3://&lt;ICEBERG-BUCKET&gt;</code></li> </ul> </li> <li> <p>Hive / Thrift Catalog</p> <ul> <li>Used when <code>type=hive</code> is specified or when <code>&lt;conn&gt;</code> is <code>thrift</code></li> <li><code>&lt;conn&gt;://&lt;path&gt;</code> is the URL to the Thrift catalog, i.e. <code>thrift://localhost:9083</code></li> <li>Parameter <code>warehouse</code> is required to create the table</li> <li>E.g. <code>iceberg+thrift://&lt;THRIFT URL&gt;</code></li> </ul> </li> </ul> <p>Example code for reading:</p> <pre><code>@bodo.jit\ndef example_read_iceberg():\ndf = pd.read_sql_table(\ntable_name=\"&lt;NAME OF ICEBERG TABLE\", \ncon=\"&lt;SEE PREVIOUS SECTION ON HOW TO FORMAT THIS FOR DIFFERENT CATALOGS&gt;\",\nschema=\"&lt;NAME OF ICEBERG DATABASE SCHEMA&gt;\"\n)\n</code></pre> <p>Note</p> <ul> <li> <p><code>schema</code> argument is required for reading Iceberg tables.</p> </li> <li> <p>The Iceberg table to read should be located at <code>&lt;warehouse-location&gt;/&lt;schema&gt;/&lt;table_name&gt;</code>,   where <code>schema</code> and <code>table_name</code> are the arguments to <code>pd.read_sql_table</code>, and <code>warehouse-location</code>   is inferred from the connection string based on the description provided above.</p> </li> </ul> <p>Warning</p> <ul> <li>Tables with delete files   or those that have gone through    schema evolution   are not supported yet.</li> </ul> <p>Bodo has basic support for writing Iceberg tables from Pandas Dataframes using the <code>to_sql</code> API, including support for appending to tables with an existing partition spec  and/or sort order.</p> <p>Example code for writing:</p> <pre><code>@bodo.jit(distributed=[\"df\"])\ndef write_iceberg_table(df: pandas.DataFrame):\ndf.to_sql(\nname=\"&lt;NAME OF ICEBERG TABLE\",\ncon=\"&lt;SEE PREVIOUS SECTION ON HOW TO FORMAT THIS FOR DIFFERENT CATALOGS&gt;\",\nschema=\"&lt;NAME OF ICEBERG DATABASE SCHEMA&gt;\",\nif_exists=\"replace\"\n)\n</code></pre> <p>Note</p> <ul> <li><code>schema</code> argument is required for reading Iceberg tables.</li> <li>Writing Pandas Dataframe index to an Iceberg table is not supported. If <code>index</code> and <code>index_label</code>   are provided, they will be ignored.</li> <li><code>chunksize</code>, <code>dtype</code> and <code>method</code> arguments are not supported and will be ignored if provided.</li> <li>While Bodo can append to tables with an existing partition spec and/or sort order, it does not    support creating new tables with a Partition Spec or Sort Order.</li> </ul>"},{"location":"file_io/#numpy-binary-section","title":"Numpy binaries","text":"<p>Numpy's <code>fromfile</code> and <code>tofile</code> are supported as below:</p> <pre><code>@bodo.jit\ndef example_np_io():\nA = np.fromfile(\"myfile.dat\", np.float64)\n...\nA.tofile(\"newfile.dat\")\n</code></pre> <p>Bodo has the same behavior as Numpy for <code>numpy.ndarray.tofile()</code>, where we always write to a single file. However, writing distributed data to POSIX is done in parallel, but writing to S3 &amp; HDFS is done sequentially (due to file system limitations).</p>"},{"location":"file_io/#hdf5","title":"HDF5","text":"<p>HDF5 is a common format in scientific computing, especially for multi-dimensional numerical data. HDF5 can be very efficient at scale, since it has native parallel I/O support. For HDF5, the syntax is the same as the h5py package. For example:</p> <pre><code>@bodo.jit\ndef example_h5():\nf = h5py.File(\"data.hdf5\", \"r\")\nX = f[\"points\"][:]\nY = f[\"responses\"][:]\n</code></pre>"},{"location":"file_io/#File","title":"File Systems","text":""},{"location":"file_io/#S3","title":"Amazon S3","text":"<p>Reading and writing CSV, Parquet, JSON, and Numpy binary files from and to Amazon S3 is supported.</p> <p>The <code>fsspec</code> package must be available, and the file path should start with <code>s3://</code>:</p> <pre><code>@bodo.jit\ndef example_s3_parquet():\ndf = pd.read_parquet(\"s3://bucket-name/file_name.parquet\")\n</code></pre> <p>These environment variables are used for File I/O with S3 credentials:</p> <ul> <li><code>AWS_ACCESS_KEY_ID</code></li> <li><code>AWS_SECRET_ACCESS_KEY</code></li> <li><code>AWS_DEFAULT_REGION</code>: default as <code>us-east-1</code></li> <li><code>AWS_S3_ENDPOINT</code>: specify custom host name, default as AWS endpoint(<code>s3.amazonaws.com</code>)</li> </ul> <p>Connecting to S3 endpoints through a proxy is supported. The proxy URI can be provided by setting one of the following environment variables (listed in order of precedence):</p> <ul> <li><code>http_proxy</code></li> <li><code>https_proxy</code></li> <li><code>HTTP_PROXY</code></li> <li><code>HTTPS_PROXY</code></li> </ul> <p>Bodo uses Apache Arrow internally for read and write of data on S3.</p>"},{"location":"file_io/#GCS","title":"Google Cloud Storage","text":"<p>Reading and writing Parquet files from and to Google Cloud is supported.</p> <p>The file path should start with <code>gs://</code> or <code>gcs://</code>:</p> <p><pre><code>@bodo.jit\ndef example_gcs_parquet():\ndf = pd.read_parquet(\"gcs://bucket-name/file_name.parquet\")\n</code></pre> These environment variables are used for File I/O with GCS credentials:</p> <ul> <li><code>GOOGLE_APPLICATION_CREDENTIALS</code></li> </ul> <p>Details for <code>GOOGLE_APPLICATION_CREDENTIALS</code> can be seen in the Google docs here.</p> <p>Bodo uses the fsspec-based gcsfs library internally for read and write of data on GCS.</p>"},{"location":"file_io/#HDFS","title":"Hadoop Distributed File System (HDFS) and Azure Data Lake Storage (ADLS) Gen2","text":"<p>Reading and writing CSV, Parquet, JSON, and Numpy binary files from and to Hadoop Distributed File System (HDFS) is supported. Note that Azure Data Lake Storage Gen2 can be accessed through HDFS.</p> <p>The <code>openjdk</code> version 11 package must be available, and the file path should start with <code>hdfs://</code> or <code>abfs[s]://</code>:</p> <pre><code>@bodo.jit\ndef example_hdfs_parquet():\ndf = pd.read_parquet(\"hdfs://host:port/dir/file_name.pq\")\n</code></pre> <p>These environment variables are used for File I/O with HDFS:</p> <ul> <li><code>HADOOP_HOME</code>: the root of your installed Hadoop distribution. Often is <code>lib/native/libhdfs.so</code>.</li> <li><code>ARROW_LIBHDFS_DIR</code>: location of libhdfs. Often is <code>$HADOOP_HOME/lib/native</code>.</li> <li><code>CLASSPATH</code>: must contain the Hadoop jars. You can set these using:     <pre><code>export CLASSPATH=`$HADOOP_HOME/bin/hdfs classpath --glob`\n</code></pre></li> </ul> <p>Bodo uses Apache Arrow internally for read and write of data on HDFS. <code>$HADOOP_HOME/etc/hadoop/hdfs-site.xml</code> provides default behaviors for the HDFS client used by Bodo. Inconsistent configurations (e.g. <code>dfs.replication</code>) could potentially cause errors in Bodo programs.</p>"},{"location":"file_io/#setting-up-hdfsadls-credentials","title":"Setting up HDFS/ADLS Credentials","text":"<p>Setting up HDFS/ADLS Credentials</p> <p>Hadoop Filesystem sources its credentials from the first available <code>core-site.xml</code> file on the <code>CLASSPATH</code>. When Hadoop is set up (including on Bodo Platform), this file is usually created at  <code>$HADOOP_HOME/etc/hadoop/core-site.xml</code> automatically. You can edit this file and set credentials appropriately.</p> <p>You can also write the core-site configuration to <code>bodo.HDFS_CORE_SITE_LOC</code>, which is a temporary file Bodo adds to the <code>CLASSPATH</code> when it is initialized:</p> <pre><code>import bodo\n# Initialize the temporary directory where the core-site file\n# will be written\nbodo.HDFS_CORE_SITE_LOC_DIR.initialize()\n# Define the core-site for your regular ADLS/HDFS read/write\n# operations\nCORE_SITE_SPEC = \"\"\"\n&lt;configuration&gt;\n...\n&lt;/configuration&gt;\n\"\"\"\n# Write it to the temporary core-site file.\n# Do it on one rank on every node to avoid filesystem conflicts.\nif bodo.get_rank() in bodo.get_nodes_first_ranks():\nwith open(bodo.HDFS_CORE_SITE_LOC, 'w') as f:\nf.write(CORE_SITE_SPEC)\n@bodo.jit\ndef etl_job():\ndf = pd.read_parquet(\"abfs://{CONTAINER_NAME}@{STORAGE_ACCOUNT_NAME}.dfs.core.windows.net/file.pq\")\n# ..\n# .. Some ETL Processing\n# ..\ndf.to_parquet(\"abfs://{CONTAINER_NAME}@{STORAGE_ACCOUNT_NAME}.dfs.core.windows.net/out_file.pq\")\nreturn\netl_job()\n</code></pre> <p>There are several authorization methods for reading from or writing to ADLS Storage Containers, all of which require slightly different core-site configurations. Here are some examples:</p> <ul> <li> <p>Using an ADLS Access Key</p> <pre><code>import bodo\nimport pandas as pd\n# Initialize the temporary directory where the core-site file\n# will be written\nbodo.HDFS_CORE_SITE_LOC_DIR.initialize()\n# Define the core-site for your regular ADLS/HDFS read/write\n# operations\nCORE_SITE_SPEC = \"\"\"&lt;configuration&gt;\n&lt;property&gt;\n    &lt;name&gt;fs.abfs.impl&lt;/name&gt;\n    &lt;value&gt;org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem&lt;/value&gt;\n&lt;/property&gt;\n&lt;property&gt;\n    &lt;name&gt;fs.azure.account.auth.type.{STORAGE_ACCOUNT_NAME}.dfs.core.windows.net&lt;/name&gt;\n    &lt;value&gt;SharedKey&lt;/value&gt;\n&lt;/property&gt;\n&lt;property&gt;\n    &lt;name&gt;fs.azure.account.key.{STORAGE_ACCOUNT_NAME}.dfs.core.windows.net&lt;/name&gt;\n    &lt;value&gt;{ADLS_SECRET}&lt;/value&gt;\n    &lt;description&gt; The ADLS storage account access key itself.&lt;/description&gt;\n&lt;/property&gt;\n&lt;/configuration&gt;\n\"\"\"\n# Write it to the temporary core-site file.\n# Do it on one rank on every node to avoid filesystem conflicts.\nif bodo.get_rank() in bodo.get_nodes_first_ranks():\nwith open(bodo.HDFS_CORE_SITE_LOC, 'w') as f:\nf.write(CORE_SITE_SPEC)\n# Run your ETL job\n@bodo.jit\ndef etl_job():\ndf = pd.read_parquet(\"abfs://{CONTAINER_NAME}@{STORAGE_ACCOUNT_NAME}.dfs.core.windows.net/file.pq\")\n# ..\n# .. Some ETL Processing\n# ..\ndf.to_parquet(\"abfs://{CONTAINER_NAME}@{STORAGE_ACCOUNT_NAME}.dfs.core.windows.net/out_file.pq\")\nreturn\netl_job()\n</code></pre> </li> <li> <p>Using a SAS Token</p> <p>To use SAS Tokens, you need to install the <code>bodo-azurefs-sas-token-provider</code> package (it can be installed using  <code>conda install bodo-azurefs-sas-token-provider -c bodo.ai -c conda-forge</code>). This is already installed on the Bodo Platform. Then in your program, do the following:</p> <pre><code>import bodo\n# Importing this module adds the required JARs to the CLASSPATH\nimport bodo_azurefs_sas_token_provider\nimport pandas as pd\nimport os\n# Initialize the temporary directory where the core-site file\n# will be written\nbodo.HDFS_CORE_SITE_LOC_DIR.initialize()\n# Define the core-site for your regular ADLS/HDFS read/write\n# operations\nCORE_SITE_SPEC = \"\"\"&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;fs.azure.account.auth.type.{STORAGE_ACCOUNT_NAME}.dfs.core.windows.net&lt;/name&gt;\n        &lt;value&gt;SAS&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;fs.azure.sas.token.provider.type.{STORAGE_ACCOUNT_NAME}.dfs.core.windows.net&lt;/name&gt;\n        &lt;value&gt;org.bodo.azurefs.sas.BodoSASTokenProvider&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;fs.abfs.impl&lt;/name&gt;\n        &lt;value&gt;org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;\n\"\"\"\n# Write it to the temporary core-site file.\n# Do it on one rank on every node to avoid filesystem conflicts.\nif bodo.get_rank() in bodo.get_nodes_first_ranks():\nwith open(bodo.HDFS_CORE_SITE_LOC, 'w') as f:\nf.write(CORE_SITE_SPEC)\n# Load the SAS token here.\nSAS_TOKEN = \"...\"\n# Write SAS Token to a file.\n# Do it on one rank on every node to avoid filesystem conflicts.\nif bodo.get_rank() in bodo.get_nodes_first_ranks():\nwith open(os.path.join(bodo.HDFS_CORE_SITE_LOC_DIR.name, \"sas_token.txt\"), 'w') as f:\nf.write(SAS_TOKEN)\n# Run your ETL job\n@bodo.jit\ndef etl_job():\ndf = pd.read_parquet(\"abfs://{CONTAINER_NAME}@{STORAGE_ACCOUNT_NAME}.dfs.core.windows.net/file.pq\")\n# ..\n# .. Some ETL Processing\n# ..\ndf.to_parquet(\"abfs://{CONTAINER_NAME}@{STORAGE_ACCOUNT_NAME}.dfs.core.windows.net/out_file.pq\")\nreturn\netl_job()\n</code></pre> </li> </ul>"},{"location":"file_io/#interleave-adls-snowflake-write","title":"Interleaving HDFS/ADLS I/O with Snowflake Write","text":"<p>Interleaving HDFS/ADLS I/O with Snowflake Write</p> <p>For writing to an Azure based Snowflake account using the direct upload strategy (see Snowflake Write), Bodo writes the required core-site configuration to <code>bodo.HDFS_CORE_SITE_LOC</code> automatically. In cases where Snowflake write (to an Azure based Snowflake account) needs to be done in the same process as a regular HDFS/ADLS read/write operation, users need to write credentials for the regular HDFS/ADLS read/write operations to the same core-site location (<code>bodo.HDFS_CORE_SITE_LOC</code>) due to limitations of Arrow and HDFS. Bodo will modify the file (temporarily) during the Snowflake write operation(s) and then restore the original configuration for the regular HDFS/ADLS read/write operations.</p> <p>Here is an example of how to do so:</p> <pre><code>import bodo\nimport pandas as pd\n# Initialize the temporary directory where the core-site file\n# will be written\nbodo.HDFS_CORE_SITE_LOC_DIR.initialize()\n# Define the core-site for your regular ADLS/HDFS read/write\n# operations\nCORE_SITE_SPEC = \"\"\"&lt;configuration&gt;\n...\n&lt;/configuration&gt;\n\"\"\"\n# Write it to the temporary core-site file\n# Do it on one rank on every node to avoid filesystem conflicts.\nif bodo.get_rank() in bodo.get_nodes_first_ranks():\nwith open(bodo.HDFS_CORE_SITE_LOC, 'w') as f:\nf.write(CORE_SITE_SPEC)\n# Write the SAS token if required.\n# import bodo_azurefs_sas_token_provider\n# SAS_TOKEN = \"...\"\n# if bodo.get_rank() in bodo.get_nodes_first_ranks():\n#     with open(os.path.join(bodo.HDFS_CORE_SITE_LOC_DIR.name, \"sas_token.txt\"), 'w') as f:\n#         f.write(SAS_TOKEN)\n@bodo.jit\ndef etl_job():\ndf = pd.read_parquet(\"abfs://{CONTAINER_NAME}@{STORAGE_ACCOUNT_NAME}.dfs.core.windows.net/file.pq\")\n# ..\n# .. Some ETL Processing\n# ..\n# Here Bodo will replace the core-site configuration to enable Snowflake write\ndf.to_sql(\"new_table\", \"snowflake://user:password@url/{db_name}/schema?warehouse=warehouse_name&amp;role=role_name\")\n# Once done, Bodo will restore the contents of the original file so that your\n# ADLS operations happen as expected.\n# ..\n# .. Some more ETL Processing\n# ..\ndf.to_parquet(\"abfs://{CONTAINER_NAME}@{STORAGE_ACCOUNT_NAME}.dfs.core.windows.net/out_file.pq\")\nreturn\netl_job()\n</code></pre>"},{"location":"file_io/#db","title":"Databases","text":"<p>Currently, Bodo supports most RDBMS that work with SQLAlchemy, with a corresponding driver.</p>"},{"location":"file_io/#snowflake-section","title":"Snowflake","text":""},{"location":"file_io/#prerequisites","title":"Prerequisites","text":"<p>In order to be able to query Snowflake or write a dataframe to Snowflake from Bodo, installing the Snowflake connector is necessary (it is installed by default on Bodo Platform). If you are using Bodo in a conda environment:</p> <pre><code>conda install -c conda-forge snowflake-connector-python\n</code></pre> <p>If you have installed Bodo using pip, then you can install the Snowflake connector using pip as well:</p> <pre><code>pip install snowflake-connector-python\n</code></pre>"},{"location":"file_io/#reading-from-snowflake","title":"Reading from Snowflake","text":"<p>To read a dataframe from a Snowflake database, users can use <code>pd.read_sql</code> with their Snowflake username and password: <code>pd.read_sql(query, \"snowflake://&lt;username&gt;:&lt;password&gt;@url\")</code>.</p>"},{"location":"file_io/#usage","title":"Usage","text":"<p>Bodo requires the Snowflake connection string to be passed as an argument to the <code>pd.read_sql</code> function. The complete code looks as follows:</p> <p><pre><code>import bodo\nimport pandas as pd\n@bodo.jit\ndef read_snowflake(db_name, table_name):\ndf = pd.read_sql(\nf\"SELECT * FROM {table_name}\",\nf\"snowflake://user:password@url/{db_name}/schema?warehouse=warehouse_name\",\n)\nreturn df\ndf = read_snowflake(db_name, temp_table_name)\n</code></pre> - <code>_bodo_read_as_dict</code> is a Bodo specific argument which forces      the specified string columns to be read with dictionary-encoding. Bodo automatically loads string columns using dictionary encoding when it determines it would be beneficial based on a heuristic. Dictionary-encoding stores data in memory in an efficient manner and is most effective when the column has many repeated values. Read more about dictionary-encoded layout here.     Bodo will raise a warning if the specified columns are not present in the schema or if they are not of type string.</p> <pre><code>For example:\n```py\n@bodo.jit()\ndef impl(query, conn):\n    df = pd.read_sql(query, conn, _bodo_read_as_dict=[\"A\", \"B\", \"C\"])\n    return df\n```\n</code></pre>"},{"location":"file_io/#snowflake-write","title":"Writing to Snowflake","text":"<p>To write a dataframe to Snowflake using Bodo, users can use <code>df.to_sql</code> with their Snowflake username and password: <code>df.to_sql(table_name, \"snowflake://&lt;username&gt;:&lt;password&gt;@url\")</code>.</p>"},{"location":"file_io/#snowflake-write-usage","title":"Usage","text":"<p>Bodo requires the Snowflake connection string to be passed as an argument to the <code>df.to_sql</code> function. The complete code looks as follows:</p> <pre><code>import bodo\nimport pandas as pd\n@bodo.jit(distributed=[\"df\"])\ndef write_to_snowflake(df, table_name):\ndf.to_sql(\ntable_name,\n\"snowflake://user:password@url/db_name/schema?warehouse=warehouse_name&amp;role=role_name\",\n)\nwrite_to_snowflake(df, table_name)\n</code></pre> <p>Note</p> <ul> <li>Writing Pandas Dataframe index to Snowflake is not supported. If <code>index</code> and/or <code>index_label</code>   are provided, they will be ignored.</li> <li><code>if_exists=append</code> is needed if you want to append to a table that already exists in Snowflake.</li> <li><code>chunksize</code> argument is supported and used for writing parquet files to Snowflake stage   in batches. It is the maximum number of rows to write to any of the intermediate parquet files.   When not provided, Bodo will estimate and use a reasonable chunk size.</li> <li><code>dtype</code> and <code>method</code> arguments are not supported and will be ignored if provided.</li> </ul>"},{"location":"file_io/#required-snowflake-permissions","title":"Required Snowflake Permissions","text":""},{"location":"file_io/#snowflake-write-perms-create","title":"Creating a new table","text":"<p>Creating a new table</p> <p>To create a new table, the role being used must have the <code>USAGE</code> permission at the database level. In addition, the following permissions are required at the Schema level:</p> <ul> <li><code>USAGE</code></li> <li><code>CREATE TABLE</code></li> <li><code>CREATE STAGE</code></li> </ul>"},{"location":"file_io/#replacing-an-existing-table","title":"Replacing an existing table","text":"<p>Replacing an existing table</p> <p>To replace an existing table (i.e. when using <code>if_exists='replace'</code>), the role must be an owner of the table, in addition to having the permissions listed in the create section (at the Database and Schema level).</p>"},{"location":"file_io/#appending-to-an-existing-table","title":"Appending to an existing table","text":"<p>Appending to an existing table</p> <p>To append to an existing table (i.e. when using <code>if_exists='append'</code>), the role must have the <code>INSERT</code> permission at the table level, in addition to the  permissions listed in the create section (at the Database and Schema level).</p>"},{"location":"file_io/#verifying-your-roles-permissions-in-snowflake","title":"Verifying your role's permissions in Snowflake","text":"<p>Verifying your role's permissions in Snowflake</p> <p>You can check the permissions granted to your role in Snowflake using the <code>SHOW GRANTS</code> command, e.g.:</p> <pre><code>show grants to role test_role\n</code></pre> <p>Alternatively, you can check the permissions at the database/schema/table level and verify that your role has the required permissions, e.g.:</p> <pre><code>-- Check that your role has the USAGE permission on the database\nshow grants on database test_db\n-- Check that your role has the required permissions on the schema\nshow grants on schema test_schema\n-- Check that your role has the required permissions on the table\nshow grants on table test_schema.\"TEST_TABLE\"\n</code></pre> <p>You can also use the Snowsight UI to check these permissions by navigating to the <code>Privileges</code> section of the <code>Details</code> tab of the database/schema/table.</p>"},{"location":"file_io/#advanced-configuration-options","title":"Advanced Configuration Options","text":"<p>Bodo provides highly performant distributed Snowflake write capability. This is done by writing parquet files to a Snowflake stage and then using Snowflake's <code>COPY INTO</code> to load the data into the Snowflake table. Based on the type of your Snowflake account (i.e. whether it is an AWS or Azure or GCP based account) and your environment (i.e. whether certain packages and modules are installed), Bodo will use one of two strategies to write to Snowflake: Direct Upload (preferred) or Put Upload.</p> <ol> <li> <p>Direct Upload: In this strategy, Bodo creates a temporary stage     and writes parquet files to it directly. Once these files are     written, Bodo will automatically execute the <code>COPY INTO</code> command     to copy the data into Snowflake. This is supported on     S3 and ADLS based Snowflake stages (used by AWS and Azure based     Snowflake accounts, respectively). Note that Bodo will drop the     temporary stage once the data has been written. Temporary stages     are also automatically cleaned up by Snowflake after the session ends.</p> <p>Note</p> <p>For writing to ADLS based stages, you must have Hadoop setup correctly (see more details here) and have the <code>bodo-azurefs-sas-token-provider</code> package installed (it can be installed using  <code>conda install bodo-azurefs-sas-token-provider -c bodo.ai -c conda-forge</code>). Bodo will fall back to the Put Upload strategy if both these conditions are not met. Also see Interleaving HDFS/ADLS I/O with Snowflake Write.</p> <p>Note that this is only applicable to on-prem use cases since all of this is pre-configured on the Bodo Platform.</p> </li> <li> <p>Put Upload: In this strategy, Bodo creates a 'named' stage, writes     parquet files to a temporary directory locally and then uses the     Snowflake Python Connector to upload these files to this named stage     using the <code>PUT</code> command. Similar to the Direct Upload strategy,     once the files have been transferred, Bodo will automatically     execute the <code>COPY INTO</code> command to copy the data into Snowflake.     This is used for GCS based stages (used by GCP based Snowflake     accounts), or when the user environment doesn't have all the     required packages and modules to use the Direct Upload strategy.</p> <p>Similar to the Direct Upload strategy, Bodo will drop the named stage after the data has been written to the table.</p> <p>Note</p> <p>In some cases, e.g. during abnormal exits, Bodo may not be able to drop these stages, which may require manual cleanup by the user. All stages created by Bodo are of the form \"bodo_io_snowflake_{random-uuid}\". You can list all stages created by Bodo in Snowflake by executing the <code>SHOW STAGES</code> command:</p> <pre><code>show stages like 'bodo_io_snowflake_%';\n</code></pre> <p>and then delete them using the <code>DROP STAGE</code> command, e.g.:</p> <pre><code>drop stage \"bodo_io_snowflake_02ca9beb-eaf6-4957-a6ff-ff426441cd7a\";\n</code></pre> <p>These operations are not supported in Bodo and must be executed directly through the Snowflake console.</p> </li> </ol> <p>Direct Upload is the preferred strategy and used by default whenever possible. When this is not possible, Bodo will show a warning to the user. For optimal Snowflake ingestion performance, Bodo writes multiple small intermediate parquet files on each rank, instead of a single file like it does for regular parquet writes.</p> <p>Users can set the environment variable <code>BODO_SF_WRITE_DEBUG</code> (to any value), to get more details during the Snowflake write process. This includes printing the raw result of the <code>COPY INTO</code> command execution, and printing more detailed error messages in case of exceptions.</p> <p>Bodo exposes the following configuration variables for tuning the write process further (for advanced users only):</p> <ul> <li><code>SF_WRITE_UPLOAD_USING_PUT</code>: This configuration variable can be set to <code>True</code>   to force Bodo to use the Put Upload strategy. This is <code>False</code> by default   since Direct Upload is the preferred strategy.</li> <li><code>SF_WRITE_PARQUET_COMPRESSION</code>: This configuration variable can set to   specify the compression method used for writing the intermediate   Parquet files. Supported values include: <code>\"snappy\"</code>, <code>\"gzip\"</code>   and <code>\"zstd\"</code>. Bodo uses <code>\"snappy\"</code> by default since it provided   the best overall performance in our benchmarks, however this can vary   based on your data.</li> <li><code>SF_WRITE_PARQUET_CHUNK_SIZE</code>: This configuration variable can be   used to specify the chunk size to use when writing the dataframe to   the intermediate Parquet files. This is measured by the uncompressed   memory usage of the dataframe (in bytes). Note that when provided,   <code>df.to_sql</code>'s <code>chunksize</code> parameter (see description in note in   the Usage section) overrides this value.</li> <li><code>SF_WRITE_OVERLAP_UPLOAD</code>: For maximum performance, the Put Upload   strategy writes intermediate parquet files to local disk and uploads   them to the stage in parallel. To alter this behavior, i.e.   write the parquet files and upload them sequentially, this configuration   variable can be set to <code>False</code>. Note that this is only applicable   when using the Put Upload strategy.</li> </ul> <p>These can be set as follows: <pre><code>import bodo\nimport bodo.io.snowflake\nbodo.io.snowflake.SF_WRITE_UPLOAD_USING_PUT = False\nbodo.io.snowflake.SF_WRITE_PARQUET_COMPRESSION = \"gzip\"\n...\n</code></pre></p>"},{"location":"file_io/#mysql","title":"MySQL","text":""},{"location":"file_io/#prerequisites_1","title":"Prerequisites","text":"<p>In addition to <code>sqlalchemy</code>, installing <code>pymysql</code> is required. If you are using Bodo in a conda environment:</p> <pre><code>conda install pymysql -c conda-forge\n</code></pre> <p>If you have installed Bodo using pip:</p> <pre><code>pip install PyMySQL\n</code></pre>"},{"location":"file_io/#usage_1","title":"Usage","text":"<p>Reading result of a SQL query in a dataframe:</p> <pre><code>import bodo\nimport pandas as pd\n@bodo.jit(distributed=[\"df\"])\ndef read_mysql(table_name, conn):\ndf = pd.read_sql(\nf\"SELECT * FROM {table_name}\",\nconn\n)\nreturn df\ntable_name = \"test_table\"\nconn = f\"mysql+pymysql://{username}:{password}@{host}/{db_name}\"\ndf = read_mysql(table_name, conn)\n</code></pre> <p>Writing dataframe as a table in the database:</p> <pre><code>import bodo\nimport pandas as pd\n@bodo.jit(distributed=[\"df\"])\ndef write_mysql(df, table_name, conn):\ndf.to_sql(table, conn)\ntable_name = \"test_table\"\ndf = pd.DataFrame({\"A\": [1.12, 1.1] * 5, \"B\": [213, -7] * 5})\nconn = f\"mysql+pymysql://{username}:{password}@{host}/{db_name}\"\nwrite_mysql(df, table_name, conn)\n</code></pre>"},{"location":"file_io/#oracle-database","title":"Oracle Database","text":""},{"location":"file_io/#prerequisites_2","title":"Prerequisites","text":"<p>In addition to <code>sqlalchemy</code>, install <code>cx_oracle</code> and Oracle instant client driver. If you are using Bodo in a conda environment:</p> <pre><code>conda install cx_oracle -c conda-forge\n</code></pre> <p>If you have installed Bodo using pip:</p> <pre><code>pip install cx-Oracle\n</code></pre> <ul> <li>Then, Download \"Basic\" or \"Basic light\" package matching your operating system from here.</li> <li>Unzip package and add it to <code>LD_LIBRARY_PATH</code> environment variable.</li> </ul> <p>Note</p> <p>For linux <code>libaio</code> package is required as well.</p> <ul> <li>conda: <code>conda install libaio -c conda-forge</code></li> <li>pip: <code>pip install libaio</code></li> </ul> <p>See cx_oracle for more information. Alternatively, Oracle instant driver can be automatically downloaded using <code>wget</code> or <code>curl</code> commands. Here's an example of automatic installation on a Linux OS machine.</p> <pre><code>conda install cx_oracle libaio -c conda-forge\nmkdir -p /opt/oracle\ncd /opt/oracle\nwget https://download.oracle.com/otn_software/linux/instantclient/215000/instantclient-basic-linux.x64-21.5.0.0.0dbru.zip\nunzip instantclient-basic-linux.x64-21.5.0.0.0dbru.zip\nexport LD_LIBRARY_PATH=/opt/oracle/instantclient_21_5:$LD_LIBRARY_PATH\n</code></pre>"},{"location":"file_io/#usage_2","title":"Usage","text":"<p>Reading result of a SQL query in a dataframe:</p> <pre><code>import bodo\nimport pandas as pd\n@bodo.jit(distributed=[\"df\"])\ndef read_oracle(table_name, conn):\ndf = pd.read_sql(\nf\"SELECT * FROM {table_name}\",\nconn\n)\nreturn df\ntable_name = \"test_table\"\nconn = f\"oracle+cx_oracle://{username}:{password}@{host}/{db_name}\"\ndf = read_oracle(table_name, conn)\n</code></pre> <p>Writing dataframe as a table in the database:</p> <pre><code>import bodo\nimport pandas as pd\n@bodo.jit(distributed=[\"df\"])\ndef write_mysql(df, table_name, conn):\ndf.to_sql(table, conn)\ntable_name = \"test_table\"\ndf = pd.DataFrame({\"A\": [1.12, 1.1] * 5, \"B\": [213, -7] * 5})\nconn = f\"oracle+cx_oracle://{username}:{password}@{host}/{db_name}\"\nwrite_mysql(df, table_name, conn)\n</code></pre>"},{"location":"file_io/#postgresql","title":"PostgreSQL","text":""},{"location":"file_io/#prerequisites_3","title":"Prerequisites","text":"<p>In addition to <code>sqlalchemy</code>, install <code>psycopg2</code>.</p> <p>If you are using Bodo in a conda environment:</p> <pre><code>conda install psycopg2 -c conda-forge\n</code></pre> <p>If you have installed Bodo using pip:</p> <pre><code>$ pip install psycopg2\n</code></pre>"},{"location":"file_io/#usage_3","title":"Usage","text":"<p>Reading result of a SQL query in a dataframe:</p> <pre><code>import bodo\nimport pandas as pd\n@bodo.jit(distributed=[\"df\"])\ndef read_postgresql(table_name, conn):\ndf = pd.read_sql(\nf\"SELECT * FROM {table_name}\",\nconn\n)\nreturn df\ntable_name = \"test_table\"\nconn = f\"postgresql+psycopg2://{username}:{password}@{host}/{db_name}\"\ndf = read_postgresql(table_name, conn)\n</code></pre> <p>Writing dataframe as a table in the database:</p> <pre><code>import bodo\nimport pandas as pd\n@bodo.jit(distributed=[\"df\"])\ndef write_postgresql(df, table_name, conn):\ndf.to_sql(table, conn)\ntable_name = \"test_table\"\ndf = pd.DataFrame({\"A\": [1.12, 1.1] * 5, \"B\": [213, -7] * 5})\nconn = f\"postgresql+psycopg2://{username}:{password}@{host}/{db_name}\"\nwrite_postgresql(df, table_name, conn)\n</code></pre>"},{"location":"file_io/#non-constant-filepaths","title":"Specifying I/O Data Types Manually","text":"<p>In some rase use cases, the dataset path cannot be a constant value or a JIT function argument. In such cases, the path is determined dynamically, which does not allow automatic Bodo data type inference. Therefore, the user has to provide the data types manually. For example, <code>names</code> and <code>dtypes</code> keyword arguments of <code>pd.read_csv</code> and <code>pd.read_excel</code> allow the user to specify the data types:</p> <pre><code>@bodo.jit\ndef example_csv(fname1, fname2, flag):\nif flag:\nfile_name = fname1\nelse:\nfile_name = fname2\nreturn pd.read_csv(file_name, names = [\"A\", \"B\", \"C\"], dtype={\"A\": int, \"B\": float, \"C\": str})\n</code></pre> <p>For other pandas read functions, the existing APIs do not currently allow this information to be provided. Users can still provide typing information in the <code>bodo.jit</code> decorator, similar to Numba's typing syntax. For example:</p> <pre><code>@bodo.jit(locals={\"df\":{\"one\": bodo.float64[:],\n\"two\": bodo.string_array_type,\n\"three\": bodo.bool_[:],\n\"four\": bodo.float64[:],\n\"five\": bodo.string_array_type,\n}})\ndef example_df_schema(fname1, fname2, flag):\nif flag:\nfile_name = fname1\nelse:\nfile_name = fname2\ndf = pd.read_parquet(file_name)\nreturn df\n@bodo.jit(locals={\"X\": bodo.float64[:,:], \"Y\": bodo.float64[:]})\ndef example_h5(fname1, fname2, flag):\nif flag:\nfile_name = fname1\nelse:\nfile_name = fname2\nf = h5py.File(file_name, \"r\")\nX = f[\"points\"][:]\nY = f[\"responses\"][:]\n</code></pre> <p>For the complete list of supported types, please see the pandas dtype section. In the event that the dtypes are improperly specified, Bodo will throw a runtime error.</p> <p>Warning</p> <p>Providing data types manually is error-prone and should be avoided as much as possible.</p>"},{"location":"objmode/","title":"Using Regular Python inside JIT (Object Mode)","text":"<p>Regular Python functions and Bodo JIT functions can be used together in applications arbitrarily, but there are cases where regular Python code needs to be used inside JIT code. For example, you may want to use Bodo's parallel constructs with some code that does not have JIT support yet. Object Mode allows switching to a Python interpreted context to be able to run non-jittable code. The main requirement is that the user has to specify the type of variables used in later JIT code.</p> <p>For example, the following code calls a non-JIT function on rows of a distributed dataframe. The code inside <code>with bodo.objmode</code> runs as regular Python, but variable <code>y</code> is returned to JIT code (since it is used after the <code>with</code> block). Therefore, the <code>y=\"float64\"</code> type annotation is required.</p> <pre><code>import pandas as pd\nimport numpy as np\nimport bodo\nimport scipy.special as sc\ndef my_non_jit_function(a, b):\nreturn np.log(a) + sc.entr(b)\n@bodo.jit\ndef f(row):\nwith bodo.objmode(y=\"float64\"):\ny = my_non_jit_function(row.A, row.B)\nreturn y\n@bodo.jit\ndef objmode_example(n):\ndf = pd.DataFrame({\"A\": np.random.ranf(n), \"B\": np.arange(n)})\ndf[\"C\"] = df.apply(f, axis=1)\nprint(df[\"C\"].sum())\nobjmode_example(10)\n</code></pre> <p>We recommend keeping the code inside the <code>with bodo.objmode</code> block minimal and call outside Python functions instead (as in this example). This reduces compilation time and sidesteps potential compiler limitations.</p>"},{"location":"objmode/#object-mode-type-annotations","title":"Object Mode Type Annotations","text":"<p>There are various ways to specify the data types in <code>objmode</code>. Basic data types such as <code>float64</code> and <code>int64</code> can be specified as string values (as in the previous example). For more complex data types like dataframes, <code>bodo.typeof()</code> can be used on sample data that has the same type as expected outputs. For example:</p> <pre><code>df_sample = pd.DataFrame({\"A\": [0], \"B\": [\"AB\"]}, index=[0])\ndf_type = bodo.typeof(df_sample)\n@bodo.jit\ndef f():\nwith bodo.objmode(df=df_type):\ndf = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [\"ab\", \"bc\", \"cd\"]}, index=[3, 2, 1])\nreturn df\n</code></pre> <p>This is equivalent to creating the <code>DataFrameType</code> directly:</p> <pre><code>@bodo.jit\ndef f():\nwith bodo.objmode(\ndf=bodo.DataFrameType(\n(bodo.int64[::1], bodo.string_array_type),\nbodo.NumericIndexType(bodo.int64),\n(\"A\", \"B\"),\n)\n):\ndf = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [\"ab\", \"bc\", \"cd\"]}, index=[3, 2, 1])\nreturn df\n</code></pre> <p>The data type can be registered in Bodo so it can be referenced using a string name later:</p> <pre><code>df_sample = pd.DataFrame({\"A\": [0], \"B\": [\"AB\"]}, index=[0])\nbodo.register_type(\"my_df_type\", bodo.typeof(df_sample))\n@bodo.jit\ndef f():\nwith bodo.objmode(df=\"my_df_type\"):\ndf = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [\"ab\", \"bc\", \"cd\"]}, index=[3, 2, 1])\nreturn df\n</code></pre> <p>See pandas datatypes for more details on Bodo data types in general. Bodo's Object Mode is built on top of Numba's Object Mode (see Numba objmode for more details).</p>"},{"location":"objmode/#what-can-be-done-inside-object-mode","title":"What Can Be Done Inside Object Mode","text":"<p>The code inside Object Mode runs in regular Python on all parallel processes, which means Object Mode does not include Bodo compiler's automatic parallel communication management. Therefore, the computation inside Object Mode should be independent on different processors and not require communication. In general:</p> <ul> <li>Operations on scalars are safe</li> <li>Operations that compute on rows independently are safe</li> <li>Operations that compute across rows may not be safe</li> </ul> <p>The example below demonstrates a valid use of Object Mode, since it uses <code>df.apply(axis=1)</code> which runs on different rows independently.</p> <pre><code>df_type = bodo.typeof(pd.DataFrame({\"A\": [1], \"B\": [1], \"C\": [1]}))\ndef f(df):\nreturn df.assign(C=df.apply(lambda r: r.A + r.B, axis=1))\n@bodo.jit\ndef valid_objmode():\ndf = pd.read_parquet(\"in_file.pq\")\nwith bodo.objmode(df2=df_type):\ndf2 = f(df)\ndf2.to_parquet(\"out_file.pq\")\nvalid_objmode()\n</code></pre> <p>In contrast, the example below demonstrates an invalid use of Object Mode. The reason is that groupby computation requires grouping together all rows with the same key across all chunks. However, on each processor, Bodo passes a chunk of <code>df</code> to Object Mode which returns results from local groupby computation. Therefore, <code>df2</code> does not include valid global groupby output.</p> <pre><code>df_type = bodo.typeof(pd.DataFrame({\"A\": [1], \"B\": [1]}))\ndef f(df):\nreturn df.groupby(\"A\", as_index=False).sum()\n@bodo.jit\ndef invalid_objmode():\ndf = pd.read_parquet(\"in_file.pq\")\n# Invalid use of objmode\nwith bodo.objmode(df2=df_type):\ndf2 = f(df)\ndf2.to_parquet(\"out_file.pq\")\ninvalid_objmode()\n</code></pre>"},{"location":"objmode/#groupbyapply-object-mode-pattern","title":"Groupby/Apply Object Mode Pattern","text":"<p>ML algorithms and other complex data science computations are often called on groups of dataframe rows. Bodo supports parallelizing these computations (which may not have JIT support yet) using Object Mode inside <code>groupby/apply</code>. For example, the code below runs Prophet on groups of rows. This is a valid use of Object Mode since Bodo handles shuffle communication for groupby/apply and brings all rows of each group in the same local chunk. Therefore, the apply function running in Object Mode has all the data it needs.</p> <pre><code>import bodo\nimport pandas as pd\nimport numpy as np\nfrom fbprophet import Prophet\nprophet_output_type = bodo.typeof(pd.DataFrame({\"ds\": pd.date_range(\"2017-01-03\", periods=1), \"yhat\": [0.0]}))\ndef run_prophet(df):\nm = Prophet()\nm.fit(df)\nreturn m.predict(df)[[\"ds\", \"yhat\"]]\n@bodo.jit\ndef apply_func(df):\nwith bodo.objmode(df2=prophet_output_type):\ndf2 = run_prophet(df)\nreturn df2\n@bodo.jit\ndef f(df):\ndf2 = df.groupby(\"A\").apply(apply_func)\nreturn df2\nn = 10\ndf = pd.DataFrame({\"A\": np.arange(n) % 3, \"ds\": pd.date_range(\"2017-01-03\", periods=n), \"y\": np.arange(n)})\nprint(f(df))\n</code></pre>"},{"location":"quick_start_platform/","title":"Getting started with the Bodo Platform","text":"<p>This page provides a quick start guide to the Bodo platform and explains its important concepts briefly. We strongly recommend reading this page before getting started with the Bodo platform.</p>","tags":["getting started","platform"]},{"location":"quick_start_platform/#basic-terminology","title":"Basic Terminology","text":"","tags":["getting started","platform"]},{"location":"quick_start_platform/#notebooks","title":"Notebooks","text":"<p>A Notebook is a simple instances of a JupyterLab Server. You can use   a notebook to navigate the files in your workspace, define and execute   your workflows on the clusters, etc.</p>","tags":["getting started","platform"]},{"location":"quick_start_platform/#clusters","title":"Clusters","text":"<p>A Cluster provides your notebooks with necessary compute resources.   Each cluster is tied to a specific Bodo version. A cluster also has   additional configuration parameters such as the number of instances,   auto-pause duration, etc. You can read more about creating a cluster here.</p>","tags":["getting started","platform"]},{"location":"quick_start_platform/#workspaces","title":"Workspaces","text":"<p>Workspaces are a basic unit of organization on Bodo platform. You can   think of a workspace as a directory on a UNIX file system. Each Workspace   contains zero or more Notebooks, Clusters, etc.</p>","tags":["getting started","platform"]},{"location":"quick_start_platform/#platformsetup","title":"Setup the Bodo Platform","text":"<ol> <li>Follow the Bodo Platform Setup Guide.</li> </ol> <p>If you sign up for Bodo through the AWS marketplace, you get a 14-day free trial. For the duration of your trial, you will only be charged for the underlying AWS resources created by your     activity on the Bodo Platform. After the trial expires you will be charged according to our pay-as-you-go pricing</p>","tags":["getting started","platform"]},{"location":"quick_start_platform/#bodo-dashboard","title":"Bodo Dashboard","text":"<ol> <li>Once your cloud config has been created navigate to the Workspaces tab and click the Create Workspace button in the  top right corner. Once your workspace has finished creating, you will be able to enter it.  </li> </ol> <p>Once inside the Workspace, navigate to the Notebooks tab.    </p> <p>That\u2019s it, you\u2019re all set to experience Bodo. Follow along one of our tutorials or go through the curated list of bodo-examples.  See <code>bodo-examples</code> for a set of notebooks ready to be run in your free trial environment.</p>","tags":["getting started","platform"]},{"location":"api_docs/","title":"API Reference","text":"<ul> <li>SQL</li> <li>Bodo Parallel APIs</li> <li>Pandas</li> <li>Numpy</li> <li>User Defined Functions (UDFs)</li> <li>Machine Learning</li> <li>Miscellaneous Supported Python API</li> </ul>"},{"location":"api_docs/BodoSQL/","title":"BodoSQL","text":"<p>BodoSQL provides high performance and scalable SQL query execution using Bodo's HPC capabilities and optimizations. It also provides native Python/SQL integration as well as SQL to Pandas conversion for the first time.</p>"},{"location":"api_docs/BodoSQL/#getting-started","title":"Getting Started","text":""},{"location":"api_docs/BodoSQL/#installation","title":"Installation","text":"<p>Install BodoSQL using:</p> <pre><code>conda install bodosql -c bodo.ai -c conda-forge\n</code></pre>"},{"location":"api_docs/BodoSQL/#using-bodosql","title":"Using BodoSQL","text":"<p>The example below demonstrates using BodoSQL in Python programs. It loads data into a dataframe, runs a SQL query on the data, and runs Python/Pandas code on query results:</p> <pre><code>import pandas as pd\nimport bodo\nimport bodosql\n@bodo.jit\ndef f(filename):\ndf1 = pd.read_parquet(filename)\nbc = bodosql.BodoSQLContext({\"table1\": df1})\ndf2 = bc.sql(\"SELECT A FROM table1 WHERE B &gt; 4\")\nprint(df2.A.sum())\nf(\"my_data.pq\")\n</code></pre> <p>This program is fully type checked, optimized and parallelized by Bodo end-to-end. <code>BodoSQLContext</code> creates a SQL environment with tables created from dataframes. <code>BodoSQLContext.sql()</code> runs a SQL query and returns the results as a dataframe. <code>BodoSQLContext</code> can be used outside Bodo JIT functions if necessary as well.</p> <p>You can run this example by creating <code>my_data.pq</code>:</p> <pre><code>import pandas as pd\nimport numpy as np\nNUM_GROUPS = 30\nNUM_ROWS = 20_000_000\ndf = pd.DataFrame({\n\"A\": np.arange(NUM_ROWS) % NUM_GROUPS,\n\"B\": np.arange(NUM_ROWS)\n})\ndf.to_parquet(\"my_data.pq\")\n</code></pre> <p>To run the example, save it in a file called <code>example.py</code> and run it using <code>mpiexec</code>, e.g.:</p> <pre><code>mpiexec -n 8 python example.py\n</code></pre>"},{"location":"api_docs/BodoSQL/#aliasing","title":"Aliasing","text":"<p>In all but the most trivial cases, BodoSQL generates internal names to avoid conflicts in the intermediate dataframes. By default, BodoSQL does not rename the columns for the final output of a query using a consistent approach. For example the query:</p> <p><pre><code>bc.sql(\"SELECT SUM(A) FROM table1 WHERE B &gt; 4\")\n</code></pre> Results in an output column named <code>$EXPR0</code>. To reliably reference this column later in your code, we highly recommend using aliases for all columns that are the final outputs of a query, such as:</p> <pre><code>bc.sql(\"SELECT SUM(A) as sum_col FROM table1 WHERE B &gt; 4\")\n</code></pre> <p>Note</p> <p>BodoSQL supports using aliases generated in <code>SELECT</code> inside <code>GROUP BY</code> and <code>HAVING</code> in the same query, but you cannot do so with <code>WHERE</code>.</p>"},{"location":"api_docs/BodoSQL/#supported-operations","title":"Supported Operations","text":"<p>We currently support the following SQL query statements and clauses with BodoSQL, and are continuously adding support towards completeness. Note that BodoSQL ignores casing of keywords, and column and table names, except for the final output column name. Therefore, <code>select a from table1</code> is treated the same as <code>SELECT A FROM Table1</code>, except for the names of the final output columns (<code>a</code> vs <code>A</code>).</p>"},{"location":"api_docs/BodoSQL/#select","title":"SELECT","text":"<p>The <code>SELECT</code> statement is used to select data in the form of columns. The data returned from BodoSQL is stored in a dataframe.</p> <pre><code>SELECT &lt;COLUMN_NAMES&gt; FROM &lt;TABLE_NAME&gt;\n</code></pre> <p>For Instance:</p> <pre><code>SELECT A FROM customers\n</code></pre> <p>Example Usage:</p> <pre><code>&gt;&gt;&gt;@bodo.jit\n... def g(df):\n...    bc = bodosql.BodoSQLContext({\"customers\":df})\n...    query = \"SELECT name FROM customers\"\n...    res = bc.sql(query)\n...    return res\n&gt;&gt;&gt;customers_df = pd.DataFrame({\n...     \"customerID\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n...     \"name\": [\"Deangelo Todd\",\"Nikolai Kent\",\"Eden Heath\", \"Taliyah Martinez\",\n...                 \"Demetrius Chavez\",\"Weston Jefferson\",\"Jonathon Middleton\",\n...                 \"Shawn Winters\",\"Keely Hutchinson\", \"Darryl Rosales\",],\n...     \"balance\": [1123.34, 2133.43, 23.58, 8345.15, 943.43, 68.34, 12764.50, 3489.25, 654.24, 25645.39]\n... })\n&gt;&gt;&gt;g(customers_df)\nname\n0       Deangelo Todd\n1        Nikolai Kent\n2          Eden Heath\n3    Taliyah Martinez\n4    Demetrius Chavez\n5    Weston Jefferson\n6  Jonathon Middleton\n7       Shawn Winters\n8    Keely Hutchinson\n9      Darryl Rosales\n</code></pre>"},{"location":"api_docs/BodoSQL/#select-distinct","title":"SELECT DISTINCT","text":"<p>The <code>SELECT DISTINCT</code> statement is used to return only distinct (different) values:</p> <pre><code>SELECT DISTINCT &lt;COLUMN_NAMES&gt; FROM &lt;TABLE_NAME&gt;\n</code></pre> <p><code>DISTINCT</code> can be used in a SELECT statement or inside an aggregate function. For example:</p> <pre><code>SELECT DISTINCT A FROM table1\nSELECT COUNT DISTINCT A FROM table1\n</code></pre> <p>Example Usage <pre><code>&gt;&gt;&gt;@bodo.jit\n... def g(df):\n...    bc = bodosql.BodoSQLContext({\"payments\":df})\n...    query = \"SELECT DISTINCT paymentType FROM payments\"\n...    res = bc.sql(query)\n...    return res\n&gt;&gt;&gt;payment_df = pd.DataFrame({\n...     \"customerID\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n...     \"paymentType\": [\"VISA\", \"VISA\", \"AMEX\", \"VISA\", \"WIRE\", \"VISA\", \"VISA\", \"WIRE\", \"VISA\", \"AMEX\"],\n... })\n&gt;&gt;&gt;g(payment_df) # inside SELECT\npaymentType\n0        VISA\n2        AMEX\n4        WIRE\n&gt;&gt;&gt;def g(df):\n...    bc = bodosql.BodoSQLContext({\"payments\":df})\n...    query = \"SELECT COUNT(DISTINCT paymentType) as num_payment_types FROM payments\"\n...    res = bc.sql(query)\n...    return res\n&gt;&gt;&gt;g(payment_df) # inside aggregate\nnum_payment_types\n0          3\n</code></pre></p>"},{"location":"api_docs/BodoSQL/#where","title":"WHERE","text":"<p>The <code>WHERE</code> clause on columns can be used to filter records that satisfy specific conditions:</p> <pre><code>SELECT &lt;COLUMN_NAMES&gt; FROM &lt;TABLE_NAME&gt; WHERE &lt;CONDITION&gt;\n</code></pre> <p>For Example: <pre><code>SELECT A FROM table1 WHERE B &gt; 4\n</code></pre></p> <p>Example Usage <pre><code>&gt;&gt;&gt;@bodo.jit\n... def g(df):\n...    bc = bodosql.BodoSQLContext({\"customers\":df})\n...    query = \"SELECT name FROM customers WHERE balance 3000\"\n...    res = bc.sql(query)\n...    return res\n&gt;&gt;&gt;customers_df = pd.DataFrame({\n...     \"customerID\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n...     \"name\": [\"Deangelo Todd\",\"Nikolai Kent\",\"Eden Heath\", \"Taliyah Martinez\",\n...                 \"Demetrius Chavez\",\"Weston Jefferson\",\"Jonathon Middleton\",\n...                 \"Shawn Winters\",\"Keely Hutchinson\", \"Darryl Rosales\",],\n...     \"balance\": [1123.34, 2133.43, 23.58, 8345.15, 943.43, 68.34, 12764.50, 3489.25, 654.24, 25645.39]\n... })\n&gt;&gt;&gt;g(customers_df)\nname\n3    Taliyah Martinez\n6  Jonathon Middleton\n7       Shawn Winters\n9      Darryl Rosales\n</code></pre></p>"},{"location":"api_docs/BodoSQL/#order-by","title":"ORDER BY","text":"<p>The <code>ORDER BY</code> keyword sorts the resulting dataframe in ascending or descending order, with <code>NULL</code> values either at the start or end of the column. By default, it sorts the records in ascending order with null values at the end. For descending order and nulls at the front, the <code>DESC</code> and <code>NULLS FIRST</code> keywords can be used:</p> <pre><code>SELECT &lt;COLUMN_NAMES&gt;\nFROM &lt;TABLE_NAME&gt;\nORDER BY &lt;ORDERED_COLUMN_NAMES&gt; [ASC|DESC] [NULLS FIRST|LAST]\n</code></pre> <p>For Example: <pre><code>SELECT A, B FROM table1 ORDER BY B, A DESC NULLS FIRST\n</code></pre></p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt;@bodo.jit\n... def g(df):\n...    bc = bodosql.BodoSQLContext({\"customers\":df})\n...    query = \"SELECT name, balance FROM customers ORDER BY balance\"\n...    res = bc.sql(query)\n...    return res\n&gt;&gt;&gt;customers_df = pd.DataFrame({\n...     \"customerID\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n...     \"name\": [\"Deangelo Todd\",\"Nikolai Kent\",\"Eden Heath\", \"Taliyah Martinez\",\n...                 \"Demetrius Chavez\",\"Weston Jefferson\",\"Jonathon Middleton\",\n...                 \"Shawn Winters\",\"Keely Hutchinson\", \"Darryl Rosales\",],\n...     \"balance\": [1123.34, 2133.43, 23.58, 8345.15, 943.43, 68.34, 12764.50, 3489.25, 654.24, 25645.39]\n... })\n&gt;&gt;&gt;g(customers_df)\nname   balance\n2          Eden Heath     23.58\n5    Weston Jefferson     68.34\n8    Keely Hutchinson    654.24\n4    Demetrius Chavez    943.43\n0       Deangelo Todd   1123.34\n1        Nikolai Kent   2133.43\n7       Shawn Winters   3489.25\n3    Taliyah Martinez   8345.15\n6  Jonathon Middleton  12764.50\n9      Darryl Rosales  25645.39\n</code></pre>"},{"location":"api_docs/BodoSQL/#limit","title":"LIMIT","text":"<p>BodoSQL supports the <code>LIMIT</code> keyword to select a limited number of rows. This keyword can optionally include an offset:</p> <p><pre><code>SELECT &lt;COLUMN_NAMES&gt;\nFROM &lt;TABLE_NAME&gt;\nWHERE &lt;CONDITION&gt;\nLIMIT &lt;LIMIT_NUMBER&gt; OFFSET &lt;OFFSET_NUMBER&gt;\n</code></pre> For Example:</p> <p><pre><code>SELECT A FROM table1 LIMIT 5\nSELECT B FROM table2 LIMIT 8 OFFSET 3\n</code></pre> Specifying a limit and offset can be also be written as:</p> <p><pre><code>LIMIT &lt;OFFSET_NUMBER&gt;, &lt;LIMIT_NUMBER&gt;\n</code></pre> For Example:</p> <p><pre><code>SELECT B FROM table2 LIMIT 3, 8\n</code></pre> Example Usage</p> <pre><code>&gt;&gt;&gt;@bodo.jit\n... def g1(df):\n...    bc = bodosql.BodoSQLContext({\"customers\":df})\n...    query = \"SELECT name FROM customers LIMIT 4\"\n...    res = bc.sql(query)\n...    return res\n&gt;&gt;&gt;@bodo.jit\n... def g2(df):\n...    bc = bodosql.BodoSQLContext({\"customers\":df})\n...    query = \"SELECT name FROM customers LIMIT 4 OFFSET 2\"\n...    res = bc.sql(query)\n...    return res\n&gt;&gt;&gt;customers_df = pd.DataFrame({\n...     \"customerID\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n...     \"name\": [\"Deangelo Todd\",\"Nikolai Kent\",\"Eden Heath\", \"Taliyah Martinez\",\n...                 \"Demetrius Chavez\",\"Weston Jefferson\",\"Jonathon Middleton\",\n...                 \"Shawn Winters\",\"Keely Hutchinson\", \"Darryl Rosales\",],\n...     \"balance\": [1123.34, 2133.43, 23.58, 8345.15, 943.43, 68.34, 12764.50, 3489.25, 654.24, 25645.39]\n... })\n&gt;&gt;&gt;g1(customers_df) # LIMIT 4\nname\n0     Deangelo Todd\n1      Nikolai Kent\n2        Eden Heath\n3  Taliyah Martinez\n&gt;&gt;&gt;g2(customers_df) # LIMIT 4 OFFSET 2\nname\n2        Eden Heath\n3  Taliyah Martinez\n4  Demetrius Chavez\n5  Weston Jefferson\n</code></pre>"},{"location":"api_docs/BodoSQL/#not-in","title":"NOT IN","text":"<p>The <code>IN</code> determines if a value can be chosen a list of options. Currently, we support lists of literals or columns with matching types: <pre><code>SELECT &lt;COLUMN_NAMES&gt;\nFROM &lt;TABLE_NAME&gt;\nWHERE &lt;COLUMN_NAME&gt; IN (&lt;val1&gt;, &lt;val2&gt;, ... &lt;valN&gt;)\n</code></pre> For example: <pre><code>SELECT A FROM table1 WHERE A IN (5, 10, 15, 20, 25)\n</code></pre> Example Usage <pre><code>&gt;&gt;&gt;@bodo.jit\n... def g1(df):\n...    bc = bodosql.BodoSQLContext({\"payments\":df})\n...    query = \"SELECT customerID FROM payments WHERE paymentType IN ('AMEX', 'WIRE')\"\n...    res = bc.sql(query)\n...    return res\n&gt;&gt;&gt;@bodo.jit\n... def g2(df):\n...    bc = bodosql.BodoSQLContext({\"payments\":df})\n...    query = \"SELECT customerID FROM payments WHERE paymentType NOT IN ('AMEX', 'VISA')\"\n...    res = bc.sql(query)\n...    return res\n&gt;&gt;&gt;payment_df = pd.DataFrame({\n...     \"customerID\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n...     \"paymentType\": [\"VISA\", \"VISA\", \"AMEX\", \"VISA\", \"WIRE\", \"VISA\", \"VISA\", \"WIRE\", \"VISA\", \"AMEX\"],\n... })\n&gt;&gt;&gt;g1(payment_df) # IN\ncustomerID\n2           2\n4           4\n7           7\n9           9\n&gt;&gt;&gt;g2(payment_df) # NOT IN\ncustomerID\n4           4\n7           7\n</code></pre></p>"},{"location":"api_docs/BodoSQL/#not-between","title":"NOT BETWEEN","text":"<p>The <code>BETWEEN</code> operator selects values within a given range. The values can be numbers, text, or datetimes. The <code>BETWEEN</code> operator is inclusive: begin and end values are included: <pre><code>SELECT &lt;COLUMN_NAMES&gt;\nFROM &lt;TABLE_NAME&gt;\nWHERE &lt;COLUMN_NAME&gt; BETWEEN &lt;VALUE1&gt; AND &lt;VALUE2&gt;\n</code></pre> For example: <pre><code>SELECT A FROM table1 WHERE A BETWEEN 10 AND 100\n</code></pre> Example Usage <pre><code>&gt;&gt;&gt;@bodo.jit\n... def g(df):\n...    bc = bodosql.BodoSQLContext({\"customers\":df})\n...    query = \"SELECT name, balance FROM customers WHERE balance BETWEEN 1000 and 5000\"\n...    res = bc.sql(query)\n...    return res\n&gt;&gt;&gt;@bodo.jit\n... def g2(df):\n...    bc = bodosql.BodoSQLContext({\"customers\":df})\n...    query = \"SELECT name, balance FROM customers WHERE balance NOT BETWEEN 100 and 10000\"\n...    res = bc.sql(query)\n...    return res\n&gt;&gt;&gt;customers_df = pd.DataFrame({\n...     \"customerID\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n...     \"name\": [\"Deangelo Todd\",\"Nikolai Kent\",\"Eden Heath\", \"Taliyah Martinez\",\n...                 \"Demetrius Chavez\",\"Weston Jefferson\",\"Jonathon Middleton\",\n...                 \"Shawn Winters\",\"Keely Hutchinson\", \"Darryl Rosales\",],\n...     \"balance\": [1123.34, 2133.43, 23.58, 8345.15, 943.43, 68.34, 12764.50, 3489.25, 654.24, 25645.39]\n... })\n&gt;&gt;&gt;g1(payment_df) # BETWEEN\nname  balance\n0  Deangelo Todd  1123.34\n1   Nikolai Kent  2133.43\n7  Shawn Winters  3489.25\n&gt;&gt;&gt;g2(payment_df) # NOT BETWEEN\nname   balance\n2          Eden Heath     23.58\n5    Weston Jefferson     68.34\n6  Jonathon Middleton  12764.50\n9      Darryl Rosales  25645.39\n</code></pre></p>"},{"location":"api_docs/BodoSQL/#cast","title":"CAST","text":"<p>THE <code>CAST</code> operator converts an input from one type to another. In many cases casts are created implicitly, but this operator can be used to force a type conversion.</p> <p>The following casts are currently supported. Please refer to <code>supported_dataframe_data_types</code> for the Python types for each type keyword:</p> From To Notes <code>VARCHAR</code> <code>VARCHAR</code> <code>VARCHAR</code> <code>TINYINT/SMALLINT/INTEGER/BIGINT</code> <code>VARCHAR</code> <code>FLOAT/DOUBLE</code> <code>VARCHAR</code> <code>DECIMAL</code> Equivalent to <code>DOUBLE</code>. This may change in the future. <code>VARCHAR</code> <code>TIMESTAMP</code> <code>VARCHAR</code> <code>DATE</code> Truncates to date but is still Timestamp type. This may change in the future. <code>TINYINT/SMALLINT/INTEGER/BIGINT</code> <code>VARCHAR</code> <code>TINYINT/SMALLINT/INTEGER/BIGINT</code> <code>TINYINT/SMALLINT/INTEGER/BIGINT</code> <code>TINYINT/SMALLINT/INTEGER/BIGINT</code> <code>FLOAT/DOUBLE</code> <code>TINYINT/SMALLINT/INTEGER/BIGINT</code> <code>DECIMAL</code> Equivalent to <code>DOUBLE</code>. This may change in the future. <code>TINYINT/SMALLINT/INTEGER/BIGINT</code> <code>TIMESTAMP</code> <code>FLOAT/DOUBLE</code> <code>VARCHAR</code> <code>FLOAT/DOUBLE</code> <code>TINYINT/SMALLINT/INTEGER/BIGINT</code> <code>FLOAT/DOUBLE</code> <code>FLOAT/DOUBLE</code> <code>FLOAT/DOUBLE</code> <code>DECIMAL</code> Equivalent to <code>DOUBLE</code>. This may change in the future <code>TIMESTAMP</code> <code>VARCHAR</code> <code>TIMESTAMP</code> <code>TINYINT/SMALLINT/INTEGER/BIGINT</code> <code>TIMESTAMP</code> <code>TIMESTAMP</code> <code>TIMESTAMP</code> <code>DATE</code> Truncates to date but is still Timestamp type. This may change in the future. <p>Note</p> <p><code>CAST</code> correctness can often not be determined at compile time. Users are responsible for ensuring that conversion is possible (e.g. <code>CAST(str_col as INTEGER)</code>).</p>"},{"location":"api_docs/BodoSQL/#_1","title":"::","text":"<p>Infix cast operator. Equivalent to cast, but the format is <code>value::Typename</code></p>"},{"location":"api_docs/BodoSQL/#join","title":"JOIN","text":"<p>A <code>JOIN</code> clause is used to combine rows from two or more tables, based on a related column between them: <pre><code>SELECT &lt;COLUMN_NAMES&gt;\nFROM &lt;LEFT_TABLE_NAME&gt;\n&lt;JOIN_TYPE&gt; &lt;RIGHT_TABLE_NAME&gt;\nON &lt;LEFT_TABLE_COLUMN_NAME&gt; OP &lt;RIGHT_TABLE_COLUMN_NAME&gt;\n</code></pre> For example: <pre><code>SELECT table1.A, table1.B FROM table1 JOIN table2 on table1.A = table2.C\n</code></pre> Here are the different types of the joins in SQL:</p> <ul> <li><code>(INNER) JOIN</code>: returns records that have matching values in both tables</li> <li><code>LEFT (OUTER) JOIN</code>: returns all records from the left table, and the matched records from the right table</li> <li><code>RIGHT (OUTER) JOIN</code>: returns all records from the right table, and the matched records from the left table</li> <li><code>FULL (OUTER) JOIN</code>: returns all records when there is a match in either left or right table</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt;@bodo.jit\n... def g1(df1, df2):\n...    bc = bodosql.BodoSQLContext({\"customers\":df1, \"payments\":df2})\n...    query = \"SELECT name, paymentType FROM customers JOIN payments ON customers.customerID = payments.customerID\"\n...    res = bc.sql(query)\n...    return res\n&gt;&gt;&gt;@bodo.jit\n... def g2(df1, df2):\n...    bc = bodosql.BodoSQLContext({\"customers\":df1, \"payments\":df2})\n...    query = \"SELECT name, paymentType FROM customers FULL JOIN payments ON customers.customerID = payments.customerID\"\n...    res = bc.sql(query)\n...    return res\n&gt;&gt;&gt;customer_df = pd.DataFrame({\n...    \"customerID\": [0, 2, 4, 5, 7,],\n...    \"name\": [\"Deangelo Todd\",\"Nikolai Kent\",\"Eden Heath\", \"Taliyah Martinez\",\"Demetrius Chavez\",],\n...    \"address\": [\"223 Iroquois LanenWest New York, NJ 07093\",\"37 Depot StreetnTaunton, MA 02780\",\n...                \"639 Maple St.nNorth Kingstown, RI 02852\",\"93 Bowman Rd.nChester, PA 19013\",\n...                \"513 Manchester Ave.nWindsor, CT 06095\",],\n...    \"balance\": [1123.34, 2133.43, 23.58, 8345.15, 943.43,]\n... })\n&gt;&gt;&gt;payment_df = pd.DataFrame({\n...     \"customerID\": [0, 1, 4, 6, 7],\n...     \"paymentType\": [\"VISA\", \"VISA\", \"AMEX\", \"VISA\", \"WIRE\",],\n... })\n&gt;&gt;&gt;g1(customer_df, payment_df) # INNER JOIN\nname paymentType\n0     Deangelo Todd        VISA\n1        Eden Heath        AMEX\n2  Demetrius Chavez        WIRE\n&gt;&gt;&gt;g2(customer_df, payment_df) # OUTER JOIN\nname paymentType\n0     Deangelo Todd        VISA\n1      Nikolai Kent         NaN\n2        Eden Heath        AMEX\n3  Taliyah Martinez         NaN\n4  Demetrius Chavez        WIRE\n5               NaN        VISA\n6               NaN        VISA\n</code></pre>"},{"location":"api_docs/BodoSQL/#natural-join","title":"NATURAL JOIN","text":"<p>A natural join is a type of join that provides an equality condition on all columns with the same name and only returns 1 column for the keys. On cannot be provided because it is implied but all join types can be provided.</p> <p><pre><code>SELECT &lt;COLUMN_NAMES&gt;\nFROM &lt;LEFT_TABLE_NAME&gt;\nNATURAL &lt;JOIN_TYPE&gt; &lt;RIGHT_TABLE_NAME&gt;\n</code></pre> For example: <pre><code>SELECT table1.A, table1.B FROM table1 NATURAL JOIN table2\n</code></pre> Here are the different types of the joins in SQL:</p> <ul> <li><code>(INNER) JOIN</code>: returns records that have matching values in both tables</li> <li><code>LEFT (OUTER) JOIN</code>: returns all records from the left table, and the matched records from the right table</li> <li><code>RIGHT (OUTER) JOIN</code>: returns all records from the right table, and the matched records from the left table</li> <li><code>FULL (OUTER) JOIN</code>: returns all records when there is a match in either left or right table</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt;@bodo.jit\n... def g1(df1, df2):\n...    bc = bodosql.BodoSQLContext({\"customers\":df1, \"payments\":df2})\n...    query = \"SELECT payments.* FROM customers NATURAL JOIN payments\"\n...    res = bc.sql(query)\n...    return res\n&gt;&gt;&gt;@bodo.jit\n... def g2(df1, df2):\n...    bc = bodosql.BodoSQLContext({\"customers\":df1, \"payments\":df2})\n...    query = \"SELECT payments.* FROM customers NATURAL FULL JOIN payments\"\n...    res = bc.sql(query)\n...    return res\n&gt;&gt;&gt;customer_df = pd.DataFrame({\n...    \"customerID\": [0, 2, 4, 5, 7,],\n...    \"name\": [\"Deangelo Todd\",\"Nikolai Kent\",\"Eden Heath\", \"Taliyah Martinez\",\"Demetrius Chavez\",],\n...    \"address\": [\"223 Iroquois LanenWest New York, NJ 07093\",\"37 Depot StreetnTaunton, MA 02780\",\n...                \"639 Maple St.nNorth Kingstown, RI 02852\",\"93 Bowman Rd.nChester, PA 19013\",\n...                \"513 Manchester Ave.nWindsor, CT 06095\",],\n...    \"balance\": [1123.34, 2133.43, 23.58, 8345.15, 943.43,]\n... })\n&gt;&gt;&gt;payment_df = pd.DataFrame({\n...     \"customerID\": [0, 1, 4, 6, 7],\n...     \"paymentType\": [\"VISA\", \"VISA\", \"AMEX\", \"VISA\", \"WIRE\",],\n... })\n&gt;&gt;&gt;g1(customer_df, payment_df) # INNER JOIN\ncustomerID paymentType\n0           0        VISA\n1           4        AMEX\n2           7        WIRE\n&gt;&gt;&gt;g2(customer_df, payment_df) # OUTER JOIN\ncustomerID paymentType\n0           0        VISA\n1        &lt;NA&gt;        &lt;NA&gt;\n2           4        AMEX\n3        &lt;NA&gt;        &lt;NA&gt;\n4           7        WIRE\n5           1        VISA\n6           6        VISA\n</code></pre>"},{"location":"api_docs/BodoSQL/#union","title":"UNION","text":"<p>The <code>UNION</code> operator is used to combine the result-set of two <code>SELECT</code> statements: <pre><code>SELECT &lt;COLUMN_NAMES&gt; FROM &lt;TABLE1&gt;\nUNION\nSELECT &lt;COLUMN_NAMES&gt; FROM &lt;TABLE2&gt;\n</code></pre> Each <code>SELECT</code> statement within the <code>UNION</code> clause must have the same number of columns. The columns must also have similar data types. The output of the <code>UNION</code> is the set of rows which are present in either of the input <code>SELECT</code> statements.</p> <p>The <code>UNION</code> operator selects only the distinct values from the inputs by default. To allow duplicate values, use <code>UNION ALL</code>:</p> <pre><code>SELECT &lt;COLUMN_NAMES&gt; FROM &lt;TABLE1&gt;\nUNION ALL\nSELECT &lt;COLUMN_NAMES&gt; FROM &lt;TABLE2&gt;\n</code></pre> <p>Example Usage</p> <pre><code>&gt;&gt;&gt;@bodo.jit\n... def g1(df):\n...    bc = bodosql.BodoSQLContext({\"customers\":df1, \"payments\":df2})\n...    query = \"SELECT name, paymentType FROM customers JOIN payments ON customers.customerID = payments.customerID WHERE paymentType in ('WIRE')\n...             UNION SELECT name, paymentType FROM customers JOIN payments ON customers.customerID = payments.customerID WHERE balance &lt; 1000\"\n...    res = bc.sql(query)\n...    return res\n&gt;&gt;&gt;@bodo.jit\n... def g2(df):\n...    bc = bodosql.BodoSQLContext({\"customers\":df1, \"payments\":df2})\n...    query = \"SELECT name, paymentType FROM customers JOIN payments ON customers.customerID = payments.customerID WHERE paymentType in ('WIRE')\n...             UNION ALL SELECT name, paymentType FROM customers JOIN payments ON customers.customerID = payments.customerID WHERE balance &lt; 1000\"\n...    res = bc.sql(query)\n...    return res\n&gt;&gt;&gt;customer_df = pd.DataFrame({\n...    \"customerID\": [0, 2, 4, 5, 7,],\n...    \"name\": [\"Deangelo Todd\",\"Nikolai Kent\",\"Eden Heath\", \"Taliyah Martinez\",\"Demetrius Chavez\",],\n...    \"address\": [\"223 Iroquois LanenWest New York, NJ 07093\",\"37 Depot StreetnTaunton, MA 02780\",\n...                \"639 Maple St.nNorth Kingstown, RI 02852\",\"93 Bowman Rd.nChester, PA 19013\",\n...                \"513 Manchester Ave.nWindsor, CT 06095\",],\n...    \"balance\": [1123.34, 2133.43, 23.58, 8345.15, 943.43,]\n... })\n&gt;&gt;&gt;payment_df = pd.DataFrame({\n...     \"customerID\": [0, 1, 4, 6, 7],\n...     \"paymentType\": [\"VISA\", \"VISA\", \"AMEX\", \"VISA\", \"WIRE\",],\n... })\n&gt;&gt;&gt;g1(customer_df, payment_df) # UNION\nname paymentType  balance\n0  Demetrius Chavez        WIRE   943.43\n0        Eden Heath        AMEX    23.58\n&gt;&gt;&gt;g2(customer_df, payment_df) # UNION ALL\nname paymentType  balance\n0  Demetrius Chavez        WIRE   943.43\n0        Eden Heath        AMEX    23.58\n1  Demetrius Chavez        WIRE   943.43\n</code></pre>"},{"location":"api_docs/BodoSQL/#intersect","title":"INTERSECT","text":"<p>The <code>INTERSECT</code> operator is used to calculate the intersection of two <code>SELECT</code> statements:</p> <pre><code>SELECT &lt;COLUMN_NAMES&gt; FROM &lt;TABLE1&gt;\nINTERSECT\nSELECT &lt;COLUMN_NAMES&gt; FROM &lt;TABLE2&gt;\n</code></pre> <p>Each <code>SELECT</code> statement within the <code>INTERSECT</code> clause must have the same number of columns. The columns must also have similar data types. The output of the <code>INTERSECT</code> is the set of rows which are present in both of the input SELECT statements. The <code>INTERSECT</code> operator selects only the distinct values from the inputs.</p>"},{"location":"api_docs/BodoSQL/#group-by","title":"GROUP BY","text":"<p>The <code>GROUP BY</code> statement groups rows that have the same values into summary rows, like \"find the number of customers in each country\". The <code>GROUP BY</code> statement is often used with aggregate functions to group the result-set by one or more columns: <pre><code>SELECT &lt;COLUMN_NAMES&gt;\nFROM &lt;TABLE_NAME&gt;\nWHERE &lt;CONDITION&gt;\nGROUP BY &lt;GROUP_EXPRESSION&gt;\nORDER BY &lt;COLUMN_NAMES&gt;\n</code></pre></p> <p>For example: <pre><code>SELECT MAX(A) FROM table1 GROUP BY B\n</code></pre> <code>GROUP BY</code> statements also referring to columns by alias or column number: <pre><code>SELECT MAX(A), B - 1 as val FROM table1 GROUP BY val\nSELECT MAX(A), B FROM table1 GROUP BY 2\n</code></pre></p> <p>BodoSQL supports several subclauses that enable grouping by multiple different sets of columns in the same <code>SELECT</code> statement. <code>GROUPING SETS</code> is the first. It is equivalent to performing a group by for each specified set (setting each column not present in the grouping set to null), and unioning the results. For example:</p> <pre><code>SELECT MAX(A), B, C FROM table1 GROUP BY GROUPING SETS (B, B, (B, C), ())\n</code></pre> <p>This is equivalent to:</p> <pre><code>SELECT * FROM\n(SELECT MAX(A), B, null FROM table1 GROUP BY B)\nUNION\n(SELECT MAX(A), B, null FROM table1 GROUP BY B)\nUNION\n(SELECT MAX(A), B, C FROM table1 GROUP BY B, C)\nUNION\n(SELECT MAX(A), null, null FROM table1)\n</code></pre> <p>Note</p> <p>The above example is not valid BodoSQL code, as we do not support null literals. It is used only to show the null filling behavior.</p> <p><code>CUBE</code> is equivalent to grouping by all possible permutations of the specified set. For example:</p> <pre><code>SELECT MAX(A), B, C FROM table1 GROUP BY CUBE(B, C)\n</code></pre> <p>Is equivalent to</p> <pre><code>SELECT MAX(A), B, C FROM table1 GROUP BY GROUPING SETS ((B, C), (B), (C), ())\n</code></pre> <p><code>ROLLUP</code> is equivalent to grouping by n + 1 grouping sets, where each set is constructed by dropping the rightmost element from the previous set, until no elements remain in the grouping set. For example:</p> <pre><code>SELECT MAX(A), B, C FROM table1 GROUP BY ROLLUP(B, C, D)\n</code></pre> <p>Is equivalent to</p> <pre><code>SELECT MAX(A), B, C FROM table1 GROUP BY GROUPING SETS ((B, C, D), (B, C), (B), ())\n</code></pre> <p><code>CUBE</code> and <code>ROLLUP</code> can be nested into a <code>GROUPING SETS</code> clause. For example:</p> <pre><code>SELECT MAX(A), B, C GROUP BY GROUPING SETS (ROLLUP(B, C, D), CUBE(B, C), (A))\n</code></pre> <p>Which is equivalent to</p> <pre><code>SELECT MAX(A), B, C GROUP BY GROUPING SETS ((B, C, D), (B, C), (B), (), (B, C), (B), (C), (), (A))\n</code></pre>"},{"location":"api_docs/BodoSQL/#having","title":"HAVING","text":"<p>The <code>HAVING</code> clause is used for filtering with <code>GROUP BY</code>. <code>HAVING</code> applies the filter after generating the groups, whereas <code>WHERE</code> applies the filter before generating any groups:</p> <pre><code>SELECT column_name(s)\nFROM table_name\nWHERE condition\nGROUP BY column_name(s)\nHAVING condition\n</code></pre> <p>For example: <pre><code>SELECT MAX(A) FROM table1 GROUP BY B HAVING C &lt; 0\n</code></pre> <code>HAVING</code> statements also referring to columns by aliases used in the <code>GROUP BY</code>: <pre><code>SELECT MAX(A), B - 1 as val FROM table1 GROUP BY val HAVING val 5\n</code></pre></p>"},{"location":"api_docs/BodoSQL/#qualify","title":"QUALIFY","text":"<p><code>QUALIFY</code> is similar to <code>HAVING</code>, except it applies filters after computing the results of at least one window function. <code>QUALIFY</code> is used after using <code>WHERE</code> and <code>HAVING</code>.</p> <p>For example:</p> <pre><code>SELECT column_name(s),\nFROM table_name\nWHERE condition\nGROUP BY column_name(s)\nHAVING condition\nQUALIFY MAX(A) OVER (PARTITION BY B ORDER BY C ROWS BETWEEN 1 FOLLOWING AND 1 PRECEDING) &gt; 1\n</code></pre> <p>Is equivalent to</p> <pre><code>SELECT column_name(s) FROM\n(SELECT column_name(s), MAX(A) OVER (PARTITION BY B ORDER BY C ROWS BETWEEN 1 FOLLOWING AND 1 PRECEDING) as window_output\nFROM table_name\nWHERE condition\nGROUP BY column_name(s)\nHAVING condition)\nWHERE window_output &gt; 1\n</code></pre>"},{"location":"api_docs/BodoSQL/#case","title":"CASE","text":"<p>The <code>CASE</code> statement goes through conditions and returns a value when the first condition is met: <pre><code>SELECT CASE WHEN cond1 THEN value1 WHEN cond2 THEN value2 ... ELSE valueN END\n</code></pre> For example: <pre><code>SELECT (CASE WHEN A 1 THEN A ELSE B END) as mycol FROM table1\n</code></pre> If the types of the possible return values are different, BodoSQL will attempt to cast them all to a common type, which is currently undefined behavior. The last else clause can optionally be excluded, in which case, the <code>CASE</code> statement will return null if none of the conditions are met. For example: <pre><code>SELECT (CASE WHEN A &lt; 0 THEN 0 END) as mycol FROM table1\n</code></pre> is equivalent to: <pre><code>SELECT (CASE WHEN A &lt; 0 THEN 0 ELSE NULL END) as mycol FROM table1\n</code></pre></p>"},{"location":"api_docs/BodoSQL/#like","title":"LIKE","text":"<p>The <code>LIKE</code> clause is used to filter the strings in a column to those that match a pattern: <pre><code>SELECT column_name(s) FROM table_name WHERE column LIKE pattern\n</code></pre> In the pattern we support the wildcards <code>%</code> and <code>_</code>. For example: <pre><code>SELECT A FROM table1 WHERE B LIKE '%py'\n</code></pre></p>"},{"location":"api_docs/BodoSQL/#greatest","title":"GREATEST","text":"<p>The <code>GREATEST</code> clause is used to return the largest value from a list of columns: <pre><code>SELECT GREATEST(col1, col2, ..., colN) FROM table_name\n</code></pre> For example: <pre><code>SELECT GREATEST(A, B, C) FROM table1\n</code></pre></p>"},{"location":"api_docs/BodoSQL/#least","title":"LEAST","text":"<p>The <code>LEAST</code> clause is used to return the smallest value from a list of columns: <pre><code>SELECT LEAST(col1, col2, ..., colN) FROM table_name\n</code></pre> For example: <pre><code>SELECT LEAST(A, B, C) FROM table1\n</code></pre></p>"},{"location":"api_docs/BodoSQL/#pivot","title":"PIVOT","text":"<p>The <code>PIVOT</code> clause is used to transpose specific data rows in one or more columns into a set of columns in a new DataFrame: <pre><code>SELECT col1, ..., colN FROM table_name PIVOT (\nAGG_FUNC_1(colName or pivotVar) AS alias1, ...,  AGG_FUNC_N(colName or pivotVar) as aliasN\nFOR pivotVar IN (ROW_VALUE_1 as row_alias_1, ..., ROW_VALUE_N as row_alias_N)\n)\n</code></pre> <code>PIVOT</code> produces a new column for each pair of pivotVar and aggregation functions.</p> <p>For example: <pre><code>SELECT single_sum_a, single_avg_c, triple_sum_a, triple_avg_c FROM table1 PIVOT (\nSUM(A) AS sum_a, AVG(C) AS avg_c\nFOR A IN (1 as single, 3 as triple)\n)\n</code></pre> Here <code>single_sum_a</code> will contain sum(A) where <code>A = 1</code>, single_avg_c will contain AVG(C) where <code>A = 1</code> etc.</p> <p>If you explicitly specify other columns as the output, those columns will be used to group the pivot columns. For example: <pre><code>SELECT B, single_sum_a, single_avg_c, triple_sum_a, triple_avg_c FROM table1 PIVOT (\nSUM(A) AS sum_a, AVG(C) AS avg_c\nFOR A IN (1 as single, 3 as triple)\n)\n</code></pre> Contains 1 row for each unique group in B. The pivotVar can also require values to match in multiple columns. For example: <pre><code>SELECT * FROM table1 PIVOT (\nSUM(A) AS sum_a, AVG(C) AS avg_c\nFOR (A, B) IN ((1, 4) as col1, (2, 5) as col2)\n)\n</code></pre></p>"},{"location":"api_docs/BodoSQL/#with","title":"WITH","text":"<p>The <code>WITH</code> clause can be used to name sub-queries: <pre><code>WITH sub_table AS (SELECT column_name(s) FROM table_name)\nSELECT column_name(s) FROM sub_table\n</code></pre> For example: <pre><code>WITH subtable as (SELECT MAX(A) as max_al FROM table1 GROUP BY B)\nSELECT MAX(max_val) FROM subtable\n</code></pre></p>"},{"location":"api_docs/BodoSQL/#aliasing_1","title":"Aliasing","text":"<p>SQL aliases are used to give a table, or a column in a table, a temporary name:</p> <pre><code>SELECT &lt;COLUMN_NAME&gt; AS &lt;ALIAS&gt;\nFROM &lt;TABLE_NAME&gt;\n</code></pre> <p>For example: <pre><code>Select SUM(A) as total FROM table1\n</code></pre></p> <p>We strongly recommend using aliases for the final outputs of any queries to ensure all column names are predictable.</p>"},{"location":"api_docs/BodoSQL/#operators","title":"Operators","text":""},{"location":"api_docs/BodoSQL/#arithmetic","title":"Arithmetic","text":"<ul> <li> <p>BodoSQL currently supports the following arithmetic     operators:</p> <ul> <li><code>+</code> (addition)</li> <li><code>-</code> (subtraction)</li> <li><code>*</code> (multiplication)</li> <li><code>/</code> (true division)</li> <li><code>%</code> (modulo)</li> </ul> </li> </ul>"},{"location":"api_docs/BodoSQL/#comparison","title":"Comparison","text":"<ul> <li> <p>BodoSQL currently supports the following comparison     operators:</p> <ul> <li><code>=</code> (equal to)</li> <li><code>&gt;</code> (greater than)</li> <li><code>&lt;</code> (less than)</li> <li><code>&gt;=</code> (greater than or equal to)</li> <li><code>&lt;=</code> (less than or equal to)</li> <li><code>&lt;&gt;</code> (not equal to)</li> <li><code>!=</code> (not equal to)</li> <li><code>&lt;=&gt;</code> (equal to or both inputs are null)</li> </ul> </li> </ul>"},{"location":"api_docs/BodoSQL/#logical","title":"Logical","text":"<ul> <li> <p>BodoSQL currently supports the following logical operators:</p> <ul> <li><code>AND</code></li> <li><code>OR</code></li> <li><code>NOT</code></li> </ul> </li> </ul>"},{"location":"api_docs/BodoSQL/#string","title":"String","text":"<ul> <li> <p>BodoSQL currently supports the following string operators:</p> <ul> <li><code>||</code> (string concatenation)</li> </ul> </li> </ul>"},{"location":"api_docs/BodoSQL/#numeric-functions","title":"Numeric Functions","text":"<p>Except where otherwise specified, the inputs to each of these functions can be any numeric type, column or scalar. Here is an example using MOD:</p> <pre><code>SELECT MOD(12.2, A) FROM table1\n</code></pre> <p>BodoSQL Currently supports the following Numeric Functions:</p>"},{"location":"api_docs/BodoSQL/#abs","title":"ABS","text":"<ul> <li> <p><code>ABS(n)</code></p> <p>Returns the absolute value of n</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#cos","title":"COS","text":"<ul> <li> <p><code>COS(n)</code></p> <p>Calculates the Cosine of n</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#sin","title":"SIN","text":"<ul> <li> <p><code>SIN(n)</code></p> <p>Calculates the Sine of n</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#tan","title":"TAN","text":"<ul> <li> <p><code>TAN(n)</code></p> <p>Calculates the Tangent of n</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#cotan","title":"COTAN","text":"<ul> <li> <p><code>COTAN(X)</code></p> <p>Calculates the Cotangent of <code>X</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#acos","title":"ACOS","text":"<ul> <li> <p><code>ACOS(n)</code></p> <p>Calculates the Arccosine of n</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#asin","title":"ASIN","text":"<ul> <li> <p><code>AIN(n)</code></p> <p>Calculates the Arcsine of n</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#atan","title":"ATAN","text":"<ul> <li> <p><code>ATAN(n)</code></p> <p>Calculates the Arctangent of n</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#atan2","title":"ATAN2","text":"<ul> <li> <p><code>ATAN2(A, B)</code></p> <p>Calculates the Arctangent of <code>A</code> divided by <code>B</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#ceil","title":"CEIL","text":"<ul> <li> <p><code>CEIL(X[, scale])</code></p> <p>Converts X to the specified scale, rounding towards positive infinity. For example, <code>scale=0</code> rounds up to the nearest integer, <code>scale=2</code> rounds up to the nearest <code>0.01</code>, and <code>scale=-1</code> rounds up to the nearest multiple of 10.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#ceiling","title":"CEILING","text":"<ul> <li> <p><code>CEILING(X)</code></p> <p>Equivalent to <code>CEIL</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#floor","title":"FLOOR","text":"<ul> <li> <p><code>FLOOR(X[, scale])</code></p> <p>Converts X to the specified scale, rounding towards negative infinity. For example, <code>scale=0</code> down up to the nearest integer, <code>scale=2</code> rounds down to the nearest <code>0.01</code>, and <code>scale=-1</code> rounds down to the nearest multiple of 10.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#degrees","title":"DEGREES","text":"<ul> <li> <p><code>DEGREES(X)</code></p> <p>Converts a value in radians to the corresponding value in degrees</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#radians","title":"RADIANS","text":"<ul> <li> <p><code>RADIANS(X)</code></p> <p>Converts a value in radians to the corresponding value in degrees</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#log10","title":"LOG10","text":"<ul> <li> <p><code>LOG10(X)</code></p> <p>Computes Log base 10 of x. Returns NaN for negative inputs, and -inf for 0 inputs.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#log","title":"LOG","text":"<ul> <li> <p><code>LOG(X)</code></p> <p>Equivalent to <code>LOG10(x)</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#log10_1","title":"LOG10","text":"<ul> <li> <p><code>LOG10(X)</code></p> <p>Computes Log base 2 of x. Returns <code>NaN</code> for negative inputs, and <code>-inf</code> for 0 inputs.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#ln","title":"LN","text":"<ul> <li> <p><code>LN(X)</code></p> <p>Computes the natural log of x. Returns <code>NaN</code> for negative inputs, and <code>-inf</code> for 0 inputs.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#mod","title":"MOD","text":"<ul> <li> <p><code>MOD(A,B)</code></p> <p>Computes A modulo B (behavior analogous to the C library function <code>fmod</code>). Returns <code>NaN</code> if B is 0 or if A is inf.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#conv","title":"CONV","text":"<ul> <li> <p><code>CONV(X, current_base, new_base)</code></p> <p><code>CONV</code> takes a string representation of an integer value, it's current_base, and the base to convert that argument to. <code>CONV</code> returns a new string, that represents the value in the new base. <code>CONV</code> is only supported for converting to/from base 2, 8, 10, and 16.</p> <p>For example:</p> <pre><code>CONV('10', 10, 2) =='1010'\nCONV('10', 2, 10) =='2'\nCONV('FA', 16, 10) =='250'\n</code></pre> </li> </ul>"},{"location":"api_docs/BodoSQL/#sqrt","title":"SQRT","text":"<ul> <li><code>SQRT(X)</code></li> </ul> <p>Computes the square root of x. Returns <code>NaN</code> for negative inputs, and <code>-inf</code> for 0 inputs.</p>"},{"location":"api_docs/BodoSQL/#pi","title":"PI","text":"<ul> <li> <p><code>PI()</code></p> <p>Returns the value of <code>PI</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#pow-power","title":"POW, POWER","text":"<ul> <li> <p><code>POW(A, B), POWER(A, B)</code></p> <p>Returns A to the power of B. Returns <code>NaN</code> if A is negative, and B is a float. <code>POW(0,0)</code> is 1</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#exp","title":"EXP","text":"<ul> <li> <p><code>EXP(X)</code></p> <p>Returns e to the power of X</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#sign","title":"SIGN","text":"<ul> <li> <p><code>SIGN(X)</code></p> <p>Returns 1 if X &gt; 0, -1 if X &lt; 0, and 0 if X = 0</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#round","title":"ROUND","text":"<ul> <li> <p><code>ROUND(X[, num_decimal_places])</code></p> <p>Rounds X to the specified number of decimal places</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#truncate","title":"TRUNCATE","text":"<ul> <li> <p><code>TRUNCATE(X, num_decimal_places)</code></p> <p>Equivalent to <code>ROUND(X, num_decimal_places)</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#bitand","title":"BITAND","text":"<ul> <li> <p><code>BITAND(A, B)</code></p> <p>Returns the bitwise-and of its inputs.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#bitor","title":"BITOR","text":"<ul> <li> <p><code>BITOR(A, B)</code></p> <p>Returns the bitwise-or of its inputs.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#bitxor","title":"BITXOR","text":"<ul> <li> <p><code>BITOR(A, B)</code></p> <p>Returns the bitwise-xor of its inputs.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#bitnot","title":"BITNOT","text":"<ul> <li> <p><code>BITNOT(A)</code></p> <p>Returns the bitwise-negation of its input.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#bitshiftleft","title":"BITSHIFTLEFT","text":"<ul> <li> <p><code>BITSHIFTLEFT(A, B)</code></p> <p>Returns the bitwise-leftshift of its inputs.</p> <p>Note</p> <ul> <li>The output is always of type int64.</li> <li>Undefined behavior when B is negative or too large.</li> </ul> </li> </ul>"},{"location":"api_docs/BodoSQL/#bitshiftright","title":"BITSHIFTRIGHT","text":"<ul> <li> <p><code>BITSHIFTRIGHT(A, B)</code></p> <p>Returns the bitwise-rightshift of its inputs. Undefined behavior when B is negative or too large.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#getbit","title":"GETBIT","text":"<ul> <li> <p><code>GETBIT(A, B)</code></p> <p>Returns the bit of A corresponding to location B, where 0 is the rightmost bit. Undefined behavior when B is negative or too large.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#booland","title":"BOOLAND","text":"<ul> <li> <p><code>BOOLAND(A, B)</code></p> <p>Returns true when <code>A</code> and <code>B</code> are both non-null non-zero. Returns false when one of the arguments is zero and the other is either zero or <code>NULL</code>. Returns <code>NULL</code> otherwise.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#boolor","title":"BOOLOR","text":"<ul> <li> <p><code>BOOLOR(A, B)</code></p> <p>Returns true if either <code>A</code> or <code>B</code> is non-null and non-zero. Returns false if both <code>A</code> and <code>B</code> are zero. Returns <code>NULL</code> otherwise.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#boolxor","title":"BOOLXOR","text":"<ul> <li> <p><code>BOOLXOR(A, B)</code></p> <p>Returns true if one of <code>A</code> and <code>B</code> is zero and the other is non-zero. Returns false if <code>A</code> and <code>B</code> are both zero or both non-zero. Returns <code>NULL</code> if either <code>A</code> or <code>B</code> is <code>NULL</code>.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#boolnot","title":"BOOLNOT","text":"<ul> <li> <p><code>BOOLNOT(A)</code></p> <p>Returns true if <code>A</code> is zero. Returns false if <code>A</code> is non-zero. Returns <code>NULL</code> if <code>A</code> is <code>NULL</code>.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#regr_valx","title":"REGR_VALX","text":"<ul> <li> <p><code>REGR_VALX(Y, X)</code></p> <p>Returns <code>NULL</code> if either input is <code>NULL</code>, otherwise <code>X</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#regr_valy","title":"REGR_VALY","text":"<ul> <li> <p><code>REGR_VALY(Y, X)</code></p> <p>Returns <code>NULL</code> if either input is <code>NULL</code>, otherwise <code>Y</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#hash","title":"HASH","text":"<ul> <li> <p><code>HASH(A, B, C, ...)</code></p> <p>Takes in a variable number of arguments of any type and returns a hash value that considers the values in each column. The hash function is deterministic across multiple ranks or multiple sessions.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#data-generation-functions","title":"Data Generation Functions","text":"<p>BodoSQL Currently supports the following data generaiton functions:</p>"},{"location":"api_docs/BodoSQL/#random","title":"RANDOM","text":"<ul> <li> <p><code>RANDOM()</code></p> <p>Outputs a random 64-bit integer. If used inside of a select statement with a table, the number of random values will match the number of rows in the input table (and each value should be randomly and independently generated). Note that running with multiple processors may affect the randomization results.</p> <p>Note</p> <p>Currently, BodoSQL does not support the format of <code>RANDOM()</code> that takes in a seed value.</p> <p>Note</p> <p>At present, aliases to <code>RANDOM</code> calls occasionally produce unexpected behavior. For certain SQL operations, calling <code>RANDOM</code> and storing the result with an alias, then later re-using that alias may result in another call to <code>RANDOM</code>. This behavior is somewhat rare.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#uniform","title":"UNIFORM","text":"<ul> <li> <p><code>UNIFORM(lo, hi, gen)</code></p> <p>Outputs a random number uniformly distributed in the interval <code>[lo, hi]</code>. If <code>lo</code> and <code>hi</code> are both integers, then the output is an integer between <code>lo</code> and <code>hi</code> (including both endpoints). If either <code>lo</code> or <code>hi</code> is a float, the output is a random float between them. The values of <code>gen</code> are used to seed the randomness, so if <code>gen</code> is all distinct values (or is randomly generated) then the output of <code>UNIFORM</code> should be random. However, if 2 rows have the same <code>gen</code> value they will produce the same output value.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#aggregation-functions","title":"Aggregation Functions","text":"<p>BodoSQL Currently supports the following Aggregation Functions on all types:</p>"},{"location":"api_docs/BodoSQL/#count","title":"COUNT","text":"<ul> <li> <p><code>COUNT</code></p> <p>Count the number of elements in a column or group.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#any_value","title":"ANY_VALUE","text":"<ul> <li> <p><code>ANY_VALUE</code></p> <p>Select an arbitrary value.</p> <p>Note</p> <p>Currently, BodoSQL always selects the first value, but this is subject to change at any time.</p> </li> </ul> <p>In addition, BodoSQL also supports the following functions on numeric types</p>"},{"location":"api_docs/BodoSQL/#avg","title":"AVG","text":"<ul> <li> <p><code>AVG</code></p> <p>Compute the mean for a column.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#max","title":"MAX","text":"<ul> <li> <p><code>MAX</code></p> <p>Compute the max value for a column.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#min","title":"MIN","text":"<ul> <li> <p><code>MIN</code></p> <p>Compute the min value for a column.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#stddev","title":"STDDEV","text":"<ul> <li> <p><code>STDDEV</code></p> <p>Compute the standard deviation for a column with N - 1 degrees of freedom.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#stddev_samp","title":"STDDEV_SAMP","text":"<ul> <li> <p><code>STDDEV_SAMP</code></p> <p>Compute the standard deviation for a column with N - 1 degrees of freedom.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#stddev_pop","title":"STDDEV_POP","text":"<ul> <li> <p><code>STDDEV_POP</code></p> <p>Compute the standard deviation for a column with N degrees of freedom.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#sum","title":"SUM","text":"<ul> <li> <p><code>SUM</code></p> <p>Compute the sum for a column.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#count_if","title":"COUNT_IF","text":"<ul> <li> <p><code>COUNT_IF</code></p> <p>Compute the total number of occurrences of <code>true</code> in a column of booleans. For example:</p> <pre><code>SELECT COUNT_IF(A) FROM table1\n</code></pre> <p>Is equivalent to <code>`sql SELECT SUM(CASE WHEN A THEN 1 ELSE 0 END) FROM table1 `#!sql</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#listagg","title":"LISTAGG","text":"<ul> <li> <p><code>LISTAGG(str_col[, delimeter]) [WITHIN GROUP (ORDER BY order_col)]</code></p> <p>Concatenates all of the strings in <code>str_col</code> within each group into a single string seperated by the characters in the string <code>delimiter</code>. If no delimiter is provided, an empty string is used by default.</p> <p>Optionally allows using a <code>WITHIN GROUP</code> clause to specify how the strings should be ordered before being concatenated. If no clause is specified, then the ordering is unpredictable.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#mode","title":"MODE","text":"<ul> <li> <p><code>MODE</code></p> <p>Returns the most frequent element in a group, or <code>NULL</code> if the group is empty.</p> <p>Note</p> <p>This aggregation function is currently only supported with a <code>GROUP BY</code> clause. In case of a tie, BodoSQL will choose a value arbitrarily based on performance considerations.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#approx_percentile","title":"APPROX_PERCENTILE","text":"<ul> <li> <p><code>APPROX_PERCENTILE(A, q)</code></p> <p>Returns the approximate value of the <code>q</code>-th percentile of column <code>A</code> (e.g. 0.5 = median, or 0.9 = the 90<sup>th</sup> percentile). <code>A</code> can be any numeric column, and <code>q</code> can be any scalar float between zero and one.</p> <p>The approximation is calculated using the t-digest algorithm.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#variance","title":"VARIANCE","text":"<ul> <li> <p><code>VARIANCE</code></p> <p>Compute the variance for a column with N - 1 degrees of freedom.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#var_samp","title":"VAR_SAMP","text":"<ul> <li> <p><code>VAR_SAMP</code></p> <p>Compute the variance for a column with N - 1 degrees of freedom.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#var_pop","title":"VAR_POP","text":"<ul> <li> <p><code>VAR_POP</code></p> <p>Compute the variance for a column with N degrees of freedom.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#skew","title":"SKEW","text":"<ul> <li> <p><code>SKEW</code></p> <p>Compute the skew of a column</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#kurtosis","title":"KURTOSIS","text":"<ul> <li> <p><code>KURTOSIS</code></p> <p>Compute the kurtosis of a column</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#bitor_agg","title":"BITOR_AGG","text":"<ul> <li> <p><code>BITOR_AGG</code></p> <p>Compute the bitwise OR of every input in a group, returning <code>NULL</code> if there are no non-<code>NULL</code> entries. Accepts floating point values, integer values, and strings. Strings are interpreted directly as numbers, converting to 64-bit floating point numbers.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#boolor_agg","title":"BOOLOR_AGG","text":"<ul> <li> <p><code>BOOLOR_AGG</code></p> <p>Compute the logical OR of the boolean value of every input in a group, returning <code>NULL</code> if there are no non-<code>NULL</code> entries, otherwise returning True if there is at least 1 non-zero entry. This is supported for numeric and boolean types.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#booland_agg","title":"BOOLAND_AGG","text":"<ul> <li> <p><code>BOOLAND_AGG</code></p> <p>Compute the logical AND of the boolean value of every input in a group, returning <code>NULL</code> if there are no non-<code>NULL</code> entries, otherwise returning True if all non-<code>NULL</code> entries are also non-zero. This is supported for numeric and boolean types.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#boolxor_agg","title":"BOOLXOR_AGG","text":"<ul> <li> <p><code>BOOLXOR_AGG</code></p> <p>Returns <code>NULL</code> if there are no non-<code>NULL</code> entries, otherwise returning True if exactly one non-<code>NULL</code> entry is also non-zero (this is counterintuitive to how the logical XOR is normally thought of). This is supported for numeric and boolean types.</p> </li> </ul> <p>All aggregate functions have the syntax:</p> <pre><code>SELECT AGGREGATE_FUNCTION(&lt;COLUMN_EXPRESSION&gt;)\nFROM &lt;TABLE_NAME&gt;\nGROUP BY &lt;COLUMN_NAMES&gt;\n</code></pre> <p>These functions can be used either in a groupby clause, where they will be computed for each group, or by itself on an entire column expression. For example:</p> <pre><code>SELECT AVG(A) FROM table1 GROUP BY B\nSELECT COUNT(Distinct A) FROM table1\n</code></pre>"},{"location":"api_docs/BodoSQL/#timestamp-functions","title":"Timestamp Functions","text":"<p>BodoSQL currently supports the following Timestamp functions:</p>"},{"location":"api_docs/BodoSQL/#datediff","title":"DATEDIFF","text":"<ul> <li> <p><code>DATEDIFF(timestamp_val1, timestamp_val2)</code></p> <p>Computes the difference in days between two Timestamp values (timestamp_val1 - timestamp_val2)</p> </li> <li> <p><code>DATEDIFF(unit, timestamp_val1, timestamp_val2)</code></p> <p>Computes the difference between two Timestamp values (timestamp_val2 - timestamp_val1) in terms of unit</p> <p>Allows the following units, with the specified abbreviations as string literals:</p> <ul> <li>YEAR: <code>year</code>, <code>years</code>, <code>yr</code>, <code>yrs</code>, <code>y</code>, <code>yy</code>, <code>yyy</code>, <code>yyyy</code></li> <li>QUARTER: <code>quarter</code>, <code>quarters</code>, <code>q</code>, <code>qtr</code>, <code>qtrs</code></li> <li>MONTH: <code>month</code>, <code>months</code>, <code>mm</code>, <code>mon</code>, <code>mons</code></li> <li>WEEK: <code>week</code>, <code>weeks</code>, <code>weekofyear</code>, <code>w</code>, <code>wk</code>, <code>woy</code>, <code>wy</code></li> <li>DAY: <code>day</code>, <code>days</code>, <code>dayofmonth</code>, <code>d</code>, <code>dd</code></li> <li>HOUR: <code>hour</code>, <code>hours</code>, <code>hrs</code>, <code>h</code>, <code>hr</code>, <code>hrs</code></li> <li>MINUTE: <code>minute</code>, <code>minutes</code>, <code>m</code>, <code>mi</code>, <code>min</code>, <code>mins</code></li> <li>SECOND: <code>second</code>, <code>seconds</code>, <code>s</code>, <code>sec</code>, <code>secs</code></li> <li>MILLISECOND: <code>millisecond</code>, <code>milliseconds</code>, <code>ms</code>, <code>msecs</code></li> <li>MICROSECOND: <code>microsecond</code>, <code>microseconds</code>, <code>us</code>, <code>usec</code></li> <li>NANOSECOND: <code>nanosecond</code>, <code>nanoseconds</code>, <code>nanosec</code>, <code>nsec</code>, <code>nsecs</code>, <code>nsecond</code>, <code>ns</code>, <code>nanonsecs</code></li> </ul> </li> </ul>"},{"location":"api_docs/BodoSQL/#str_to_date","title":"STR_TO_DATE","text":"<ul> <li> <p><code>STR_TO_DATE(str_val, literal_format_string)</code></p> <p>Converts a string value to a Timestamp value given a literal format string. If a year, month, and day value is not specified, they default to 1900, 01, and 01 respectively. Will throw a runtime error if the string cannot be parsed into the expected values. See <code>DATE_FORMAT</code> for recognized formatting characters.</p> <p>For example:</p> <pre><code>STR_TO_DATE('2020 01 12', '%Y %m %d') ==Timestamp '2020-01-12'\nSTR_TO_DATE('01 12', '%m %d') ==Timestamp '1900-01-12'\nSTR_TO_DATE('hello world', '%Y %m %d') ==RUNTIME ERROR\n</code></pre> </li> </ul>"},{"location":"api_docs/BodoSQL/#date_format","title":"DATE_FORMAT","text":"<ul> <li> <p><code>DATE_FORMAT(timestamp_val, literal_format_string)</code></p> <p>Converts a timestamp value to a String value given a scalar format string.</p> <p>Recognized formatting characters:</p> <ul> <li><code>%i</code> Minutes, zero padded (00 to 59)</li> <li><code>%M</code> Full month name (January to December)</li> <li><code>%r</code> Time in format in the format (hh:mm:ss AM/PM)</li> <li><code>%s</code> Seconds, zero padded (00 to 59)</li> <li><code>%T</code> Time in format in the format (hh:mm:ss)</li> <li><code>%T</code> Time in format in the format (hh:mm:ss)</li> <li><code>%u</code> week of year, where monday is the first day of the week(00 to 53)</li> <li><code>%a</code> Abbreviated weekday name (sun-sat)</li> <li><code>%b</code> Abbreviated month name (jan-dec)</li> <li><code>%f</code> Microseconds, left padded with 0's, (000000 to 999999)</li> <li><code>%H</code> Hour, zero padded (00 to 23)</li> <li><code>%j</code> Day Of Year, left padded with 0's (001 to 366)</li> <li><code>%m</code> Month number (00 to 12)</li> <li><code>%p</code> AM or PM, depending on the time of day</li> <li><code>%d</code> Day of month, zero padded (01 to 31)</li> <li><code>%Y</code> Year as a 4 digit value</li> <li><code>%y</code> Year as a 2 digit value, zero padded (00 to 99)</li> <li><code>%U</code> Week of year, where Sunday is the first day of the week     (00 to 53)</li> <li><code>%S</code> Seconds, zero padded (00 to 59)</li> </ul> <p>For example:</p> <pre><code>DATE_FORMAT(Timestamp '2020-01-12', '%Y %m %d') =='2020 01 12'\nDATE_FORMAT(Timestamp '2020-01-12 13:39:12', 'The time was %T %p. It was a %u') =='The time was 13:39:12 PM. It was a Sunday'\n</code></pre> </li> </ul>"},{"location":"api_docs/BodoSQL/#date_from_parts","title":"DATE_FROM_PARTS","text":"<ul> <li> <p><code>DATE_FROM_PARTS(year, month, day)</code></p> <p>Constructs a date from the integer inputs specified, e.g. <code>(2020, 7, 4)</code> will output July 4<sup>th</sup>, 2020.</p> <p>Note: month does not have to be in the 1-12 range, and day does not have to be in the 1-31 range. Values out of bounds are overflowed logically, e.g. <code>(2020, 14, -1)</code> will output January 31<sup>st</sup>, 2021.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#datefromparts","title":"DATEFROMPARTS","text":"<ul> <li> <p><code>DATEFROMPARTS(year, month, day)</code></p> <p>Equivalent to <code>DATE_FROM_PARTS</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#time_from_parts","title":"TIME_FROM_PARTS","text":"<ul> <li> <p><code>TIME_FROM_PARTS(integer_hour_val, integer_minute_val, integer_second_val [, integer_nanoseconds_val])</code></p> <p>Creates a time from individual numeric components. Usually, <code>integer_hour_val</code> is in the 0-23 range, <code>integer_minute_val</code> is in the 0-59 range, <code>integer_second_val</code> is in the 0-59 range, and <code>integer_nanoseconds_val</code> (if provided) is a 9-digit integer. <pre><code>TIMEFROMPARTS(12, 34, 56, 987654321)\n12:34:56.987654321\n</code></pre></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#timefromparts","title":"TIMEFROMPARTS","text":"<ul> <li> <p><code>TIMEFROMPARTS(integer_hour_val, integer_minute_val, integer_second_val [, integer_nanoseconds_val])</code></p> <p>See TIME_FROM_PARTS.</p> <pre><code>TIMEFROMPARTS(12, 34, 56, 987654321)\n12:34:56.987654321\n</code></pre> </li> </ul>"},{"location":"api_docs/BodoSQL/#timestamp_from_parts","title":"TIMESTAMP_FROM_PARTS","text":"<ul> <li> <p><code>TIMESTAMP_FROM_PARTS(year, month, day, hour, minute, second[, nanosecond[, timezone]])</code></p> <p>Equivalent to <code>DATE_FROM_PARTS</code> but also takes in an hour, minute and second (which can be out of bounds just like the month/day). Optionally takes in a nanosecond value, and a timezone value for the output. If the timezone is not specified, the output is timezone-naive.</p> <p>Note: timezone argument is not supported at this time.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#timestampfromparts","title":"TIMESTAMPFROMPARTS","text":"<ul> <li> <p><code>TIMESTAMPFROMPARTS(year, month, day, hour, minute, second[, nanosecond[, timezone]])</code></p> <p>Equivalent to <code>TIMESTAMP_FROM_PARTS</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#timestamp_ntz_from_parts","title":"TIMESTAMP_NTZ_FROM_PARTS","text":"<ul> <li> <p><code>TIMESTAMP_NTZ_FROM_PARTS(year, month, day, hour, minute, second[, nanosecond])</code></p> <p>Equivalent to <code>TIMESTAMP_FROM_PARTS</code> but without the optional timezone argument. The output is always timezone-naive.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#timestampntzfrom_parts","title":"TIMESTAMPNTZFROM_PARTS","text":"<ul> <li> <p><code>TIMESTAMP_NTZ_FROM_PARTS(year, month, day, hour, minute, second[, nanosecond])</code></p> <p>Equivalent to <code>TIMESTAMP_NTZ_FROM_PARTS</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#timestamp_ltz_from_parts","title":"TIMESTAMP_LTZ_FROM_PARTS","text":"<ul> <li> <p><code>TIMESTAMP_LTZ_FROM_PARTS(year, month, day, hour, minute, second[, nanosecond])</code></p> <p>Equivalent to <code>TIMESTAMP_FROM_PARTS</code> but without the optional timezone argument. The output is always timezone-aware using the local timezone.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#timestampltzfrom_parts","title":"TIMESTAMPLTZFROM_PARTS","text":"<ul> <li> <p><code>TIMESTAMP_LTZ_FROM_PARTS(year, month, day, hour, minute, second[, nanosecond])</code></p> <p>Equivalent to <code>TIMESTAMP_LTZ_FROM_PARTS</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#timestamp_tz_from_parts","title":"TIMESTAMP_TZ_FROM_PARTS","text":"<ul> <li> <p><code>TIMESTAMP_TZ_FROM_PARTS(year, month, day, hour, minute, second[, nanosecond[, timezone]])</code></p> <p>Equivalent to <code>TIMESTAMP_FROM_PARTS</code> except the default behavior if no timezone is provided is to use the local timezone instead of timezone-naive.</p> <p>Note: timezone argument is not supported at this time.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#timestamptzfromparts","title":"TIMESTAMPTZFROMPARTS","text":"<ul> <li> <p><code>TIMESTAMPTZFROMPARTS(year, month, day, hour, minute, second[, nanosecond[, timezone]])</code></p> <p>Equivalent to <code>TIMESTAMP_TZ_FROM_PARTS</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#dateadd","title":"DATEADD","text":"<ul> <li> <p><code>DATEADD(unit, amount, timestamp_val)</code></p> <p>Computes a timestamp column by adding the amount of the specified unit to the timestamp val. For example, <code>DATEADD('day', 3, T)</code> adds 3 days to column <code>T</code>. Allows the following units, with the specified abbreviations as string literals:</p> <ul> <li>YEAR: <code>year</code>, <code>years</code>, <code>yr</code>, <code>yrs</code>, <code>y</code>, <code>yy</code>, <code>yyy</code>, <code>yyyy</code></li> <li>QUARTER: <code>quarter</code>, <code>quarters</code>, <code>q</code>, <code>qtr</code>, <code>qtrs</code></li> <li>MONTH: <code>month</code>, <code>months</code>, <code>mm</code>, <code>mon</code>, <code>mons</code></li> <li>WEEK: <code>week</code>, <code>weeks</code>, <code>weekofyear</code>, <code>w</code>, <code>wk</code>, <code>woy</code>, <code>wy</code></li> <li>DAY: <code>day</code>, <code>days</code>, <code>dayofmonth</code>, <code>d</code>, <code>dd</code></li> <li>HOUR: <code>hour</code>, <code>hours</code>, <code>hrs</code>, <code>h</code>, <code>hr</code>, <code>hrs</code></li> <li>MINUTE: <code>minute</code>, <code>minutes</code>, <code>m</code>, <code>mi</code>, <code>min</code>, <code>mins</code></li> <li>SECOND: <code>second</code>, <code>seconds</code>, <code>s</code>, <code>sec</code>, <code>secs</code></li> <li>MILLISECOND: <code>millisecond</code>, <code>milliseconds</code>, <code>ms</code>, <code>msecs</code></li> <li>MICROSECOND: <code>microsecond</code>, <code>microseconds</code>, <code>us</code>, <code>usec</code></li> <li>NANOSECOND: <code>nanosecond</code>, <code>nanoseconds</code>, <code>nanosec</code>, <code>nsec</code>, <code>nsecs</code>, <code>nsecond</code>, <code>ns</code>, <code>nanonsecs</code></li> </ul> <p>Supported with timezone-aware data.</p> </li> <li> <p><code>DATEADD(timestamp_val, amount)</code></p> <p>Equivalent to <code>DATEADD('day', amount, timestamp_val)</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#timeadd","title":"TIMEADD","text":"<ul> <li> <p><code>TIMEADD(unit, amount, timestamp_val)</code></p> <p>Equivalent to <code>DATEADD</code>.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#date_add","title":"DATE_ADD","text":"<ul> <li> <p><code>DATE_ADD(timestamp_val, interval)</code></p> <p>Computes a timestamp column by adding an interval column/scalar to a timestamp value. If the first argument is a string representation of a timestamp, Bodo will cast the value to a timestamp.</p> </li> <li> <p><code>DATE_ADD(timestamp_val, amount)</code></p> <p>Equivalent to <code>DATE_ADD('day', amount, timestamp_val)</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#date_sub","title":"DATE_SUB","text":"<ul> <li> <p><code>DATE_SUB(timestamp_val, interval)</code></p> <p>Computes a timestamp column by subtracting an interval column/scalar to a timestamp value. If the first argument is a string representation of a timestamp, Bodo will cast the value to a timestamp.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#date_trunc","title":"DATE_TRUNC","text":"<ul> <li> <p><code>DATE_TRUNC(str_literal, timestamp_val)</code></p> <p>Truncates a timestamp to the provided str_literal field. str_literal must be a compile time constant and one of:</p> <ul> <li>\"MONTH\"</li> <li>\"WEEK\"</li> <li>\"DAY\"</li> <li>\"HOUR\"</li> <li>\"MINUTE\"</li> <li>\"SECOND\"</li> <li>\"MILLISECOND\"</li> <li>\"MICROSECOND\"</li> <li>\"NANOSECOND\"</li> </ul> </li> </ul>"},{"location":"api_docs/BodoSQL/#time_slice","title":"TIME_SLICE","text":"<ul> <li> <p><code>TIME_SLICE(date_or_time_expr, slice_length, unit[, start_or_end])</code></p> <p>Calculates one of the endpoints of a \"slice\" of time containing the date specified by <code>date_or_time_expr</code> where each slice has length of time corresponding to <code>slice_length</code> times the date/time unit specified by <code>unit</code>. The slice start/ends are always aligned to the unix epoch <code>1970-01-1</code> (at midnight). The fourth argument specifies whether to return the begining or the end of the slice (<code>'START'</code> for begining, <code>'END'</code> for end), where the default is <code>'START'</code>.</p> <p>For example, <code>TIME_SLICE(T, 3, 'YEAR')</code> would return the timestamp corresponding to the begining of the first 3-year window (aligned with 1970) that contains timestamp <code>T</code>. So <code>T = 1995-7-4 12:30:00</code> would output <code>1994-1-1</code> for <code>'START'</code> or <code>1997-1-1</code> for <code>'END'</code>. </p> </li> </ul>"},{"location":"api_docs/BodoSQL/#now","title":"NOW","text":"<ul> <li> <p><code>NOW()</code></p> <p>Computes a timestamp equal to the current time in the session's timezone. By default, the current timezone is UTC, and it can be updated as a parameter when using the Snowflake Catalog.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#localtimestamp","title":"LOCALTIMESTAMP","text":"<ul> <li> <p><code>LOCALTIMESTAMP()</code></p> <p>Equivalent to <code>NOW</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#current_timestamp","title":"CURRENT_TIMESTAMP","text":"<ul> <li> <p><code>CURRENT_TIMESTAMP()</code></p> <p>Equivalent to <code>NOW</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#getdate","title":"GETDATE","text":"<ul> <li> <p><code>GETDATE()</code></p> <p>Equivalent to <code>NOW</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#systimestamp","title":"SYSTIMESTAMP","text":"<ul> <li> <p><code>SYSTIMESTAMP()</code></p> <p>Equivalent to <code>NOW</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#localtime","title":"LOCALTIME","text":"<ul> <li> <p><code>LOCALTIME()</code></p> <p>Computes a time equal to the current time in the session's timezone. By default the current time is in local time, and it can be updated as a parameter when using the Snowflake Catalog.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#current_time","title":"CURRENT_TIME","text":"<ul> <li> <p><code>CURRENT_TIME()</code></p> <p>Equivalent to <code>LOCALTIME</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#curdate","title":"CURDATE","text":"<ul> <li> <p><code>CURDATE()</code></p> <p>Computes a timestamp equal to the current system time, excluding the time information</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#current_date","title":"CURRENT_DATE","text":"<ul> <li> <p><code>CURRENT_DATE()</code></p> <p>Equivalent to <code>CURDATE</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#extract","title":"EXTRACT","text":"<ul> <li> <p><code>EXTRACT(TimeUnit from timestamp_val)</code></p> <p>Extracts the specified TimeUnit from the supplied date.</p> <p>Allowed TimeUnits are:</p> <ul> <li><code>MICROSECOND</code></li> <li><code>MINUTE</code></li> <li><code>HOUR</code></li> <li><code>DAY</code> (Day of Month)</li> <li><code>DOY</code> (Day of Year)</li> <li><code>DOW</code> (Day of week)</li> <li><code>WEEK</code></li> <li><code>MONTH</code></li> <li><code>QUARTER</code></li> <li><code>YEAR</code></li> </ul> <p>TimeUnits are not case-sensitive.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#date_part","title":"DATE_PART","text":"<ul> <li> <p><code>DATE_PART(unit, timestamp_val)</code></p> <p>Equivalent to <code>EXTRACT(unit FROM timestamp_val)</code> with the following unit string literals:</p> <ul> <li>YEAR: <code>year</code>, <code>years</code>, <code>yr</code>, <code>yrs</code>, <code>y</code>, <code>yy</code>, <code>yyy</code>, <code>yyyy</code></li> <li>QUARTER: <code>quarter</code>, <code>quarters</code>, <code>q</code>, <code>qtr</code>, <code>qtrs</code></li> <li>MONTH: <code>month</code>, <code>months</code>, <code>mm</code>, <code>mon</code>, <code>mons</code></li> <li>WEEK: <code>week</code>, <code>weeks</code>, <code>weekofyear</code>, <code>w</code>, <code>wk</code>, <code>woy</code>, <code>wy</code></li> <li>DAY: <code>day</code>, <code>days</code>, <code>dayofmonth</code>, <code>d</code>, <code>dd</code></li> <li>HOUR: <code>hour</code>, <code>hours</code>, <code>hrs</code>, <code>h</code>, <code>hr</code>, <code>hrs</code></li> <li>MINUTE: <code>minute</code>, <code>minutes</code>, <code>m</code>, <code>mi</code>, <code>min</code>, <code>mins</code></li> <li>SECOND: <code>second</code>, <code>seconds</code>, <code>s</code>, <code>sec</code>, <code>secs</code></li> <li>MILLISECOND: <code>millisecond</code>, <code>milliseconds</code>, <code>ms</code>, <code>msecs</code></li> <li>MICROSECOND: <code>microsecond</code>, <code>microseconds</code>, <code>us</code>, <code>usec</code></li> <li>NANOSECOND: <code>nanosecond</code>, <code>nanoseconds</code>, <code>nanosec</code>, <code>nsec</code>, <code>nsecs</code>, <code>nsecond</code>, <code>ns</code>, <code>nanonsecs</code></li> </ul> <p>Supported with timezone-aware data.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#microsecond","title":"MICROSECOND","text":"<ul> <li> <p><code>MICROSECOND(timestamp_val)</code></p> <p>Equivalent to <code>EXTRACT(MICROSECOND from timestamp_val)</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#second","title":"SECOND","text":"<ul> <li> <p><code>SECOND(timestamp_val)</code></p> <p>Equivalent to <code>EXTRACT(SECOND from timestamp_val)</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#minute","title":"MINUTE","text":"<ul> <li> <p><code>MINUTE(timestamp_val)</code></p> <p>Equivalent to <code>EXTRACT(MINUTE from timestamp_val)</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#hour","title":"HOUR","text":"<ul> <li> <p><code>HOUR(timestamp_val)</code></p> <p>Equivalent to <code>EXTRACT(HOUR from timestamp_val)</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#week","title":"WEEK","text":"<ul> <li> <p><code>WEEK(timestamp_val)</code></p> <p>Equivalent to <code>EXTRACT(WEEK from timestamp_val)</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#weekofyear","title":"WEEKOFYEAR","text":"<ul> <li> <p><code>WEEKOFYEAR(timestamp_val)</code></p> <p>Equivalent to <code>EXTRACT(WEEK from timestamp_val)</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#month","title":"MONTH","text":"<ul> <li> <p><code>MONTH(timestamp_val)</code></p> <p>Equivalent to <code>EXTRACT(MONTH from timestamp_val)</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#quarter","title":"QUARTER","text":"<ul> <li> <p><code>QUARTER(timestamp_val)</code></p> <p>Equivalent to <code>EXTRACT(QUARTER from timestamp_val)</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#year","title":"YEAR","text":"<ul> <li> <p><code>YEAR(timestamp_val)</code></p> <p>Equivalent to <code>EXTRACT(YEAR from timestamp_val)</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#weekiso","title":"WEEKISO","text":"<ul> <li> <p><code>WEEKISO(timestamp_val)</code></p> <p>Computes the ISO week for the provided timestamp value.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#yearofweekiso","title":"YEAROFWEEKISO","text":"<ul> <li> <p><code>YEAROFWEEKISO(timestamp_val)</code></p> <p>Computes the ISO year for the provided timestamp value.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#makedate","title":"MAKEDATE","text":"<ul> <li> <p><code>MAKEDATE(integer_years_val, integer_days_val)</code></p> <p>Computes a timestamp value that is the specified number of days after the specified year.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#dayname","title":"DAYNAME","text":"<ul> <li> <p><code>DAYNAME(timestamp_val)</code></p> <p>Computes the string name of the day of the timestamp value.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#monthname","title":"MONTHNAME","text":"<ul> <li> <p><code>MONTHNAME(timestamp_val)</code></p> <p>Computes the string name of the month of the timestamp value.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#month_name","title":"MONTH_NAME","text":"<ul> <li> <p><code>MONTH_NAME(timestamp_val)</code></p> <p>Computes the string name of the month of the timestamp value.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#to_days","title":"TO_DAYS","text":"<ul> <li> <p><code>TO_DAYS(timestamp_val)</code></p> <p>Computes the difference in days between the input timestamp, and year 0 of the Gregorian calendar</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#to_seconds","title":"TO_SECONDS","text":"<ul> <li> <p><code>TO_SECONDS(timestamp_val)</code></p> <p>Computes the number of seconds since year 0 of the Gregorian calendar</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#from_days","title":"FROM_DAYS","text":"<ul> <li> <p><code>FROM_DAYS(n)</code></p> <p>Returns a timestamp values that is n days after year 0 of the Gregorian calendar</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#unix_timestamp","title":"UNIX_TIMESTAMP","text":"<ul> <li> <p><code>UNIX_TIMESTAMP()</code></p> <p>Computes the number of seconds since the unix epoch</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#from_unixtime","title":"FROM_UNIXTIME","text":"<ul> <li> <p><code>FROM_UNIXTIME(n)</code></p> <p>Returns a Timestamp value that is n seconds after the unix epoch</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#adddate","title":"ADDDATE","text":"<ul> <li> <p><code>ADDDATE(timestamp_val, interval)</code></p> <p>Same as <code>DATE_ADD</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#subdate","title":"SUBDATE","text":"<ul> <li> <p><code>SUBDATE(timestamp_val, interval)</code></p> <p>Same as <code>DATE_SUB</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#timestampdiff","title":"TIMESTAMPDIFF","text":"<ul> <li> <p><code>TIMESTAMPDIFF(unit, timestamp_val1, timestamp_val2)</code></p> <p>Returns the amount of time that has passed since <code>timestamp_val1</code> until <code>timestamp_val2</code> in terms of the unit specified, ignoring all smaller units. E.g., December 31 of 2020 and January 1 of 2021 count as 1 year apart.</p> <p>Note</p> <p>For all units larger than <code>NANOSECOND</code>, the output type is <code>INTEGER</code> instead of <code>BIGINT</code>, so any difference values that cannot be stored as signed 32-bit integers might not be returned correct.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#weekday","title":"WEEKDAY","text":"<ul> <li> <p><code>WEEKDAY(timestamp_val)</code></p> <p>Returns the weekday number for timestamp_val.</p> <p>Note</p> <p><code>Monday = 0</code>, <code>Sunday=6</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#yearweek","title":"YEARWEEK","text":"<ul> <li> <p><code>YEARWEEK(timestamp_val)</code></p> <p>Returns the year and week number for the provided timestamp_val concatenated as a single number. For example: <pre><code>YEARWEEK(TIMESTAMP '2021-08-30::00:00:00')\n202135\n</code></pre></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#last_day","title":"LAST_DAY","text":"<ul> <li> <p><code>LAST_DAY(timestamp_val)</code></p> <p>Given a timestamp value, returns a timestamp value that is the last day in the same month as timestamp_val.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#utc_timestamp","title":"UTC_TIMESTAMP","text":"<ul> <li> <p><code>UTC_TIMESTAMP()</code></p> <p>Returns the current UTC date and time as a timestamp value.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#sysdate","title":"SYSDATE","text":"<ul> <li> <p><code>SYSDATE()</code></p> <p>Equivalent to <code>UTC_TIMESTAMP</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#utc_date","title":"UTC_DATE","text":"<ul> <li> <p><code>UTC_DATE()</code></p> <p>Returns the current UTC date as a Timestamp value.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#string-functions","title":"String Functions","text":"<p>BodoSQL currently supports the following string functions:</p>"},{"location":"api_docs/BodoSQL/#lower","title":"LOWER","text":"<ul> <li> <p><code>LOWER(str)</code></p> <p>Converts the string scalar/column to lower case.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#lcase","title":"LCASE","text":"<ul> <li> <p><code>LCASE(str)</code></p> <p>Same as <code>LOWER</code>.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#upper","title":"UPPER","text":"<ul> <li> <p><code>UPPER(str)</code></p> <p>Converts the string scalar/column to upper case.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#ucase","title":"UCASE","text":"<ul> <li> <p><code>UCASE(str)</code></p> <p>Same as <code>UPPER</code>.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#concat","title":"CONCAT","text":"<ul> <li> <p><code>CONCAT(str_0, str_1, ...)</code></p> <p>Concatenates the strings together. Requires at least two arguments.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#concat_ws","title":"CONCAT_WS","text":"<ul> <li> <p><code>CONCAT_WS(str_separator, str_0, str_1, ...)</code></p> <p>Concatenates the strings together, with the specified separator. Requires at least three arguments</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#substring","title":"SUBSTRING","text":"<ul> <li> <p><code>SUBSTRING(str, start_index, len)</code></p> <p>Takes a substring of the specified string, starting at the specified index, of the specified length. <code>start_index = 1</code> specifies the first character of the string, <code>start_index = -1</code> specifies the last character of the string. <code>start_index = 0</code> causes the function to return empty string. If <code>start_index</code> is positive and greater than the length of the string, returns an empty string. If <code>start_index</code> is negative, and has an absolute value greater than the length of the string, the behavior is equivalent to <code>start_index = 1</code>.</p> <p>For example:</p> <pre><code>SUBSTRING('hello world', 1, 5) =='hello'\nSUBSTRING('hello world', -5, 7) =='world'\nSUBSTRING('hello world', -20, 8) =='hello wo'\nSUBSTRING('hello world', 0, 10) ==''\n</code></pre> </li> </ul>"},{"location":"api_docs/BodoSQL/#mid","title":"MID","text":"<ul> <li><code>MID(str, start_index, len)</code></li> </ul> <p>Equivalent to <code>SUBSTRING</code></p>"},{"location":"api_docs/BodoSQL/#substr","title":"SUBSTR","text":"<ul> <li> <p><code>SUBSTR(str, start_index, len)</code></p> <p>Equivalent to <code>SUBSTRING</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#left","title":"LEFT","text":"<ul> <li> <p><code>LEFT(str, n)</code></p> <p>Takes a substring of the specified string consisting of the leftmost n characters</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#right","title":"RIGHT","text":"<ul> <li> <p><code>RIGHT(str, n)</code></p> <p>Takes a substring of the specified string consisting of the rightmost n characters</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#repeat","title":"REPEAT","text":"<ul> <li> <p><code>REPEAT(str, len)</code></p> <p>Extends the specified string to the specified length by repeating the string. Will truncate the string If the string's length is less than the len argument</p> <p>For example:</p> <pre><code>REPEAT('abc', 7) =='abcabca'\nREPEAT('hello world', 5) =='hello'\n</code></pre> </li> </ul>"},{"location":"api_docs/BodoSQL/#strcmp","title":"STRCMP","text":"<ul> <li> <p><code>STRCMP(str1, str2)</code></p> <p>Compares the two strings lexicographically. If <code>str1 &gt; str2</code>, return 1. If <code>str1 &lt; str2</code>, returns -1. If <code>str1 == str2</code>, returns 0.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#reverse","title":"REVERSE","text":"<ul> <li> <p><code>REVERSE(str)</code></p> <p>Returns the reversed string.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#ord","title":"ORD","text":"<ul> <li> <p><code>ORD(str)</code></p> <p>Returns the integer value of the unicode representation of the first character of the input string. returns 0 when passed the empty string</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#char","title":"CHAR","text":"<ul> <li> <p><code>CHAR(int)</code></p> <p>Returns the character of the corresponding unicode value. Currently only supported for ASCII characters (0 to 127, inclusive)</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#space","title":"SPACE","text":"<ul> <li> <p><code>SPACE(int)</code></p> <p>Returns a string containing the specified number of spaces.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#ltrim","title":"LTRIM","text":"<ul> <li> <p><code>LTRIM(str[, chars])</code></p> <p>Removes leading characters from a string column/literal str. These characters are specified by chars or are whitespace.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#rtrim","title":"RTRIM","text":"<ul> <li> <p><code>RTRIM(str[, chars])</code></p> <p>Removes trailing characters from a string column/literal str. These characters are specified by chars or are whitespace.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#trim","title":"TRIM","text":"<ul> <li> <p><code>TRIM(str[, chars])</code></p> <p>Returns the input string, will remove all spaces from the left and right of the string</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#substring_index","title":"SUBSTRING_INDEX","text":"<ul> <li> <p><code>SUBSTRING_INDEX(str, delimiter_str, n)</code></p> <p>Returns a substring of the input string, which contains all characters that occur before n occurrences of the delimiter string. if n is negative, it will return all characters that occur after the last n occurrences of the delimiter string. If <code>num_occurrences</code> is 0, it will return the empty string</p> <p>For example: <pre><code>SUBSTRING_INDEX('1,2,3,4,5', ',', 2) =='1,2'\nSUBSTRING_INDEX('1,2,3,4,5', ',', -2) =='4,5'\nSUBSTRING_INDEX('1,2,3,4,5', ',', 0) ==''\n</code></pre></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#lpad","title":"LPAD","text":"<ul> <li> <p><code>LPAD(string, len, padstring)</code></p> <p>Extends the input string to the specified length, by appending copies of the padstring to the left of the string. If the input string's length is less than the len argument, it will truncate the input string.</p> <p>For example: <pre><code>LPAD('hello', 10, 'abc') =='abcabhello'\nLPAD('hello', 1, 'abc') =='h'\n</code></pre></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#rpad","title":"RPAD","text":"<ul> <li> <p><code>RPAD(string, len, padstring)</code></p> <p>Extends the input string to the specified length, by appending copies of the padstring to the right of the string. If the input string's length is less than the len argument, it will truncate the input string.</p> <p>For example: <pre><code>RPAD('hello', 10, 'abc') =='helloabcab'\nRPAD('hello', 1, 'abc') =='h'\n</code></pre></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#replace","title":"REPLACE","text":"<ul> <li> <p><code>REPLACE(base_string, substring_to_remove, string_to_substitute)</code></p> <p>Replaces all occurrences of the specified substring with the substitute string.</p> <p>For example: <pre><code>REPLACE('hello world', 'hello' 'hi') =='hi world'\n</code></pre></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#length","title":"LENGTH","text":"<ul> <li> <p><code>LENGTH(string)</code></p> <p>Returns the number of characters in the given string.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#editdistance","title":"EDITDISTANCE","text":"<ul> <li> <p><code>EDITDISTANCE(string0, string1[, max_distance])</code></p> <p>Returns the minimum edit distance between string0 and string1 according to Levenshtein distance. Optionally accepts a third argument specifying a maximum distance value. If the minimum edit distance between the two strings exceeds this value, then this value is returned instead. If it is negative, zero is returned.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#split_part","title":"SPLIT_PART","text":"<ul> <li> <p><code>SPLIT_PART(source, delimiter, part)</code></p> <p>Returns the substring of the source between certain occurrence of the delimiter string, the occurrence being specified by the part. I.e. if part=1, returns the substring before the first occurrence, and if part=2, returns the substring between the first and second occurrence. Zero is treated like 1. Negative indices are allowed. If the delimiter is empty, the source is treated like a single token. If the part is out of bounds, '' is returned.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#strtok","title":"STRTOK","text":"<ul> <li> <p><code>STRTOK(source[, delimiter[, part]])</code></p> <p>Tokenizes the source string by occurrences of any character in the delimiter string and returns the occurrence specified by the part. I.e. if part=1, returns the substring before the first occurrence, and if part=2, returns the substring between the first and second occurrence. Zero and negative indices are not allowed. Empty tokens are always skipped in favor of the next non-empty token. In any case where the only possible output is '', the output is <code>NULL</code>. The delimiter is optional and defaults to ' '. The part is optional and defaults to 1.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#position","title":"POSITION","text":"<ul> <li> <p><code>POSITION(str1, str2)</code></p> <p>Returns the 1-indexed location where <code>str1</code> first occurs in <code>str2</code>, or 0 if there is no occurrences of <code>str1</code> in <code>str2</code>.</p> <p>Note</p> <p>BodoSQL oes not currently support alternate syntax <code>POSITION(str1, str2)</code>, or binary data.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#charindex","title":"CHARINDEX","text":"<ul> <li> <p><code>CHARINDEX(str1, str2[, start_position])</code></p> <p>Equivalent to <code>POSITION(str1, str2)</code> when 2 arguments are provided. When the optional third argument is provided, it only starts searching at that index.</p> <p>Note</p> <p>Not currently supported on binary data.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#startswith","title":"STARTSWITH","text":"<ul> <li> <p><code>STARTSWITH(str1, str2)</code></p> <p>Returns whether <code>str2</code> is a prefix of <code>str1</code>.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#endswith","title":"ENDSWITH","text":"<ul> <li> <p><code>ENDSWITH(str1, str2)</code></p> <p>Returns whether <code>str2</code> is a suffix of <code>str1</code>.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#insert","title":"INSERT","text":"<ul> <li> <p><code>INSERT(str1, pos, len, str2)</code></p> <p>Inserts <code>str2</code> into <code>str1</code> at position <code>pos</code> (1-indexed), replacing the first <code>len</code> characters after <code>pos</code> in the process. If <code>len</code> is zero, inserts <code>str2</code> into <code>str1</code> without deleting any characters. If <code>pos</code> is one, prepends <code>str2</code> to <code>str1</code>. If <code>pos</code> is larger than the length of <code>str1</code>, appends <code>str2</code> to <code>str1</code>.</p> <p>Note</p> <p>Behavior when <code>pos</code> or <code>len</code> are negative is not well-defined at this time.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#sha2","title":"SHA2","text":"<ul> <li> <p><code>SHA2(msg[, digest_size])</code></p> <p>Encodes the <code>msg</code> string using the <code>SHA-2</code> algorithm with the specified digest size (only values supported are, 224, 256, 384 and 512). Outputs the result as a hex-encoded string.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#sha2_hex","title":"SHA2_HEX","text":"<ul> <li> <p><code>SHA2_HEX(msg[, digest_size])</code></p> <p>Equivalent to <code>SHA2(msg[, digest_size])</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#md5","title":"MD5","text":"<ul> <li> <p><code>MD5(msg])</code></p> <p>Encodes the <code>msg</code> string using the <code>MD5</code> algorithm. Outputs the result as a hex-encoded string.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#md5_hex","title":"MD5_HEX","text":"<ul> <li> <p><code>MD5_HEX(msg)</code></p> <p>Equivalent to <code>MD5_HEX(msg)</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#regex-functions","title":"Regex Functions","text":"<p>BodoSQL currently uses Python's regular expression library via the <code>re</code> module. Although this may be subject to change, it means that there are several deviations from the behavior of Snowflake's regular expression functions (see here for snowflake documentation). The key points and major deviations are noted below:</p> <ul> <li> <p>Snowflake uses a superset of the POSIX ERE regular expression syntax. This means that BodoSQL can utilize several syntactic forms of regular expressions that Snowflake cannot (see here for Python re documentation). However, there are several features that POSIX ERE has that Python's <code>re</code> does not:</p> </li> <li> <p>POSIX character classes (see here for a full list). BodoSQL does support these as macros for character sets. In other words, <code>[[:lower:]]</code> is transformed into <code>[a-z]</code>. However, this form of replacement cannot be escaped. Additionally, any character classes that are supposed to include the null terminator <code>\\x00</code> instead start at <code>\\x01</code></p> </li> <li> <p>Equivalence classes (not supported by BodoSQL).</p> </li> <li> <p>Returning the longest match when using alternation patterns (BodoSQL returns the leftmost match).</p> </li> <li> <p>The regex functions can optionally take in a flag argument. The flag is a string whose characters control how matches to patterns occur. The following characters have meaning when contained in the flag string:</p> </li> <li> <p><code>'c'</code>: case-sensitive matching (the default behavior)</p> </li> <li><code>'i'</code>: case-insensitive matching (if both 'c' and 'i' are provided, whichever one occurs last is used)</li> <li><code>'m'</code>: allows anchor patterns to interact with the start/end of each line, not just the start/end of the entire string.</li> <li><code>'s'</code>: allows the <code>.</code> metacharacter to capture newline characters</li> <li> <p><code>'e'</code>: see <code>REGEXP_SUBSTR</code>/<code>REGEXP_INSTR</code></p> </li> <li> <p>Currently, BodoSQL supports the lazy <code>?</code> operator whereas Snowflake does not. So for example, in Snowflake, the pattern <code>`(.*?),'</code> would match with as many characters as possible so long as the last character was a comma. However, in BodoSQL, the match would end as soon as the first comma.</p> </li> <li> <p>Currently, BodoSQL supports the following regexp features which should crash when done in Snowflake: <code>(?...)</code>, <code>\\A</code>, <code>\\Z</code>, <code>\\1</code>, <code>\\2</code>, <code>\\3</code>, etc.</p> </li> <li> <p>Currently, BodoSQL requires the pattern argument and the flag argument (if provided) to be string literals as opposed to columns or expressions.</p> </li> <li> <p>Currently, extra backslashes may be required to escape certain characters if they have meaning in Python. The amount of backslashes required to properly escape a character depends on the usage.</p> </li> <li> <p>All matches are non-overlapping.</p> </li> <li> <p>If any of the numeric arguments are zero or negative, or the <code>group_num</code> argument is out of bounds, an error is raised. The only exception is <code>REGEXP_REPLACE</code>, which allows its occurrence argument to be zero.</p> </li> </ul> <p>BodoSQL currently supports the following regex functions:</p>"},{"location":"api_docs/BodoSQL/#regexp_like","title":"REGEXP_LIKE","text":"<ul> <li> <p><code>REGEXP_LIKE(str, pattern[, flag])</code></p> <p>Returns <code>true</code> if the entire string matches with the pattern. If <code>flag</code> is not provided, <code>''</code> is used.</p> <p>If the pattern is empty, then <code>true</code> is returned if the string is also empty.</p> <p>For example:</p> <ul> <li> <p>2 arguments: Returns <code>true</code> if <code>A</code> is a 5-character string where the first character is an a, the last character is a z, and the middle 3 characters are also lowercase characters (case-sensitive). <pre><code>SELECT REGEXP_LIKE(A, 'a[a-z]{3}z')\n</code></pre></p> </li> <li> <p>3 arguments: Returns <code>true</code> if <code>A</code> starts with the letters <code>'THE'</code> (case-insensitive). <pre><code>SELECT REGEXP_LIKE(A, 'THE.*', 'i')\n</code></pre></p> </li> </ul> </li> </ul>"},{"location":"api_docs/BodoSQL/#regexp_count","title":"REGEXP_COUNT","text":"<ul> <li> <p><code>REGEXP_COUNT(str, pattern[, position[, flag]])</code></p> <p>Returns the number of times the string contains matches to the pattern, starting at the location specified by the <code>position</code> argument (with 1-indexing). If <code>position</code> is not provided, <code>1</code> is used. If <code>flag</code> is not provided, <code>''</code> is used.</p> <p>If the pattern is empty, 0 is returned.</p> <p>For example:</p> <ul> <li> <p>2 arguments: Returns the number of times that any letters occur in <code>A</code>. <pre><code>SELECT REGEXP_COUNT(A, '[[:alpha:]]')\n</code></pre></p> </li> <li> <p>3 arguments: Returns the number of times that any digit characters occur in <code>A</code>, not including the first 5 characters. <pre><code>SELECT REGEXP_COUNT(A, '\\d', 6)\n</code></pre></p> </li> <li> <p>4 arguments: Returns the number of times that a substring occurs in <code>A</code> that contains two ones with any character (including newlines) in between. <pre><code>SELECT REGEXP_COUNT(A, '1.1', 1, 's')\n</code></pre></p> </li> </ul> </li> </ul>"},{"location":"api_docs/BodoSQL/#regexp_replace","title":"REGEXP_REPLACE","text":"<ul> <li> <p><code>REGEXP_REPLACE(str, pattern[, replacement[, position[, occurrence[, flag]]]])</code></p> <p>Returns the version of the inputted string where each match to the pattern is replaced by the replacement string, starting at the location specified by the <code>position</code> argument (with 1-indexing). The occurrence argument specifies which match to replace, where 0 means replace all occurrences. If <code>replacement</code> is not provided, <code>''</code> is used. If <code>position</code> is not provided, <code>1</code> is used. If <code>occurrence</code> is not provided, <code>0</code> is used. If <code>flag</code> is not provided, <code>''</code> is used.</p> <p>If there are an insufficient number of matches, or the pattern is empty, the original string is returned.</p> <p>Note</p> <p>back-references in the replacement pattern are supported, but may require additional backslashes to work correctly.</p> <p>For example:</p> <ul> <li> <p>2 arguments: Deletes all whitespace in <code>A</code>. <pre><code>SELECT REGEXP_REPLACE(A, '[[:space:]]')\n</code></pre></p> </li> <li> <p>3 arguments: Replaces all occurrences of <code>'hate'</code> in <code>A</code> with <code>'love'</code> (case-sensitive). <pre><code>SELECT REGEXP_REPLACE(A, 'hate', 'love')\n</code></pre></p> </li> <li> <p>4 arguments: Replaces all occurrences of two consecutive digits in <code>A</code> with the same two digits reversed, excluding the first 2 characters. <pre><code>SELECT REGEXP_REPLACE(A, '(\\d)(\\d)', '\\\\\\\\2\\\\\\\\1', 3)\n</code></pre></p> </li> <li> <p>5 arguments: Replaces the first character in <code>A</code> with an underscore. <pre><code>SELECT REGEXP_REPLACE(A, '^.', '_', 1, 2)\n</code></pre></p> </li> <li> <p>6 arguments: Removes the first and last word from each line of <code>A</code> that contains at least 3 words. <pre><code>SELECT REGEXP_REPLACE(A, '^\\w+ (.*) \\w+$', '\\\\\\\\1', 0, 1, 'm')\n</code></pre></p> </li> </ul> </li> </ul>"},{"location":"api_docs/BodoSQL/#regexp_substr","title":"REGEXP_SUBSTR","text":"<ul> <li> <p><code>REGEXP_SUBSTR(str, pattern[, position[, occurrence[, flag[, group_num]]]])</code></p> <p>Returns the substring of the original string that caused a match with the pattern, starting at the location specified by the <code>position</code> argument (with 1-indexing). The occurrence argument specifies which match to extract (with 1-indexing). If <code>position</code> is not provided, <code>1</code> is used. If <code>occurrence</code> is not provided, <code>1</code> is used. If <code>flag</code> is not provided, <code>''</code> is used. If <code>group_num</code> is not provided, and <code>flag</code> contains <code>'e</code>', <code>1</code> is used. If <code>group_num</code> is provided but the flag does not contain <code>e</code>, then it behaves as if it did. If the flag does contain <code>e</code>, then one of the subgroups of the match is returned instead of the entire match. The subgroup returned corresponds to the <code>group_num</code> argument (with 1-indexing).</p> <p>If there are an insufficient number of matches, or the pattern is empty, <code>NULL</code> is returned.</p> <p>For example:</p> <ul> <li> <p>2 arguments: Returns the first number that occurs inside of <code>A</code>. <pre><code>SELECT REGEXP_SUBSTR(A, '\\d+')\n</code></pre></p> </li> <li> <p>3 arguments: Returns the first punctuation symbol that occurs inside of <code>A</code>, excluding the first 10 characters. <pre><code>SELECT REGEXP_SUBSTR(A, '[[:punct:]]', 11)\n</code></pre></p> </li> <li> <p>4 arguments: Returns the fourth occurrence of two consecutive lowercase vowels in <code>A</code>. <pre><code>SELECT REGEXP_SUBSTR(A, '[aeiou]{2}', 1, 4)\n</code></pre></p> </li> <li> <p>5 arguments: Returns the first 3+ character substring of <code>A</code> that starts with and ends with a vowel (case-insensitive, and it can contain newline characters). <pre><code>SELECT REGEXP_SUBSTR(A, '[aeiou].+[aeiou]', 1, 1, 'im')\n</code></pre></p> </li> <li> <p>6 arguments: Looks for third occurrence in <code>A</code> of a number followed by a colon, a space, and a word that starts with <code>'a'</code> (case-sensitive) and returns the word that starts with <code>'a'</code>. <pre><code>SELECT REGEXP_SUBSTR(A, '(\\d+): (a\\w+)', 1, 3, 'e', 2)\n</code></pre></p> </li> </ul> </li> </ul>"},{"location":"api_docs/BodoSQL/#regexp_instr","title":"REGEXP_INSTR","text":"<ul> <li> <p><code>REGEXP_INSTR(str, pattern[, position[, occurrence[, option[, flag[, group_num]]]]])</code></p> <p>Returns the location within the original string that caused a match with the pattern, starting at the location specified by the <code>position</code> argument (with 1-indexing). The occurrence argument specifies which match to extract (with 1-indexing). The option argument specifies whether to return the start of the match (if <code>0</code>) or the first location after the end of the match (if <code>1</code>). If <code>position</code> is not provided, <code>1</code> is used. If <code>occurrence</code> is not provided, <code>1</code> is used. If <code>option</code> is not provided, <code>0</code> is used. If <code>flag</code> is not provided, <code>''</code> is used. If <code>group_num</code> is not provided, and <code>flag</code> contains <code>'e</code>', <code>1</code> is used. If <code>group_num</code> is provided but the flag does not contain <code>e</code>, then it behaves as if it did. If the flag does contain <code>e</code>, then the location of one of the subgroups of the match is returned instead of the location of the entire match. The subgroup returned corresponds to the <code>group_num</code> argument (with 1-indexing).</p> <p>If there are an insufficient number of matches, or the pattern is empty, <code>0</code> is returned.</p> <ul> <li> <p>2 arguments: Returns the index of the first <code>'#'</code> in <code>A</code>. <pre><code>SELECT REGEXP_INSTR(A, '#')\n</code></pre></p> </li> <li> <p>3 arguments: Returns the starting index of the first occurrence of 3 consecutive digits in <code>A</code>, excluding the first 3 characters.  ```sql SELECT REGEXP_INSTR(A, '\\d{3}', 4) <pre><code>- 4 arguments: Returns the starting index of the 9th word sandwiched between angle brackets in `A`.\n```sql\nSELECT REGEXP_INSTR(A, '&lt;\\w+&gt;', 1, 9)\n</code></pre></p> </li> <li> <p>5 arguments: Returns the ending index of the first substring of <code>A</code> that starts and ends with non-ascii characters. <pre><code>SELECT REGEXP_INSTR(A, '[^[:ascii:]].*[^[:ascii:]]', 1, 1, 1)\n</code></pre></p> </li> <li> <p>6 arguments: Returns the starting index of the second line of <code>A</code> that begins with an uppercase vowel. <pre><code>SELECT REGEXP_INSTR(A, '^[AEIOU].*', 1, 2, 0, 'm')\n</code></pre></p> </li> <li> <p>7 arguments: Looks for the first substring of <code>A</code> that has the format of a name in a phonebook (i.e. <code>Lastname, Firstname</code>) and returns the starting index of the first name. <pre><code>SELECT REGEXP_INSTR(A, '([[:upper]][[:lower:]]+), ([[:upper]][[:lower:]]+)', 1, 1, 0, 'e', 2)\n</code></pre></p> </li> </ul> </li> </ul>"},{"location":"api_docs/BodoSQL/#json-functions","title":"JSON Functions","text":"<p>BodoSQL currently supports the following JSON functions:</p>"},{"location":"api_docs/BodoSQL/#json_extract_path_text","title":"JSON_EXTRACT_PATH_TEXT","text":"<ul> <li> <p><code>JSON_EXTRACT_PATH_TEXT(data, path)</code></p> <p>Parses the string <code>data</code> as if it were JSON data, then extracts values from within (possibly multiple times if the data is nested) using the string <code>path</code>.</p> <p>Obeys the following specification: https://docs.snowflake.com/en/sql-reference/functions/json_extract_path_text.html</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#control-flow-functions","title":"Control Flow Functions","text":""},{"location":"api_docs/BodoSQL/#decode","title":"DECODE","text":"<ul> <li> <p><code>DECODE(Arg0, Arg1, Arg2, ...)</code></p> <p>When <code>Arg0</code> is <code>Arg1</code>, outputs <code>Arg2</code>. When <code>Arg0</code> is <code>Arg3</code>, outputs <code>Arg4</code>. Repeats until it runs out of pairs of arguments. At this point, if there is one remaining argument, this is used as a default value. If not, then the output is <code>NULL</code>.</p> <p>Note</p> <p>Treats <code>NULL</code> as a literal value that can be matched on.</p> <p>Therefore, the following:</p> <pre><code>DECODE(A, NULL, 0, 'x', 1, 'y', 2, 'z', 3, -1)\n</code></pre> <p>Is logically equivalent to:</p> <pre><code>CASE WHEN A IS NULL THEN 0\nWHEN A = 'x' THEN 1\nWHEN A = 'y' THEN 2\nWHEN A = 'z' THEN 3\nELSE -1 END\n</code></pre> </li> </ul>"},{"location":"api_docs/BodoSQL/#equal_null","title":"EQUAL_NULL","text":"<ul> <li> <p><code>EQUAL_NULL(A, B)</code></p> <p>Returns true if A and B are both <code>NULL</code>, or both non-null and equal to each other.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#if","title":"IF","text":"<ul> <li> <p><code>IF(Cond, TrueValue, FalseValue)</code></p> <p>Returns <code>TrueValue</code> if cond is true, and <code>FalseValue</code> if cond is false. Logically equivalent to:</p> <pre><code>CASE WHEN Cond THEN TrueValue ELSE FalseValue END\n</code></pre> </li> </ul>"},{"location":"api_docs/BodoSQL/#iff","title":"IFF","text":"<ul> <li> <p><code>IFF(Cond, TrueValue, FalseValue)</code></p> <p>Equivalent to <code>IF</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#ifnull","title":"IFNULL","text":"<ul> <li> <p><code>IFNULL(Arg0, Arg1)</code></p> <p>Returns <code>Arg1</code> if <code>Arg0</code> is <code>null</code>, and otherwise returns <code>Arg1</code>. If arguments do not have the same type, BodoSQL will attempt to cast them all to a common type, which is currently undefined behavior.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#zeroifnull","title":"ZEROIFNULL","text":"<ul> <li> <p><code>ZEROIFNULL(Arg0, Arg1)</code></p> <p>Equivalent to <code>IFNULL(Arg0, 0)</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#nvl","title":"NVL","text":"<ul> <li> <p><code>NVL(Arg0, Arg1)</code></p> <p>Equivalent to <code>IFNULL</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#nvl2","title":"NVL2","text":"<ul> <li> <p><code>NVL2(Arg0, Arg1, Arg2)</code></p> <p>Equivalent to <code>NVL(NVL(Arg0, Arg1), Arg2)</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#nullif","title":"NULLIF","text":"<ul> <li> <p><code>NULLIF(Arg0, Arg1)</code></p> <p>Returns <code>null</code> if the <code>Arg0</code> evaluates to true, and otherwise returns <code>Arg1</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#nullifzero","title":"NULLIFZERO","text":"<ul> <li> <p><code>NULLIFZERO(Arg0)</code></p> <p>Equivalent to <code>NULLIF(Arg0, 0)</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#coalesce","title":"COALESCE","text":"<ul> <li> <p><code>COALESCE(A, B, C, ...)</code></p> <p>Returns the first non-<code>NULL</code> argument, or <code>NULL</code> if no non-<code>NULL</code> argument is found. Requires at least two arguments. If Arguments do not have the same type, BodoSQL will attempt to cast them to a common data type, which is currently undefined behavior.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#window-functions","title":"Window Functions","text":"<p>Window functions can be used to compute an aggregation across a row and its surrounding rows. Most window functions have the following syntax:</p> <p><pre><code>SELECT WINDOW_FN(ARG1, ..., ARGN) OVER (PARTITION BY PARTITION_COLUMN_1, ..., PARTITION_COLUMN_N ORDER BY SORT_COLUMN_1, ..., SORT_COLUMN_N ROWS BETWEEN &lt;LOWER_BOUND&gt; AND &lt;UPPER_BOUND&gt;) FROM table_name\n</code></pre> The <code>ROWS BETWEEN ROWS BETWEEN &lt;LOWER_BOUND&gt; AND &lt;UPPER_BOUND&gt;</code> section is used to specify the window over which to compute the function. A bound can can come before the current row, using <code>PRECEDING</code> or after the current row, using <code>FOLLOWING</code>. The bounds can be relative (i.e. <code>N PRECEDING</code> or <code>N FOLLOWING</code>), where <code>N</code> is a positive integer, or they can be absolute (i.e. <code>UNBOUNDED PRECEDING</code> or <code>UNBOUNDED FOLLOWING</code>).</p> <p>For example:</p> <p><pre><code>SELECT SUM(A) OVER (PARTITION BY B ORDER BY C ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING) FROM table1\n</code></pre> This query computes the sum of every 3 rows, i.e. the sum of a row of interest, its preceding row, and its following row.</p> <p>In contrast:</p> <p><pre><code>SELECT SUM(A) OVER (PARTITION BY B ORDER BY C ROWS BETWEEN UNBOUNDED PRECEDING AND 0 FOLLOWING) FROM table1\n</code></pre> This query computes the cumulative sum over a row and all of its preceding rows.</p> <p>Note</p> <p>For most window functions, BodoSQL returns <code>NULL</code> if the specified window frame is empty or all <code>NULL</code>. Exceptions to this behavior are noted.</p> <p>Window functions perform a series of steps as followed:</p> <ol> <li>Partition the data by <code>PARTITION_COLUMN</code>. This is effectively a groupby operation on <code>PARTITION_COLUMN</code>.</li> <li>Sort each group as specified by the <code>ORDER BY</code> clause.</li> <li>Perform the calculation over the specified window, i.e. the newly ordered subset of data.</li> <li>Shuffle the data back to the original ordering.</li> </ol> <p>For BodoSQL, <code>PARTITION BY</code> is required, but <code>ORDER BY</code> is optional for most functions and <code>ROWS BETWEEN</code> is optional for all of them. If <code>ROWS BETWEEN</code> is not specified then it defaults to either computing the result over the entire window (if no <code>ORDER BY</code> clause is specified) or to using the window <code>UNBOUNDED PRECEDING TO CURRENT ROW</code> (if there is an <code>ORDER BY</code> clause).</p> <p>Note</p> <p><code>RANGE BETWEEN</code> is not currently supported.</p> <p>Currently, BodoSQL supports the following Window functions:</p> <p>Note</p> <p>If a window frame contains <code>NaN</code> values, the output may diverge from Snowflake's behavior. When a <code>NaN</code> value enters a window, any window function that combines the results with arithmetic (e.g. <code>SUM</code>, <code>AVG</code>, <code>VARIANCE</code>, etc.) will output <code>NaN</code> until the <code>NaN</code> value has exited the window.</p>"},{"location":"api_docs/BodoSQL/#count_1","title":"COUNT","text":"<ul> <li> <p><code>COUNT(*)</code></p> <p>Compute the number of entries in a window, including <code>NULL</code>.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#sum_1","title":"SUM","text":"<ul> <li> <p><code>SUM(COLUMN_EXPRESSION)</code></p> <p>Compute the sum over the window or <code>NULL</code> if the window is empty.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#avg_1","title":"AVG","text":"<ul> <li> <p><code>AVG(COLUMN_EXPRESSION)</code></p> <p>Compute the average over the window or <code>NULL</code> if the window is empty.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#stddev_1","title":"STDDEV","text":"<ul> <li> <p><code>STDDEV(COLUMN_EXPRESSION)</code></p> <p>Compute the standard deviation for a sample over the window or <code>NULL</code> if the window is empty.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#stddev_pop_1","title":"STDDEV_POP","text":"<ul> <li> <p><code>STDDEV_POP(COLUMN_EXPRESSION)</code></p> <p>Compute the standard deviation for a population over the window or <code>NULL</code> if the window is empty.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#variance_1","title":"VARIANCE","text":"<ul> <li> <p><code>VARIANCE(COLUMN_EXPRESSION)</code></p> <p>Compute the variance for a sample over the window or <code>NULL</code> if the window is empty.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#var_pop_1","title":"VAR_POP","text":"<ul> <li> <p><code>VAR_POP(COLUMN_EXPRESSION)</code></p> <p>Compute the variance for a population over the window or <code>NULL</code> if the window is empty.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#covar_samp","title":"COVAR_SAMP","text":"<ul> <li> <p><code>COVAR_SAMP(Y, X)</code></p> <p>Compute the sample covariance over the window of both inputs, or <code>NULL</code> if the window is empty.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#covar_pop","title":"COVAR_POP","text":"<ul> <li> <p><code>COVAR_POP(Y, X)</code></p> <p>Compute the population covariance over the window of both inputs, or <code>NULL</code> if the window is empty.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#corr","title":"CORR","text":"<ul> <li> <p><code>CORR(Y, X)</code></p> <p>Compute the correlation over the window of both inputs, or <code>NULL</code> if the window is empty. Equivalent to <code>COVAR(Y, X) / (STDDEV_POP(Y) * STDDEV_POP(X))</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#max_1","title":"MAX","text":"<ul> <li> <p><code>MAX(COLUMN_EXPRESSION)</code></p> <p>Compute the maximum value over the window or <code>NULL</code> if the window is empty.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#min_1","title":"MIN","text":"<ul> <li> <p><code>MIN(COLUMN_EXPRESSION)</code></p> <p>Compute the minimum value over the window or <code>NULL</code> if the window is empty.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#count_2","title":"COUNT","text":"<ul> <li> <p><code>COUNT(COLUMN_EXPRESSION)</code></p> <p>Compute the number of non-<code>NULL</code> entries in a window, or zero if the window is empty.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#count_if_1","title":"COUNT_IF","text":"<ul> <li> <p><code>COUNT_IF(BOOLEAN_COLUMN_EXPRESSION)</code></p> <p>Compute the number of <code>true</code> entries in a boolean column, or zero if the window is empty.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#median","title":"MEDIAN","text":"<ul> <li> <p><code>MEDIAN(COLUMN_EXPRESSION)</code></p> <p>Compute the median over the window, or <code>NULL</code> if the window is empty.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#mode_1","title":"MODE","text":"<ul> <li> <p><code>MODE(COLUMN_EXPRESSION)</code></p> <p>Returns the most frequent element in the window, or <code>NULL</code> if the window is empty.</p> <p>Note</p> <p>In case of a tie, BodoSQL will choose a value arbitrarily based on performance considerations.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#skew_1","title":"SKEW","text":"<ul> <li> <p><code>SKEW(COLUMN_EXPRESSION)</code></p> <p>Compute the skew over the window, or <code>NULL</code> if the window contains fewer than 3 non-<code>NULL</code> entries.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#kurtosis_1","title":"KURTOSIS","text":"<ul> <li> <p><code>KURTOSIS(COLUMN_EXPRESSION)</code></p> <p>Compute the skew over the window, or <code>NULL</code> if the window contains fewer than 4 non-<code>NULL</code> entries.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#bitor_agg_1","title":"BITOR_AGG","text":"<ul> <li> <p><code>BITOR_AGG</code></p> <p>Outputs the bitwise OR of every input in the window, or <code>NULL</code> if the window has no non-<code>NULL</code> elements. Accepts floating point values, integer values, and strings. Strings are interpreted directly as numbers, converting to 64-bit floating point numbers.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#boolor_agg_1","title":"BOOLOR_AGG","text":"<ul> <li> <p><code>BOOLOR_AGG</code></p> <p>Outputs <code>true</code> if there is at least 1 non-zero<code>element in the window, or</code>#!sql NULL<code>if the window has no non-</code>#!sql NULL` elements.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#booland_agg_1","title":"BOOLAND_AGG","text":"<ul> <li> <p><code>BOOLAND_AGG</code></p> <p>Outputs <code>true</code> if every element in the window that is non-<code>NULL</code> is also non-zero, or <code>NULL</code> if the window has no non-<code>NULL</code> elements.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#boolxor_agg_1","title":"BOOLXOR_AGG","text":"<ul> <li> <p><code>BOOLXOR_AGG</code></p> <p>Outputs <code>true</code> if there is at exactly 1 non-zero element in the window, or <code>NULL</code> if the window has no non-<code>NULL</code> elements.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#lead","title":"LEAD","text":"<ul> <li> <p><code>LEAD(COLUMN_EXPRESSION, [N], [FILL_VALUE])</code></p> <p>Returns the row that follows the current row by N. If N is not specified, defaults to 1. If FILL_VALUE is not specified, defaults to <code>NULL</code>. If there are fewer than N rows the follow the current row in the window, it returns FILL_VALUE. N must be a literal non-negative integer if specified. FILL_VALUE must be a scalar if specified.</p> <p>Note</p> <ul> <li>At this time Bodo does not support the <code>IGNORE NULLS</code> keyword.</li> <li>This function cannot be used with <code>ROWS BETWEEN</code>.</li> </ul> </li> </ul>"},{"location":"api_docs/BodoSQL/#lag","title":"LAG","text":"<ul> <li> <p><code>LAG(COLUMN_EXPRESSION, [N], [FILL_VALUE])</code></p> <p>Returns the row that precedes the current row by N. If N is not specified, defaults to 1. If FILL_VALUE is not specified, defaults to <code>NULL</code>. If there are fewer than N rows that precede the current row in the window, it returns FILL_VALUE. N must be a literal non-negative integer if specified. FILL_VALUE must be a scalar if specified.</p> <p>Note</p> <ul> <li>At this time BodoSQL does not support the <code>IGNORE NULLS</code> keyword.</li> <li>This function cannot be used with <code>ROWS BETWEEN</code>.</li> </ul> </li> </ul>"},{"location":"api_docs/BodoSQL/#first_value","title":"FIRST_VALUE","text":"<ul> <li> <p><code>FIRST_VALUE(COLUMN_EXPRESSION)</code></p> <p>Select the first value in the window or <code>NULL</code> if the window is empty. Select the first value in the window.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#last_value","title":"LAST_VALUE","text":"<ul> <li> <p><code>LAST_VALUE(COLUMN_EXPRESSION)</code></p> <p>Select the last value in the window or <code>NULL</code> if the window is empty. Select the last value in the window.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#nth_value","title":"NTH_VALUE","text":"<ul> <li> <p><code>NTH_VALUE(COLUMN_EXPRESSION, N)</code></p> <p>Select the Nth value in the window (1-indexed) or <code>NULL</code> if the window is empty. If N is greater or than the window size, this returns <code>NULL</code>. Select the Nth value in the window (1-indexed). If N is greater or than the window size, this returns <code>NULL</code>.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#any_value_1","title":"ANY_VALUE","text":"<ul> <li> <p><code>ANY_VALUE(COLUMN_EXPRESSION)</code></p> <p>Select an arbitrary value in the window or <code>NULL</code> if the window is empty.</p> <p>Note</p> <p>Currently, BodoSQL always selects the first value, but this is subject to change at any time.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#ntile","title":"NTILE","text":"<ul> <li> <p><code>NTILE(N)</code></p> <p>Divides the partitioned groups into N buckets based on ordering. For example if N=3 and there are 30 rows in a partition, the first 10 are assigned 1, the next 10 are assigned 2, and the final 10 are assigned 3. In cases where the number of rows cannot be evenly divided by the number of buckets, the first buckets will have one more value than the last bucket. For example, if N=4 and there are 22 rows in a partition, the first 6 are assigned 1, the next 6 are assigned 2, the next 5 are assigned 3, and the last 5 are assigned 4.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#rank","title":"RANK","text":"<ul> <li> <p><code>RANK()</code></p> <p>Compute the rank of each row based on the value(s) in the row relative to all value(s) within the partition. The rank begins with 1 and increments by one for each succeeding value. Duplicate value(s) will produce the same rank, producing gaps in the rank (compare with <code>DENSE_RANK</code>). <code>ORDER BY</code> is required for this function.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#dense_rank","title":"DENSE_RANK","text":"<ul> <li> <p><code>DENSE_RANK()</code></p> <p>Compute the rank of each row based on the value(s) in the row relative to all value(s) within the partition without producing gaps in the rank (compare with <code>RANK</code>). The rank begins with 1 and increments by one for each succeeding value. Rows with the same value(s) produce the same rank. <code>ORDER BY</code> is required for this function.</p> </li> </ul> <p>Note</p> <p>To compare <code>RANK</code> and <code>DENSE_RANK</code>, on input array <code>['a', 'b', 'b', 'c']</code>, <code>RANK</code> will output <code>[1, 2, 2, 4]</code> while <code>DENSE_RANK</code> outputs <code>[1, 2, 2, 3]</code>.</p>"},{"location":"api_docs/BodoSQL/#percent_rank","title":"PERCENT_RANK","text":"<ul> <li> <p><code>PERCENT_RANK()</code></p> <p>Compute the percentage ranking of the value(s) in each row based on the value(s) relative to all value(s) within the window partition. Ranking calculated using <code>RANK()</code> divided by the number of rows in the window partition minus one. Partitions with one row have <code>PERCENT_RANK()</code> of 0. <code>ORDER BY</code> is required for this function.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#cume_dist","title":"CUME_DIST","text":"<ul> <li> <p><code>CUME_DIST()</code></p> <p>Compute the cumulative distribution of the value(s) in each row based on the value(s) relative to all value(s) within the window partition. <code>ORDER BY</code> is required for this function.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#row_number","title":"ROW_NUMBER","text":"<ul> <li> <p><code>ROW_NUMBER()</code></p> <p>Compute an increasing row number (starting at 1) for each row. This function cannot be used with <code>ROWS BETWEEN</code>.</p> </li> </ul> <p>Note</p> <p>This window function is supported without a partition.</p>"},{"location":"api_docs/BodoSQL/#conditional_true_event","title":"CONDITIONAL_TRUE_EVENT","text":"<ul> <li> <p><code>CONDITIONAL_TRUE_EVENT(BOOLEAN_COLUMN_EXPRESSION)</code></p> <p>Computes a counter within each partition that starts at zero and increases by 1 each time the boolean column's value is <code>true</code>. <code>ORDER BY</code> is required for this function.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#conditional_change_event","title":"CONDITIONAL_CHANGE_EVENT","text":"<ul> <li> <p><code>CONDITIONAL_CHANGE_EVENT(COLUMN_EXPRESSION)</code></p> <p>Computes a counter within each partition that starts at zero and increases by 1 each time the value inside the window changes. <code>NULL</code> does not count as a new/changed value. <code>ORDER BY</code> is required for this function.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#ratio_to_report","title":"RATIO_TO_REPORT","text":"<ul> <li> <p><code>RATIO_TO_REPORT(COLUMN_EXPRESSION)</code></p> <p>Returns an element in the window frame divided by the sum of all elements in the same window frame, or <code>NULL</code> if the window frame has a sum of zero. For example, if calculating <code>RATIO_TO_REPORT</code> on <code>[2, 5, NULL, 10, 3]</code> where the window is the entire partition, the answer is <code>[0.1, 0.25, NULL, 0.5, 0.15]</code>.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#casting-conversion-functions","title":"Casting / Conversion Functions","text":"<p>BodoSQL currently supports the following casting/conversion functions:</p>"},{"location":"api_docs/BodoSQL/#to_boolean","title":"TO_BOOLEAN","text":"<ul> <li> <p><code>TO_BOOLEAN(COLUMN_EXPRESSION)</code></p> <p>Casts the input to a boolean value. If the input is a string, it will be cast to <code>true</code> if it is <code>'true'</code>, <code>'t'</code>, <code>'yes'</code>, <code>'y'</code>, <code>'1'</code>, cast to <code>false</code> if it is <code>'false'</code>, <code>'f'</code>, <code>'no'</code>, <code>'n'</code>, <code>'0'</code>, and throw an error otherwise. If the input is an integer, it will be cast to <code>true</code> if it is non-zero and <code>false</code> if it is zero. If the input is a float, it will be cast to <code>true</code> if it is non-zero, <code>false</code> if it is zero, and throw an error on other inputs (e.g. <code>inf</code>) input. If the input is <code>NULL</code>, the output will be <code>NULL</code>.</p> <p>Example:</p> <p>We are given <code>table1</code> with columns <code>a</code> and <code>b</code> and <code>c</code> <pre><code>table1 = pd.DataFrame({\n'a': [1.1, 0, 2],\n'b': ['t', 'f', 'YES'],\n'c': [None, 1, 0]\n})\n</code></pre> upon query <pre><code>SELECT\nTO_BOOLEAN(a) AS a,\nTO_BOOLEAN(b) AS b,\nTO_BOOLEAN(c) AS c\nFROM table1;\n</code></pre> we will get the following output: <pre><code>       a      b      c\n0   True   True   &lt;NA&gt;\n1  False  False   True\n2   True   True  False\n</code></pre> Upon query <pre><code>SELECT TO_BOOLEAN('other')\n</code></pre> we see the following error: <pre><code>ValueError: invalid value for boolean conversion: string must be one of {'true', 't', 'yes', 'y', 'on', '1'} or {'false', 'f', 'no', 'n', 'off', '0'}\n</code></pre></p> </li> </ul> <p>Note</p> <p>BodoSQL will read <code>NaN</code>s as <code>NULL</code> and thus will not produce errors on <code>NaN</code> input.</p>"},{"location":"api_docs/BodoSQL/#try_to_boolean","title":"TRY_TO_BOOLEAN","text":"<ul> <li> <p><code>TRY_TO_BOOLEAN(COLUMN_EXPRESSION)</code></p> <p>This is similar to <code>TO_BOOLEAN</code> except that it will return <code>NULL</code> instead of throwing an error invalid inputs.</p> <p>Example:</p> <p>We are given <code>table1</code> with columns <code>a</code> and <code>b</code> and <code>c</code> <pre><code>table1 = pd.DataFrame({\n'a': [1.1, 0, np.inf],\n'b': ['t', 'f', 'YES'],\n'c': [None, 1, 0]\n})\n</code></pre> upon query <pre><code>SELECT\nTRY_TO_BOOLEAN(a) AS a,\nTRY_TO_BOOLEAN(b) AS b,\nTRY_TO_BOOLEAN(c) AS c\nFROM table1;\n</code></pre> we will get the following output: <pre><code>    a      b      c\n0   True   True   &lt;NA&gt;\n1  False  False   True\n2   &lt;NA&gt;   True  False\n</code></pre></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#to_binary","title":"TO_BINARY","text":"<ul> <li> <p><code>TO_BINARY(COLUMN_EXPRESSION)</code></p> <p>Casts the input string to binary data. Currently only supports the <code>HEX</code> format. Raises an exception if the input is not a valid hex string: - Must have an even number of characters - All characters must be hexedecimal digits (0-9, a-f case insensitive)</p> <p>Example:</p> <p>We are given <code>table1</code> with columns <code>a</code> and <code>b</code>: <pre><code>table1 = pd.DataFrame({\n'a': [\"AB\", \"626f646f\", \"4a2F3132\"],\n'b': [\"ABC\", \"ZETA\", \"#fizz\"],\n})\n</code></pre> upon query <pre><code>SELECT TO_BINARY(a),\nFROM table1\n</code></pre> we will get the following output: <pre><code>    TO_BINARY(a)\n0   b'\\xab'             -- Binary encoding of the character '\u00bc'\n1   b'\\x62\\x6f\\x64\\x6f' -- Binary encoding of the string 'bodo'\n2   b'\\x4a\\x2f\\x31\\x32' -- Binary encoding of the string 'J/12'\n</code></pre> Upon query <pre><code>SELECT TO_BINARY(b)\nFROM table1\n</code></pre> we will see a value error because all of the values in column b are not valid hex strings: - <code>'ABC'</code> is 3 characters, which is not an even number - <code>'ZETA'</code> contains non-hex characters <code>Z</code> and <code>T</code> - <code>'#fizz'</code> is 5 characters, which is not an even number and contains non-hex characters <code>#</code>, <code>i</code> and <code>z</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#try_to_binary","title":"TRY_TO_BINARY","text":"<ul> <li> <p><code>TRY_TO_BINARY(COLUMN_EXPRESSION)</code></p> <p>See <code>TO_BINARY</code>. The only difference is that <code>TRY_TO_BINARY</code> will return <code>NULL</code> upon encountering an invalid expression instead of raising an exception.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#to_char","title":"TO_CHAR","text":"<ul> <li> <p><code>TO_CHAR(COLUMN_EXPRESSION)</code></p> <p>Casts the input to a string value. If the input is a boolean, it will be cast to <code>'true'</code> if it is <code>true</code> and <code>'false'</code> if it is <code>false</code>. If the input is <code>NULL</code>, the output will be <code>NULL</code>.</p> <p>Example:</p> <p>We are given <code>table1</code> with columns <code>a</code> and <code>b</code> and <code>c</code> <pre><code>table1 = pd.DataFrame({\n'a': [1.1, 0, 2],\n'b': [True, False, True],\n'c': [None, 1, 0]\n})\n</code></pre> upon query <pre><code>SELECT\nTO_CHAR(a) AS a,\nTO_CHAR(b) AS b,\nTO_CHAR(c) AS c\nFROM table1;\n</code></pre> we will get the following output: <pre><code>    a      b      c\n0  1.1   true   &lt;NA&gt;\n1    0  false      1\n2    2   true      0\n</code></pre></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#to_varchar","title":"TO_VARCHAR","text":"<ul> <li> <p><code>TO_VARCHAR(COLUMN_EXPRESSION)</code></p> <p>Alias for <code>TO_CHAR</code>.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#to_double","title":"TO_DOUBLE","text":"<ul> <li> <p><code>TO_DOUBLE(COLUMN_EXPRESSION)</code></p> <p>Converts a numeric or string expression to a double-precision floating-point number. For <code>NULL</code> input, the result is <code>NULL</code>. Fixed-point numbers are converted to floating point; the conversion cannot fail, but might result in loss of precision. Strings are converted as decimal or integer numbers. Scientific notation and special values (nan, inf, infinity) are accepted, case insensitive.</p> <p>Example:</p> <p>We are given <code>table1</code> with columns <code>a</code> and <code>b</code> <pre><code>table1 = pd.DataFrame({\n'a': [1, 0, 2],\n'b': ['3.7', '-2.2e-1', 'nan'],\n})\n</code></pre> upon query <pre><code>SELECT\nTO_DOUBLE(a) AS a,\nTO_DOUBLE(b) AS b,\nFROM table1;\n</code></pre> we will get the following output: <pre><code>       a      b\n0    1.0    3.7\n1    0.0  -0.22\n2    2.0   &lt;NA&gt;\n</code></pre></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#try_to_double","title":"TRY_TO_DOUBLE","text":"<ul> <li> <p><code>TRY_TO_DOUBLE(COLUMN_EXPRESSION)</code></p> <p>This is similar to <code>TO_DOUBLE</code> except that it will return <code>NULL</code> instead of throwing an error invalid inputs.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#to_number","title":"TO_NUMBER","text":"<ul> <li> <p><code>TO_NUMBER(EXPR)</code></p> <p>Converts an input expression to a fixed-point number. For <code>NULL</code> input, the output is <code>NULL</code>.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#to_numeric","title":"TO_NUMERIC","text":"<ul> <li> <p><code>TO_NUMERIC(EXPR)</code></p> <p>Equivalent to <code>TO_NUMBER(EXPR)</code>.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#to_decimal","title":"TO_DECIMAL","text":"<ul> <li> <p><code>TO_DECIMAL(EXPR)</code></p> <p>Equivalent to <code>TO_NUMBER(EXPR)</code>.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#try_to_number","title":"TRY_TO_NUMBER","text":"<ul> <li> <p><code>TRY_TO_NUMBER(EXPR)</code></p> <p>A special version of <code>TO_NUMBER</code> that performs the same operation (i.e. converts an input expression to a fixed-point number), but with error-handling support (i.e. if the conversion cannot be performed, it returns a <code>NULL</code> value instead of raising an error).</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#try_to_numeric","title":"TRY_TO_NUMERIC","text":"<ul> <li> <p><code>TRY_TO_NUMERIC(EXPR)</code></p> <p>Equivalent to <code>TRY_TO_NUMBER(EXPR)</code>.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#try_to_decimal","title":"TRY_TO_DECIMAL","text":"<ul> <li> <p><code>TRY_TO_DECIMAL(EXPR)</code></p> <p>Equivalent to <code>TRY_TO_NUMBER(EXPR)</code>.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#to_date","title":"TO_DATE","text":"<ul> <li> <p><code>TO_DATE(EXPR)</code></p> <p>Converts an input expression to a <code>DATE</code> type. The input can be one of the following:</p> <ul> <li><code>TO_DATE(timestamp_expr)</code> truncates the timestamp to its date value.</li> <li><code>TO_DATE(string_expr)</code> if the string is in date format (e.g. <code>\"1999-01-01\"</code>) then it is convrted to a corresponding date. If the string represents an integer (e.g. <code>\"123456\"</code>) then it is interpreted as the number of seconds/milliseconds/microseconds/nanoseconds since <code>1970-01-1</code>. Which unit it is interpreted as depends on the magnitude of the number, in accordance with the semantics used by Snowflake.</li> <li><code>TO_DATE(string_expr, format_expr)</code> uses the format string to specify how to parse the string expression as a date. Uses the format string rules as specified by Snowflake.</li> <li>If the input is <code>NULL</code>, outputs <code>NULL</code>.</li> </ul> <p>Raises an error if the input expression does not match one of these formats.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#try_to_date","title":"TRY_TO_DATE","text":"<ul> <li> <p><code>TRY_TO_DATE(EXPR)</code></p> <p>A special version of <code>TO_DATE</code> that performs the same operation but returns <code>NULL</code> instead of raising an error if something goes wrong during the conversion.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#to_time","title":"TO_TIME","text":"<ul> <li> <p><code>TO_TIME(EXPR)</code></p> <p>Converts an input expression to a <code>TIME</code> type. The input can be one of the following:</p> <ul> <li><code>TO_TIME(timestamp_expr)</code> extracts the time component from a timestamp.</li> <li><code>TO_TIME(string_expr)</code> if the string is in date format (e.g. <code>\"12:30:15\"</code>) then it is convrted to a corresponding time.</li> <li><code>TO_TIME(string_expr, format_expr)</code> uses the format string to specify how to parse the string expression as a time. Uses the format string rules as specified by Snowflake.</li> <li>If the input is <code>NULL</code>, outputs <code>NULL</code></li> </ul> <p>Raises an error if the input expression does not match one of these formats.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#try_to_time","title":"TRY_TO_TIME","text":"<ul> <li> <p><code>TRY_TO_TIME(EXPR)</code></p> <p>A special version of <code>TO_TIME</code> that performs the same operation but returns <code>NULL</code> instead of raising an error if something goes wrong during the conversion.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#to_timestamp","title":"TO_TIMESTAMP","text":"<ul> <li> <p><code>TO_TIMESTAMP(EXPR)</code></p> <p>Converts an input expression to a <code>TIMESTAMP</code> type without a timezone. The input can be one of the following:</p> <ul> <li><code>TO_TIMESTAMP(date_expr)</code> upcasts a <code>DATE</code> to a <code>TIMESTAMP</code>.</li> <li><code>TO_TIMESTAMP(integer)</code> creates a timestamp using the integer as the number of  seconds/milliseconds/microseconds/nanoseconds since <code>1970-01-1</code>. Which unit it is interpreted  as depends on the magnitude of the number, in accordance with the semantics used by Snowflake.</li> <li><code>TO_TIMESTAMP(integer, scale)</code> the same as the integer case except that the scale provided specifes which unit is used. THe scale can be an integer constant between 0 and 9, where 0 means seconds and 9 means nanoseconds.</li> <li><code>TO_TIMESTAMP(string_expr)</code> if the string is in timestamp format (e.g. <code>\"1999-12-31 23:59:30\"</code>) then it is convrted to a corresponding timestamp. If the string represents an integer (e.g. <code>\"123456\"</code>) then it uses the same rule as the corresponding input integer.</li> <li><code>TO_TIMESTAMP(string_expr, format_expr)</code> uses the format string to specify how to parse the string expression as a timestamp. Uses the format string rules as specified by Snowflake.</li> <li><code>TO_TIMESTAMP(timestamp_exr)</code> returns a timestamp expression representing the same moment in time, but changing the timezone if necessary to be timezone-naive.</li> <li>If the input is <code>NULL</code>, outputs <code>NULL</code></li> </ul> <p>Raises an error if the input expression does not match one of these formats.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#try_to_timestamp","title":"TRY_TO_TIMESTAMP","text":"<ul> <li> <p><code>TRY_TO_TIMESTAMP(EXPR)</code></p> <p>A special version of <code>TO_TIMESTAMP</code> that performs the same operation but returns <code>NULL</code> instead of raising an error if something goes wrong during the conversion.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#to_timestamp_ntz","title":"TO_TIMESTAMP_NTZ","text":"<ul> <li> <p><code>TO_TIMESTAMP_NTZ(EXPR)</code></p> <p>Equivalent to <code>TO_TIMESTAMP</code>.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#try_to_timestamp_ntz","title":"TRY_TO_TIMESTAMP_NTZ","text":"<ul> <li> <p><code>TRY_TO_TIMESTAMP_NTZ(EXPR)</code></p> <p>Equivalent to <code>TRY_TO_TIMESTAMP</code>.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#to_timestamp_ltz","title":"TO_TIMESTAMP_LTZ","text":"<ul> <li> <p><code>TO_TIMESTAMP_LTZ(EXPR)</code></p> <p>Equivalent to <code>TO_TIMESTAMP</code> except that it uses the local time zone.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#try_to_timestamp_ltz","title":"TRY_TO_TIMESTAMP_LTZ","text":"<ul> <li> <p><code>TRY_TO_TIMESTAMP_NTZ(EXPR)</code></p> <p>Equivalent to <code>TRY_TO_TIMESTAMP</code> except that it uses the local time zone.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#to_timestamp_tz","title":"TO_TIMESTAMP_TZ","text":"<ul> <li> <p><code>TO_TIMESTAMP_LTZ(EXPR)</code></p> <p>Equivalent to <code>TO_TIMESTAMP</code> except that it uses the local time zone, or keeps the original timezone if the input is a timezone-aware timestamp.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#try_to_timestamp_tz","title":"TRY_TO_TIMESTAMP_TZ","text":"<ul> <li> <p><code>TRY_TO_TIMESTAMP_NTZ(EXPR)</code></p> <p>Equivalent to <code>TRY_TO_TIMESTAMP</code> except that it uses the local time zone, or keeps the original timezone if the input is a timezone-aware timestamp.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#supported-dataframe-data-types","title":"Supported DataFrame Data Types","text":"<p>BodoSQL uses Pandas DataFrames to represent SQL tables in memory and converts SQL types to corresponding Python types which are used by Bodo. Below is a table mapping SQL types used in BodoSQL to their respective Python types and Bodo data types.</p> <p> SQL Type(s) Equivalent Python Type Bodo Data Type <code>TINYINT</code> <code>np.int8</code> <code>bodo.int8</code> <code>SMALLINT</code> <code>np.int16</code> <code>bodo.int16</code> <code>INT</code> <code>np.int32</code> <code>bodo.int32</code> <code>BIGINT</code> <code>np.int64</code> <code>bodo.int64</code> <code>FLOAT</code> <code>np.float32</code> <code>bodo.float32</code> <code>DECIMAL</code>, <code>DOUBLE</code> <code>np.float64</code> <code>bodo.float64</code> <code>VARCHAR</code>, <code>CHAR</code> <code>str</code> <code>bodo.string_type</code> <code>TIMESTAMP</code>, <code>DATE</code> <code>np.datetime64[ns]</code> <code>bodo.datetime64ns</code> <code>INTERVAL(day-time)</code> <code>np.timedelta64[ns]</code> <code>bodo.timedelta64ns</code> <code>BOOLEAN</code> <code>np.bool_</code> <code>bodo.bool_</code> <p></p> <p>BodoSQL can also process DataFrames that contain Categorical or Date columns. However, Bodo will convert these columns to one of the supported types, which incurs a performance cost. We recommend restricting your DataFrames to the directly supported types when possible.</p>"},{"location":"api_docs/BodoSQL/#nullable-and-unsigned-types","title":"Nullable and Unsigned Types","text":"<p>Although SQL does not explicitly support unsigned types, by default, BodoSQL maintains the exact types of the existing DataFrames registered in a [BodoSQLContext], including unsigned and non-nullable type behavior. If an operation has the possibility of creating null values or requires casting data, BodoSQL will convert the input of that operation to a nullable, signed version of the type.</p>"},{"location":"api_docs/BodoSQL/#supported-literals","title":"Supported Literals","text":"<p>BodoSQL supports the following literal types:</p> <ul> <li><code>boolean_literal</code></li> <li><code>datetime_literal</code></li> <li><code>float_literal</code></li> <li><code>integer_literal</code></li> <li><code>interval_literal</code></li> <li><code>string_literal</code></li> </ul>"},{"location":"api_docs/BodoSQL/#boolean_literal","title":"Boolean Literal","text":"<p>Syntax:</p> <pre><code>TRUE | FALSE\n</code></pre> <p>Boolean literals are case-insensitive.</p>"},{"location":"api_docs/BodoSQL/#datetime_literal","title":"Datetime Literal","text":"<p>Syntax:</p> <pre><code>DATE 'yyyy-mm-dd' |\nTIMESTAMP 'yyyy-mm-dd' |\nTIMESTAMP 'yyyy-mm-dd HH:mm:ss'\n</code></pre>"},{"location":"api_docs/BodoSQL/#float_literal","title":"Float Literal","text":"<p>Syntax:</p> <pre><code>[ + | - ] { digit [ ... ] . [ digit [ ... ] ] | . digit [ ... ] }\n</code></pre> <p>where digit is any numeral from 0 to 9</p>"},{"location":"api_docs/BodoSQL/#integer_literal","title":"Integer Literal","text":"<p>Syntax:</p> <pre><code>[ + | - ] digit [ ... ]\n</code></pre> <p>where digit is any numeral from 0 to 9</p>"},{"location":"api_docs/BodoSQL/#interval_literal","title":"Interval Literal","text":"<p>Syntax:</p> <pre><code>INTERVAL integer_literal interval_type\n</code></pre> <p>Where integer_literal is a valid integer literal and interval type is one of:</p> <pre><code>DAY[S] | HOUR[S] | MINUTE[S] | SECOND[S]\n</code></pre> <p>In addition, we also have limited support for <code>YEAR[S]</code> and <code>MONTH[S]</code>. These literals cannot be stored in columns and currently are only supported for operations involving add and sub.</p>"},{"location":"api_docs/BodoSQL/#string_literal","title":"String Literal","text":"<p>Syntax:</p> <pre><code>'char [ ... ]'\n</code></pre> <p>Where char is a character literal in a Python string.</p>"},{"location":"api_docs/BodoSQL/#bodosql_named_params","title":"BodoSQL Caching &amp; Parameterized Queries","text":"<p>BodoSQL can reuse Bodo caching to avoid recompilation when used inside a JIT function. BodoSQL caching works the same as Bodo, so for example:</p> <pre><code>@bodo.jit(cache=True)\ndef f(filename):\ndf1 = pd.read_parquet(filename)\nbc = bodosql.BodoSQLContext({\"table1\": df1})\ndf2 = bc.sql(\"SELECT A FROM table1 WHERE B &gt; 4\")\nprint(df2.A.sum())\n</code></pre> <p>This will avoid recompilation so long as the DataFrame scheme stored in <code>filename</code> has the same schema and the code does not change.</p> <p>To enable caching for queries with scalar parameters that you may want to adjust between runs, we introduce a feature called parameterized queries. In a parameterized query, the SQL query replaces a constant/scalar value with a variable, which we call a named parameter. In addition, the query is passed a dictionary of parameters which maps each name to a corresponding Python variable.</p> <p>For example, if in the above SQL query we wanted to replace 4 with other integers, we could rewrite our query as:</p> <pre><code>bc.sql(\"SELECT A FROM table1 WHERE B @var\", {\"var\": python_var})\n</code></pre> <p>Now anywhere that <code>@var</code> is used, the value of python_var at runtime will be used instead. This can be used in caching, because python_var can be provided as an argument to the JIT function itself, thus enabling changing the filter without recompiling. The full example looks like this:</p> <pre><code>@bodo.jit(cache=True)\ndef f(filename, python_var):\ndf1 = pd.read_parquet(filename)\nbc = bodosql.BodoSQLContext({\"table1\": df1})\ndf2 = bc.sql(\"SELECT A FROM table1 WHERE B @var\", {\"var\": python_var})\nprint(df2.A.sum())\n</code></pre> <p>Named parameters cannot be used in places that require a constant value to generate the correct implementation (e.g. TimeUnit in EXTRACT).</p>"},{"location":"api_docs/BodoSQL/#io-handling","title":"IO Handling","text":"<p>BodoSQL is great for compute based SQL queries, but you cannot yet access external storage directly from SQL. Instead, you can load and store data using Bodo and various Python APIs. Here we explain a couple common methods for loading data.</p>"},{"location":"api_docs/BodoSQL/#pandas-io-in-jit-function-with-sql-query","title":"Pandas IO in JIT function with SQL Query","text":"<p>The most common way to load data is to first use Pandas APIs to load a DataFrame inside a JIT function and then to use that DataFrame inside a BodoSQLContext.</p> <pre><code>def f(f1, f2):\ndf1 = pd.read_parquet(f1)\ndf2 = pd.read_parquet(f2)\nbc = bodosql.BodoSQLContext(\n{\n\"t1\": df1,\n\"t2\": df2,\n}\n)\nreturn bc.sql(\"select t1.A, t2.B from t1, t2 where t1.C &gt; 5 and t1.D = t2.D\")\n</code></pre>"},{"location":"api_docs/BodoSQL/#pandas-io-in-a-jit-function-separate-from-query","title":"Pandas IO in a JIT Function Separate from Query","text":"<p>The previous approach works well for most individual queries. However, when running several queries on the same dataset, it should ideally be loaded once for all queries. To do this, you can structure your JIT code to contain a single load function at the beginning. For example:</p> <pre><code>@bodo.jit\ndef load_data(f1, f2):\ndf1 = pd.read_parquet(f1)\ndf2 = pd.read_parquet(f2)\nreturn df1, df2\ndef q1(df1, df2):\nbc = bodosql.BodoSQLContext(\n{\n\"t1\": df1,\n\"t2\": df2,\n}\n)\nreturn bc.sql(\"select t1.A, t2.B from t1, t2 where t1.C &gt; 5 and t1.D = t2.D\")\n...\n@bodo.jit\ndef run_queries(f1, f2):\ndf1, df2 = load_data(f1, f2)\nprint(q1(df1, df2))\nprint(q2(df2))\nprint(q3(df1))\n...\nrun_queries(f1, f2)\n</code></pre> <p>This approach prevents certain optimizations, such as filter pushdown. However, the assumption here is that you will use the entire DataFrame across the various benchmarks, so no optimization is useful by itself. In addition, any optimizations that can apply to all queries can be done explicitly inside <code>load_data</code>. For example, if all queries are operate on a single day's data with <code>df1</code>, you can write that filter in <code>load_data</code> to limit IO and filter pushdown will be performed.</p> <pre><code>@bodo.jit\ndef load_data(f1, f2, target_date):\ndf1 = pd.read_parquet(f1)\n# Applying this filter limits how much data is loaded.\ndf1 = df1[df1.date_val == target_date]\ndf2 = pd.read_parquet(f2)\nreturn df1, df2\n@bodo.jit\ndef run_queries(f1, f2, target_date):\ndf1, df2 = load_data(f1, f2, target_date)\n...\nrun_queries(f1, f2, target_date)\n</code></pre>"},{"location":"api_docs/BodoSQL/#bodosqlcontext-api","title":"BodoSQLContext API","text":"<p>The <code>BodoSQLContext</code> API is the primary interface for executing SQL queries. It performs two roles:</p> <ol> <li>Registering data and connection information to load tables of interest.</li> <li>Forwarding SQL queries to the BodoSQL engine for compilation and execution. This is done via the      <code>bc.sql(query)</code> method, where <code>bc</code> is a <code>BodoSQLContext</code> object.</li> </ol> <p>A <code>BodoSQLContext</code> can be defined in regular Python and passed as an argument to JIT functions or can be defined directly inside JIT functions. We recommend defining and modifying a <code>BodoSQLContext</code> in regular Python whenever possible.</p> <p>For example:</p> <pre><code>bc = bodosql.BodoSQLContext(\n{\n\"t1\": bodosql.TablePath(\"my_file_path.pq\", \"parquet\"),\n},\ncatalog=bodosql.SnowflakeCatalog(\nusername,\npassword,\naccount_name,\nwarehouse_name,\ndatabase name,\n)\n)\n@bodo.jit\ndef f(bc):\nreturn bc.sql(\"select t1.A, t2.B from t1, catalogSchema.t2 where t1.C &gt; 5 and t1.D = catalogSchema.t2.D\")\n</code></pre>"},{"location":"api_docs/BodoSQL/#api-reference","title":"API Reference","text":"<ul> <li> <p><code>bodosql.BodoSQLContext(tables: Optional[Dict[str, Union[pandas.DataFrame|TablePath]]] = None, catalog: Optional[DatabaseCatalog] = None)</code> </p> <p>Defines a <code>BodoSQLContext</code> with the given local tables and catalog.</p> <p>Arguments</p> <ul> <li> <p><code>tables</code>: A dictionary that maps a name used in a SQL query to a <code>DataFrame</code> or <code>TablePath</code> object.</p> </li> <li> <p><code>catalog</code>: A <code>DatabaseCatalog</code> used to load tables from a remote database (e.g. Snowflake).</p> </li> </ul> </li> <li> <p><code>bodosql.BodoSQLContext.sql(self, query: str, params_dict: Optional[Dict[str, Any] = None)</code> </p> <p>Executes a SQL query using the tables registered in this <code>BodoSQLContext</code>. This function should be used inside a <code>@bodo.jit</code> function.</p> <p>Arguments</p> <ul> <li><code>query</code>: The SQL query to execute. This function generates code that is compiled so the <code>query</code> argument is required to be a compile time constant.</li> </ul> </li> <li> <p><code>params_dict</code>: A dictionary that maps a SQL usable name to Python variables. For more information please     refer to the BodoSQL named parameters section.</p> <p>Returns</p> <p>A <code>DataFrame</code> that results from executing the query.</p> </li> <li> <p><code>bodosql.BodoSQLContext.add_or_replace_view(self, name: str, table: Union[pandas.DataFrame, TablePath])</code> </p> <p>Create a new <code>BodoSQLContext</code> from an existing <code>BodoSQLContext</code> by adding or replacing a table.</p> <p>Arguments</p> <ul> <li> <p><code>name</code>: The name of the table to add. If the name already exists references to that table are removed from the new context.</p> </li> <li> <p><code>table</code>: The table object to add. <code>table</code> must be a <code>DataFrame</code> or <code>TablePath</code> object.</p> </li> </ul> <p>Returns</p> <p>A new <code>BodoSQLContext</code> that retains the tables and catalogs from the old <code>BodoSQLContext</code> and inserts the new table specified.</p> <p>Note</p> <p>This DOES NOT update the given context. Users should always use the <code>BodoSQLContext</code> object returned from the function call. e.g. <code>bc = bc.add_or_replace_view(\"t1\", table)</code></p> </li> <li> <p><code>bodosql.BodoSQLContext.remove_view(self, name: str)</code> </p> <p>Creates a new <code>BodoSQLContext</code> from an existing context by removing the table with the given name. If the name does not exist, a <code>BodoError</code> is thrown.</p> <p>Arguments</p> <ul> <li><code>name</code>: The name of the table to remove.</li> </ul> <p>Returns</p> <p>A new <code>BodoSQLContext</code> that retains the tables and catalogs from the old <code>BodoSQLContext</code> minus the table specified.</p> <p>Note</p> <p>This DOES NOT update the given context. Users should always use the <code>BodoSQLContext</code> object returned from the function call. e.g. <code>bc = bc.remove_view(\"t1\")</code></p> </li> <li> <p><code>bodosql.BodoSQLContext.add_or_replace_catalog(self, catalog: DatabaseCatalog)</code> </p> <p>Create a new <code>BodoSQLContext</code> from an existing context by replacing the <code>BodoSQLContext</code> object's <code>DatabaseCatalog</code> with a new catalog.</p> <p>Arguments</p> <ul> <li><code>catalog</code>: The catalog to insert.</li> </ul> <p>Returns</p> <p>A new <code>BodoSQLContext</code> that retains tables from the old <code>BodoSQLContext</code> but replaces the old catalog with the new catalog specified.</p> <p>Note</p> <p>This DOES NOT update the given context. Users should always use the <code>BodoSQLContext</code> object returned from the function call. e.g. <code>bc = bc.add_or_replace_catalog(catalog)</code></p> </li> <li> <p><code>bodosql.BodoSQLContext.remove_catalog(self)</code> </p> <p>Create a new <code>BodoSQLContext</code> from an existing context by removing its <code>DatabaseCatalog</code>.</p> <p>Returns</p> <p>A new <code>BodoSQLContext</code> that retains tables from the old <code>BodoSQLContext</code> but removes the old catalog.</p> <p>Note</p> <p>This DOES NOT update the given context. Users should always use the <code>BodoSQLContext</code> object returned from the function call. e.g. <code>bc = bc.remove_catalog()</code></p> </li> </ul>"},{"location":"api_docs/BodoSQL/#tablepath-api","title":"TablePath API","text":"<p>The <code>TablePath</code> API is a general purpose IO interface to specify IO sources. This API is meant as an alternative to natively loading tables in Python inside JIT functions. The <code>TablePath</code> API stores the user-defined data location and the storage type to load a table of interest. For example, here is some sample code that loads two DataFrames from parquet using the <code>TablePath</code> API.</p> <pre><code>bc = bodosql.BodoSQLContext(\n{\n\"t1\": bodosql.TablePath(\"my_file_path1.pq\", \"parquet\"),\n\"t2\": bodosql.TablePath(\"my_file_path2.pq\", \"parquet\"),\n}\n)\n@bodo.jit\ndef f(bc):\nreturn bc.sql(\"select t1.A, t2.B from t1, t2 where t1.C &gt; 5 and t1.D = t2.D\")\n</code></pre> <p>Here, the <code>TablePath</code> constructor doesn't load any data. Instead, a <code>BodoSQLContext</code> internally generates code to load the tables of interest after parsing the SQL query. Note that a <code>BodoSQLContext</code> loads all used tables from I/O on every query, which means that if users would like to perform multiple queries on the same data, they should consider loading the DataFrames once in a separate JIT function.</p>"},{"location":"api_docs/BodoSQL/#api-reference_1","title":"API Reference","text":"<ul> <li> <p><code>bodosql.TablePath(file_path: str, file_type: str, *, conn_str: Optional[str] = None, reorder_io: Optional[bool] = None)</code> </p> <p>Specifies how a DataFrame should be loaded from IO by a BodoSQL query. This can only load data when used with a <code>BodoSQLContext</code> constructor.</p> <p>Arguments</p> <ul> <li> <p><code>file_path</code>: Path to IO file or name of the table for SQL. This must constant at compile time if used inside JIT.</p> </li> <li> <p><code>file_type</code>: Type of file to load as a string. Supported values are <code>\"parquet\"</code> and <code>\"sql\"</code>. This must constant at compile time if used inside JIT.</p> </li> <li> <p><code>conn_str</code>: Connection string used to connect to a SQL DataBase, equivalent to the conn argument to <code>pandas.read_sql</code>. This must be constant at compile time if used inside JIT and must be None if not loading from a SQL DataBase.</p> </li> </ul> </li> <li> <p><code>reorder_io</code>: Boolean flag determining when to load IO. If <code>False</code>, all used tables are loaded before executing any of the query. If <code>True</code>, tables are loaded just before first use inside the query, which often results in decreased     peak memory usage as each table is partially processed before loading the next table. The default value, <code>None</code>, behaves like <code>True</code>, but this may change in the future. This must be constant at compile time if used inside JIT.</p> </li> </ul>"},{"location":"api_docs/BodoSQL/#database-catalogs","title":"Database Catalogs","text":"<p>Database Catalogs are configuration objects that grant BodoSQL access to load tables from a remote database. For example, when a user wants to load data from Snowflake, a user will create a <code>SnowflakeCatalog</code> to grant BodoSQL access to their Snowflake account and load the tables of interest.</p> <p>A database catalog can be registered during the construction of the <code>BodoSQLContext</code> by passing it in as a parameter, or can be manually set using the <code>BodoSQLContext.add_or_replace_catalog</code> API. Currently, a <code>BodoSQLContext</code> can support at most one database catalog.</p> <p>When using a catalog in a <code>BodoSQLContext</code> we strongly recommend creating the <code>BodoSQLContext</code> once in regular Python and then passing the <code>BodoSQLContext</code> as an argument to JIT functions. There is no benefit to creating the <code>BodoSQLContext</code> in JIT and this could increase compilation time.</p> <pre><code>catalog = bodosql.SnowflakeCatalog(\nusername,\npassword,\naccount_name,\n\"DEMO_WH\", # warehouse name\n\"SNOWFLAKE_SAMPLE_DATA\", # database name\n)\nbc = bodosql.BodoSQLContext({\"local_table1\": df1}, catalog=catalog)\n@bodo.jit\ndef run_query(bc):\nreturn bc.sql(\"SELECT r_name, local_id FROM TPCH_SF1.REGION, local_table1 WHERE R_REGIONKEY = local_table1.region_key ORDER BY r_name\")\nrun_query(bc)\n</code></pre> <p>Database catalogs can be used alongside local, in-memory <code>DataFrame</code> or <code>TablePath</code> tables. If a table is specified without a schema then BodoSQL resolves the table in the following order:</p> <ol> <li>Default Catalog Schema</li> <li>Local (in-memory) DataFrames / TablePath names</li> </ol> <p>An error is raised if the table cannot be resolved after searching through both of these data sources.</p> <p>This ordering indicates that in the event of a name conflict between a table in the database catalog and a local table, the table in the database catalog is used.</p> <p>If a user wants to use the local table instead, the user can explicitly specify the table with the local schema <code>__bodolocal__</code>.</p> <p>For example:</p> <pre><code>SELECT A from __bodolocal__.table1\n</code></pre> <p>Currently, BodoSQL supports catalogs Snowflake, but support for other data storage systems will be added in future releases.</p>"},{"location":"api_docs/BodoSQL/#snowflakecatalog","title":"SnowflakeCatalog","text":"<p>The Snowflake Catalog offers an interface for users to connect their Snowflake accounts to use with BodoSQL. With a Snowflake Catalog, users only have to specify their Snowflake connection once, and can access any tables of interest in their Snowflake account. Currently, the Snowflake Catalog is defined to use a single <code>DATABASE</code> (e.g. <code>USE DATABASE</code>)  at a time, as shown below.</p> <pre><code>catalog = bodosql.SnowflakeCatalog(\nusername,\npassword,\naccount_name,\n\"DEMO_WH\", # warehouse name\n\"SNOWFLAKE_SAMPLE_DATA\", # database name\n)\nbc = bodosql.BodoSQLContext(catalog=catalog)\n@bodo.jit\ndef run_query(bc):\nreturn bc.sql(\"SELECT r_name FROM TPCH_SF1.REGION ORDER BY r_name\")\nrun_query(bc)\n</code></pre> <p>BodoSQL does not currently support Snowflake syntax for specifying defaults and session parameters (e.g. <code>USING SCHEMA &lt;NAME&gt;</code>). Instead users can pass any session parameters through the optional <code>connection_params</code> argument, which accepts a <code>Dict[str, str]</code> for each session parameter. For example, users can provide a default schema to simplify the previous example.</p> <pre><code>catalog = bodosql.SnowflakeCatalog(\nusername,\npassword,\naccount,\n\"DEMO_WH\", # warehouse name\n\"SNOWFLAKE_SAMPLE_DATA\", # database name\nconnection_params={\"schema\": \"TPCH_SF1\"}\n)\nbc = bodosql.BodoSQLContext(catalog=catalog)\n@bodo.jit\ndef run_query(bc):\nreturn bc.sql(\"SELECT r_name FROM REGION ORDER BY r_name\")\nrun_query(bc)\n</code></pre> <p>Internally, Bodo uses the following connections to Snowflake:</p> <ol> <li>A JDBC connection to lazily fetch metadata.</li> <li>The Snowflake-Python-Connector's distributed fetch API to load batches of arrow data.</li> </ol>"},{"location":"api_docs/BodoSQL/#api-reference_2","title":"API Reference","text":"<ul> <li> <p><code>bodosql.SnowflakeCatalog(username: str, password: str, account: str, warehouse: str, database: str, connection_params: Optional[Dict[str, str]] = None)</code> </p> <p>Constructor for <code>SnowflakeCatalog</code>. Allows users to execute queries on tables stored in Snowflake when the <code>SnowflakeCatalog</code> object is registered with a <code>BodoSQLContext</code>.</p> <p>Arguments</p> <ul> <li> <p><code>username</code>: Snowflake account username.</p> </li> <li> <p><code>password</code>: Snowflake account password.</p> </li> <li> <p><code>account</code>: Snowflake account name.</p> </li> <li> <p><code>warehouse</code>: Snowflake warehouse to use when loading data.</p> </li> <li> <p><code>database</code>: Name of Snowflake database to load data from. The Snowflake     Catalog is currently restricted to using a single Snowflake <code>database</code>.</p> </li> <li> <p><code>connection_params</code>: A dictionary of Snowflake session parameters.</p> </li> </ul> </li> </ul>"},{"location":"api_docs/BodoSQL/#supported-query-types","title":"Supported Query Types","text":"<p>The <code>SnowflakeCatalog</code> currently supports the following types of SQL queries:</p> <ul> <li><code>SELECT</code></li> <li><code>INSERT INTO</code></li> <li><code>DELETE</code></li> </ul>"},{"location":"api_docs/bodo_parallel_apis/","title":"Bodo Parallel APIs","text":"<p>This page lists advanced parallel APIs provided by Bodo for finer-grained control over data distribution and processes.</p>"},{"location":"api_docs/bodo_parallel_apis/#bodoallgatherv","title":"bodo.allgatherv","text":"<p><code>bodo.allgatherv(data, warn_if_rep=True)</code>Gather data from all ranks and send to all, effectively replicating the data.</p> <p>Arguments</p> <ul> <li><code>data</code>: data to gather.</li> <li><code>warn_if_rep</code>: prints a BodoWarning if data to gather is replicated. </li> </ul> <p>Example Usage</p> <pre><code>import bodo\nimport pandas as pd\n@bodo.jit\ndef mean_power():\ndf = pd.read_parquet(\"data/cycling_dataset.pq\")\nreturn bodo.allgatherv(df)\ndf = mean_power()\nprint(df)\n</code></pre> <p>Save code in <code>test_allgatherv.py</code> file and run with <code>mpiexec</code>.</p> <pre><code>mpiexec -n 4 python test_allgatherv.py\n</code></pre> <p>Output:</p> <pre><code>[stdout:0]\n      Unnamed: 0    altitude  cadence  ...  power  speed                time\n0              0  185.800003       51  ...     45  3.459 2016-10-20 22:01:26\n1              1  185.800003       68  ...      0  3.710 2016-10-20 22:01:27\n2              2  186.399994       38  ...     42  3.874 2016-10-20 22:01:28\n3              3  186.800003       38  ...      5  4.135 2016-10-20 22:01:29\n4              4  186.600006       38  ...      1  4.250 2016-10-20 22:01:30\n...          ...         ...      ...  ...    ...    ...                 ...\n3897        1127  178.199997        0  ...      0  3.497 2016-10-20 23:14:31\n3898        1128  178.199997        0  ...      0  3.289 2016-10-20 23:14:32\n3899        1129  178.199997        0  ...      0  2.969 2016-10-20 23:14:33\n3900        1130  178.399994        0  ...      0  2.969 2016-10-20 23:14:34\n3901        1131  178.399994        0  ...      0  2.853 2016-10-20 23:14:35\n[3902 rows x 10 columns]\n[stdout:1]\n      Unnamed: 0    altitude  cadence  ...  power  speed                time\n0              0  185.800003       51  ...     45  3.459 2016-10-20 22:01:26\n1              1  185.800003       68  ...      0  3.710 2016-10-20 22:01:27\n2              2  186.399994       38  ...     42  3.874 2016-10-20 22:01:28\n3              3  186.800003       38  ...      5  4.135 2016-10-20 22:01:29\n4              4  186.600006       38  ...      1  4.250 2016-10-20 22:01:30\n...          ...         ...      ...  ...    ...    ...                 ...\n3897        1127  178.199997        0  ...      0  3.497 2016-10-20 23:14:31\n3898        1128  178.199997        0  ...      0  3.289 2016-10-20 23:14:32\n3899        1129  178.199997        0  ...      0  2.969 2016-10-20 23:14:33\n3900        1130  178.399994        0  ...      0  2.969 2016-10-20 23:14:34\n3901        1131  178.399994        0  ...      0  2.853 2016-10-20 23:14:35\n[3902 rows x 10 columns]\n[stdout:2]\n      Unnamed: 0    altitude  cadence  ...  power  speed                time\n0              0  185.800003       51  ...     45  3.459 2016-10-20 22:01:26\n1              1  185.800003       68  ...      0  3.710 2016-10-20 22:01:27\n2              2  186.399994       38  ...     42  3.874 2016-10-20 22:01:28\n3              3  186.800003       38  ...      5  4.135 2016-10-20 22:01:29\n4              4  186.600006       38  ...      1  4.250 2016-10-20 22:01:30\n...          ...         ...      ...  ...    ...    ...                 ...\n3897        1127  178.199997        0  ...      0  3.497 2016-10-20 23:14:31\n3898        1128  178.199997        0  ...      0  3.289 2016-10-20 23:14:32\n3899        1129  178.199997        0  ...      0  2.969 2016-10-20 23:14:33\n3900        1130  178.399994        0  ...      0  2.969 2016-10-20 23:14:34\n3901        1131  178.399994        0  ...      0  2.853 2016-10-20 23:14:35\n[3902 rows x 10 columns]\n[stdout:3]\n      Unnamed: 0    altitude  cadence  ...  power  speed                time\n0              0  185.800003       51  ...     45  3.459 2016-10-20 22:01:26\n1              1  185.800003       68  ...      0  3.710 2016-10-20 22:01:27\n2              2  186.399994       38  ...     42  3.874 2016-10-20 22:01:28\n3              3  186.800003       38  ...      5  4.135 2016-10-20 22:01:29\n4              4  186.600006       38  ...      1  4.250 2016-10-20 22:01:30\n...          ...         ...      ...  ...    ...    ...                 ...\n3897        1127  178.199997        0  ...      0  3.497 2016-10-20 23:14:31\n3898        1128  178.199997        0  ...      0  3.289 2016-10-20 23:14:32\n3899        1129  178.199997        0  ...      0  2.969 2016-10-20 23:14:33\n3900        1130  178.399994        0  ...      0  2.969 2016-10-20 23:14:34\n3901        1131  178.399994        0  ...      0  2.853 2016-10-20 23:14:35\n[3902 rows x 10 columns]\n</code></pre>"},{"location":"api_docs/bodo_parallel_apis/#bodobarrier","title":"bodo.barrier","text":"<p><code>bodo.barrier()</code>  Synchronize all processes. Block process from proceeding until all processes reach this point.</p> <p>Example Usage</p> <p>A typical example is to make sure all processes see side effects simultaneously. For example, a process can delete files from storage while others wait before writing to file:</p> <pre><code>import shutil, os\nimport numpy as np\n# remove file if exists\nif bodo.get_rank() == 0:\nif os.path.exists(\"data/data.pq\"):\nshutil.rmtree(\"data/data.pq\")\n# make sure all processes are synchronized\n# (e.g. all processes need to see effect of rank 0's work)\nbodo.barrier()\n@bodo.jit\ndef f(n):\ndf = pd.DataFrame({\"A\": np.arange(n)})\ndf.to_parquet(\"data/data.pq\")\nf(10)\n</code></pre> <p>The following figure illustrates what happens when processes call <code>bodo.barrier()</code>. When barrier is called, a process pauses and waits until all other processes have reached the barrier:</p> <p></p> <p>Danger</p> <p>The example above shows that it is possible to have each process follow a different control flow, but all processes must always call the same Bodo functions in the same order.</p>"},{"location":"api_docs/bodo_parallel_apis/#bodogatherv","title":"bodo.gatherv","text":"<p><code>bodo.gatherv(data, allgather=False, warn_if_rep=True, root=0)</code>  Collect distributed data manually by gathering them into a single rank. </p> <p>Arguments</p> <ul> <li><code>data</code>: data to gather.</li> <li><code>root</code>: specify rank to collect the data. Default: rank <code>0</code>.</li> <li><code>warn_if_rep</code>: prints a BodoWarning if data to gather is replicated. </li> <li><code>allgather</code>: send gathered data to all ranks. Default: <code>False</code>. Same behavior as <code>bodo.allgatherv</code>.</li> </ul> <p>Example Usage</p> <p><pre><code>import bodo\nimport pandas as pd\n@bodo.jit\ndef mean_power():\ndf = pd.read_parquet(\"data/cycling_dataset.pq\")\nreturn bodo.gatherv(df, root=1)\ndf = mean_power()\nprint(df)\n</code></pre> Save code in <code>test_gatherv.py</code> file and run with <code>mpiexec</code>.</p> <pre><code>mpiexec -n 4 python test_gatherv.py\n</code></pre> <p>Output:</p> <pre><code>[stdout:1]\n      Unnamed: 0    altitude  cadence  ...  power  speed                time\n0              0  185.800003       51  ...     45  3.459 2016-10-20 22:01:26\n1              1  185.800003       68  ...      0  3.710 2016-10-20 22:01:27\n2              2  186.399994       38  ...     42  3.874 2016-10-20 22:01:28\n3              3  186.800003       38  ...      5  4.135 2016-10-20 22:01:29\n4              4  186.600006       38  ...      1  4.250 2016-10-20 22:01:30\n...          ...         ...      ...  ...    ...    ...                 ...\n3897        1127  178.199997        0  ...      0  3.497 2016-10-20 23:14:31\n3898        1128  178.199997        0  ...      0  3.289 2016-10-20 23:14:32\n3899        1129  178.199997        0  ...      0  2.969 2016-10-20 23:14:33\n3900        1130  178.399994        0  ...      0  2.969 2016-10-20 23:14:34\n3901        1131  178.399994        0  ...      0  2.853 2016-10-20 23:14:35\n[3902 rows x 10 columns]\n[stdout:0]\nEmpty DataFrame\nColumns: [Unnamed: 0, altitude, cadence, distance, hr, latitude, longitude, power, speed, time]\nIndex: []\n[0 rows x 10 columns]\n[stdout:2]\nEmpty DataFrame\nColumns: [Unnamed: 0, altitude, cadence, distance, hr, latitude, longitude, power, speed, time]\nIndex: []\n[0 rows x 10 columns]\n[stdout:3]\nEmpty DataFrame\nColumns: [Unnamed: 0, altitude, cadence, distance, hr, latitude, longitude, power, speed, time]\nIndex: []\n[0 rows x 10 columns]\n</code></pre>"},{"location":"api_docs/bodo_parallel_apis/#bodoget_rank","title":"bodo.get_rank","text":"<p><code>bodo.get_rank()</code> Get the process number from Bodo (called <code>rank</code> in MPI terminology).</p> <p>Example Usage</p> <p>Save following code in <code>get_rank.py</code> file and run with <code>mpiexec</code>.</p> <pre><code>import bodo\n# some work only on rank 0\nif bodo.get_rank() == 0:\nprint(\"rank 0 done\")\n# some work on every process\nprint(\"rank\", bodo.get_rank(), \"here\")\n</code></pre> <pre><code>mpiexec -n 4 python get_rank.py\n</code></pre> <p>Output</p> <pre><code>rank 0 done\nrank 0 here\nrank 1 here\nrank 2 here\nrank 3 here\n</code></pre>"},{"location":"api_docs/bodo_parallel_apis/#bodoget_size","title":"bodo.get_size","text":"<p><code>bodo.get_size() </code>Get the total number of processes.</p> <p>Example Usage</p> <p>Save following code in <code>get_rank_size.py</code> file and run with <code>mpiexec</code>.</p> <pre><code>import bodo\n# some work only on rank 0\nif bodo.get_rank() == 0:\nprint(\"rank 0 done\")\n# some work on every process\nprint(\"rank\", bodo.get_rank(), \"here\")\nprint(\"total ranks:\", bodo.get_size())\n</code></pre> <pre><code>mpiexec -n 4 python get_rank_size.py\n</code></pre> <p>Output</p> <pre><code>rank 0 done\nrank 0 here\ntotal ranks: 4\nrank 1 here\ntotal ranks: 4\nrank 2 here\ntotal ranks: 4\nrank 3 here\ntotal ranks: 4\n</code></pre>"},{"location":"api_docs/bodo_parallel_apis/#bodorandom_shuffle","title":"bodo.random_shuffle","text":"<p><code>bodo.random_shuffle(data, seed=None, dests=None, parallel=False)</code>Manually shuffle data evenly across selected ranks.</p> <p>Arguments</p> <ul> <li><code>data</code>: data to shuffle.</li> <li><code>seed</code>: number to initialze random number generator.</li> <li><code>dests</code>: selected ranks to distribute shuffled data to. By default, distribution includes all ranks.</li> <li><code>parallel</code>: flag to indicate whether data is distributed. Default: <code>False</code>. Inside JIT default value depends on Bodo's distribution analysis algorithm for the data passed (For more information, see Data Distribution section below).</li> </ul> <p>Example Usage</p> <pre><code>import bodo\nimport pandas as pd\n@bodo.jit\ndef test_random_shuffle():\ndf = pd.DataFrame({\"A\": range(100)})\nreturn df\ndf = test_random_shuffle()\nprint(df.head())\ndf = bodo.random_shuffle(res, parallel=True)\nprint(df.head())\n</code></pre> <p>Save code in <code>test_random_shuffle.py</code> file and run with <code>mpiexec</code>.</p> <pre><code>mpiexec -n 4 python test_random_shuffle.py\n</code></pre> <p>Output:</p> <pre><code>[stdout:1]\n    A\n0  25\n1  26\n2  27\n3  28\n4  29\n    A\n19  19\n10  10\n17  42\n9    9\n17  17\n[stdout:3]\n    A\n0  75\n1  76\n2  77\n3  78\n4  79\n    A\n6   31\n0   25\n24  49\n22  22\n5   30\n[stdout:2]\n    A\n0  50\n1  51\n2  52\n3  53\n4  54\n    A\n11  36\n24  24\n15  65\n14  14\n10  35\n[stdout:0]\n    A\n0  0\n1  1\n2  2\n3  3\n4  4\n    A\n4   29\n18  18\n8   58\n15  15\n3   28\n</code></pre>"},{"location":"api_docs/bodo_parallel_apis/#bodorebalance","title":"bodo.rebalance","text":"<p><code>bodo.rebalance(data, dests=None, random=False, random_seed=None, parallel=False) </code>Manually redistribute data evenly across [selected] ranks.</p> <p>Arguments</p> <ul> <li><code>data</code>: data to rebalance.</li> <li><code>dests</code>: selected ranks to distribute data to. By default, distribution includes all ranks.</li> <li><code>random</code>: flag to randomize order of the rows of the data. Default: <code>False</code>.</li> <li><code>random_seed</code>: number to initialize random number generator.</li> <li><code>parallel</code>: flag to indicate whether data is distributed. Default: <code>False</code>. Inside JIT default value depends on Bodo's distribution analysis algorithm for the data passed (For more information, see Data Distribution section below).</li> </ul> <p>Example Usage </p> <ul> <li> <p>Example with just the <code>parallel</code> flag set to <code>True</code>:</p> <pre><code>import bodo\nimport pandas as pd\n@bodo.jit\ndef mean_power():\ndf = pd.read_parquet(\"data/cycling_dataset.pq\")\ndf = df.sort_values(\"power\")[df[\"power\"] &gt; 400]\nreturn df\ndf = mean_power()\nprint(df.shape)\ndf = bodo.rebalance(df, parallel=True)\nprint(\"After rebalance: \", df.shape)\n</code></pre> <p>Save code in <code>test_rebalance.py</code> file and run with <code>mpiexec</code>.</p> <pre><code>mpiexec -n 4 python test_rebalance.py\n</code></pre> <pre><code>[stdout:0]\n(5, 10)\nAfter rebalance: (33, 10)\n[stdout:1]\n(18, 10)\nAfter rebalance: (33, 10)\n[stdout:2]\n(82, 10)\nAfter rebalance: (33, 10)\n[stdout:3]\n(26, 10)\nAfter rebalance: (32, 10)\n</code></pre> </li> <li> <p>Example to distribute the data from all ranks to subset of ranks using <code>dests</code> argument.</p> <p><pre><code>import bodo\nimport pandas as pd\n@bodo.jit\ndef mean_power():\ndf = pd.read_parquet(\"data/cycling_dataset.pq\")\ndf = df.sort_values(\"power\")[df[\"power\"] &gt; 400]\nreturn df\ndf = mean_power()\nprint(df.shape)\ndf = bodo.rebalance(df, dests=[1,3], parallel=True)\nprint(\"After rebalance: \", df.shape)\n</code></pre> Save code in <code>test_rebalance.py</code> file and run with <code>mpiexec</code>.</p> <pre><code>mpiexec -n 4 python test_rebalance.py\n</code></pre> <p>Output:</p> <pre><code>[stdout:0]\n(5, 10)\nAfter rebalance: (0, 10)\n[stdout:1]\n(18, 10)\nAfter rebalance: (66, 10)\n[stdout:2]\n(82, 10)\nAfter rebalance: (0, 10)\n[stdout:3]\n(26, 10)\nAfter rebalance: (65, 10)\n</code></pre> </li> </ul>"},{"location":"api_docs/bodo_parallel_apis/#bodoscatterv","title":"bodo.scatterv","text":"<p><code>bodo.scatterv(data, warn_if_dist=True)</code>  Distribute data manually by scattering data from one process to all processes.</p> <p>Arguments</p> <ul> <li><code>data</code>: data to distribute.</li> <li><code>warn_if_dist</code>: flag to print a BodoWarning if <code>data</code> is already distributed.</li> </ul> <p>Note</p> <p>Currently, <code>bodo.scatterv</code> only supports scattering from rank 0.</p> <p>Example Usage</p> <ul> <li>When used outside of JIT code, we recommend that the argument be set to <code>None</code> for all ranks except rank 0.    For example:</li> </ul> <pre><code>import bodo\nimport pandas as pd\n@bodo.jit(distributed=[\"df\"])\ndef mean_power(df):\nx = df.power.mean()\nreturn x\ndf = None\n# only rank 0 reads the data\nif bodo.get_rank() == 0:\ndf = pd.read_parquet(\"data/cycling_dataset.pq\")\ndf = bodo.scatterv(df)\nres = mean_power(df)\nprint(res)\n</code></pre> <p>Save the code in <code>test_scatterv.py</code> file and run with <code>mpiexec</code>.</p> <pre><code>mpiexec -n 4 python test_scatterv.py\n</code></pre> <p>Output: </p> <pre><code>[stdout:0] 102.07842132239877\n[stdout:1] 102.07842132239877\n[stdout:2] 102.07842132239877\n[stdout:3] 102.07842132239877\n</code></pre> <p>Note</p> <p><code>data/cycling_dataset.pq</code> is located in the Bodo tutorial repo.</p> <ul> <li>This is not a strict requirement. However, since this might be bad practice in certain situations,    Bodo will throw a warning if the data is not None on other ranks.</li> </ul> <pre><code>import bodo\nimport pandas as pd\ndf = pd.read_parquet(\"data/cycling_dataset.pq\")\ndf = bodo.scatterv(df)\nres = mean_power(df)\nprint(res)\n</code></pre> <p>Save code in <code>test_scatterv.py</code> file and run with <code>mpiexec</code>.</p> <pre><code>mpiexec -n 4 python test_scatterv.py\n</code></pre> <p>Output:</p> <pre><code>BodoWarning: bodo.scatterv(): A non-None value for 'data' was found on a rank other than the root. This data won't be sent to any other ranks and will be overwritten with data from rank 0.\n[stdout:0] 102.07842132239877\n[stdout:1] 102.07842132239877\n[stdout:2] 102.07842132239877\n[stdout:3] 102.07842132239877\n</code></pre> <ul> <li>When using <code>scatterv</code> inside of JIT code, the argument must have the same type on each rank due to Bodo's typing constraints.   All inputs except for rank 0 are ignored.</li> </ul> <pre><code>import bodo\nimport pandas as pd\n@bodo.jit()\ndef impl():\nif bodo.get_rank() == 0:\ndf = pd.DataFrame({\"A\": [1,2,3,4,5,6,7,8]})\nelse:\ndf = pd.DataFrame({\"A\": [-1]*8})\nreturn bodo.scatterv(df)\nprint(impl())\n</code></pre> <p>Save code in <code>test_scatterv.py</code> file and run with <code>mpiexec</code>.</p> <pre><code>mpiexec -n 8 python test_scatterv.py\n</code></pre> <p>Output:</p> <pre><code>[stdout:6]\n      A\n6     7\n[stdout:0]\n      A\n0     1\n[stdout:1]\n      A\n1     2\n[stdout:4]\n      A\n4     5\n[stdout:7]\n      A\n7     8\n[stdout:3]\n      A\n3     4\n[stdout:2]\n      A\n2     3\n[stdout:5]\n      A\n5     6\n</code></pre> <p>Note</p> <p><code>scatterv</code>, <code>gatherv</code>, <code>allgatherv</code>, <code>rebalance</code>, and <code>random_shuffle</code> work with all distributable data types. This includes:</p> <ul> <li>All supported numpy array types.</li> <li>All supported pandas array types (with the exception of Interval Arrays).</li> <li>All supported pandas Series types.</li> <li>All supported DataFrame types.</li> <li>All supported Index types (with the exception of Interval Index).</li> <li>Tuples of the above types.</li> </ul>"},{"location":"api_docs/bodosqlerrors/","title":"Common Bodo SQL Errors","text":"<p>BodoSQL can raise a number of different errors when parsing SQL queries. This page contains a list of the most commonly encountered parsing errors and their causes.</p> <ul> <li> <p>A binary operation was used on two types for which it is not supported. </p> <pre><code>\"Cannot apply 'OP' to arguments of type '&lt;SQL_TYPE_ENUM&gt; OP &lt;SQL_TYPE_ENUM&gt;'\"\n</code></pre> <p>This error can be resolved by casting either side of the expression to a common type.</p> </li> </ul> <p></p> <ul> <li> <p>The format string passed to STR_TO_DATE is not a valid SQL format string.</p> <pre><code>\"STR_TO_DATE contains an invalid format string\"\n</code></pre> <p>See <code>DATE_FORMAT</code> for the list of supported SQL format characters.</p> </li> </ul> <p></p> <ul> <li> <p>The format string passed to STR_TO_DATE is a valid SQL format string, which contains one or more escape     characters that BodoSQL does not currently support.</p> <pre><code>\"STR_TO_DATE contains an invalid escape character (escape char)\"\n</code></pre> <p>For the list of supported SQL format characters, see <code>DATE_FORMAT</code>.</p> </li> </ul> <p></p> <ul> <li> <p>The specified column (<code>COL_NAME</code>) of one of the pandas DataFrames used to initialize a BodoSQLContext has an unsupported type.</p> <pre><code>\"Pandas column 'COL_NAME' with type PANDAS_TYPE not supported in BodoSQL.\"\n</code></pre> <p>For the list of supported pandas types, see here.</p> </li> </ul> <p></p> <ul> <li> <p>The parser encountered something other than a query at a location where a query was expected. </p> <pre><code>\"Non-query expression encountered in illegal context\"\n</code></pre> <p>See here for the syntax of a select clause.</p> </li> </ul> <p></p> <ul> <li> <p>The table name specified in a SQL query doesn't match a table name registered in the BodoSQLContext. </p> <pre><code>\"Object 'tablename' not found\"\n</code></pre> <p>Generally, this is caused by misnaming a table when initializing the BodoSqlContext, or misnaming a table in the query itself.</p> </li> </ul> <p></p> <ul> <li> <p>The query attempted to select a column from one or more tables, and the column wasn't present in any of them.</p> <pre><code>\"Column 'COL_NAME' not found in any table\"\n</code></pre> <p>Generally, this is caused by misnaming a column while initializing the BodoSQLContext, or misnaming a column in the query itself.``</p> </li> </ul> <p></p> <ul> <li> <p>The query attempted to select a column for two or more tables, and the column was present in multiple tables.</p> <pre><code>\"Column 'COL_NAME' is ambiguous\"\n</code></pre> </li> </ul> <p></p> <ul> <li> <p>The types of arguments supplied to the function don't match the types supported by the function. </p> <pre><code>\"Cannot apply 'FN_NAME' to arguments of type 'FN_NAME(&lt;ARG1_SQL_TYPE&gt;, &lt;ARG2_SQL_TYPE&gt;, ...)'. Supported form(s): 'FN_NAME(&lt;ARG1_SQL_TYPE&gt;, &lt;ARG2_SQL_TYPE&gt;, ...)'\"\n</code></pre> <p>Generally, this can be resolved by the specifying the origin table like so:</p> <p><code>Select A from table1, table2</code> \u2192 <code>Select table1.A from table1, table2</code></p> <p>This can be resolved by explicitly casting the problematic argument(s) to the appropriate type. For the list of functions and the argument types they support, see here.</p> </li> </ul> <p></p> <ul> <li> <p>Either BodoSQL doesn't support the function or an incorrect number of arguments was supplied.</p> <pre><code>\"No match found for function signature FN_NAME(&lt;ARG1_SQL_TYPE&gt;, &lt;ARG2_SQL_TYPE&gt;, ...)\"\n</code></pre> <p>In both cases, the list of functions which we support, and their calling conventions can be found here.</p> </li> </ul> <p></p> <ul> <li> <p>A Window function that does not support windows with a <code>ROWS_BETWEEN</code> clause was called over a window containing a <code>ROWS_BETWEEN</code> clause.</p> <pre><code>\"ROW/RANGE not allowed with RANK, DENSE_RANK or ROW_NUMBER functions\"\n</code></pre> <p>In addition to the RANK, DENSE_RANK, or ROW_NUMBER functions listed in the error message, LEAD and LAG also have this requirement. The list of window aggregations we support, and their calling syntax can be found here.</p> </li> </ul> <p></p> <ul> <li> <p>BodoSQL was unable to parse your SQL because the query contained unsupported syntax.</p> <pre><code>\"Encountered \"KEYWORD\" at line X, column Y. Was expecting one of: ...\"\n</code></pre> <p>There are a variety of reasons this could occur, but here are some of the common ones:</p> <ul> <li>A typo in one of the query words, for example <code>groupby</code> instead of <code>group by</code>. In this situation <code>line X, column Y</code> should point you to the first typo.</li> <li>All the components are legal SQL keywords, but they are used in an incorrect order. Please refer to our support syntax to check for legal constructions. If you believe your query should be supported please file an issue.</li> <li>Trying to use double-quotes for a string literal (i.e. <code>py\"example\"</code> instead of <code>'example'</code>)</li> <li>Unclosed parenthesis or trailing commas</li> </ul> </li> </ul> <p></p> <ul> <li> <p>A parameter was not properly registered in the BodoSQLContext.</p> <pre><code>\"SQL query contains a unregistered parameter: '@param_name'\"\n</code></pre> <p>This is often caused by failing to pass the parameter to <code>BodoSQLContext.sql()</code> or using an incorrect name in either the query or the registration. For more information on named parameters, see here.</p> </li> </ul> <p></p> <ul> <li> <p>A non-dataframe value was used to initialize a BodoSQLContext.</p> <pre><code>\"BodoSQLContext(): 'table' values must be DataFrames\"\n</code></pre> <p>The dictionary used to initialize a BodoSQLContext must map string table names to pandas DataFrames.</p> </li> </ul>"},{"location":"api_docs/miscellaneous/","title":"Miscellaneous Supported Python API","text":"<p>In this page, we will discuss some useful Bodo features and concepts.</p>"},{"location":"api_docs/miscellaneous/#nullable-integers-in-pandas","title":"Nullable Integers in Pandas","text":"<p>DataFrame and Series objects with integer data need special care due to integer NA issues in Pandas. By default, Pandas dynamically converts integer columns to floating point when missing values (NAs) are needed, which can result in loss of precision as well as type instability.</p> <p></p> <p>Pandas introduced a new nullable integer datatype that can solve this issue, which is also supported by Bodo. For example, this code reads column A into a nullable integer array (the capital \"I\" denotes nullable integer type):</p> <pre><code>data = (\n\"11,1.2\\n\"\n\"-2,\\n\"\n\",3.1\\n\"\n\"4,-0.1\\n\"\n)\nwith open(\"data/data.csv\", \"w\") as f:\nf.write(data)\n@bodo.jit(distributed=[\"df\"])\ndef f():\ndtype = {\"A\": \"Int64\", \"B\": \"float64\"}\ndf = pd.read_csv(\"data/data.csv\", dtype = dtype, names = dtype.keys())\nreturn df\nf()\n</code></pre> <p> </p> <p></p>"},{"location":"api_docs/miscellaneous/#checking-na-values","title":"Checking NA Values","text":"<p>When an operation iterates over the values in a Series or Array, type stability requires special handling for NAs using <code>pd.isna()</code>. For example, <code>Series.map()</code> applies an operation to each element in the series and failing to check for NAs can result in garbage values propagating.</p> <pre><code>S = pd.Series(pd.array([1, None, None, 3, 10], dtype=\"Int8\"))\n@bodo.jit\ndef map_copy(S):\nreturn S.map(lambda a: a if not pd.isna(a) else None)\nprint(map_copy(S))\n</code></pre> <pre><code>0       1\n1     &lt;NA&gt;\n2     &lt;NA&gt;\n3       3\n4      10\ndtype: Int8\n</code></pre>"},{"location":"api_docs/miscellaneous/#boxingunboxing-overheads","title":"Boxing/Unboxing Overheads","text":"<p>Bodo uses efficient native data structures which can be different than Python. When Python values are passed to Bodo, they are unboxed to native representation. On the other hand, returning Bodo values requires boxing to Python objects. Boxing and unboxing can have significant overhead depending on size and type of data. For example, passing string column between Python/Bodo repeatedly can be expensive:</p> <p><pre><code>@bodo.jit(distributed=[\"df\"])\ndef gen_data():\ndf = pd.read_parquet(\"data/cycling_dataset.pq\")\ndf[\"hr\"] = df[\"hr\"].astype(str)\nreturn df\n@bodo.jit(distributed=[\"df\", \"x\"])\ndef mean_power(df):\nx = df.hr.str[1:]\nreturn x\ndf = gen_data()\nres = mean_power(df)\nprint(res)\n</code></pre> Output:</p> <pre><code>0        1\n1        2\n2        2\n3        3\n4        3\n        ..\n3897    00\n3898    00\n3899    00\n3900    00\n3901    00\nName: hr, Length: 3902, dtype: object\n</code></pre> <p>One can try to keep data in Bodo functions as much as possible to avoid boxing/unboxing overheads:</p> <pre><code>@bodo.jit(distributed=[\"df\"])\ndef gen_data():\ndf = pd.read_parquet(\"data/cycling_dataset.pq\")\ndf[\"hr\"] = df[\"hr\"].astype(str)\nreturn df\n@bodo.jit(distributed=[\"df\", \"x\"])\ndef mean_power(df):\nx = df.hr.str[1:]\nreturn x\n@bodo.jit\ndef f():\ndf = gen_data()\nres = mean_power(df)\nprint(res)\nf()\n</code></pre> <pre><code>0        1\n1        2\n2        2\n3        3\n4        3\n        ..\n3897    00\n3898    00\n3899    00\n3900    00\n3901    00\nName: hr, Length: 3902, dtype: object\n</code></pre>"},{"location":"api_docs/miscellaneous/#iterating-over-columns","title":"Iterating Over Columns","text":"<p>Iterating over columns in a dataframe can cause type stability issues, since column types in each iteration can be different. Bodo supports this usage for many practical cases by automatically unrolling loops over dataframe columns when possible. For example, the example below computes the sum of all data frame columns:</p> <pre><code>@bodo.jit\ndef f():\nn = 20\ndf = pd.DataFrame({\"A\": np.arange(n), \"B\": np.arange(n) ** 2, \"C\": np.ones(n)})\ns = 0\nfor c in df.columns:\ns += df[c].sum()\nreturn s\nf()\n</code></pre> <pre><code>2680.0\n</code></pre> <p>For automatic unrolling, the loop needs to be a <code>for</code> loop over column names that can be determined by Bodo at compile time.</p>"},{"location":"api_docs/miscellaneous/#regular-expressions-using-re","title":"Regular Expressions using <code>re</code>","text":"<p>Bodo supports string processing using Pandas and the <code>re</code> standard package, offering significant flexibility for string processing applications. For example, <code>re</code> can be used in user-defined functions (UDFs) applied to Series and DataFrame values:</p> <pre><code>import re\n@bodo.jit\ndef f(S):\ndef g(a):\nres = 0\nif re.search(\".*AB.*\", a):\nres = 3\nif re.search(\".*23.*\", a):\nres = 5\nreturn res\nreturn S.map(g)\nS = pd.Series([\"AABCDE\", \"BBABCE\", \"1234\"])\nf(S)\n</code></pre> <pre><code>0    3\n1    3\n2    5\ndtype: int64\n</code></pre> <p>Below is a reference list of supported functionality. Full functionality is documented in standard re documentation. All functions except finditer are supported. Note that currently, Bodo JIT uses Python's <code>re</code> package as backend and therefore the compute speed of these functions is similar to Python.</p>"},{"location":"api_docs/miscellaneous/#rea","title":"re.A","text":"<ul> <li><code>re.A</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#reascii","title":"re.ASCII","text":"<ul> <li><code>re.ASCII</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#redebug","title":"re.DEBUG","text":"<ul> <li><code>re.DEBUG</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#rei","title":"re.I","text":"<ul> <li><code>re.I</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#reignorecase","title":"re.IGNORECASE","text":"<ul> <li><code>re.IGNORECASE</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#rel","title":"re.L","text":"<ul> <li><code>re.L</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#relocale","title":"re.LOCALE","text":"<ul> <li><code>re.LOCALE</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#rem","title":"re.M","text":"<ul> <li><code>re.M</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#remultiline","title":"re.MULTILINE","text":"<ul> <li><code>re.MULTILINE</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#res","title":"re.S","text":"<ul> <li><code>re.S</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#redotall","title":"re.DOTALL","text":"<ul> <li><code>re.DOTALL</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#rex","title":"re.X","text":"<ul> <li><code>re.X</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#reverbose","title":"re.VERBOSE","text":"<ul> <li><code>re.VERBOSE</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#research","title":"re.search","text":"<ul> <li><code>re.search(pattern, string, flags=0)</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#rematch","title":"re.match","text":"<ul> <li><code>re.match(pattern, string, flags=0)</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#refullmatch","title":"re.fullmatch","text":"<ul> <li><code>re.fullmatch(pattern, string, flags=0)</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#resplit","title":"re.split","text":"<ul> <li><code>re.split(pattern, string, maxsplit=0, flags=0)</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#refindall","title":"re.findall","text":"<ul> <li> <p><code>re.findall(pattern, string, flags=0)</code>      The <code>pattern</code> argument should be a constant string for     multi-group patterns (for Bodo to know the output will be a list of     string tuples). An error is raised otherwise.</p> <p>Example Usage:</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(pat, in_str):\n...     return re.findall(pat, in_str)\n...\n&gt;&gt;&gt; f(r\"\\w+\", \"Words, words, words.\")\n['Words', 'words', 'words']\n</code></pre> <p>Constant multi-group pattern works:</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f2(in_str):\n...     return re.findall(r\"(\\w+).*(\\d+)\", in_str)\n...\n&gt;&gt;&gt; f2(\"Words, 123\")\n[('Words', '3')]\n</code></pre> <p>Non-constant multi-group pattern throws an error:</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(pat, in_str):\n...     return re.findall(pat, in_str)\n...\n&gt;&gt;&gt; f(r\"(\\w+).*(\\d+)\", \"Words, 123\")\nTraceback (most recent call last):\nFile \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nFile \"/Users/user/dev/bodo/bodo/libs/re_ext.py\", line 338, in _pat_findall_impl\nraise ValueError(\nValueError: pattern string should be constant for 'findall' with multiple groups\n</code></pre> </li> </ul>"},{"location":"api_docs/miscellaneous/#resub","title":"re.sub","text":"<ul> <li><code>re.sub(pattern, repl, string, count=0, flags=0)</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#resubn","title":"re.subn","text":"<ul> <li><code>re.subn(pattern, repl, string, count=0, flags=0)</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#reescape","title":"re.escape","text":"<ul> <li><code>re.escape(pattern)</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#repurge","title":"re.purge","text":"<ul> <li><code>re.purge</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#repatternsearch","title":"re.Pattern.search","text":"<ul> <li><code>re.Pattern.search(string[, pos[, endpos]])</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#repatternmatch","title":"re.Pattern.match","text":"<ul> <li><code>re.Pattern.match(string[, pos[, endpos]])</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#repatternfullmatch","title":"re.Pattern.fullmatch","text":"<ul> <li><code>re.Pattern.fullmatch(string[, pos[, endpos]])</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#repatternsplit","title":"re.Pattern.split","text":"<ul> <li><code>re.Pattern.split(string, maxsplit=0)</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#repatternfindall","title":"re.Pattern.findall","text":"<ul> <li><code>re.Pattern.findall(string[, pos[, endpos]])</code>  This has the same limitation as <code>re.findall</code>. </li> </ul>"},{"location":"api_docs/miscellaneous/#repatternsub","title":"re.Pattern.sub","text":"<ul> <li><code>re.Pattern.sub(repl, string, count=0)</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#repatternsubn","title":"re.Pattern.subn","text":"<ul> <li><code>re.Pattern.subn(repl, string, count=0)</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#repatternflags","title":"re.Pattern.flags","text":"<ul> <li><code>re.Pattern.flags</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#repatterngroups","title":"re.Pattern.groups","text":"<ul> <li><code>re.Pattern.groups</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#repatterngroupindex","title":"re.Pattern.groupindex","text":"<ul> <li><code>re.Pattern.groupindex</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#repatternpattern","title":"re.Pattern.pattern","text":"<ul> <li><code>re.Pattern.pattern</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#rematchexpand","title":"re.Match.expand","text":"<ul> <li><code>re.Match.expand(template)</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#rematchgroup","title":"re.Match.group","text":"<ul> <li><code>re.Match.group([group1, ...])</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#rematch__getitem__","title":"re.Match.__getitem__","text":"<ul> <li><code>re.Match.__getitem__(g)</code></li> </ul>"},{"location":"api_docs/miscellaneous/#rematchgroups","title":"re.Match.groups","text":"<ul> <li><code>re.Match.groups(default=None)</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#rematchgroupdict","title":"re.Match.groupdict","text":"<ul> <li><code>re.Match.groupdict(default=None)</code>  (does not support default=None for groups that did not participate     in the match)</li> </ul>"},{"location":"api_docs/miscellaneous/#rematchstart","title":"re.Match.start","text":"<ul> <li><code>re.Match.start([group])</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#rematchend","title":"re.Match.end","text":"<ul> <li><code>re.Match.end([group])</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#rematchspan","title":"re.Match.span","text":"<ul> <li><code>re.Match.span([group])</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#rematchpos","title":"re.Match.pos","text":"<ul> <li><code>re.Match.pos</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#rematchendpos","title":"re.Match.endpos","text":"<ul> <li><code>re.Match.endpos</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#rematchlastindex","title":"re.Match.lastindex","text":"<ul> <li><code>re.Match.lastindex</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#rematchlastgroup","title":"re.Match.lastgroup","text":"<ul> <li><code>re.Match.lastgroup</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#rematchre","title":"re.Match.re","text":"<ul> <li><code>re.Match.re</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#rematchstring","title":"re.Match.string","text":"<ul> <li><code>re.Match.string</code> </li> </ul>"},{"location":"api_docs/miscellaneous/#class-support-using-jitclass","title":"Class Support using <code>@jitclass</code>","text":"<p>Bodo supports Python classes using the <code>@bodo.jitclass</code> decorator. It requires type annotation of the fields, as well as distributed annotation where applicable. For example, the example class below holds a distributed dataframe and a name filed. Types can either be specified directly using the imports in the bodo package or can be inferred from existing types using <code>bodo.typeof</code>. The <code>%%init%%</code> function is required, and has to initialize the attributes. In addition, subclasses are not supported in <code>jitclass</code> yet.</p> <p>Warning</p> <p>Class support is currently experimental and therefore we recommend refactoring computation into regular JIT functions instead if possible.</p> <pre><code>@bodo.jitclass(\n{\n\"df\": bodo.typeof(pd.DataFrame({\"A\": [1], \"B\": [0.1]})),\n\"name\": bodo.string_type,\n},\ndistributed=[\"df\"],\n)\nclass MyClass:\ndef %%init%%(self, n, name):\nself.df = pd.DataFrame({\"A\": np.arange(n), \"B\": np.ones(n)})\nself.name = name\ndef sum(self):\nreturn self.df.A.sum()\n@property\ndef sum_vals(self):\nreturn self.df.sum().sum()\ndef get_name(self):\nreturn self.name\n@staticmethod\ndef add_one(a):\nreturn a + 1\n</code></pre> <p>This JIT class can be used in regular Python code, as well as other Bodo JIT code.</p> <pre><code># From a compiled function\n@bodo.jit\ndef f():\nmy_instance = MyClass(32, \"my_name_jit\")\nprint(my_instance.sum())\nprint(my_instance.sum_vals)\nprint(my_instance.get_name())\nf()\n</code></pre> <pre><code>496\n528.0\nmy_name_jit\n</code></pre> <pre><code># From regular Python\nmy_instance = MyClass(32, \"my_name_python\")\nprint(my_instance.sum())\nprint(my_instance.sum_vals)\nprint(my_instance.get_name())\nprint(MyClass.add_one(8))\n</code></pre> <pre><code>496\n528.0\nmy_name_python\n9\n</code></pre> <p>Bodo's <code>jitclass</code> is built on top of Numba's <code>jitclass</code> (see Numba jitclass for more details).</p>"},{"location":"api_docs/numpy/","title":"Numpy Operations","text":"<p>Below is the list of the data-parallel Numpy operators that Bodo can optimize and parallelize.</p>"},{"location":"api_docs/numpy/#numpy-element-wise-array-operations","title":"Numpy element-wise array operations","text":""},{"location":"api_docs/numpy/#unary-operators","title":"Unary operators","text":"<ul> <li><code>+</code> </li> <li><code>-</code></li> <li><code>~</code></li> </ul>"},{"location":"api_docs/numpy/#binary-operators","title":"Binary operators","text":"<ul> <li><code>+</code> </li> <li><code>-</code> </li> <li><code>*</code> </li> <li><code>/</code> </li> <li><code>/?</code></li> <li><code>%</code> </li> <li><code>|</code> </li> <li><code>&gt;&gt;</code> </li> <li><code>^</code> </li> <li><code>&lt;&lt;</code></li> <li><code>&amp;</code> </li> <li><code>**</code> </li> <li><code>//</code></li> </ul>"},{"location":"api_docs/numpy/#comparison-operators","title":"Comparison operators","text":"<ul> <li><code>==</code></li> <li><code>!=</code></li> <li><code>&lt;</code> </li> <li><code>&lt;=</code> </li> <li><code>&gt;</code> </li> <li><code>&gt;=</code></li> </ul>"},{"location":"api_docs/numpy/#data-parallel-math-operations","title":"Data-parallel math operations","text":"<ul> <li><code>numpy.add</code></li> <li><code>numpy.subtract</code></li> <li><code>numpy.multiply</code></li> <li><code>numpy.divide</code></li> <li><code>numpy.logaddexp</code></li> <li><code>numpy.logaddexp2</code></li> <li><code>numpy.true_divide</code></li> <li><code>numpy.floor_divide</code></li> <li><code>numpy.negative</code></li> <li><code>numpy.positive</code></li> <li><code>numpy.power</code></li> <li><code>numpy.remainder</code></li> <li><code>numpy.mod</code></li> <li><code>numpy.fmod</code></li> <li><code>numpy.abs</code></li> <li><code>numpy.absolute</code></li> <li><code>numpy.fabs</code></li> <li><code>numpy.rint</code></li> <li><code>numpy.sign</code></li> <li><code>numpy.conj</code></li> <li><code>numpy.exp</code></li> <li><code>numpy.exp2</code></li> <li><code>numpy.log</code></li> <li><code>numpy.log2</code></li> <li><code>numpy.log10</code></li> <li><code>numpy.expm1</code></li> <li><code>numpy.log1p</code></li> <li><code>numpy.sqrt</code></li> <li><code>numpy.square</code></li> <li><code>numpy.reciprocal</code></li> <li><code>numpy.gcd</code></li> <li><code>numpy.lcm</code></li> <li><code>numpy.conjugate</code></li> </ul>"},{"location":"api_docs/numpy/#trigonometric-functions","title":"Trigonometric functions","text":"<ul> <li><code>numpy.sin</code></li> <li><code>numpy.cos</code></li> <li><code>numpy.tan</code></li> <li><code>numpy.arcsin</code></li> <li><code>numpy.arccos</code></li> <li><code>numpy.arctan</code></li> <li><code>numpy.arctan2</code></li> <li><code>numpy.hypot</code></li> <li><code>numpy.sinh</code></li> <li><code>numpy.cosh</code></li> <li><code>numpy.tanh</code></li> <li><code>numpy.arcsinh</code></li> <li><code>numpy.arccosh</code></li> <li><code>numpy.arctanh</code></li> <li><code>numpy.deg2rad</code></li> <li><code>numpy.rad2deg</code></li> <li><code>numpy.degrees</code></li> <li><code>numpy.radians</code></li> </ul>"},{"location":"api_docs/numpy/#bit-manipulation-functions","title":"Bit manipulation functions","text":"<ul> <li><code>numpy.bitwise_and</code></li> <li><code>numpy.bitwise_or</code></li> <li><code>numpy.bitwise_xor</code></li> <li><code>numpy.bitwise_not</code></li> <li><code>numpy.invert</code></li> <li><code>numpy.left_shift</code></li> <li><code>numpy.right_shift</code></li> </ul>"},{"location":"api_docs/numpy/#comparison-functions","title":"Comparison functions","text":"<ul> <li><code>numpy.logical_and</code></li> <li><code>numpy.logical_or</code></li> <li><code>numpy.logical_xor</code></li> <li><code>numpy.logical_not</code></li> </ul>"},{"location":"api_docs/numpy/#floating-functions","title":"Floating functions","text":"<ul> <li><code>numpy.isfinite</code></li> <li><code>numpy.isinf</code></li> <li><code>numpy.signbit</code></li> <li><code>numpy.ldexp</code></li> <li><code>numpy.floor</code></li> <li><code>numpy.ceil</code></li> <li><code>numpy.trunc</code></li> </ul>"},{"location":"api_docs/numpy/#numpy-reduction-functions","title":"Numpy reduction functions","text":"<ul> <li><code>numpy.sum</code></li> <li><code>numpy.prod</code></li> <li><code>numpy.min</code></li> <li><code>numpy.max</code></li> <li><code>numpy.argmin</code></li> <li><code>numpy.argmax</code></li> <li><code>numpy.all</code></li> <li><code>numpy.any</code></li> </ul>"},{"location":"api_docs/numpy/#numpy-array-creation-functions","title":"Numpy array creation functions","text":"<ul> <li><code>numpy.empty</code></li> <li><code>numpy.identity</code></li> <li><code>numpy.zeros</code></li> <li><code>numpy.ones</code></li> <li><code>numpy.empty_like</code></li> <li><code>numpy.zeros_like</code></li> <li><code>numpy.ones_like</code></li> <li><code>numpy.full_like</code></li> <li><code>numpy.array</code></li> <li><code>numpy.asarray</code></li> <li><code>numpy.copy</code></li> <li><code>numpy.arange</code></li> <li><code>numpy.linspace</code></li> <li><code>numpy.repeat</code>  only scalar <code>num_repeats</code></li> </ul>"},{"location":"api_docs/numpy/#numpy-array-manipulation-functions","title":"Numpy array manipulation functions","text":"<ul> <li><code>numpy.shape</code></li> <li> <p><code>numpy.reshape</code> </p> <p><code>shape</code> values cannot be -1.</p> </li> <li> <p><code>numpy.sort</code></p> </li> <li><code>numpy.concatenate</code></li> <li><code>numpy.append</code></li> <li> <p><code>numpy.unique</code>  The output is assumed to be \"small\" relative to input and is replicated.                   Use <code>Series.drop_duplicates()</code> if the output should remain distributed.</p> </li> <li> <p><code>numpy.where</code> (1 and 3 arguments)</p> </li> <li><code>numpy.select</code>  The default value for numeric/boolean types is <code>0/False</code>. For all other                   types, the default is <code>pd.NA</code>. If any of the values in                   <code>choicelist</code> are nullable, or the default is <code>pd.NA</code> or <code>None</code>, the                   output will be a nullable pandas array instead of a numpy                   array.  </li> <li><code>numpy.union1d</code></li> <li><code>numpy.intersect1d</code>  no distributed support yet</li> <li><code>numpy.setdiff1d</code>  no distributed support yet</li> <li><code>numpy.hstack</code>  concatenates elements on each rank without maintaining order</li> </ul>"},{"location":"api_docs/numpy/#numpy-mathematical-and-statistics-functions","title":"Numpy mathematical and statistics functions","text":"<ul> <li><code>numpy.cumsum</code></li> <li><code>numpy.diff</code></li> <li><code>numpy.percentile</code></li> <li><code>numpy.quantile</code></li> <li><code>numpy.median</code></li> <li><code>numpy.mean</code></li> <li><code>numpy.std</code></li> </ul>"},{"location":"api_docs/numpy/#random-number-generator-functions","title":"Random number generator functions","text":"<ul> <li><code>numpy.random.rand</code></li> <li><code>numpy.random.randn</code></li> <li><code>numpy.random.ranf</code></li> <li><code>numpy.random.random_sample</code></li> <li><code>numpy.random.sample</code></li> <li><code>numpy.random.random</code></li> <li><code>numpy.random.standard_normal</code></li> <li><code>numpy.random.multivariate_normal</code> (must provide size)</li> <li><code>numpy.random.chisquare</code></li> <li><code>numpy.random.weibull</code></li> <li><code>numpy.random.power</code></li> <li><code>numpy.random.geometric</code></li> <li><code>numpy.random.exponential</code></li> <li><code>numpy.random.poisson</code></li> <li><code>numpy.random.rayleigh</code></li> <li><code>numpy.random.normal</code></li> <li><code>numpy.random.uniform</code></li> <li><code>numpy.random.beta</code></li> <li><code>numpy.random.binomial</code></li> <li><code>numpy.random.f</code></li> <li><code>numpy.random.gamma</code></li> <li><code>numpy.random.lognormal</code></li> <li><code>numpy.random.laplace</code></li> <li><code>numpy.random.randint</code></li> <li><code>numpy.random.triangular</code></li> </ul>"},{"location":"api_docs/numpy/#numpydot-function","title":"<code>numpy.dot</code> function","text":"<ul> <li><code>numpy.dot</code> between a matrix and a vector</li> <li><code>numpy.dot</code>two vectors.</li> </ul>"},{"location":"api_docs/numpy/#numpy-io","title":"Numpy I/O","text":"<ul> <li><code>numpy.ndarray.tofile</code> </li> <li><code>numpy.fromfile</code></li> </ul> <p>Our documentation on scalable I/O contains example usage and more system specific instructions.</p>"},{"location":"api_docs/numpy/#miscellaneous","title":"Miscellaneous","text":"<ul> <li>Numpy array comprehension : e.g. : A = np.array([i**2 for i in range(N)])</li> </ul> <p>Note</p> <p>Optional arguments are not supported unless if explicitly mentioned here. For operations on multi-dimensional arrays, automatic broadcast of dimensions of size 1 is not supported.</p>"},{"location":"api_docs/numpy/#numpy-dot-parallelization","title":"Numpy dot() Parallelization","text":"<p>The <code>np.dot</code> function has different distribution rules based on the number of dimensions and the distributions of its input arrays. The example below demonstrates two cases:</p> <pre><code>@bodo.jit\ndef example_dot(N, D):\nX = np.random.ranf((N, D))\nY = np.random.ranf(N)\nw = np.dot(Y, X)\nz = np.dot(X, w)\nreturn z.sum()\nexample_dot(1024, 10)\nexample_dot.distributed_diagnostics()\n</code></pre> <p>Here is the output of <code>distributed_diagnostics()</code>:</p> <pre><code>Data distributions:\n  $X.130               1D_Block\n  $Y.131               1D_Block\n  $b.2.158             REP\n\nParfor distributions:\n  0                    1D_Block\n  1                    1D_Block\n  3                    1D_Block\nDistributed listing for function example_dot, ../tmp/dist_rep.py (4)\n++++++++++++++++++++++++++++++++++| parfor_id/variable: distribution\n@bodo.jit                         |\ndef example_dot(N, D):            |\n    X = np.random.ranf((N, D))++++| #0: 1D_Block, $X.130: 1D_Block\n    Y = np.random.ranf(N)+++++++++| #1: 1D_Block, $Y.131: 1D_Block\n    w = np.dot(Y, X)++++++++++++++| $b.2.158: REP\n    z = np.dot(X, w)++++++++++++++| #3: 1D_Block\n    return z.sum()                |\n</code></pre> <p>The first <code>dot</code> has a 1D array with <code>1D_Block</code> distribution as first input <code>Y</code>), while the second input is a 2D array with <code>1D_Block</code> distribution (<code>X</code>). Hence, <code>dot</code> is a sum reduction across distributed datasets and therefore, the output (<code>w</code>) is on the <code>reduce</code> side and is  assigned <code>REP</code> distribution.</p> <p>The second <code>dot</code> has a 2D array with <code>1D_Block</code> distribution (<code>X</code>) as first input, while the second input is a REP array (<code>w</code>). Hence, the computation is data-parallel across rows of <code>X</code>, which implies a <code>1D_Block</code> distribution for output (<code>z</code>).</p> <p>Variable <code>z</code> does not exist in the distribution report since the compiler optimizations were able to eliminate it. Its values are generated and consumed on-the-fly, without memory load/store overheads.</p>"},{"location":"api_docs/udfs/","title":"User-Defined Functions (UDFs)","text":"<p>While Pandas and other APIs can be extremely expressive, many data science and data engineering use cases require additional functionality beyond what is directly offered. In these situations, many programmers create User Defined Functions, or UDFs, which are Python functions designed to compute on each row or groups of rows depending on the context.</p>"},{"location":"api_docs/udfs/#using-udfs-with-bodo","title":"Using UDFs with Bodo","text":"<p>Bodo users can construct UDFs either by defining a separate JIT function or by creating a function within a JIT function (either via a lambda or closure). For example, here are two ways to construct a UDF that advances each element of a Timestamp Series to the last day of the current month.</p> <pre><code>import pandas as pd\nimport bodo\n@bodo.jit\ndef jit_udf(x):\nreturn x + pd.tseries.offsets.MonthEnd(n=0, normalize=True)\n@bodo.jit\ndef jit_example(S):\nreturn S.map(jit_udf)\n@bodo.jit\ndef lambda_example(S):\nreturn S.map(lambda x: x + pd.tseries.offsets.MonthEnd(n=0, normalize=True))\nS = pd.Series(pd.date_range(start='1/1/2021', periods=100))\npd.testing.assert_series_equal(jit_example(S), lambda_example(S))\n</code></pre> <p>UDFs can be used to compute one value per row or group (map functions) or compute an aggregation (agg functions). Bodo provides APIs for both, which are summarized below. Please refer to supported Pandas API for more information.</p>"},{"location":"api_docs/udfs/#map-functions","title":"Map Functions","text":"<ul> <li><code>Series.map</code></li> <li><code>Series.apply</code></li> <li><code>Series.pipe</code></li> <li><code>DataFrame.map</code></li> <li><code>DataFrame.apply</code></li> <li><code>DataFrame.pipe</code></li> <li><code>GroupBy.apply</code></li> <li><code>GroupBy.pipe</code></li> <li><code>GroupBy.transform</code></li> </ul>"},{"location":"api_docs/udfs/#agg-functions","title":"Agg Functions","text":"<ul> <li><code>GroupBy.agg</code></li> <li><code>GroupBy.aggregate</code></li> </ul>"},{"location":"api_docs/udfs/#udf-performance","title":"UDF Performance","text":"<p>Bodo offers support for UDFs without the significant runtime penalty generally incurred in Pandas. An example of this is shown in the quick started guide.</p> <p>Bodo achieves a drastic performance advantage on UDFs because UDFs can be optimized by similar to any other JIT code. In contrast, library based solutions are typically limited in their ability to optimize UDFs.</p>"},{"location":"api_docs/udfs/#additional-arguments","title":"Additional Arguments","text":"<p>We recommend passing additional variables to UDFs explicitly, instead of directly using variables local to the function defining the UDF. The latter is called the \\\"captured\\\" variables case, which is often error-prone and may result in compilation errors.</p> <p>For example, consider a UDF that appends a variable suffix to each string in a Series of strings. The proper way to write this function is to use the <code>args</code> argument to <code>Series.apply()</code>.</p> <pre><code>import pandas as pd\nimport bodo\n@bodo.jit\ndef add_suffix(S, suffix):\nreturn S.apply(lambda x, suf: x + suf, args=(suffix,))\nS = pd.Series([\"abc\", \"edf\", \"32\", \"Vew3\", \"er3r2\"] * 10)\nsuffix = \"_\"\nadd_suffix(S, suffix)\n</code></pre> <p>Alternatively, arguments can be passed by keyword.</p> <pre><code>@bodo.jit\ndef add_suffix(S, suffix):\nreturn S.apply(lambda x, suf: x + suf, suf=suffix)\n</code></pre> <p>Note</p> <p>Not all APIs support additional arguments. Please refer to supported Pandas API for more information on intended API usage.</p>"},{"location":"api_docs/udfs/#apply-with-pandas-methods-and-numpy-ufuncs","title":"Apply with Pandas Methods and Numpy ufuncs","text":"<p>In addition to UDFs, the <code>apply</code> API can also be used to call Pandas methods and Numpy ufuncs. To execute a Pandas method, you can provide the method name as a string.</p> <pre><code>import pandas as pd\nimport bodo\n@bodo.jit\ndef ex(S):\nreturn S.apply(\"nunique\")\nS = pd.Series(list(np.arange(100) + list(np.arange(100))))\nex(S)\n</code></pre> <p>Numpy ufuncs can either be provided with a string matching the name or with the function itself.</p> <pre><code>import numpy as np\nimport pandas as pd\nimport bodo\n@bodo.jit\ndef ex_str(S):\nreturn S.apply(\"sin\")\ndef ex_func(S):\nreturn S.apply(np.sin)\nS = pd.Series(list(np.arange(100) + list(np.arange(100))))\npd.testing.assert_series_equal(ex_str(S), ex_func(S))\n</code></pre> <p>Note</p> <p>Numpy ufuncs are not currently supported with DataFrames.</p>"},{"location":"api_docs/udfs/#type-stability-restrictions","title":"Type Stability Restrictions","text":"<p>Bodo's type stability requirements can encounter some limitations when either using <code>DataFrame.apply</code> with different column types or when returning a DataFrame.</p>"},{"location":"api_docs/udfs/#differently-typed-columns","title":"Differently Typed Columns","text":"<p><code>DataFrame.apply</code> maps user provided UDFs to each row of the DataFrame. In the situation where a DataFrame has columns of different types, the Series passed to the UDF will contain values with different types. Bodo internally represents these as a Heterogeneous Series. This representation has limitations in the Series operations it supports. Please refer to the supported operations for heterogeneous series for more information.</p>"},{"location":"api_docs/udfs/#returning-a-dataframe","title":"Returning a DataFrame","text":"<p>In Pandas, <code>Series.apply</code> or <code>DataFrame.apply</code> there are multiple ways to return a DataFrame instead of a Series. However, for type stability reasons, Bodo can only infer a DataFrame when returning a Series whose size can be inferred at compile time for each row.</p> <p>Note</p> <p>If you provide an Index, then all Index values must be compile time constants.</p> <p>Here is an example using<code>Series.apply</code> to return a DataFrame.</p> <pre><code>import pandas as pd\nimport bodo\n@bodo.jit\ndef series_ex(S):\nreturn S.apply(lambda x: pd.Series((1, x)))\nS = pd.Series(list(np.arange(100) + list(np.arange(100))))\nseries_ex(S)\n</code></pre> <p>If using a UDF that returns a DataFrame in Pandas through another means, this behavior will not match in Bodo and may result in a compilation error. Please convert your solution to one of the supported methods if possible.</p>"},{"location":"api_docs/ml/","title":"Machine Learning","text":"<p>Bodo natively supports use of scikit-learn and XGBoost libraries with large-scale distributed data inside <code>bodo.jit</code> decorated functions.</p> <ul> <li>Scikit-Learn</li> <li>XGBoost</li> </ul>"},{"location":"api_docs/ml/xgboost/","title":"XGBoost","text":"<p>This page lists the XGBoost (using the Scikit-Learn-like API) classes and functions that Bodo supports natively inside JIT functions.</p>"},{"location":"api_docs/ml/xgboost/#installing-xgboost","title":"Installing XGBoost","text":"<p>You will need to build XGBoost with MPI support from source. XGBoost version must be <code>&lt;= 1.5.1</code>. Refer to XGBoost instructions about building requirements for more details. Then, build XGBoost with MPI support from source and install it in your Bodo environment as follows:</p> <pre><code>git clone --recursive https://github.com/dmlc/xgboost --branch v1.5.1\ncd xgboost\nmkdir build\ncd build\ncmake -DRABIT_BUILD_MPI=ON ..\nmake -j4\ncd ../python-package\npython setup.py install\n</code></pre>"},{"location":"api_docs/ml/xgboost/#xgboostxgbclassifier","title":"<code>xgboost.XGBClassifier</code>","text":"<p>This class provides implementation of the scikit-learn API for XGBoost classification with distributed large-scale learning.</p>"},{"location":"api_docs/ml/xgboost/#methods","title":"Methods","text":""},{"location":"api_docs/ml/xgboost/#xgboostxgbclassifierfit","title":"<code>xgboost.XGBClassifier.fit</code>","text":"<ul> <li> <p><code>xgboost.XGBClassifier.fit(X, y, sample_weight=None, base_margin=None, eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True, xgb_model=None, sample_weight_eval_set=None, feature_weights=None, callbacks=None)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>X</code></p> <p>NumPy Array or Pandas Dataframes</p> <p><code>y</code></p> <p>NumPy Array or Pandas Dataframes</p> </li> </ul>"},{"location":"api_docs/ml/xgboost/#xgboostxgbclassifierpredict","title":"<code>xgboost.XGBClassifier.predict</code>","text":"<ul> <li> <p><code>xgboost.XGBClassifier.predict(X, output_margin=False, ntree_limit=None, validate_features=True, base_margin=None)</code> </p> <p>Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>X</code></p> <p>NumPy Array or Pandas Dataframes</p> </li> </ul>"},{"location":"api_docs/ml/xgboost/#xgboostxgbclassifierpredict_proba","title":"<code>xgboost.XGBClassifier.predict_proba</code>","text":"<ul> <li> <p><code>xgboost.XGBClassifier.predict_proba(X, ntree_limit=None, validate_features=True, base_margin=None)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>X</code></p> <p>NumPy Array or Pandas Dataframes</p> </li> </ul>"},{"location":"api_docs/ml/xgboost/#attributes","title":"Attributes","text":""},{"location":"api_docs/ml/xgboost/#xgboostxgbclassifierfeature_importances_","title":"<code>xgboost.XGBClassifier.feature_importances_</code>","text":"<ul> <li><code>xgboost.XGBClassifier.feature_importances_</code> </li> </ul>"},{"location":"api_docs/ml/xgboost/#example-usage","title":"Example Usage:","text":"<pre><code>&gt;&gt;&gt; import bodo\n&gt;&gt;&gt; import xgboost as xgb\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; @bodo.jit\n&gt;&gt;&gt; def test_xgbc():\n...   X = np.random.rand(5, 10)\n...   y = np.random.randint(0, 2, 5)\n...   clf = xgb.XGBClassifier(\n...   booster=\"gbtree\",\n...   random_state=0,\n...   tree_method=\"hist\",\n...   )\n...   clf.fit(X, y)\n...   print(clf.predict([[1, 2, 3, 4, 5, 6]]))\n...   print(clf.feature_importances_)\n...\n&gt;&gt;&gt; test_xgbc(X, y)\n[1]\n[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n</code></pre>"},{"location":"api_docs/ml/xgboost/#xgboostxgbregressor","title":"<code>xgboost.XGBRegressor</code>","text":"<p>This class provides implementation of the scikit-learn API for XGBoost regression with distributed large-scale learning.</p>"},{"location":"api_docs/ml/xgboost/#methods_1","title":"Methods","text":""},{"location":"api_docs/ml/xgboost/#xgboostxgbregressorfit","title":"<code>xgboost.XGBRegressor.fit</code>","text":"<ul> <li> <p><code>xgboost.XGBRegressor.fit(X, y, sample_weight=None, base_margin=None, eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True, xgb_model=None, sample_weight_eval_set=None, feature_weights=None, callbacks=None)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>X</code></p> <p>NumPy Array</p> <p><code>y</code></p> <p>NumPy Array</p> </li> </ul>"},{"location":"api_docs/ml/xgboost/#xgboostxgbregressorpredict","title":"<code>xgboost.XGBRegressor.predict</code>","text":"<ul> <li> <p><code> xgboost.XGBRegressor.predict(X, output_margin=False, ntree_limit=None, validate_features=True, base_margin=None)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>X</code></p> <p>NumPy Array</p> </li> </ul>"},{"location":"api_docs/ml/xgboost/#attributes_1","title":"Attributes","text":""},{"location":"api_docs/ml/xgboost/#xgboostxgbregressorfeature_importances_","title":"<code>xgboost.XGBRegressor.feature_importances_</code>","text":"<ul> <li><code>xgboost.XGBRegressor.feature_importances_</code> </li> </ul>"},{"location":"api_docs/ml/xgboost/#example-usage_1","title":"Example Usage","text":"<pre><code>&gt;&gt;&gt; import bodo\n&gt;&gt;&gt; import xgboost as xgb\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; np.random.seed(42)\n&gt;&gt;&gt; @bodo.jit\n&gt;&gt;&gt; def test_xgbc():\n...   X = np.random.rand(5, 10)\n...   y = np.random.rand(5)\n...   clf = xgb.XGBRegressor()\n...   clf.fit(X, y)\n...   print(clf.predict([[1, 2, 3, 4, 5, 6]]))\n...   print(clf.feature_importances_)\n...\n&gt;&gt;&gt; test_xgbc(X, y)\n[0.84368145]\n[5.7460850e-01 1.2052832e-04 0.0000000e+00 4.2441860e-01 1.5441242e-04\n6.9795933e-04 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n</code></pre>"},{"location":"api_docs/ml/sklearn/","title":"Scikit-learn","text":"<p>Bodo supports <code>scikit-learn</code> versions <code>1.1.*</code>.</p> <p>Install scikit-learn in your Bodo environment:</p> <pre><code>conda install scikit-learn='1.1.*' -c conda-forge\n</code></pre> <ul> <li>sklearn.cluster</li> <li>sklearn.ensemble</li> <li>sklearn.feature_extraction</li> <li>sklearn.linear_model</li> <li>sklearn.metrics</li> <li>sklearn.model_selection</li> <li>sklearn.naive_bayes</li> <li>sklearn.preprocessing</li> <li>sklearn.svm</li> </ul>"},{"location":"api_docs/ml/sklearn/cluster/","title":"sklearn.cluster: Clustering","text":""},{"location":"api_docs/ml/sklearn/cluster/#sklearnclusterkmeans","title":"sklearn.cluster.KMeans","text":"<p><code>sklearn.cluster.KMeans</code>This class provides K-Means clustering model.</p> <p>Important</p> <p>Currently, this model works by gathering all the data in a single node and  then generating K-Means model. Make sure you have enough memory on the first  node in your hostfile.</p>"},{"location":"api_docs/ml/sklearn/cluster/#methods","title":"Methods","text":""},{"location":"api_docs/ml/sklearn/cluster/#sklearnclusterkmeansfit","title":"sklearn.cluster.KMeans.fit","text":"<ul> <li> <p><code>sklearn.cluster.KMeans.fit(X, y=None, sample_weight=None)</code> Supported Arguments </p> <ul> <li><code>X</code>: NumPy Array, Pandas Dataframes, or CSR sparse matrix.</li> <li><code>sample_weight</code>: Numeric NumPy Array</li> </ul> <p>Note</p> <p>Bodo ignores <code>y</code>, which is consistent with scikit-learn.</p> </li> </ul>"},{"location":"api_docs/ml/sklearn/cluster/#sklearnclusterkmeanspredict","title":"sklearn.cluster.KMeans.predict","text":"<ul> <li><code> sklearn.cluster.KMeans.predict(X, sample_weight=None)</code> Supported Arguments <ul> <li><code>X</code>: NumPy Array, Pandas Dataframes, or CSR sparse matrix.</li> <li><code>sample_weight</code>: Numeric NumPy Array</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/cluster/#sklearnclusterkmeansscore","title":"sklearn.cluster.KMeans.score","text":"<ul> <li> <p><code> sklearn.cluster.KMeans.score(X, y=None, sample_weight=None)</code> Supported Arguments </p> <ul> <li><code>X</code>: NumPy Array, Pandas Dataframes, or CSR sparse matrix.</li> <li><code>sample_weight</code>: Numeric NumPy Array</li> </ul> <p>Note</p> <p>Bodo ignores y, which is consistent with scikit-learn.</p> </li> </ul>"},{"location":"api_docs/ml/sklearn/cluster/#sklearnclusterkmeanstransform","title":"sklearn.cluster.KMeans.transform","text":"<ul> <li><code> sklearn.cluster.KMeans.transform(X)</code> Supported Arguments <ul> <li><code>X</code>: NumPy Array, Pandas Dataframes, or CSR sparse matrix.</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/cluster/#example-usage","title":"Example Usage","text":"<pre><code>&gt;&gt;&gt; import bodo\n&gt;&gt;&gt; from sklearn.cluster import KMeans\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; @bodo.jit\n&gt;&gt;&gt; def test_kmeans(X):\n...   kmeans = KMeans(n_clusters=2)\n...   kmeans.fit(X)\n...   ans = kmeans.predict([[0, 0], [12, 3]])\n...   print(ans)\n...\n&gt;&gt;&gt; X = np.array([[1, 2], [1, 4], [1, 0], [10, 2], [10, 4], [10, 0]])\n&gt;&gt;&gt; test_kmeans(X)\n[1 0]\n</code></pre>"},{"location":"api_docs/ml/sklearn/ensemble/","title":"sklearn.ensemble","text":""},{"location":"api_docs/ml/sklearn/ensemble/#sklearnensemblerandomforestclassifier","title":"sklearn.ensemble.RandomForestClassifier","text":"<p><code>sklearn.ensemble.RandomForestClassifier</code></p> <p>This class provides Random Forest Classifier, an ensemble learning model, for distributed large-scale learning.</p> <p>Important</p> <p><code>random_state</code> value is ignored when running on a multi-node cluster.</p>"},{"location":"api_docs/ml/sklearn/ensemble/#methods","title":"Methods","text":""},{"location":"api_docs/ml/sklearn/ensemble/#sklearnensemblerandomforestclassifierfit","title":"sklearn.ensemble.RandomForestClassifier.fit","text":"<ul> <li><code>sklearn.ensemble.RandomForestClassifier.fit(X, y, sample_weight=None)</code> Supported Arguments <ul> <li><code>X</code>: NumPy Array, Pandas Dataframes, or CSR sparse matrix.</li> <li><code>y</code>: NumPy Array</li> <li><code>sample_weight</code>: Numeric NumPy Array (only if data is not     distributed)</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/ensemble/#sklearnensemblerandomforestclassifierpredict","title":"sklearn.ensemble.RandomForestClassifier.predict","text":"<ul> <li><code>sklearn.ensemble.RandomForestClassifier.predict(X)</code> Supported Arguments <ul> <li><code>X</code>: NumPy Array, Pandas Dataframes, or CSR sparse matrix.</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/ensemble/#sklearnensemblerandomforestclassifierpredict_log_proba","title":"sklearn.ensemble.RandomForestClassifier.predict_log_proba","text":"<ul> <li><code>sklearn.ensemble.RandomForestClassifier.predict_log_proba(X)</code> Supported Arguments <ul> <li><code>X</code>: NumPy Array, Pandas Dataframes, or CSR sparse matrix.</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/ensemble/#sklearnensemblerandomforestclassifierpredict_proba","title":"sklearn.ensemble.RandomForestClassifier.predict_proba","text":"<ul> <li><code>sklearn.ensemble.RandomForestClassifier.predict_proba(X)</code> Supported Arguments <ul> <li><code>X</code>: NumPy Array, Pandas Dataframes, or CSR sparse matrix.</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/ensemble/#sklearnensemblerandomforestclassifierscore","title":"sklearn.ensemble.RandomForestClassifier.score","text":"<ul> <li><code>sklearn.ensemble.RandomForestClassifier.score(X, y, sample_weight=None)</code> Supported Arguments <ul> <li><code>X</code>: NumPy Array or Pandas Dataframes.</li> <li><code>y</code>: NumPy Array</li> <li><code>sample_weight</code>: Numeric NumPy Array</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/ensemble/#example-usage","title":"Example Usage","text":"<pre><code>&gt;&gt;&gt; import bodo\n&gt;&gt;&gt; from sklearn.ensemble import RandomForestClassifier\n&gt;&gt;&gt; from sklearn.datasets import make_classification\n&gt;&gt;&gt; X, y = make_classification(n_samples=1000, n_features=4,\n...                            n_informative=2, n_redundant=0,\n...                            random_state=0, shuffle=False)\n&gt;&gt;&gt; @bodo.jit\n&gt;&gt;&gt; def test_random_forest_classifier(X, y):\n...   clf = RandomForestClassifier(max_depth=2)\n...   clf.fit(X, y)\n...   ans = clf.predict(np.array([[0, 0, 0, 0]]))\n...   print(ans)\n...\n&gt;&gt;&gt; test_random_forest_classifier(X, y)\n[1]\n</code></pre>"},{"location":"api_docs/ml/sklearn/ensemble/#sklearnensemblerandomforestregressor","title":"sklearn.ensemble.RandomForestRegressor","text":"<p><code>sklearn.ensemble.RandomForestRegressor</code> This class provides Random Forest Regressor, an ensemble learning model, for distributed large-scale learning.</p> <p>Important</p> <p><code>random_state</code> value is ignored when running on a multi-node cluster.</p>"},{"location":"api_docs/ml/sklearn/ensemble/#methods_1","title":"Methods","text":""},{"location":"api_docs/ml/sklearn/ensemble/#sklearnensemblerandomforestregressorfit","title":"sklearn.ensemble.RandomForestRegressor.fit","text":"<ul> <li><code>sklearn.ensemble.RandomForestRegressor.fit(X, y, sample_weight=None)</code> Supported Arguments <ul> <li><code>X</code>: NumPy Array, Pandas Dataframes, or CSR sparse matrix.</li> <li><code>y</code>: NumPy Array</li> <li><code>sample_weight</code>: Numeric NumPy Array (only if data is not     distributed)</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/ensemble/#sklearnensemblerandomforestregressorpredict","title":"sklearn.ensemble.RandomForestRegressor.predict","text":"<ul> <li><code>sklearn.ensemble.RandomForestRegressor.predict(X)</code> Supported Arguments <ul> <li><code>X</code>: NumPy Array, Pandas Dataframes, or CSR sparse matrix.</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/ensemble/#sklearnensemblerandomforestregressorscore","title":"sklearn.ensemble.RandomForestRegressor.score","text":"<ul> <li><code>sklearn.ensemble.RandomForestRegressor.score(X, y, sample_weight=None)</code> Supported Arguments <ul> <li><code>X</code>: NumPy Array, Pandas Dataframes, or CSR sparse matrix.</li> <li><code>y</code>: NumPy Array</li> <li><code>sample_weight</code>: Numeric NumPy Array</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/ensemble/#example-usage_1","title":"Example Usage","text":"<pre><code>&gt;&gt;&gt; import bodo\n&gt;&gt;&gt; from sklearn.ensemble import RandomForestRegressor\n&gt;&gt;&gt; from sklearn.datasets import make_regression\n&gt;&gt;&gt; X, y = make_regression(n_features=4, n_informative=2,\n... random_state=0, shuffle=False)\n&gt;&gt;&gt; @bodo.jit\n&gt;&gt;&gt; def test_random_forest_regressor(X, y):\n...   regr = RandomForestRegressor(max_depth=2)\n...   regr.fit(X, y)\n...   ans = regr.predict(np.array([[0, 0, 0, 0]]))\n...   print(ans)\n...\n&gt;&gt;&gt; test_random_forest_regressor(X, y)\n[-6.7933243]\n</code></pre>"},{"location":"api_docs/ml/sklearn/feature_extraction/","title":"sklearn.feature_extraction","text":""},{"location":"api_docs/ml/sklearn/feature_extraction/#sklearnfeature_extractiontextcountvectorizer","title":"sklearn.feature_extraction.text.CountVectorizer","text":"<p><code>sklearn.feature_extraction.text.CountVectorizer</code></p> <p>This class provides CountVectorizer support to convert a collection of text documents to a matrix of token counts.</p> <p>Note</p> <p>Arguments <code>max_df</code> and <code>min_df</code> are not supported yet.</p>"},{"location":"api_docs/ml/sklearn/feature_extraction/#methods","title":"Methods","text":""},{"location":"api_docs/ml/sklearn/feature_extraction/#sklearnfeature_extractiontextcountvectorizerfit_transform","title":"sklearn.feature_extraction.text.CountVectorizer.fit_transform","text":"<ul> <li> <p><code>sklearn.feature_extraction.text.CountVectorizer.fit_transform ( raw_documents, y=None ) </code> Supported Arguments </p> <ul> <li><code>raw_documents</code>: iterables ( list, tuple, or NumPy Array, or Pandas Series that contains string)</li> </ul> <p>Note</p> <p>Bodo ignores <code>y</code>, which is consistent with scikit-learn.</p> </li> </ul>"},{"location":"api_docs/ml/sklearn/feature_extraction/#sklearnfeature_extractiontextcountvectorizerget_feature_names_out","title":"sklearn.feature_extraction.text.CountVectorizer.get_feature_names_out","text":"<ul> <li><code>sklearn.feature_extraction.text.CountVectorizer. get_feature_names_out()</code> </li> </ul>"},{"location":"api_docs/ml/sklearn/feature_extraction/#example-usage","title":"Example Usage","text":"<pre><code>&gt;&gt;&gt; import bodo\n&gt;&gt;&gt; from sklearn.feature_extraction.text import CountVectorizer\n&gt;&gt;&gt; corpus = [\n... 'This is the first document.',\n... 'This document is the second document.',\n... 'And this is the third one.',\n... 'Is this the first document?',\n... ]\n&gt;&gt;&gt; @bodo.jit\n&gt;&gt;&gt; def test_count_vectorizer(corpus):\n&gt;&gt;&gt;   vectorizer = CountVectorizer()\n&gt;&gt;&gt;   X = vectorizer.fit_transform(corpus)\n&gt;&gt;&gt;   print(vectorizer.get_feature_names_out())\n...\n&gt;&gt;&gt; test_count_vectorizer(corpus)\n['and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n</code></pre>"},{"location":"api_docs/ml/sklearn/feature_extraction/#sklearnfeature_extractiontexthashingvectorizer","title":"sklearn.feature_extraction.text.HashingVectorizer","text":"<p><code>sklearn.feature_extraction.text.HashingVectorizer</code></p> <p>This class provides <code>HashingVectorizer</code> support to convert a collection of text documents to a matrix of token occurrences.</p>"},{"location":"api_docs/ml/sklearn/feature_extraction/#methods_1","title":"Methods","text":""},{"location":"api_docs/ml/sklearn/feature_extraction/#sklearnfeature_extractiontexthashingvectorizerfit_transform","title":"sklearn.feature_extraction.text.HashingVectorizer.fit_transform","text":"<ul> <li> <p><code>sklearn.feature_extraction.text.HashingVectorizer.fit_transform(X, y=None)</code> Supported Arguments </p> <ul> <li><code>X</code>: iterables ( list, tuple, or NumPy Array, or Pandas        Series that contains string)</li> </ul> <p>Note</p> <p>Bodo ignores <code>y</code>, which is consistent with scikit-learn.</p> </li> </ul>"},{"location":"api_docs/ml/sklearn/feature_extraction/#example-usage_1","title":"Example Usage","text":"<pre><code>&gt;&gt;&gt; import bodo\n&gt;&gt;&gt; from sklearn.feature_extraction.text import HashingVectorizer\n&gt;&gt;&gt; corpus = [\n... 'This is the first document.',\n... 'This document is the second document.',\n... 'And this is the third one.',\n... 'Is this the first document?',\n... ]\n&gt;&gt;&gt; @bodo.jit\n&gt;&gt;&gt; def test_hashing_vectorizer(corpus):\n&gt;&gt;&gt;   vectorizer = HashingVectorizer(n_features=2**4)\n&gt;&gt;&gt;   X = vectorizer.fit_transform(corpus)\n&gt;&gt;&gt;   print(X.shape)\n...\n&gt;&gt;&gt; test_hashing_vectorizer(corpus)\n(4, 16)\n</code></pre>"},{"location":"api_docs/ml/sklearn/linear_model/","title":"sklearn.linear_model","text":""},{"location":"api_docs/ml/sklearn/linear_model/#sklearnlinear_modellasso","title":"sklearn.linear_model.Lasso","text":"<p><code>sklearn.linear_model.Lasso</code></p> <p>This class provides Lasso regression support.</p>"},{"location":"api_docs/ml/sklearn/linear_model/#methods","title":"Methods","text":""},{"location":"api_docs/ml/sklearn/linear_model/#sklearnlinear_modellassofit","title":"sklearn.linear_model.Lasso.fit","text":"<ul> <li><code>sklearn.linear_model.Lasso.fit(X, y, sample_weight=None, check_input=True)</code> Supported Arguments <ul> <li><code>X</code>: NumPy Array or Pandas Dataframes.</li> <li><code>y</code>: NumPy Array.</li> <li><code>sample_weight</code>: Numeric NumPy Array (only if data is not     distributed)</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/linear_model/#sklearnlinear_modellassopredict","title":"sklearn.linear_model.Lasso.predict","text":"<ul> <li><code>sklearn.linear_model.Lasso.predict(X)</code> Supported Arguments <ul> <li><code>X</code>: NumPy Array or Pandas Dataframes.</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/linear_model/#sklearnlinear_modellassoscore","title":"sklearn.linear_model.Lasso.score","text":"<ul> <li><code>sklearn.linear_model.Lasso.score(X, y, sample_weight=None)</code> Supported Arguments <ul> <li><code>X</code>: NumPy Array or Pandas Dataframes.</li> <li><code>y</code>: NumPy Array or Pandas Dataframes.</li> <li><code>sample_weight</code>: Numeric NumPy Array or Pandas Dataframes.</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/linear_model/#example-usage","title":"Example Usage","text":"<pre><code>&gt;&gt;&gt; import bodo\n&gt;&gt;&gt; from sklearn.linear_model import Lasso\n&gt;&gt;&gt; from sklearn.preprocessing import StandardScaler\n&gt;&gt;&gt; from sklearn.datasets import make_regression\n&gt;&gt;&gt; X, y = make_regression(\n... n_samples=10,\n... n_features=10,\n... n_informative=5,\n... )\n&gt;&gt;&gt; @bodo.jit\n... def test_lasso(X, y):\n...   scaler = StandardScaler()\n...   scaler.fit(X)\n...   X = scaler.transform(X)\n...   reg = Lasso(alpha=0.1)\n...   reg.fit(X, y)\n...   ans = reg.predict(X)\n...   print(ans)\n...   print(\"score: \", reg.score(X, y))\n...\n&gt;&gt;&gt; test_lasso(X, y)\n[-108.40717491  -92.14977392  -54.82835898  -52.81762142  291.33173703\n60.60660979  128.64172956   30.42129155  110.20607814   58.05321319]\nscore:  0.9999971902794988\n</code></pre>"},{"location":"api_docs/ml/sklearn/linear_model/#sklearnlinear_modellinearregression","title":"sklearn.linear_model.LinearRegression","text":"<p><code>sklearn.linear_model.LinearRegression</code></p> <p>This class provides linear regression support.</p> <p>Note</p> <p>Multilabel targets are not currently supported.</p>"},{"location":"api_docs/ml/sklearn/linear_model/#methods_1","title":"Methods","text":""},{"location":"api_docs/ml/sklearn/linear_model/#sklearnlinear_modellinearregressionfit","title":"sklearn.linear_model.LinearRegression.fit","text":"<ul> <li><code>sklearn.linear_model.LinearRegression.fit(X, y, sample_weight=None)</code> Supported Arguments <ul> <li><code>X</code>: NumPy Array or Pandas Dataframes.</li> <li><code>y</code>: NumPy Array.</li> <li><code>sample_weight</code>: Numeric NumPy Array (only if data is not     distributed)</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/linear_model/#sklearnlinear_modellinearregressionpredict","title":"sklearn.linear_model.LinearRegression.predict","text":"<ul> <li><code>sklearn.linear_model.LinearRegression.predict(X)</code> Supported Arguments <ul> <li><code>X</code>: NumPy Array or Pandas Dataframes.</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/linear_model/#sklearnlinear_modellinearregressionscore","title":"sklearn.linear_model.LinearRegression.score","text":"<ul> <li><code>sklearn.linear_model.LinearRegression.score(X, y, sample_weight=None)</code> Supported Arguments <ul> <li><code>X</code>: NumPy Array or Pandas Dataframes.</li> <li><code>y</code>: NumPy Array or Pandas Dataframes.</li> <li><code>sample_weight</code>: Numeric NumPy Array or Pandas Dataframes.</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/linear_model/#attributes","title":"Attributes","text":""},{"location":"api_docs/ml/sklearn/linear_model/#sklearnlinear_modellinearregressioncoef_","title":"sklearn.linear_model.LinearRegression.coef_","text":"<ul> <li><code>sklearn.linear_model.LinearRegression.coef_</code> </li> </ul>"},{"location":"api_docs/ml/sklearn/linear_model/#example-usage_1","title":"Example Usage","text":"<pre><code>&gt;&gt;&gt; import bodo\n&gt;&gt;&gt; from sklearn.linear_model import LinearRegression\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n&gt;&gt;&gt; y = np.dot(X, np.array([1, 2])) + 3\n&gt;&gt;&gt; @bodo.jit\n... def test_linear_reg(X, y):\n...   reg = LinearRegression()\n...   reg.fit(X, y)\n...   print(\"score: \", reg.score(X, y))\n...   print(\"coef_: \", reg.coef_)\n...   ans = reg.predict(np.array([[3, 5]]))\n...   print(ans)\n...\n&gt;&gt;&gt; test_linear_reg(X, y)\nscore:  1.0\ncoef_:  [1. 2.]\n[16.]\n</code></pre>"},{"location":"api_docs/ml/sklearn/linear_model/#sklearnlinear_modellogisticregression","title":"sklearn.linear_model.LogisticRegression","text":"<p><code>sklearn.linear_model.LogisticRegression</code>This class provides logistic regression classifier.</p> <p>Note</p> <p>Bodo uses Stochastic Gradient Descent (SGD) to train linear models across multiple nodes in a distributed fashion. This produces models that have similar accuracy compared to their corresponding sequential version in most cases. To achieve that, it is highly recommended to scale your data using <code>StandardScaler</code> before training and/or testing the model. See scikit-learn for more tips on how to tune model parameters for SGD here.</p>"},{"location":"api_docs/ml/sklearn/linear_model/#methods_2","title":"Methods","text":""},{"location":"api_docs/ml/sklearn/linear_model/#sklearnlinear_modellogisticregressionfit","title":"sklearn.linear_model.LogisticRegression.fit","text":"<ul> <li><code>sklearn.linear_model.LogisticRegression.fit(X, y, sample_weight=None)</code> Supported Arguments <ul> <li><code>X</code>: NumPy Array or Pandas Dataframes.</li> <li><code>y</code>: NumPy Array.</li> <li><code>sample_weight</code>: Numeric NumPy Array (only if data is not      distributed)</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/linear_model/#sklearnlinear_modellogisticregressionpredict","title":"sklearn.linear_model.LogisticRegression.predict","text":"<ul> <li><code>sklearn.linear_model.LogisticRegression.predict(X)</code> Supported Arguments <ul> <li><code>X</code>: NumPy Array or Pandas Dataframes.</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/linear_model/#sklearnlinear_modellogisticregressionpredict_log_proba","title":"sklearn.linear_model.LogisticRegression.predict_log_proba","text":"<ul> <li><code>sklearn.linear_model.LogisticRegression.predict_log_proba(X)</code> Supported Arguments <ul> <li><code>X</code>: NumPy Array or Pandas Dataframes.</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/linear_model/#sklearnlinear_modellogisticregressionpredict_proba","title":"sklearn.linear_model.LogisticRegression.predict_proba","text":"<ul> <li><code>sklearn.linear_model.LogisticRegression.predict_proba(X)</code> Supported Arguments <ul> <li><code>X</code>: NumPy Array or Pandas Dataframes.</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/linear_model/#sklearnlinear_modellogisticregressionscore","title":"sklearn.linear_model.LogisticRegression.score","text":"<ul> <li><code>sklearn.linear_model.LogisticRegression.score(X, y, sample_weight=None)</code> Supported Arguments <ul> <li><code>X</code>: NumPy Array or Pandas Dataframes.</li> <li><code>y</code>: NumPy Array or Pandas Dataframes.</li> <li><code>sample_weight</code>: Numeric NumPy Array or Pandas Dataframes.</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/linear_model/#attributes_1","title":"Attributes","text":""},{"location":"api_docs/ml/sklearn/linear_model/#sklearnlinear_modellogisticregressioncoef_","title":"sklearn.linear_model.LogisticRegression.coef_","text":"<ul> <li><code>sklearn.linear_model.LogisticRegression.coef_</code> </li> </ul>"},{"location":"api_docs/ml/sklearn/linear_model/#example-usage_2","title":"Example Usage","text":"<pre><code>&gt;&gt;&gt; import bodo\n&gt;&gt;&gt; from sklearn.datasets import make_classification\n&gt;&gt;&gt; from sklearn.linear_model import LogisticRegression\n&gt;&gt;&gt; X, y = make_classification(\n... n_samples=1000,\n... n_features=10,\n... n_informative=5,\n... n_redundant=0,\n... random_state=0,\n... shuffle=0,\n... n_classes=2,\n... n_clusters_per_class=1\n... )\n&gt;&gt;&gt; @bodo.jit\n... def test_logistic(X, y):\n...   clf = LogisticRegression()\n...   clf.fit(X, y)\n...   ans = clf.predict(X)\n...   print(\"score: \", clf.score(X, y))\n...\n&gt;&gt;&gt; test_logistic(X, y)\nscore:  0.997\n</code></pre>"},{"location":"api_docs/ml/sklearn/linear_model/#sklearnlinear_modelridge","title":"sklearn.linear_model.Ridge","text":"<p><code>sklearn.linear_model.Ridge</code> This class provides ridge regression support.</p>"},{"location":"api_docs/ml/sklearn/linear_model/#methods_3","title":"Methods","text":""},{"location":"api_docs/ml/sklearn/linear_model/#sklearnlinear_modelridgefit","title":"sklearn.linear_model.Ridge.fit","text":"<ul> <li><code>sklearn.linear_model.Ridge.fit(X, y, sample_weight=None)</code> Supported Arguments <ul> <li><code>X</code>: NumPy Array or Pandas Dataframes.</li> <li><code>y</code>: NumPy Array.</li> <li><code>sample_weight</code>: Numeric NumPy Array (only if data is not  distributed)</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/linear_model/#sklearnlinear_modelridgepredict","title":"sklearn.linear_model.Ridge.predict","text":"<ul> <li><code>sklearn.linear_model.Ridge.predict(X)</code> Supported Arguments <ul> <li><code>X</code>: NumPy Array or Pandas Dataframes.</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/linear_model/#sklearnlinear_modelridgescore","title":"sklearn.linear_model.Ridge.score","text":"<ul> <li><code>sklearn.linear_model.Ridge.score(X, y, sample_weight=None)</code> Supported Arguments <ul> <li><code>X</code>: NumPy Array or Pandas Dataframes.</li> <li><code>y</code>: NumPy Array or Pandas Dataframes.</li> <li><code>sample_weight</code>: Numeric NumPy Array or Pandas Dataframes.</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/linear_model/#attributes_2","title":"Attributes","text":""},{"location":"api_docs/ml/sklearn/linear_model/#sklearnlinear_modelridgecoef_","title":"sklearn.linear_model.Ridge.coef_","text":"<ul> <li><code>sklearn.linear_model.Ridge.coef_</code> </li> </ul>"},{"location":"api_docs/ml/sklearn/linear_model/#example-usage_3","title":"Example Usage","text":"<pre><code>&gt;&gt;&gt; import bodo\n&gt;&gt;&gt; from sklearn.linear_model import Ridge\n&gt;&gt;&gt; from sklearn.datasets import make_regression\n&gt;&gt;&gt; X, y = make_regression(\n... n_samples=1000,\n... n_features=10,\n... n_informative=5,\n... )\n&gt;&gt;&gt; @bodo.jit\n... def test_ridge(X, y):\n...   reg = Ridge(alpha=1.0)\n...   reg.fit(X, y)\n...   print(\"score: \", reg.score(X, y))\n...   print(\"coef_: \", reg.coef_)\n...\n&gt;&gt;&gt; test_ridge(X, y)\nscore:  0.999998857191076\ncoef_:  [ 1.07963671e-03  2.35051611e+01  9.46672751e+01  8.01581769e-03\n3.66612234e+01  5.82527987e-03  2.60885671e+01 -3.49454103e-03\n8.39573884e+01 -7.52605483e-03]\n</code></pre>"},{"location":"api_docs/ml/sklearn/linear_model/#sklearnlinear_modelsgdclassifier","title":"sklearn.linear_model.SGDClassifier","text":"<p><code>sklearn.linear_model.SGDClassifier</code></p> <p>This class provides linear classification models with SGD optimization which allows distributed large-scale learning.</p> <ul> <li>Supported loss functions <code>hinge</code> and <code>log</code>.</li> <li><code>SGDClassifier(loss='hinge')</code> is equivalent to SVM linear classifer.</li> <li><code>SGDClassifier(loss='log')</code> is equivalent to logistic regression classifer.</li> <li><code>early_stopping</code> is not supported yet.</li> </ul>"},{"location":"api_docs/ml/sklearn/linear_model/#methods_4","title":"Methods","text":""},{"location":"api_docs/ml/sklearn/linear_model/#sklearnlinear_modelsgdclassifierfit","title":"sklearn.linear_model.SGDClassifier.fit","text":"<ul> <li> <p><code>sklearn.linear_model.SGDClassifier.fit(X, y, coef_init=None, intercept_init=None, sample_weight=None)</code> </p> <p>Supported Arguments  -   <code>X</code>: NumPy Array or Pandas Dataframes. -   <code>y</code>: NumPy Array. -   <code>sample_weight</code>: Numeric NumPy Array (only if data is not  distributed)</p> </li> </ul>"},{"location":"api_docs/ml/sklearn/linear_model/#sklearnlinear_modelsgdclassifierpredict","title":"sklearn.linear_model.SGDClassifier.predict","text":"<ul> <li><code>sklearn.linear_model.SGDClassifier.predict(X)</code> Supported Arguments <ul> <li><code>X</code>: NumPy Array or Pandas Dataframes.</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/linear_model/#sklearnlinear_modelsgdclassifierpredict_log_proba","title":"sklearn.linear_model.SGDClassifier.predict_log_proba","text":"<ul> <li><code>sklearn.linear_model.SGDClassifier.predict_log_proba(X)</code> Supported Arguments <ul> <li><code>X</code>: NumPy Array or Pandas Dataframes.</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/linear_model/#sklearnlinear_modelsgdclassifierpredict_proba","title":"sklearn.linear_model.SGDClassifier.predict_proba","text":"<ul> <li><code>sklearn.linear_model.SGDClassifier.predict_proba(X)</code> Supported Arguments <ul> <li><code>X</code>: NumPy Array or Pandas Dataframes.</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/linear_model/#sklearnlinear_modelsgdclassifierscore","title":"sklearn.linear_model.SGDClassifier.score","text":"<ul> <li><code>sklearn.linear_model.SGDClassifier.score(X, y, sample_weight=None)</code> Supported Arguments <ul> <li><code>X</code>: NumPy Array or Pandas Dataframes.</li> <li><code>y</code>: NumPy Array or Pandas Dataframes.</li> <li><code>sample_weight</code>: Numeric NumPy Array or Pandas Dataframes.</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/linear_model/#attributes_3","title":"Attributes","text":""},{"location":"api_docs/ml/sklearn/linear_model/#sklearnlinear_modelsgdclassifiercoef_","title":"sklearn.linear_model.SGDClassifier.coef_","text":"<ul> <li><code>sklearn.linear_model.SGDClassifier.coef_"},{"location":"api_docs/ml/sklearn/linear_model/#example-usage_4","title":"Example Usage","text":"<pre><code>&gt;&gt;&gt; import bodo\n&gt;&gt;&gt; from sklearn.linear_model import SGDClassifier\n&gt;&gt;&gt; from sklearn.preprocessing import StandardScaler\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n&gt;&gt;&gt; y = np.array([1, 1, 2, 2])\n&gt;&gt;&gt; @bodo.jit\n... def test_sgdclassifier(X, y):\n...   scaler = StandardScaler()\n...   scaler.fit(X)\n...   X = scaler.transform(X)\n...   clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\")\n...   clf.fit(X, y)\n...   ans = clf.predict(np.array([[-0.8, -1]]))\n...   print(ans)\n...   print(\"coef_: \", clf.coef_)\n...\n&gt;&gt;&gt; test_sgdclassifier(X, y)\n[1]\ncoef_:  [[6.18236102 9.77517107]]\n</code></pre>"},{"location":"api_docs/ml/sklearn/linear_model/#sklearnlinear_modelsgdregressor","title":"sklearn.linear_model.SGDRegressor","text":"<p><code>sklearn.linear_model.SGDRegressor</code></p> <p>This class provides linear regression models with SGD optimization which allows distributed large-scale learning.</p> <ul> <li>Supported loss function is <code>squared_error</code>. </li> <li> <p><code>early_stopping</code> is not supported yet.</p> </li> <li> <p><code>SGDRegressor(loss='squared_error', penalty='None')</code> is equivalent to linear regression.</p> </li> <li> <p><code>SGDRegressor(loss='squared_error', penalty='l2')</code> is equivalent to Ridge regression.</p> </li> <li> <p><code>SGDRegressor(loss='squared_error', penalty='l1')</code> is equivalent to Lasso regression.</p> </li> </ul>"},{"location":"api_docs/ml/sklearn/linear_model/#methods_5","title":"Methods","text":""},{"location":"api_docs/ml/sklearn/linear_model/#sklearnlinear_modelsgdregressorfit","title":"sklearn.linear_model.SGDRegressor.fit","text":"<ul> <li><code>sklearn.linear_model.SGDRegressor.fit(X, y, coef_init=None, intercept_init=None, sample_weight=None)</code> Supported Arguments <ul> <li><code>X</code>: NumPy Array or Pandas Dataframes.</li> <li><code>y</code>: NumPy Array.</li> <li><code>sample_weight</code>: Numeric NumPy Array (only if data is not                      distributed)</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/linear_model/#sklearnlinear_modelsgdregressorpredict","title":"sklearn.linear_model.SGDRegressor.predict","text":"<ul> <li> <p><code>sklearn.linear_model.SGDRegressor.predict(X)</code> Supported Arguments</p> <ul> <li><code>X</code>: NumPy Array or Pandas Dataframes.</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/linear_model/#sklearnlinear_modelsgdregressorscore","title":"sklearn.linear_model.SGDRegressor.score","text":"<ul> <li><code>sklearn.linear_model.SGDRegressor.score(X, y, sample_weight=None)</code> Supported Arguments <ul> <li><code>X</code>: NumPy Array or Pandas Dataframes.</li> <li><code>y</code>: NumPy Array or Pandas Dataframes.</li> <li><code>sample_weight</code>: Numeric NumPy Array or Pandas Dataframes.</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/linear_model/#example-usage_5","title":"Example Usage","text":"<pre><code>&gt;&gt;&gt; import bodo\n&gt;&gt;&gt; from sklearn.linear_model import SGDRegressor\n&gt;&gt;&gt; from sklearn.preprocessing import StandardScaler\n&gt;&gt;&gt; from sklearn.datasets import make_regression\n&gt;&gt;&gt; X, y = make_regression(\n... n_samples=1000,\n... n_features=10,\n... n_informative=5,\n... )\n&gt;&gt;&gt; @bodo.jit\n... def test_sgd_reg(X, y):\n...   scaler = StandardScaler()\n...   scaler.fit(X)\n...   X = scaler.transform(X)\n...   reg = SGDRegressor()\n...   reg.fit(X, y)\n...   print(\"score: \", reg.score(X, y))\n...\n&gt;&gt;&gt; test_sgd_reg(X, y)\n0.9999999836265652\n</code></pre>"},{"location":"api_docs/ml/sklearn/metrics/","title":"sklearn.metrics","text":""},{"location":"api_docs/ml/sklearn/metrics/#sklearnmetricsaccuracy_score","title":"sklearn.metrics.accuracy_score","text":"<ul> <li> <p><code>sklearn.metrics.accuracy_score(y_true, y_pred, normalize=True, sample_weight=None)</code> Supported Arguments </p> <ul> <li><code>y_true</code>: 1d array-like.</li> <li><code>y_pred</code>: 1d array-like.</li> <li><code>normalize</code>: bool.</li> <li><code>sample_weight</code>: 1d numeric array-like or None.</li> </ul> <p>Note</p> <p><code>y_true</code>, <code>y_pred</code>, and <code>sample_weight</code> (if provided) must be of same length.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; import bodo\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from sklearn.metrics import accuracy_score\n&gt;&gt;&gt; y_pred = np.array([0, 2, 1, 3])\n&gt;&gt;&gt; y_true = np.array([0, 1, 2, 3])\n&gt;&gt;&gt; @bodo.jit\n&gt;&gt;&gt; def test_accuracy_score(y_true, y_pred):\n...   print(accuracy_score(y_true, y_pred))\n&gt;&gt;&gt; test_accuracy_score(y_true, y_pred)\n0.5\n</code></pre> </li> </ul>"},{"location":"api_docs/ml/sklearn/metrics/#sklearnmetricsconfusion_matrix","title":"sklearn.metrics.confusion_matrix","text":"<ul> <li> <p><code>sklearn.metrics.confusion_matrix(y_true, y_pred, labels=None, sample_weight=None, normalize=None)</code> Supported Arguments </p> <ul> <li><code>y_true</code>: 1d array-like.</li> <li><code>y_pred</code>: 1d array-like.</li> <li><code>labels</code>: 1d array-like.</li> <li><code>sample_weight</code>: 1d numeric array-like or <code>None</code>.</li> <li><code>normalize</code>: Must be one of <code>'true'</code>, <code>'pred'</code>, <code>'all'</code>, or <code>None</code></li> </ul> <p>Note</p> <p><code>y_true</code>, <code>y_pred</code>, and <code>sample_weight</code> (if provided) must be of same length.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; import bodo\n&gt;&gt;&gt; from sklearn.metrics import confusion_matrix\n&gt;&gt;&gt; y_true = [2, 0, 2, 2, 0, 1]\n&gt;&gt;&gt; y_pred = [0, 0, 2, 2, 0, 2]\n&gt;&gt;&gt; @bodo.jit\n&gt;&gt;&gt; def test_confusion_matirx(y_true, y_pred):\n...   print(confusion_matrix(y_true, y_pred))\n&gt;&gt;&gt; test_confusion_matrix(y_true, y_pred)\n[[2 0 0]\n[0 0 1]\n[1 0 2]]\n</code></pre> </li> </ul>"},{"location":"api_docs/ml/sklearn/metrics/#sklearnmetricsf1_score","title":"sklearn.metrics.f1_score","text":"<ul> <li> <p><code>sklearn.metrics.f1_score(y_true, y_pred, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')</code> Supported Arguments </p> <ul> <li><code>y_true</code>: 1d array-like.</li> <li><code>y_pred</code>: 1d array-like.</li> <li><code>average</code>: Must be one of <code>'micro'</code>, <code>'macro'</code>, <code>'samples'</code>,     <code>'weighted'</code>, <code>'binary'</code>, or None.</li> </ul> <p>Note</p> <p><code>y_true</code> and <code>y_pred</code> must be of same length.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; import bodo\n&gt;&gt;&gt; from sklearn.metrics import f1_score\n&gt;&gt;&gt; y_true = [0, 1, 2, 0, 1, 2]\n&gt;&gt;&gt; y_pred = [0, 2, 1, 0, 0, 1]\n&gt;&gt;&gt; @bodo.jit\n&gt;&gt;&gt; def test_f1_score(y_true, y_pred):\n...   print(f1_score(y_true, y_pred, average='macro'))\n&gt;&gt;&gt; test_f1_score(y_true, y_pred)\n0.26666666666666666\n</code></pre> </li> </ul>"},{"location":"api_docs/ml/sklearn/metrics/#sklearnmetricsmean_absolute_error","title":"sklearn.metrics.mean_absolute_error","text":"<ul> <li> <p><code>sklearn.metrics.mean_absolute_error(y_true, y_pred, sample_weight=None, multioutput='uniform_average')</code> Supported Arguments </p> <ul> <li><code>y_true</code>: NumPy array.</li> <li><code>y_pred</code>: NumPy array.</li> <li><code>sample_weight</code>: Numeric NumPy array or None.</li> <li><code>multioutput</code>: Must be one of <code>'raw_values'</code>,     <code>'uniform_average'</code>, or array-like.</li> </ul> <p>Note</p> <p><code>y_true</code>, <code>y_pred</code>, and <code>sample_weight</code> (if provided) must be of same length.</p> <p>Example Usage <pre><code>&gt;&gt;&gt; import bodo\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from sklearn.metrics import mean_absolute_error\n&gt;&gt;&gt; y_true = np.array([[0.5, 1], [-1, 1], [7, -6]])\n&gt;&gt;&gt; y_pred = np.array([[0, 2], [-1, 2], [8, -5]])\n&gt;&gt;&gt; @bodo.jit\n&gt;&gt;&gt; def test_mean_absolute_error(y_true, y_pred):\n...   print(mean_absolute_error(y_true, y_pred, multioutput=[0.3, 0.7]))\n&gt;&gt;&gt; test_mean_absolute_error(y_true, y_pred)\n0.85\n</code></pre></p> </li> </ul>"},{"location":"api_docs/ml/sklearn/metrics/#sklearnmetricsmean_squared_error","title":"sklearn.metrics.mean_squared_error","text":"<ul> <li> <p><code>sklearn.metrics.mean_squared_error(y_true, y_pred, sample_weight=None, multioutput='uniform_average', squared=True)</code> Supported Arguments </p> <ul> <li><code>y_true</code>: NumPy array.</li> <li><code>y_pred</code>: NumPy array.</li> <li><code>sample_weight</code>: Numeric NumPy array or None.</li> <li><code>multioutput</code>: Must be one of <code>'raw_values'</code>,     <code>'uniform_average'</code>, or array-like.</li> </ul> <p>Note</p> <p><code>y_true</code>, <code>y_pred</code>, and <code>sample_weight</code> (if provided) must be of same length.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; import bodo\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from sklearn.metrics import mean_squared_error\n&gt;&gt;&gt; y_true = np.array([[0.5, 1], [-1, 1], [7, -6]])\n&gt;&gt;&gt; y_pred = np.array([[0, 2], [-1, 2], [8, -5]])\n&gt;&gt;&gt; @bodo.jit\n&gt;&gt;&gt; def test_mean_squared_error(y_true, y_pred):\n...   print(mean_squared_error(y_true, y_pred, multioutput=[0.3, 0.7]))\n&gt;&gt;&gt; test_mean_squared_error(y_true, y_pred)\n0.825\n</code></pre> </li> </ul>"},{"location":"api_docs/ml/sklearn/metrics/#sklearnmetricsprecision_score","title":"sklearn.metrics.precision_score","text":"<ul> <li> <p><code>sklearn.metrics.precision_score(y_true, y_pred, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')</code> Supported Arguments </p> <ul> <li><code>y_true</code>: 1d array-like.</li> <li><code>y_pred</code>: 1d array-like.</li> <li><code>average</code>: Must be one of <code>'micro'</code>, <code>'macro'</code>, <code>'samples'</code>,     <code>'weighted'</code>, <code>'binary'</code>, or <code>None</code>.</li> </ul> <p>Note</p> <p><code>y_true</code> and <code>y_pred</code> must be of same length.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; import bodo\n&gt;&gt;&gt; from sklearn.metrics import precision_score\n&gt;&gt;&gt; y_true = [0, 1, 2, 0, 1, 2]\n&gt;&gt;&gt; y_pred = [0, 2, 1, 0, 0, 1]\n&gt;&gt;&gt; @bodo.jit\n&gt;&gt;&gt; def test_precision_score(y_true, y_pred):\n...   print(precision_score(y_true, y_pred, average='macro'))\n&gt;&gt;&gt; test_precision_score(y_true, y_pred)\n0.2222222222222222\n</code></pre> </li> </ul>"},{"location":"api_docs/ml/sklearn/metrics/#sklearnmetricsr2_score","title":"sklearn.metrics.r2_score","text":"<ul> <li> <p><code>sklearn.metrics.r2_score(y_true, y_pred, sample_weight=None, multioutput='uniform_average')</code> Supported Arguments </p> <ul> <li><code>y_true</code>: NumPy array.</li> <li><code>y_pred</code>: NumPy array.</li> <li><code>sample_weight</code>: Numeric NumPy array or <code>None</code>.</li> <li><code>multioutput</code>: Must be one of <code>'raw_values'</code>,     <code>'uniform_average'</code>, <code>'variance_weighted'</code>, <code>None</code>, or      array-like.</li> </ul> <p>Note</p> <p><code>y_true</code>, <code>y_pred</code>, and <code>sample_weight</code> (if provided) must be of same length.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; import bodo\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from sklearn.metrics import r2_score\n&gt;&gt;&gt; y_true = np.array([[0.5, 1], [-1, 1], [7, -6]])\n&gt;&gt;&gt; y_pred = np.array([[0, 2], [-1, 2], [8, -5]])\n&gt;&gt;&gt; @bodo.jit\n&gt;&gt;&gt; def test_r2_score(y_true, y_pred):\n...   print(r2_score(y_true, y_pred, multioutput=[0.3, 0.7]))\n&gt;&gt;&gt; test_r2_score(y_true, y_pred)\n0.9253456221198156\n</code></pre> </li> </ul>"},{"location":"api_docs/ml/sklearn/metrics/#sklearnmetricsrecall_score","title":"sklearn.metrics.recall_score","text":"<ul> <li> <p><code>sklearn.metrics.recall_score(y_true, y_pred, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')</code> Supported Arguments </p> <ul> <li><code>y_true</code>: 1d array-like.</li> <li><code>y_pred</code>: 1d array-like.</li> <li><code>average</code>: Must be one of <code>'micro'</code>, <code>'macro'</code>, <code>'samples'</code>,     <code>'weighted'</code>, <code>'binary'</code>, or <code>None</code>.</li> </ul> <p>Note</p> <p><code>y_true</code> and <code>y_pred</code> must be of same length.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; import bodo\n&gt;&gt;&gt; from sklearn.metrics import recall_score\n&gt;&gt;&gt; y_true = [0, 1, 2, 0, 1, 2]\n&gt;&gt;&gt; y_pred = [0, 2, 1, 0, 0, 1]\n&gt;&gt;&gt; @bodo.jit\n&gt;&gt;&gt; def test_recall_score(y_true, y_pred):\n...   print(recall_score(y_true, y_pred, average='macro'))\n&gt;&gt;&gt; test_recall_score(y_true, y_pred)\n0.3333333333333333\n</code></pre> </li> </ul>"},{"location":"api_docs/ml/sklearn/model_selection/","title":"sklearn.model_selection","text":""},{"location":"api_docs/ml/sklearn/model_selection/#sklearnmodel_selectiontrain_test_split","title":"sklearn.model_selection.train_test_split","text":"<p><code>sklearn.model_selection.train_test_split(X, y, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)</code> Supported Arguments</p> <ul> <li><code>X</code>: NumPy array or Pandas Dataframes.</li> <li><code>y</code>: NumPy array or Pandas Dataframes.</li> <li><code>train_size</code>: float between 0.0 and 1.0 or <code>None</code> only.</li> <li><code>test_size</code>: float between 0.0 and 1.0 or <code>None</code> only.</li> <li><code>random_state</code>: int, RandomState, or None.</li> <li><code>shuffle</code>: bool.</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; import bodo\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from sklearn.model_selection import train_test_split\n&gt;&gt;&gt; @bodo.jit\n&gt;&gt;&gt; def test_split():\n...   X, y = np.arange(10).reshape(5, 2), np.arange(5)\n...   X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=42)\n...   print(X_train)\n...   print(y_train)\nX_train:  [[4 5]\n[6 7]\n[8 9]]\ny_train:  [2 3 4]\nX_test:  [[2 3]\n[0 1]]\ny_test:  [1 0]\n</code></pre>"},{"location":"api_docs/ml/sklearn/naive_bayes/","title":"sklearn.naive_bayes","text":""},{"location":"api_docs/ml/sklearn/naive_bayes/#sklearnnaive_bayesmultinomialnb","title":"sklearn.naive_bayes.MultinomialNB","text":"<ul> <li><code>sklearn.naive_bayes.MultinomialNB</code> </li> </ul> <p>This class provides Naive Bayes classifier for multinomial models with distributed large-scale learning.</p>"},{"location":"api_docs/ml/sklearn/naive_bayes/#methods","title":"Methods","text":""},{"location":"api_docs/ml/sklearn/naive_bayes/#sklearnnaive_bayesmultinomialnbfit","title":"sklearn.naive_bayes.MultinomialNB.fit","text":"<ul> <li><code>sklearn.naive_bayes.MultinomialNB.fit(X, y, sample_weight=None)</code> Supported Arguments <ul> <li><code>X</code>: NumPy Array or Pandas Dataframes.</li> <li><code>y</code>: NumPy Array or Pandas Dataframes.</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/naive_bayes/#sklearnnaive_bayesmultinomialnbpredict","title":"sklearn.naive_bayes.MultinomialNB.predict","text":"<ul> <li><code>sklearn.naive_bayes.MultinomialNB.predict(X)</code> Supported Arguments <ul> <li><code>X</code>: NumPy Array or Pandas Dataframes.</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/naive_bayes/#sklearnnaive_bayesmultinomialnbscore","title":"sklearn.naive_bayes.MultinomialNB.score","text":"<ul> <li><code>sklearn.naive_bayes.MultinomialNB.score(X, y, sample_weight=None)</code> Supported Arguments <ul> <li><code>X</code>: NumPy Array or Pandas Dataframes.</li> <li><code>y</code>: NumPy Array or Pandas Dataframes.</li> <li><code>sample_weight</code>: Numeric NumPy Array or Pandas Dataframes.</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/naive_bayes/#example-usage","title":"Example Usage","text":"<pre><code>&gt;&gt;&gt; import bodo\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from sklearn.naive_bayes import MultinomialNB\n&gt;&gt;&gt; rng = np.random.RandomState(1)\n&gt;&gt;&gt; X = rng.randint(5, size=(6, 100))\n&gt;&gt;&gt; y = np.array([1, 2, 3, 4, 5, 6])\n&gt;&gt;&gt; X_test = rng.randint(5, size=(1, 100))\n&gt;&gt;&gt; @bodo.jit\n... def test_mnb(X, y, X_test):\n...   clf = MultinomialNB()\n...   clf.fit(X, y)\n...   ans = clf.predict(X_test)\n...   print(ans)\n...\n&gt;&gt;&gt; test_mnb(X, y, X_test)\n[5]\n</code></pre>"},{"location":"api_docs/ml/sklearn/preprocessing/","title":"sklearn.preprocessing","text":""},{"location":"api_docs/ml/sklearn/preprocessing/#sklearnpreprocessinglabelencoder","title":"sklearn.preprocessing.LabelEncoder","text":"<ul> <li><code>sklearn.preprocessing.LabelEncoder</code> </li> </ul> <p>This class provides LabelEncoder support to encode target labels <code>y</code> with values between 0 and n-classes-1.</p>"},{"location":"api_docs/ml/sklearn/preprocessing/#methods","title":"Methods","text":""},{"location":"api_docs/ml/sklearn/preprocessing/#sklearnpreprocessinglabelencoderfit","title":"sklearn.preprocessing.LabelEncoder.fit","text":"<ul> <li><code>sklearn.preprocessing.LabelEncoder.fit(y)</code> Supported Arguments <ul> <li><code>y</code>: 1d array-like.</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/preprocessing/#sklearnpreprocessinglabelencoderfit_transform","title":"sklearn.preprocessing.LabelEncoder.fit_transform","text":"<ul> <li><code>sklearn.preprocessing.LabelEncoder.fit_transform(y)</code> Supported Arguments <ul> <li><code>y</code>: 1d array-like.</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/preprocessing/#sklearnpreprocessinglabelencodertransform","title":"sklearn.preprocessing.LabelEncoder.transform","text":"<ul> <li><code>sklearn.preprocessing.LabelEncoder.transform(y)</code> Supported Arguments <ul> <li><code>y</code>: 1d array-like.</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/preprocessing/#example-usage","title":"Example Usage","text":"<pre><code>&gt;&gt;&gt; import bodo\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from sklearn.preprocessing import LabelEncoder\n&gt;&gt;&gt; @bodo.jit\n... def test_le():\n...   le = LabelEncoder()\n...   le.fit([1, 2, 2, 6])\n...   print(le.transform([1, 1, 2, 6]))\n...\n&gt;&gt;&gt; test_le()\n[0 0 1 2]\n</code></pre>"},{"location":"api_docs/ml/sklearn/preprocessing/#sklearnpreprocessingminmaxscaler","title":"sklearn.preprocessing.MinMaxScaler","text":"<p><code>sklearn.preprocessing.MinMaxScaler</code></p> <p>This class provides MinMax Scaler support to scale your data based on the range of its features.</p>"},{"location":"api_docs/ml/sklearn/preprocessing/#methods_1","title":"Methods","text":""},{"location":"api_docs/ml/sklearn/preprocessing/#sklearnpreprocessingminmaxscalerfit","title":"sklearn.preprocessing.MinMaxScaler.fit","text":"<ul> <li><code>sklearn.preprocessing.MinMaxScaler.fit(X, y=None)</code> Supported Arguments <ul> <li><code>X</code>: NumPy array or Pandas Dataframes.</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/preprocessing/#sklearnpreprocessingminmaxscalerinverse_transform","title":"sklearn.preprocessing.MinMaxScaler.inverse_transform","text":"<ul> <li><code>sklearn.preprocessing.MinMaxScaler.inverse_transform(X)</code> Supported Arguments <ul> <li><code>X</code>: NumPy array or Pandas Dataframes.</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/preprocessing/#sklearnpreprocessingminmaxscalertransform","title":"sklearn.preprocessing.MinMaxScaler.transform","text":"<ul> <li><code>sklearn.preprocessing.MinMaxScaler.transform(X)</code> Supported Arguments <ul> <li><code>X</code>: NumPy array or Pandas Dataframes.</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/preprocessing/#example-usage_1","title":"Example Usage","text":"<pre><code>&gt;&gt;&gt; import bodo\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from sklearn.preprocessing import MinMaxScaler\n&gt;&gt;&gt; data = np.array([[-1, 2], [-0.5, 6], [0, 10], [1, 18]])\n&gt;&gt;&gt; @bodo.jit\n... def test_minmax(data):\n...   scaler = MinMaxScaler()\n...   scaler.fit(data)\n...   print(scaler.transform(data))\n...\n&gt;&gt;&gt; test_minmax(data)\n[[0.   0.  ]\n[0.25 0.25]\n[0.5  0.5 ]\n[1.   1.  ]]\n</code></pre>"},{"location":"api_docs/ml/sklearn/preprocessing/#sklearnpreprocessingstandardscaler","title":"sklearn.preprocessing.StandardScaler","text":"<p><code>sklearn.preprocessing.StandardScaler</code></p> <p>This class provides Standard Scaler support to center your data and to scale it to achieve unit variance.</p>"},{"location":"api_docs/ml/sklearn/preprocessing/#methods_2","title":"Methods","text":""},{"location":"api_docs/ml/sklearn/preprocessing/#sklearnpreprocessingstandardscalerfit","title":"sklearn.preprocessing.StandardScaler.fit","text":"<ul> <li> <p><code>sklearn.preprocessing.StandardScaler.fit(X, y=None, sample_weight=None)</code> </p> <p>Supported Arguments  -   <code>X</code>: NumPy Array or Pandas Dataframes. -   <code>y</code>: NumPy Array. -   <code>sample_weight</code>: Numeric NumPy Array (only if data is not         distributed)</p> </li> </ul>"},{"location":"api_docs/ml/sklearn/preprocessing/#sklearnpreprocessingstandardscalerinverse_transform","title":"sklearn.preprocessing.StandardScaler.inverse_transform","text":"<ul> <li><code>sklearn.preprocessing.StandardScaler.inverse_transform(X, copy=None)</code> Supported Arguments <ul> <li><code>X</code>: NumPy Array or Pandas Dataframes.</li> <li><code>copy</code>: bool or None.</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/preprocessing/#sklearnpreprocessingstandardscalertransform","title":"sklearn.preprocessing.StandardScaler.transform","text":"<ul> <li><code>sklearn.preprocessing.StandardScaler.transform(X, copy=None)</code> Supported Arguments <ul> <li><code>X</code>: NumPy Array or Pandas Dataframes.</li> <li><code>copy</code>: bool or None.</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/preprocessing/#example-usage_2","title":"Example Usage","text":"<pre><code>&gt;&gt;&gt; import bodo\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from sklearn.svm import LinearSVC\n&gt;&gt;&gt; from sklearn.preprocessing import StandardScaler\n&gt;&gt;&gt; from sklearn.datasets import make_classification\n&gt;&gt;&gt; X, y = make_classification(n_features=4, random_state=0)\n&gt;&gt;&gt; @bodo.jit\n... def test_linearsvc(X, y):\n...   scaler = StandardScaler()\n...   scaler.fit(X)\n...   X = scaler.transform(X)\n...   clf = LinearSVC()\n...   clf.fit(X, y)\n...   ans = clf.predict(np.array([[0, 0, 0, 0]]))\n...   print(ans)\n...\n&gt;&gt;&gt; test_linearsvc(X, y)\n[1]\n</code></pre>"},{"location":"api_docs/ml/sklearn/preprocessing/#sklearnpreprocessingrobustscaler","title":"sklearn.preprocessing.RobustScaler","text":"<p><code>sklearn.preprocessing.RobustScaler</code></p> <p>This class provides Robust Scaler support to scale your data while being robust to outliers.</p>"},{"location":"api_docs/ml/sklearn/preprocessing/#methods_3","title":"Methods","text":""},{"location":"api_docs/ml/sklearn/preprocessing/#sklearnpreprocessingrobustscalerfit","title":"sklearn.preprocessing.RobustScaler.fit","text":"<ul> <li><code>sklearn.preprocessing.RobustScaler.fit(X, y=None)</code> Supported Arguments <ul> <li><code>X</code>: NumPy array or Pandas DataFrame. Sparse matrices are not yet supported.</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/preprocessing/#sklearnpreprocessingrobustscalerinverse_transform","title":"sklearn.preprocessing.RobustScaler.inverse_transform","text":"<ul> <li><code>sklearn.preprocessing.RobustScaler.inverse_transform(X)</code> Supported Arguments <ul> <li><code>X</code>: NumPy array or Pandas DataFrame. Sparse matrices are not yet supported.</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/preprocessing/#sklearnpreprocessingrobustscalertransform","title":"sklearn.preprocessing.RobustScaler.transform","text":"<ul> <li><code>sklearn.preprocessing.RobustScaler.transform(X)</code> Supported Arguments <ul> <li><code>X</code>: NumPy array or Pandas DataFrame. Sparse matrices are not yet supported.</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/preprocessing/#example-usage_3","title":"Example Usage","text":"<pre><code>&gt;&gt;&gt; import bodo\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from sklearn.preprocessing import RobustScaler\n&gt;&gt;&gt; data = np.array([[-1, 2], [-0.5, 6], [0, 10], [1, 18], [-100, 3], [0, 500]])\n&gt;&gt;&gt; @bodo.jit(distributed=[\"data\"])\n... def test_robust(data):\n...   scaler = RobustScaler()\n...   scaler.fit(data)\n...   print(scaler.transform(data))\n...\n&gt;&gt;&gt; test_robust(data)\n[[  -0.85714286   -0.48979592]\n[  -0.28571429   -0.16326531]\n[   0.28571429    0.16326531]\n[   1.42857143    0.81632653]\n[-114.           -0.40816327]\n[   0.28571429   40.16326531]]\n</code></pre>"},{"location":"api_docs/ml/sklearn/svm/","title":"sklearn.svm","text":""},{"location":"api_docs/ml/sklearn/svm/#sklearnsvmlinearsvc","title":"sklearn.svm.LinearSVC","text":"<p><code>sklearn.svm.LinearSVC</code></p> <p>This class provides Linear Support Vector Classification.</p>"},{"location":"api_docs/ml/sklearn/svm/#methods","title":"Methods","text":""},{"location":"api_docs/ml/sklearn/svm/#sklearnsvmlinearsvcfit","title":"sklearn.svm.LinearSVC.fit","text":"<ul> <li><code>sklearn.svm.LinearSVC.fit(X, y, sample_weight=None)</code> Supported Arguments <ul> <li><code>X</code>: NumPy Array or Pandas Dataframes.</li> <li><code>y</code>: NumPy Array.</li> <li><code>sample_weight</code>: Numeric NumPy Array (only if data is not  distributed)</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/svm/#sklearnsvmlinearsvcpredict","title":"sklearn.svm.LinearSVC.predict","text":"<ul> <li><code>sklearn.svm.LinearSVC.predict(X)</code> Supported Arguments <ul> <li><code>X</code>: NumPy Array or Pandas Dataframes.</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/svm/#sklearnsvmlinearsvcscore","title":"sklearn.svm.LinearSVC.score","text":"<ul> <li><code>sklearn.svm.LinearSVC.score(X, y, sample_weight=None)</code> Supported Arguments <ul> <li><code>X</code>: NumPy Array or Pandas Dataframes.</li> <li><code>y</code>: NumPy Array or Pandas Dataframes.</li> <li><code>sample_weight</code>: Numeric NumPy Array or Pandas Dataframes.</li> </ul> </li> </ul>"},{"location":"api_docs/ml/sklearn/svm/#example-usage","title":"Example Usage:","text":"<pre><code>&gt;&gt;&gt; import bodo\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from sklearn.svm import LinearSVC\n&gt;&gt;&gt; from sklearn.preprocessing import StandardScaler\n&gt;&gt;&gt; from sklearn.datasets import make_classification\n&gt;&gt;&gt; X, y = make_classification(n_features=4, random_state=0)\n&gt;&gt;&gt; @bodo.jit\n... def test_linearsvc(X, y):\n...   scaler = StandardScaler()\n...   scaler.fit(X)\n...   X = scaler.transform(X)\n...   clf = LinearSVC()\n...   clf.fit(X, y)\n...   ans = clf.predict(np.array([[0, 0, 0, 0]]))\n...   print(ans)\n...\n&gt;&gt;&gt; test_linearsvc(X, y)\n[1]\n</code></pre>"},{"location":"api_docs/pandas/","title":"Pandas","text":"<ul> <li>General Functions</li> <li>Dataframe API</li> <li>Groupby</li> <li>Series API</li> <li>Window</li> <li>Date Offsets</li> <li>Input/Output</li> <li>Index Objects</li> <li>TimeDelta</li> <li>Timestamp</li> </ul>"},{"location":"api_docs/pandas/dataframe/","title":"DataFrame","text":"<p>Bodo provides extensive DataFrame support documented below.</p>"},{"location":"api_docs/pandas/dataframe/#pddataframe","title":"pd.DataFrame","text":"<ul> <li> <p><code>pandas.DataFrame(data=None, index=None, columns=None, dtype=None, copy=None)</code> </p> <p>Supported Arguments</p> <ul> <li><code>data</code>: constant key dictionary, 2D Numpy array<ul> <li><code>columns</code> argument is required when using a 2D Numpy array</li> </ul> </li> <li><code>index</code>: List, Tuple, Pandas index types, Pandas array types, Pandas series types, Numpy array types</li> <li><code>columns</code>: Constant list of String, Constant tuple of String<ul> <li>Must be constant at Compile Time</li> </ul> </li> <li><code>dtype</code>: All values supported with <code>dataframe.astype</code> (see below)</li> <li><code>copy</code>: boolean<ul> <li>Must be constant at Compile Time</li> </ul> </li> </ul> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#attributes-and-underlying-data","title":"Attributes and underlying data","text":"`pd.DataFrame.columns++ <ul> <li> <p><code>pandas.DataFrame.columns</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [\"X\", \"Y\", \"Z\"], \"C\": [pd.Timedelta(10, unit=\"D\"), pd.Timedelta(10, unit=\"H\"), pd.Timedelta(10, unit=\"S\")]})\n...   return df.columns\n&gt;&gt;&gt; f()\nIndex(['A', 'B', 'C'], dtype='object')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframedtypes","title":"<code>pd.DataFrame.dtypes</code>","text":"<ul> <li> <p><code>pandas.DataFrame.dtypes</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [\"X\", \"Y\", \"Z\"], \"C\": [pd.Timedelta(10, unit=\"D\"), pd.Timedelta(10, unit=\"H\"), pd.Timedelta(10, unit=\"S\")]})\n...   return df.dtypes\n&gt;&gt;&gt; f()\nA              int64\nB             string\nC    timedelta64[ns]\ndtype: object\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframeempty","title":"<code>pd.DataFrame.empty</code>","text":"<ul> <li> <p><code>pandas.DataFrame.empty</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df1 = pd.DataFrame({\"A\": [1,2,3]})\n...   df2 = pd.DataFrame()\n...   return df1.empty, df2.empty\n&gt;&gt;&gt; f()\n(False, True)\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframeindex","title":"<code>pd.DataFrame.index</code>","text":"<ul> <li> <p><code>pandas.DataFrame.index</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3]}, index=[\"x\", \"y\", \"z\"])\n...   return df.index\n&gt;&gt;&gt; f()\nIndex(['x', 'y', 'z'], dtype='object')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframendim","title":"<code>pd.DataFrame.ndim</code>","text":"<ul> <li> <p><code>pandas.DataFrame.ndim</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [\"X\", \"Y\", \"Z\"], \"C\": [pd.Timedelta(10, unit=\"D\"), pd.Timedelta(10, unit=\"H\"), pd.Timedelta(10, unit=\"S\")]})\n...   return df.ndim\n&gt;&gt;&gt; f()\n2\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframeselect_dtypes","title":"<code>pd.DataFrame.select_dtypes</code>","text":"<ul> <li> <p><code>pandas.DataFrame.select_dtypes(include=None, exclude=None)</code> Supported Arguments</p> <ul> <li><code>include</code>: string, type, List or tuple of string/type<ul> <li>Must be constant at Compile Time</li> </ul> </li> <li><code>exclude</code>: string, type, List or tuple of string/type<ul> <li>Must be constant at Compile Time</li> </ul> </li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df= pd.DataFrame({\"A\": [1], \"B\": [\"X\"], \"C\": [pd.Timedelta(10, unit=\"D\")], \"D\": [True], \"E\": [3.1]})\n...   out_1 = df_l.select_dtypes(exclude=[np.float64, \"bool\"])\n...   out_2 = df_l.select_dtypes(include=\"int\")\n...   out_3 = df_l.select_dtypes(include=np.bool_, exclude=(np.int64, \"timedelta64[ns]\"))\n...   formated_out = \"\\n\".join([out_1.to_string(), out_2.to_string(), out_3.to_string()])\n...   return formated_out\n&gt;&gt;&gt; f()\nA  B       C\n0  1  X 10 days\nA\n0  1\nD\n0  True\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframefilter","title":"<code>pd.DataFrame.filter</code>","text":"<ul> <li> <p><code>pandas.DataFrame.filter(items=None, like=None, regex=None, axis=None)</code> </p> <p>Supported Arguments</p> <ul> <li><code>items</code>: Constant list of String</li> <li><code>like</code>: Constant string</li> <li><code>regex</code>: Constant String</li> <li><code>axis</code> (only supports the \"column\" axis): Constant String, Constant integer</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"ababab\": [1], \"hello world\": [2], \"A\": [3]})\n...   filtered_df_1 = pd.DataFrame({\"ababab\": [1], \"hello world\": [2], \"A\": [3]}).filter(items = [\"A\"])\n...   filtered_df_2 = pd.DataFrame({\"ababab\": [1], \"hello world\": [2], \"A\": [3]}).filter(like =\"hello\", axis = \"columns\")\n...   filtered_df_3 = pd.DataFrame({\"ababab\": [1], \"hello world\": [2], \"A\": [3]}).filter(regex=\"(ab){3}\", axis = 1)\n...   formated_out = \"\\n\".join([filtered_df_1.to_string(), filtered_df_2.to_string(), filtered_df_3.to_string()])\n...   return formated_out\n&gt;&gt;&gt; f()\nA\n0  3\nhello world\n0            2\nababab\n0       1\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframeshape","title":"<code>pd.DataFrame.shape</code>","text":"<ul> <li> <p><code>pandas.DataFrame.shape</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [3,4,5]})\n...   return df.shape\n&gt;&gt;&gt; f()\n(3, 2)\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframesize","title":"<code>pd.DataFrame.size</code>","text":"<ul> <li> <p><code>pandas.DataFrame.size</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [3,4,5]})\n...   return df.size\n&gt;&gt;&gt; f()\n6\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframeto_numpy","title":"<code>pd.DataFrame.to_numpy</code>","text":"<ul> <li> <p><code>pandas.DataFrame.to_numpy(dtype=None, copy=False, na_value=NoDefault.no_default)</code> Supported Arguments</p> <ul> <li><code>copy</code>: boolean</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [3.1,4.2,5.3]})\n...   return df.to_numpy()\n&gt;&gt;&gt; f()\n[[1.  3.1]\n[2.  4.2]\n[3.  5.3]]\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframevalues","title":"<code>pd.DataFrame.values</code>","text":"<ul> <li> <p><code>pandas.DataFrame.values (only for numeric dataframes)</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [3.1,4.2,5.3]})\n...   return df.values\n&gt;&gt;&gt; f()\n[[1.  3.1]\n[2.  4.2]\n[3.  5.3]]\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#conversion","title":"Conversion","text":""},{"location":"api_docs/pandas/dataframe/#pddataframeastype","title":"<code>pd.DataFrame.astype</code>","text":"<ul> <li> <p><code>pandas.DataFrame.astype(dtype, copy=True, errors='raise')</code> Supported Arguments</p> <ul> <li> <p><code>dtype</code>: dict of string column names keys, and Strings/types values. String (string must be parsable by <code>np.dtype</code>), Valid type (see types), The following functions: float, int, bool, str</p> <ul> <li>Must be constant at Compile Time</li> </ul> </li> <li> <p><code>copy</code>: boolean</p> </li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [3.1,4.2,5.3]})\n...   return df.astype({\"A\": float, \"B\": \"datetime64[ns]\"})\n&gt;&gt;&gt; f()\nA                             B\n0  1.0 1970-01-01 00:00:00.000000003\n1  2.0 1970-01-01 00:00:00.000000004\n2  3.0 1970-01-01 00:00:00.000000005\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframecopy","title":"<code>pd.DataFrame.copy</code>","text":"<ul> <li> <p><code>pandas.DataFrame.copy(deep=True)</code> </p> <p>Supported Arguments</p> <ul> <li><code>copy</code>: boolean</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3]})\n...   shallow_df = df.copy(deep=False)\n...   deep_df = df.copy()\n...   shallow_df[\"A\"][0] = -1\n...   formated_out = \"\\n\".join([df.to_string(), shallow_df.to_string(), deep_df.to_string()])\n...   return formated_out\n&gt;&gt;&gt; f()\nA\n0  -1\n1  2\n2  3\nA\n0  -1\n1  2\n2  3\nA\n0  1\n1  2\n2  3\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframeisna","title":"<code>pd.DataFrame.isna</code>","text":"<ul> <li> <p><code>pandas.DataFrame.isna()</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,None,3]})\n...   return df.isna()\n&gt;&gt;&gt; f()\nA\n0  False\n1   True\n2  False\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframeisnull","title":"<code>pd.DataFrame.isnull</code>","text":"<ul> <li> <p><code>pandas.DataFrame.isnull()</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,None,3]})\n...   return df.isnull()\n&gt;&gt;&gt; f()\nA\n0  False\n1   True\n2  False\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframenotna","title":"<code>pd.DataFrame.notna</code>","text":"<ul> <li> <p><code>pandas.DataFrame.notna()</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,None,3]})\n...   return df.notna()\n&gt;&gt;&gt; f()\nA\n0   True\n1  False\n2   True\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframenotnull","title":"<code>pd.DataFrame.notnull</code>","text":"<ul> <li> <p><code>pandas.DataFrame.notnull()</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,None,3]})\n...   return df.notnull()\n&gt;&gt;&gt; f()\nA\n0   True\n1  False\n2   True\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframeinfo","title":"<code>pd.DataFrame.info</code>","text":"<ul> <li> <p><code>pandas.DataFrame.info(verbose=None, buf=None, max_cols=None, memory_usage=None, show_counts=None, null_counts=None)</code> Supported Arguments: None</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [\"X\", \"Y\", \"Z\"], \"C\": [pd.Timedelta(10, unit=\"D\"), pd.Timedelta(10, unit=\"H\"), pd.Timedelta(10, unit=\"S\")]})\n...   return df.info()\n&gt;&gt;&gt; f()\n&lt;class 'DataFrameType'&gt;\nRangeIndexType(none): 3 entries, 0 to 2\nData columns (total 3 columns):\n#   Column  Non-Null Count  Dtype\n\n0  A       3 non-null      int64\n1  B       3 non-null      unicode_type\n2  C       3 non-null      timedelta64[ns]\ndtypes: int64(1), timedelta64[ns](1), unicode_type(1)\nmemory usage: 108.0 bytes\n</code></pre> <p>Note</p> <p>The exact output string may vary slightly from Pandas.</p> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframeinfer_objects","title":"<code>pd.DataFrame.infer_objects</code>","text":"<ul> <li> <p><code>pandas.DataFrame.infer_objects()</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3]})\n...   return df.infer_objects()\nA\n0  1\n1  2\n2  3\n</code></pre> <p>Note</p> <p>Bodo does not internally use the object dtype, so types are never inferred. As a result, this API just produces a deep copy, consistent with Pandas.</p> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#indexing-iteration","title":"Indexing, iteration","text":""},{"location":"api_docs/pandas/dataframe/#pddataframehead","title":"<code>pd.DataFrame.head</code>","text":"<ul> <li> <p><code>pandas.DataFrame.head(n=5)</code> </p> <p>Supported Arguments</p> <ul> <li><code>head</code>: integer</li> </ul> <p>Example Usage</p> <pre><code>    &gt;&gt;&gt; @bodo.jit\n... def f():\n...   return pd.DataFrame({\"A\": np.arange(1000)}).head(3)\nA\n0  0\n1  1\n2  2\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframeiat","title":"<code>pd.DataFrame.iat</code>","text":"<ul> <li> <p><code>pandas.DataFrame.iat</code> </p> <p>Note</p> <p>We only support indexing using <code>iat</code> using a pair of integers. We require that the second int (the column integer) is a compile time constant</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [4,5,6], \"C\": [7,8,9]})\n...   df.iat[0, 0] = df.iat[2,2]\n...   return df\n&gt;&gt;&gt; f()\nA  B  C\n0  9  4  7\n1  2  5  8\n2  3  6  9\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframeiloc","title":"<code>pd.DataFrame.iloc</code>","text":"<ul> <li> <p><code>pandas.DataFrame.iloc</code> </p> <p>getitem:</p> <ul> <li><code>df.iloc</code> supports single integer indexing (returns row as series) <code>df.iloc[0]</code></li> <li><code>df.iloc</code> supports single list/array/series of integers/bool <code>df.iloc[[0,1,2]]</code></li> <li>for tuples indexing <code>df.iloc[row_idx, col_idx]</code> we allow:<ul> <li><code>row_idx</code> to be int list/array/series of integers/bool slice</li> <li><code>col_idx</code> to be constant int, constant list of integers, or constant slice</li> </ul> </li> <li>e.g.: <code>df.iloc[[0,1,2], :]</code></li> </ul> <p>setitem:</p> <ul> <li><code>df.iloc</code> only supports scalar setitem</li> <li><code>df.iloc</code> only supports tuple indexing <code>df.iloc[row_idx, col_idx]</code></li> <li><code>row_idx</code> can be anything supported for series setitem:<ul> <li>int</li> <li>list/array/series of integers/bool</li> <li>slice</li> </ul> </li> <li><code>col_idx</code> can be: constant int, constant list/tuple of integers</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [4,5,6], \"C\": [7,8,9]})\n...   df.iloc[0, 0] = df.iloc[2,2]\n...   df.iloc[1, [1,2]] = df.iloc[0, 1]\n...   df[\"D\"] = df.iloc[0]\n...   return df\n&gt;&gt;&gt; f()\nA  B  C  D\n0  9  4  7  7\n1  2  4  4  4\n2  3  6  9  9\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframeinsert","title":"<code>pd.DataFrame.insert</code>","text":"<ul> <li> <p><code>pandas.DataFrame.insert(loc, column, value, allow_duplicates=False)</code> Supported Arguments</p> <ul> <li><code>loc</code>: constant integer</li> <li><code>column</code>: constant string</li> <li><code>value</code>: scalar, list/tuple, Pandas/Numpy array, Pandas index types, series</li> <li><code>allow_duplicates</code>: constant boolean</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [4,5,6], \"C\": [7,8,9]})\n...   df.insert(3, \"D\", [-1,-2,-3])\n...   return df\n&gt;&gt;&gt; f()\nA  B  C  D\n0  1  4  7 -1\n1  2  5  8 -2\n2  3  6  9 -3\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframeisin","title":"<code>pd.DataFrame.isin</code>","text":"<ul> <li> <p><code>pandas.DataFrame.isin(values)</code> Supported Arguments</p> <ul> <li><code>values</code>: DataFrame (must have same indices) + iterable type, Numpy array types, Pandas array types, List/Tuple, Pandas Index Types (excluding interval Index and MultiIndex)</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [4,5,6], \"C\": [7,8,9]})\n...   isin_1 = df.isin([1,5,9])\n...   isin_2 = df.isin(pd.DataFrame({\"A\": [4,5,6], \"C\": [7,8,9]}))\n...   formated_out = \"\\n\".join([isin_1.to_string(), isin_2.to_string()])\n...   return formated_out\n&gt;&gt;&gt; f()\nA      B      C\n0  True   False  False\n1  False  True   False\n2  False  False  True\nA      B     C\n0  False  False  True\n1  False  False  True\n2  False  False  True\n</code></pre> <p>Note</p> <p><code>DataFrame.isin</code> ignores DataFrame indices. For example:</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [4,5,6], \"C\": [7,8,9]})\n...   return df.isin(pd.DataFrame({\"A\": [1,2,3]}, index=[\"A\", \"B\", \"C\"]))\n&gt;&gt;&gt; f()\nA      B      C\n0  True  False  False\n1  True  False  False\n2  True  False  False\n&gt;&gt;&gt; def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [4,5,6], \"C\": [7,8,9]})\n...   return df.isin(pd.DataFrame({\"A\": [1,2,3]}, index=[\"A\", \"B\", \"C\"]))\n&gt;&gt;&gt; f()\nA      B      C\n0  False  False  False\n1  False  False  False\n2  False  False  False\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframeitertuples","title":"<code>pd.DataFrame.itertuples</code>","text":"<ul> <li> <p><code>pandas.DataFrame.itertuples(index=True, name='Pandas')</code> Supported Arguments: None</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   for x in pd.DataFrame({\"A\": [1,2,3], \"B\": [4,5,6], \"C\": [7,8,9]}).itertuples():\n...      print(x)\n...      print(x[0])\n...      print(x[2:])\n&gt;&gt;&gt; f()\nPandas(Index=0, A=1, B=4, C=7)\n0\n(4, 7)\nPandas(Index=1, A=2, B=5, C=8)\n1\n(5, 8)\nPandas(Index=2, A=3, B=6, C=9)\n2\n(6, 9)\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframequery","title":"<code>pd.DataFrame.query</code>","text":"<ul> <li> <p><code>pandas.DataFrame.query(expr, inplace=False, **kwargs)</code></p> <p>Supported Arguments</p> <ul> <li><code>expr</code>:  Constant String</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(a):\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [4,5,6], \"C\": [7,8,9]})\n...   return df.query('A &gt; @a')\n&gt;&gt;&gt; f(1)\nA  B  C\n1  2  5  8\n2  3  6  9\n</code></pre> <p>Note</p> <ul> <li>The output of the query must evaluate to a 1d boolean array.</li> <li>Cannot refer to the index by name in the query string.</li> <li>Query must be one line.</li> <li>If using environment variables, they should be passed as arguments to the function.</li> </ul> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframetail","title":"<code>pd.DataFrame.tail</code>","text":"<ul> <li> <p><code>pandas.DataFrame.tail(n=5)</code> </p> <p>Supported Arguments</p> <ul> <li><code>n</code>: Integer</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   return pd.DataFrame({\"A\": np.arange(1000)}).tail(3)\n&gt;&gt;&gt; f()\nA\n997  997\n998  998\n999  999\n</code></pre> </li> <li> <p><code>pandas.DataFrame.where(cond, other=np.nan, inplace=False, axis=1, level=None, errors='raise', try_cast=NoDefault.no_default)</code> Supported Arguments</p> <ul> <li><code>cond</code>: Boolean DataFrame, Boolean Series, Boolean Array<ul> <li>If 1-dimensional array or Series is provided, equivalent to Pandas <code>df.where</code> with <code>axis=1</code>.</li> </ul> </li> <li><code>other</code>: Scalar, DataFrame, Series, 1 or 2-D Array, <code>None</code><ul> <li>Data types in <code>other</code> must match corresponding entries in DataFrame.</li> <li><code>None</code> or omitting argument defaults to the respective <code>NA</code> value for each type.</li> </ul> </li> </ul> <p>Note</p> <p>DataFrame can contain categorical data if <code>other</code> is a scalar.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df, cond, other):\n...   return df.where(cond, other)\n&gt;&gt;&gt; df = pd.DataFrame({\"A\": [1,2,3], \"B\": [4.3, 2.4, 1.2]})\n&gt;&gt;&gt; cond = df &gt; 2\n&gt;&gt;&gt; other = df + 100\n&gt;&gt;&gt; f(df, cond, other)\nA      B\n0  101    4.3\n1  102    2.4\n2    3  101.2\n</code></pre> </li> <li> <p><code>pandas.DataFrame.mask(cond, other=np.nan, inplace=False, axis=1, level=None, errors='raise', try_cast=NoDefault.no_default)</code> </p> <p>Supported Arguments</p> <ul> <li><code>cond</code>: Boolean DataFrame,Boolean Series,Boolean Array</li> <li>If 1-dimensional array or Series is provided, equivalent to Pandas <code>df.mask</code> with <code>axis=1</code>.</li> <li><code>other</code>: Scalar, DataFrame, Series, 1 or 2-D Array</li> <li><code>None</code>, - Data types in <code>other</code> must match corresponding entries in DataFrame.</li> <li><code>None</code> or omitting argument defaults to the respective <code>NA</code> value for each type.</li> </ul> <p>Note</p> <p>DataFrame can contain categorical data if <code>other</code> is a scalar.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df, cond, other):\n...   return df.mask(cond, other)\n&gt;&gt;&gt; df = pd.DataFrame({\"A\": [1,2,3], \"B\": [4.3, 2.4, 1.2]})\n&gt;&gt;&gt; cond = df &gt; 2\n&gt;&gt;&gt; other = df + 100\n&gt;&gt;&gt; f(df, cond, other)\nA      B\n0    1  104.3\n1    2  102.4\n2  103    1.2\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#function-application-groupby-window","title":"Function application, GroupBy &amp; Window","text":""},{"location":"api_docs/pandas/dataframe/#pddataframeapply","title":"<code>pd.DataFrame.apply</code>","text":"<ul> <li> <p><code>pandas.DataFrame.apply(func, axis=0, raw=False, result_type=None, args=(), _bodo_inline=False, **kwargs)</code></p> <p>Supported Arguments</p> <ul> <li><code>func</code>: function (e.g. lambda) (axis must = 1), jit function (axis must = 1), String which refers to a supported DataFrame method<ul> <li>Must be constant at Compile Time</li> </ul> </li> <li><code>axis</code>: Integer (0, 1), String (only if the method takes axis as an argument )<ul> <li>Must be constant at Compile Time</li> </ul> </li> <li><code>_bodo_inline</code>: boolean<ul> <li>Must be constant at Compile Time</li> </ul> </li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [4,5,6], \"C\": [7,8,9]})\n...   return df.apply(lambda x: x[\"A\"] * (x[\"B\"] + x[\"C\"]))\n&gt;&gt;&gt; f()\n0    11\n1    26\n2    45\ndtype: int64\n</code></pre> <p>Note</p> <p>Supports extra <code>_bodo_inline</code> boolean argument to manually control bodo's inlining behavior. Inlining user-defined functions (UDFs) can potentially improve performance at the expense of extra compilation time. Bodo uses heuristics to make a decision automatically if <code>_bodo_inline</code> is not provided.</p> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframegroupby","title":"<code>pd.DataFrame.groupby</code>","text":"<ul> <li> <p><code>pandas.DataFrame.groupby(by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=NoDefault.no_default, observed=False, dropna=True)</code> Supported Arguments</p> <ul> <li><code>by</code>: String column label,  List/Tuple of column labels<ul> <li>Must be constant at Compile Time</li> </ul> </li> <li><code>as_index</code>: boolean<ul> <li>Must be constant at Compile Time</li> </ul> </li> <li><code>dropna</code>: boolean<ul> <li>Must be constant at Compile Time</li> </ul> </li> </ul> <p>Note</p> <p><code>sort=False</code> and <code>observed=True</code> are set by default. These are the only support values for sort and observed. For more information on using groupby, see the groupby section.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,1,2,2], \"B\": [-2,-2,2,2]})\n...   return df.groupby(\"A\").sum()\n&gt;&gt;&gt; f()\nB\nA\n1 -4\n2  4\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframerolling","title":"<code>pd.DataFrame.rolling</code>","text":"<ul> <li> <p><code>pandas.DataFrame.rolling(window, min_periods=None, center=False, win_type=None, on=None, axis=0, closed=None, method='single')</code> Supported Arguments</p> <ul> <li><code>window</code>: Integer, String (must be parsable as a time offset),<code>datetime.timedelta</code> ,pd.Timedelta`, List/Tuple of column labels</li> <li><code>min_periods</code>: Integer</li> <li><code>center</code>: boolean</li> <li><code>on</code>: Scalar column label<ul> <li>Must be constant at Compile Time</li> </ul> </li> <li><code>dropna</code>:boolean<ul> <li>Must be constant at Compile Time</li> </ul> </li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3,4,5]})\n...   return df.rolling(3,center=True).mean()\n&gt;&gt;&gt; f()\nA\n0  NaN\n1  2.0\n2  3.0\n3  4.0\n4  NaN\n</code></pre> <p>For more information, please see the Window section.</p> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#computations-descriptive-stats","title":"Computations / Descriptive Stats","text":""},{"location":"api_docs/pandas/dataframe/#pddataframeabs","title":"<code>pd.DataFrame.abs</code>","text":"<ul> <li> <p><code>pandas.DataFrame.abs()</code> </p> <p>Note</p> <p>Only supported for dataframes containing numerical data and Timedeltas</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,-2], \"B\": [3.1,-4.2], \"C\": [pd.Timedelta(10, unit=\"D\"), pd.Timedelta(-10, unit=\"D\")]})\n...   return df.abs()\n&gt;&gt;&gt; f()\nA    B       C\n0  1  3.1 10 days\n1  2  4.2 10 days\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframecorr","title":"<code>pd.DataFrame.corr</code>","text":"<ul> <li> <p><code>pandas.DataFrame.corr(method='pearson', min_periods=1)</code> </p> <p>Supported Arguments</p> <ul> <li><code>min_periods</code>: Integer</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [.9, .8, .7, .4], \"B\": [-.8, -.9, -.8, -.4], \"c\": [.7, .7, .7, .4]})\n...   return df.corr()\n&gt;&gt;&gt; f()\nA         B        c\nA  1.000000 -0.904656  0.92582\nB -0.904656  1.000000 -0.97714\nc  0.925820 -0.977140  1.00000\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframecount","title":"<code>pd.DataFrame.count</code>","text":"<ul> <li> <p><code>pandas.DataFrame.count(axis=0, level=None, numeric_only=False)</code> Supported Arguments : None</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1, None, 3], \"B\": [None, 2, None]})\n...   return df.count()\n&gt;&gt;&gt; f()\nA    2\nB    1\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframecov","title":"<code>pd.DataFrame.cov</code>","text":"<ul> <li> <p><code>pandas.DataFrame.cov(min_periods=None, ddof=1)</code> </p> <p>Supported Arguments</p> <ul> <li><code>min_periods</code>: Integer</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [0.695, 0.478, 0.628], \"B\": [-0.695, -0.478, -0.628], \"C\": [0.07, -0.68, 0.193]})\n...   return df.cov()\n&gt;&gt;&gt; f()\nA         B         C\nA  0.012346 -0.012346  0.047577\nB -0.012346  0.012346 -0.047577\nC  0.047577 -0.047577  0.223293\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframecumprod","title":"<code>pd.DataFrame.cumprod</code>","text":"<ul> <li> <p><code>pandas.DataFrame.cumprod(axis=None, skipna=True)</code> Supported Arguments : None</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [.1,np.NaN,12.3],})\n...   return df.cumprod()\n&gt;&gt;&gt; f()\nA    B\n0  1  0.1\n1  2  NaN\n2  6  NaN\n</code></pre> <p>Note</p> <p>Not supported for dataframe with nullable integer.</p> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframecumsum","title":"<code>pd.DataFrame.cumsum</code>","text":"<ul> <li> <p><code>pandas.DataFrame.cumsum(axis=None, skipna=True)</code> Supported Arguments : None</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [.1,np.NaN,12.3],})\n...   return df.cumsum()\n&gt;&gt;&gt; f()\nA    B\n0  1  0.1\n1  3  NaN\n2  6  NaN\n</code></pre> <p>Note</p> <p>Not supported for dataframe with nullable integer.</p> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframedescribe","title":"<code>pd.DataFrame.describe</code>","text":"<ul> <li> <p><code>pandas.DataFrame.describe(percentiles=None, include=None, exclude=None, datetime_is_numeric=False)</code> Supported Arguments : None</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [pd.Timestamp(2000, 10, 2), pd.Timestamp(2001, 9, 5), pd.Timestamp(2002, 3, 11)]})\n...   return df.describe()\n&gt;&gt;&gt; f()\nA                    B\ncount  3.0                    3\nmean   2.0  2001-07-16 16:00:00\nmin    1.0  2000-10-02 00:00:00\n25%    1.5  2001-03-20 00:00:00\n50%    2.0  2001-09-05 00:00:00\n75%    2.5  2001-12-07 12:00:00\nmax    3.0  2002-03-11 00:00:00\nstd    1.0                  NaN\n</code></pre> <p>Note</p> <p>Only supported for dataframes containing numeric data, and datetime data. Datetime_is_numeric defaults to True in JIT code.</p> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframediff","title":"<code>pd.DataFrame.diff</code>","text":"<ul> <li> <p><code>pandas.DataFrame.diff(periods=1, axis=0)</code> </p> <p>Supported Arguments</p> <ul> <li><code>periods</code>: Integer</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [pd.Timestamp(2000, 10, 2), pd.Timestamp(2001, 9, 5), pd.Timestamp(2002, 3, 11)]})\n...   return df.diff(1)\n&gt;&gt;&gt; f()\nA        B\n0  NaN      NaT\n1  1.0 338 days\n2  1.0 187 days\n</code></pre> <p>Note</p> <p>Only supported for dataframes containing float, non-null int, and datetime64ns values</p> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframemax","title":"<code>pd.DataFrame.max</code>","text":"<ul> <li> <p><code>pandas.DataFrame.max(axis=None, skipna=None, level=None, numeric_only=None)</code> </p> <p>Supported Arguments</p> <ul> <li><code>axis</code>: Integer (0 or 1)<ul> <li>Must be constant at Compile Time</li> </ul> </li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [4,5,6], \"C\": [7,8,9]})\n...   return df.max(axis=1)\n&gt;&gt;&gt; f()\n0    7\n1    8\n2    9\n</code></pre> <p>Note</p> <p>Only supported for dataframes containing float, non-null int, and datetime64ns values.</p> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframemean","title":"<code>pd.DataFrame.mean</code>","text":"<ul> <li> <p><code>pandas.DataFrame.mean(axis=None, skipna=None, level=None, numeric_only=None)</code> Supported Arguments</p> <ul> <li><code>axis</code>: Integer (0 or 1)<ul> <li>Must be constant at Compile Time</li> </ul> </li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [4,5,6], \"C\": [7,8,9]})\n...   return df.mean(axis=1)\n&gt;&gt;&gt; f()\n0    4.0\n1    5.0\n2    6.0\n</code></pre> <p>Note</p> <p>Only supported for dataframes containing float, non-null int, and datetime64ns values.</p> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframemedian","title":"<code>pd.DataFrame.median</code>","text":"<ul> <li> <p><code>pandas.DataFrame.median(axis=None, skipna=None, level=None, numeric_only=None)</code> </p> <p>Supported Arguments</p> <ul> <li><code>axis</code>: Integer (0 or 1)<ul> <li>Must be constant at Compile Time</li> </ul> </li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [4,5,6], \"C\": [7,8,9]})\n...   return df.median(axis=1)\n&gt;&gt;&gt; f()\n0    4.0\n1    5.0\n2    6.0\n</code></pre> <p>Note</p> <p>Only supported for dataframes containing float, non-null int, and datetime64ns values.</p> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframemin","title":"<code>pd.DataFrame.min</code>","text":"<ul> <li> <p><code>pandas.DataFrame.min(axis=None, skipna=None, level=None, numeric_only=None)</code> </p> <p>Supported Arguments</p> <ul> <li><code>axis</code>: Integer (0 or 1)<ul> <li>Must be constant at Compile Time</li> </ul> </li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [4,5,6], \"C\": [7,8,9]})\n...   return df.min(axis=1)\n&gt;&gt;&gt; f()\n0    1\n1    2\n2    3\n</code></pre> <p>Note</p> <p>Only supported for dataframes containing float, non-null int, and datetime64ns values.</p> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframenunique","title":"<code>pd.DataFrame.nunique</code>","text":"<ul> <li> <p><code>pandas.DataFrame.nunique(axis=0, dropna=True)</code> </p> <p>Supported Arguments</p> <ul> <li><code>dropna</code>: boolean</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [1,1,1], \"C\": [4, None, 6]})\n...   return df.nunique()\n&gt;&gt;&gt; f()\nA    3\nB    1\nC    2\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframepct_change","title":"<code>pd.DataFrame.pct_change</code>","text":"<ul> <li> <p><code>pandas.DataFrame.pct_change(periods=1, fill_method='pad', limit=None, freq=None)</code> </p> <p>Supported Arguments</p> <ul> <li><code>periods</code>: Integer</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [10,100,1000,10000]})\n...   return df.pct_change()\n&gt;&gt;&gt; f()\nA\n0  NaN\n1  9.0\n2  9.0\n3  9.0\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframepipe","title":"<code>pd.DataFrame.pipe</code>","text":"<ul> <li> <p><code>pandas.DataFrame.pipe(func, *args, **kwargs)</code></p> <p>Supported Arguments</p> <ul> <li><code>func</code>: JIT function or callable defined within a JIT function.<ul> <li>Additional arguments for <code>func</code> can be passed as additional arguments.</li> </ul> </li> </ul> <p>Note</p> <p><code>func</code> cannot be a tuple</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   def g(df, axis):\n...       return df.max(axis)\n...   df = pd.DataFrame({\"A\": [10,100,1000,10000]})\n...   return df.pipe(g, axis=0)\n...\n&gt;&gt;&gt; f()\nA    10000\ndtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframeprod","title":"<code>pd.DataFrame.prod</code>","text":"<ul> <li> <p><code>pandas.DataFrame.prod(axis=None, skipna=None, level=None, numeric_only=None)</code> </p> <p>Supported Arguments</p> <ul> <li><code>axis</code>: Integer (0 or 1)<ul> <li>Must be constant at Compile Time</li> </ul> </li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [4,5,6], \"C\": [7,8,9]})\n...   return df.prod(axis=1)\n&gt;&gt;&gt; f()\nA      6\nB    120\nC    504\ndtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframeproduct","title":"<code>pd.DataFrame.product</code>","text":"<ul> <li> <p><code>pandas.DataFrame.product(axis=None, skipna=None, level=None, numeric_only=None)</code> </p> <p>Supported Arguments</p> <ul> <li><code>axis</code>: Integer (0 or 1)<ul> <li>Must be constant at Compile Time</li> </ul> </li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [4,5,6], \"C\": [7,8,9]})\n...   return df.product(axis=1)\n&gt;&gt;&gt; f()\nA      6\nB    120\nC    504\ndtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframequantile","title":"<code>pd.DataFrame.quantile</code>","text":"<ul> <li> <p><code>pandas.DataFrame.quantile(q=0.5, axis=0, numeric_only=True, interpolation='linear')</code> </p> <p>Supported Arguments</p> <ul> <li><code>q</code>: Float or Int<ul> <li>must be 0&lt;= q &lt;= 1</li> </ul> </li> <li><code>axis</code>: Integer (0 or 1)<ul> <li>Must be constant at Compile Time</li> </ul> </li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [4,5,6], \"C\": [7,8,9]})\n...   return df.quantile()\n&gt;&gt;&gt; f()\nA    2.0\nB    5.0\nC    8.0\ndtype: float64\ndtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframerank","title":"<code>pd.DataFrame.rank</code>","text":"<ul> <li> <p><code>pandas.DataFrame.rank(axis=0, method='average', numeric_only=NoDefault.no_default, na_option='keep', ascending=True, pct=False)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>method</code></p> <ul> <li>String in {'average', 'min', 'max', 'first', 'dense'}</li> </ul> <p><code>na_option</code></p> <ul> <li>String in {'keep', 'top', 'bottom'}</li> </ul> <p><code>ascending</code></p> <ul> <li>Boolean</li> </ul> <p><code>pct</code></p> <ul> <li>Boolean</li> </ul> <p>Note</p> <ul> <li>Using <code>method='first'</code>  with <code>ascending=False</code> is currently unsupported.</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return df.rank(method='dense', na_option='keep', pct=True)\n&gt;&gt;&gt; df = pd.DataFrame('A': [np.nan, 4, 2, 4, 8, np.nan])\n&gt;&gt;&gt; f(df)\nA    B\n0  NaN  0.5\n1  1.0  1.0\n2  0.5  1.0\n3  1.0  NaN\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframestd","title":"<code>pd.DataFrame.std</code>","text":"<ul> <li> <p><code>pandas.DataFrame.std(axis=None, skipna=None, level=None, ddof=1, numeric_only=None)</code> </p> <p>Supported Arguments</p> <ul> <li><code>axis</code>: Integer (0 or 1)</li> <li>Must be constant at Compile Time</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [4,5,6], \"C\": [7,8,9]})\n...   return df.std(axis=1)\n&gt;&gt;&gt; f()\n0    3.0\n1    3.0\n2    3.0\ndtype: float64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframesum","title":"<code>pd.DataFrame.sum</code>","text":"<ul> <li> <p><code>pandas.DataFrame.sum(axis=None, skipna=None, level=None, numeric_only=None, min_count=0)</code> Supported Arguments</p> <ul> <li><code>axis</code>: Integer (0 or 1)<ul> <li>Must be constant at Compile Time</li> </ul> </li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [4,5,6], \"C\": [7,8,9]})\n...   return df.sum(axis=1)\n&gt;&gt;&gt; f()\n0    12\n1    15\n2    18\ndtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframevar","title":"<code>pd.DataFrame.var</code>","text":"<ul> <li> <p><code>pandas.DataFrame.var(axis=None, skipna=None, level=None, ddof=1, numeric_only=None)</code> </p> <p>Supported Arguments</p> <ul> <li><code>axis</code>: Integer (0 or 1)<ul> <li>Must be constant at Compile Time</li> </ul> </li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [4,5,6], \"C\": [7,8,9]})\n...   return df.var(axis=1)\n&gt;&gt;&gt; f()\n0    9.0\n1    9.0\n2    9.0\ndtype: float64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframememory_usage","title":"<code>pd.DataFrame.memory_usage</code>","text":"<ul> <li> <p><code>pandas.DataFrame.memory_usage(index=True, deep=False)</code> </p> <p>Supported Arguments</p> <ul> <li><code>index</code>: boolean</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": np.array([1,2,3], dtype=np.int64), \"B\": np.array([1,2,3], dtype=np.int32), \"C\": [\"1\", \"2\", \"3456689\"]})\n...   return df.memory_usage()\n&gt;&gt;&gt; f()\nIndex    24\nA        24\nB        12\nC        42\ndtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#reindexing-selection-label-manipulation","title":"Reindexing / Selection / Label manipulation","text":""},{"location":"api_docs/pandas/dataframe/#pddataframedrop","title":"<code>pd.DataFrame.drop</code>","text":"<ul> <li> <p><code>pandas.DataFrame.drop(labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')</code> </p> <ul> <li>Only dropping columns supported, either using <code>columns</code> argument or setting <code>axis=1</code> and using the <code>labels</code> argument</li> <li><code>labels</code> and <code>columns</code> require constant string, or constant list/tuple of string values</li> <li><code>inplace</code> supported with a constant boolean value</li> <li>All other arguments are unsupported</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [4,5,6], \"C\": [7,8,9]})\n...   df.drop(columns = [\"B\", \"C\"], inplace=True)\n...   return df\n&gt;&gt;&gt; f()\nA\n0  1\n1  2\n2  3\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframedrop_duplicates","title":"<code>pd.DataFrame.drop_duplicates</code>","text":"<ul> <li> <p><code>pandas.DataFrame.drop_duplicates(subset=None, keep='first', inplace=False, ignore_index=False)</code> </p> <p>Supported Arguments</p> <ul> <li><code>subset</code>: Constant list/tuple of String column names, Constant list/tuple of Integer column names, Constant String column names, Constant Integer column names</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,1,3,4], \"B\": [1,1,3,3], \"C\": [7,8,9,10]})\n...   return df.drop_duplicates(subset = [\"A\", \"B\"])\n&gt;&gt;&gt; f()\nA  B   C\n0  1  1   7\n2  3  3   9\n3  4  3  10\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframeduplicated","title":"<code>pd.DataFrame.duplicated</code>","text":"<ul> <li> <p><code>pandas.DataFrame.duplicated(subset=None, keep='first')</code> Supported Arguments : None</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,1,3,4], \"B\": [1,1,3,3]})\n...   return df.duplicated()\n&gt;&gt;&gt; f()\n0    False\n1     True\n2    False\n3    False\ndtype: bool\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframefirst","title":"<code>pd.DataFrame.first</code>","text":"<ul> <li> <p><code>pandas.DataFrame.first(offset)</code> Supported Arguments</p> <ul> <li><code>offset</code>: String or Offset type<ul> <li>String argument must be a valid frequency alias.</li> </ul> </li> </ul> <p>Note</p> <p>DataFrame must have a valid DatetimeIndex and is assumed to already be sorted. This function have undefined behavior if the DatetimeIndex is not sorted.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df, offset):\n...     return df.first(offset)\n&gt;&gt;&gt; df = pd.DataFrame({\"A\": np.arange(100), \"B\": np.arange(100, 200)}, index=pd.date_range(start='1/1/2022', end='12/31/2024', periods=100))\n&gt;&gt;&gt; f(df, \"2M\")\nA    B\n2022-01-01 00:00:00.000000000  0  100\n2022-01-12 01:27:16.363636363  1  101\n2022-01-23 02:54:32.727272727  2  102\n2022-02-03 04:21:49.090909091  3  103\n2022-02-14 05:49:05.454545454  4  104\n2022-02-25 07:16:21.818181818  5  105\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframeidxmax","title":"<code>pd.DataFrame.idxmax</code>","text":"<ul> <li> <p><code>pandas.DataFrame.idxmax(axis=0, skipna=True)</code> Supported Arguments : None</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [4,5,6], \"C\": [7,8,9]})\n...   return df.idxmax()\n&gt;&gt;&gt; f()\nA    2\nB    2\nC    2\ndtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframeidxmin","title":"<code>pd.DataFrame.idxmin</code>","text":"<ul> <li> <p><code>pandas.DataFrame.idxmin(axis=0, skipna=True)</code> Supported Arguments : None</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [4,5,6], \"C\": [7,8,9]})\n...   return df.idxmax()\n&gt;&gt;&gt; f()\nA    0\nB    0\nC    20\ndtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframelast","title":"<code>pd.DataFrame.last</code>","text":"<ul> <li> <p><code>pandas.DataFrame.last(offset)</code> Supported Arguments</p> <ul> <li><code>offset</code>: String or Offset type<ul> <li>String argument must be a valid frequency alias</li> </ul> </li> </ul> <p>Note</p> <p>DataFrame must have a valid DatetimeIndex and is assumed to already be sorted. This function have undefined behavior if the DatetimeIndex is not sorted.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df, offset):\n...     return df.last(offset)\n&gt;&gt;&gt; df = pd.DataFrame({\"A\": np.arange(100), \"B\": np.arange(100, 200)}, index=pd.date_range(start='1/1/2022', end='12/31/2024', periods=100))\n&gt;&gt;&gt; f(df, \"2M\")\nA    B\n2024-11-05 16:43:38.181818176  94  194\n2024-11-16 18:10:54.545454544  95  195\n2024-11-27 19:38:10.909090912  96  196\n2024-12-08 21:05:27.272727264  97  197\n2024-12-19 22:32:43.636363632  98  198\n2024-12-31 00:00:00.000000000  99  199\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframerename","title":"<code>pd.DataFrame.rename</code>","text":"<ul> <li> <p><code>pandas.DataFrame.rename(mapper=None, index=None, columns=None, axis=None, copy=True, inplace=False, level=None, errors='ignore')</code> Supported Arguments</p> <ul> <li><code>mapper</code>: must be constant dictionary.<ul> <li>Can only be used alongside axis=1</li> </ul> </li> <li><code>columns</code>: must be constant dictionary</li> <li><code>axis</code>: Integer<ul> <li>Can only be used alongside mapper argument</li> </ul> </li> <li><code>copy</code>: boolean</li> <li><code>inplace</code>:  must be constant boolean</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [4,5,6], \"C\": [7,8,9]})\n...   return df.rename(columns={\"A\": \"X\", \"B\":\"Y\", \"C\":\"Z\"})\n&gt;&gt;&gt; f()\nX  Y  Z\n0  1  4  7\n1  2  5  8\n2  3  6  9\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframereset_index","title":"<code>pd.DataFrame.reset_index</code>","text":"<ul> <li> <p><code>pandas.DataFrame.reset_index(level=None, drop=False, inplace=False, col_level=0, col_fill='')</code> Supported Arguments</p> <ul> <li><code>level</code>: Integer<ul> <li>If specified, must drop all levels.</li> </ul> </li> <li><code>drop</code>: Constant boolean</li> <li><code>inplace</code>: Constant boolean</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [4,5,6], \"C\": [7,8,9]}, index = [\"X\", \"Y\", \"Z\"])\n...   return df.reset_index()\n&gt;&gt;&gt; f()\nindex  A  B  C\n0     X  1  4  7\n1     Y  2  5  8\n2     Z  3  6  9\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframeset_index","title":"<code>pd.DataFrame.set_index</code>","text":"<ul> <li> <p><code>pandas.DataFrame.set_index(keys, drop=True, append=False, inplace=False, verify_integrity=False)</code> Supported Arguments</p> <ul> <li>keys: must be a constant string</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [4,5,6], \"C\": [7,8,9]}, index = [\"X\", \"Y\", \"Z\"])\n...   return df.set_index(\"C\")\n&gt;&gt;&gt; f()\nA  B\nC\n7  1  4\n8  2  5\n9  3  6\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframetake","title":"<code>pd.DataFrame.take</code>","text":"<ul> <li> <p><code>pandas.DataFrame.take(indices, axis=0, is_copy=None)</code> </p> <p>Supported Arguments</p> <ul> <li>indices: scalar Integer, Pandas Integer Array, Numpy Integer Array, Integer Series</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [4,5,6], \"C\": [7,8,9]})\n...   return df.take(pd.Series([-1,-2]))\n&gt;&gt;&gt; f()\nA  B  C\n2  3  6  9\n1  2  5  8\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#missing-data-handling","title":"Missing data handling","text":""},{"location":"api_docs/pandas/dataframe/#pddataframedropna","title":"<code>pd.DataFrame.dropna</code>","text":"<ul> <li> <p><code>pandas.DataFrame.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)</code> Supported Arguments</p> <ul> <li><code>how</code>: Constant String: either \"all\" or \"any\"</li> <li><code>thresh</code>: Integer</li> <li><code>subset</code>: Constant list/tuple of String column names, Constant list/tuple of Integer column names, Constant String column names, Constant Integer column names</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3,None], \"B\": [4, 5,None, None], \"C\": [6, None, None, None]})\n...   df_1 = df.dropna(how=\"all\", subset=[\"B\", \"C\"])\n...   df_2 = df.dropna(thresh=3)\n...   formated_out = \"\\n\".join([df_1.to_string(), df_2.to_string()])\n...   return formated_out\n&gt;&gt;&gt; f()\nA  B     C\n0  1  4     6\n1  2  5  &lt;NA&gt;\nA  B  C\n0  1  4  6\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframefillna","title":"<code>pd.DataFrame.fillna</code>","text":"<ul> <li> <p><code>pandas.DataFrame.fillna(value=None, method=None, axis=None, inplace=False, limit=None, downcast=None)</code> Supported Arguments</p> <ul> <li><code>value</code>: various scalars<ul> <li>Must be of the same type as the filled column</li> </ul> </li> <li><code>inplace</code>: Constant boolean<ul> <li><code>inplace</code> is not supported alongside method</li> </ul> </li> <li><code>method</code>: One of <code>bfill</code>, <code>backfill</code>, <code>ffill</code> , or <code>pad</code><ul> <li>Must be constant at Compile Time</li> <li><code>inplace</code> is not supported alongside method</li> </ul> </li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3,None], \"B\": [4, 5,None, None], \"C\": [6, None, None, None]})\n...   return df.fillna(-1)\n&gt;&gt;&gt; f()\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframereplace","title":"<code>pd.DataFrame.replace</code>","text":"<ul> <li> <p><code>pandas.DataFrame.replace(to_replace=None, value=None, inplace=False, limit=None, regex=False, method='pad')</code> </p> <p>Supported Arguments</p> <ul> <li><code>to_replace</code>: various scalars<ul> <li>Required argument</li> </ul> </li> <li><code>value</code>: various scalars<ul> <li>Must be of the same type as to_replace</li> </ul> </li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [4,5,6], \"C\": [7,8,9]})\n...   return df.replace(1, -1)\n&gt;&gt;&gt; f()\nA  B  C\n0 -1  4  7\n1  2  5  8\n2  3  6  9\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#reshaping-sorting-transposing","title":"Reshaping, sorting, transposing","text":""},{"location":"api_docs/pandas/dataframe/#pddataframeexplode","title":"<code>pd.DataFrame.explode</code>","text":"<ul> <li> <p><code>pandas.DataFrame.explode(column, ignore_index=False)</code> </p> <p>Supported Arguments</p> <ul> <li><code>column</code>: Constant Column label or list of labels</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df, cols):\n...   return df.explode(cols)\n&gt;&gt;&gt; df = pd.DataFrame({\"A\": [[0, 1, 2], [5], [], [3, 4]], \"B\": [1, 7, 2, 4], \"C\": [[1, 2, 3], np.nan, [], [1, 2]]})\n&gt;&gt;&gt; f(df, [\"A\", \"C\"])\nA  B     C\n0     0  1     1\n0     1  1     2\n0     2  1     3\n1     5  7  &lt;NA&gt;\n2  &lt;NA&gt;  2  &lt;NA&gt;\n3     3  4     1\n3     4  4     2\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframemelt","title":"<code>pd.DataFrame.melt</code>","text":"<ul> <li> <p><code>pandas.DataFrame.melt(id_vars=None, value_vars=None, var_name=None, value_name='value', col_level=None)</code> </p> <p>Supported Arguments</p> <ul> <li><code>id_vars</code>: Constant Column label or list of labels</li> <li><code>value_vars</code>: Constant Column label or list of labels</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df, id_vars, value_vars):\n...   return df.melt(id_vars, value_vars)\n&gt;&gt;&gt; df = pd.DataFrame({\"A\": [\"a\", \"b\", \"c\"], 'B': [1, 3, 5], 'C': [2, 4, 6])\n&gt;&gt;&gt; f(df, [\"A\"], [\"B\", \"C\"])\nA variable  value\n0  a        B      1\n1  b        B      3\n2  c        B      5\n3  a        C      2\n4  b        C      4\n5  c        C      6\n</code></pre> <p>Note</p> <p>To offer increased performance, row ordering and corresponding Index value may not match Pandas when run on multiple cores.</p> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframepivot","title":"<code>pd.DataFrame.pivot</code>","text":"<ul> <li> <p><code>pandas.DataFrame.pivot(values=None, index=None, columns=None)</code> </p> <p>Supported Arguments</p> <ul> <li><code>values</code>: Constant Column Label or list of labels</li> <li><code>index</code>: Constant Column Label or list of labels</li> <li><code>columns</code>: Constant Column Label</li> </ul> <p>Note</p> <p>The the number of columns and names of the output DataFrame won't be known   at compile time. To update typing information on DataFrame you should pass it back to Python.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [\"X\",\"X\",\"X\",\"X\",\"Y\",\"Y\"], \"B\": [1,2,3,4,5,6], \"C\": [10,11,12,20,21,22]})\n...   pivoted_tbl = df.pivot(columns=\"A\", index=\"B\", values=\"C\")\n...   return pivoted_tbl\n&gt;&gt;&gt; f()\nA     X     Y\nB\n1  10.0   NaN\n2  11.0   NaN\n3  12.0   NaN\n4  20.0   NaN\n5   NaN  21.0\n6   NaN  22.0\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframepivot_table","title":"<code>pd.DataFrame.pivot_table</code>","text":"<ul> <li> <p><code>pandas.DataFrame.pivot_table(values=None, index=None, columns=None, aggfunc='mean', fill_value=None, margins=False, dropna=True, margins_name='All', observed=False, sort=True)</code> </p> <p>Supported Arguments</p> <ul> <li><code>values</code>: Constant Column Label or list of labels</li> <li><code>index</code>: Constant Column Label or list of labels</li> <li><code>columns</code>: Constant Column Label</li> <li><code>aggfunc</code>: String Constant</li> </ul> <p>Note</p> <p>This code takes two different paths depending on if pivot values are annotated. When   pivot values are annotated then output columns are set to the annotated values.   For example, <code>@bodo.jit(pivots={'pt': ['small', 'large']})</code>   declares the output pivot table <code>pt</code> will have columns called <code>small</code> and <code>large</code>.</p> <p>If pivot values are not annotated, then the number of columns and names of the output DataFrame won't be known   at compile time. To update typing information on DataFrame you should pass it back to Python.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit(pivots={'pivoted_tbl': ['X', 'Y']})\n... def f():\n...   df = pd.DataFrame({\"A\": [\"X\",\"X\",\"X\",\"X\",\"Y\",\"Y\"], \"B\": [1,2,3,4,5,6], \"C\": [10,11,12,20,21,22]})\n...   pivoted_tbl = df.pivot_table(columns=\"A\", index=\"B\", values=\"C\", aggfunc=\"mean\")\n...   return pivoted_tbl\n&gt;&gt;&gt; f()\nX     Y\nB\n1  10.0   NaN\n2  11.0   NaN\n3  12.0   NaN\n4  20.0   NaN\n5   NaN  21.0\n6   NaN  22.0\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframesample","title":"<code>pd.DataFrame.sample</code>","text":"<ul> <li> <p><code>pandas.DataFrame.sample(n=None, frac=None, replace=False, weights=None, random_state=None, axis=None, ignore_index=False)</code> </p> <p>Supported Arguments</p> <ul> <li><code>n</code>: Integer</li> <li><code>frac</code>: Float</li> <li><code>replace</code>: boolean</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [4,5,6], \"C\": [7,8,9]})\n...   return df.sample(1)\n&gt;&gt;&gt; f()\nA  B  C\n2  3  6  9\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframesort_index","title":"<code>pd.DataFrame.sort_index</code>","text":"<ul> <li> <p><code>pandas.DataFrame.sort_index(axis=0, level=None, ascending=True, inplace=False, kind='quicksort', na_position='last', sort_remaining=True, ignore_index=False, key=None)</code> </p> <p>Supported Arguments</p> <ul> <li><code>ascending</code>: boolean</li> <li><code>na_position</code>:constant String (\"first\" or \"last\")</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3]}, index=[1,None,3])\n...   return df.sort_index(ascending=False, na_position=\"last\")\n&gt;&gt;&gt; f()\nA\n3    3\n1    1\nNaN  2\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframesort_values","title":"<code>pd.DataFrame.sort_values</code>","text":"<ul> <li> <p><code>pandas.DataFrame.sort_values(by, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last', ignore_index=False, key=None)</code> Supported Arguments</p> <ul> <li><code>by</code>: constant String or constant list of strings</li> <li><code>ascending</code>: boolean, list/tuple of boolean, with length equal to the number of key columns</li> <li><code>inplace</code>: Constant boolean</li> <li><code>na_position</code>: constant String (\"first\" or \"last\"), constant list/tuple of String, with length equal to the number of key columns</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,2,None], \"B\": [4, 5, 6, None]})\n...   df.sort_values(by=[\"A\", \"B\"], ascending=[True, False], na_position=[\"first\", \"last\"], inplace=True)\n...   return df\n&gt;&gt;&gt; f()\nA     B\n3  &lt;NA&gt;  &lt;NA&gt;\n0     1     4\n2     2     6\n1     2     5\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframeto_string","title":"<code>pd.DataFrame.to_string</code>","text":"<ul> <li> <p><code>pandas.DataFrame.to_string(buf=None, columns=None, col_space=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, justify=None, max_rows=None, min_rows=None, max_cols=None, show_dimensions=False, decimal='.', line_width=None, max_colwidth=None, encoding=None)</code> Supported Arguments</p> <ul> <li><code>buf</code></li> <li><code>columns</code></li> <li><code>col_space</code></li> <li><code>header</code></li> <li><code>index</code></li> <li><code>na_rep</code></li> <li><code>formatters</code></li> <li><code>float_format</code></li> <li><code>sparsify</code></li> <li><code>index_names</code></li> <li><code>justify</code></li> <li><code>max_rows</code></li> <li><code>min_rows</code></li> <li><code>max_cols</code></li> <li><code>how_dimensions</code></li> <li><code>decimal</code></li> <li><code>line_width</code></li> <li><code>max_colwidth</code></li> <li><code>encoding</code></li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3]})\n...   return df.to_string()\n&gt;&gt;&gt; f()\nA\n0  1\n1  2\n2  3\n</code></pre> <p>Note</p> <ul> <li>This function is not optimized.</li> <li>When called on a distributed dataframe, the string returned for each rank will be reflective of the dataframe for that rank.</li> </ul> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#combining-joining-merging","title":"Combining / joining / merging","text":""},{"location":"api_docs/pandas/dataframe/#pddataframeappend","title":"<code>pd.DataFrame.append</code>","text":"<ul> <li> <p><code>pandas.DataFrame.append(other, ignore_index=False, verify_integrity=False, sort=False)</code> </p> <p>Supported Arguments</p> <ul> <li><code>other</code>: DataFrame, list/tuple of DataFrame</li> <li><code>ignore_index</code>: constant boolean</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [4,5,6]})\n...   return df.append(pd.DataFrame({\"A\": [-1,-2,-3], \"C\": [4,5,6]}))\n&gt;&gt;&gt; f()\nA    B    C\n0  1  4.0  NaN\n1  2  5.0  NaN\n2  3  6.0  NaN\n0 -1  NaN  4.0\n1 -2  NaN  5.0\n2 -3  NaN  6.0\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframeassign","title":"<code>pd.DataFrame.assign</code>","text":"<ul> <li> <p><code>pandas.DataFrame.assign(**kwargs)</code></p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,2,3], \"B\": [4,5,6]})\n...   df2 = df.assign(C = 2 * df[\"B\"], D = lambda x: x.C -1)\n...   return df2\n&gt;&gt;&gt; f()\nA  B   C   D\n0  1  4   8  -8\n1  2  5  10 -10\n2  3  6  12 -12\n</code></pre> <p>Note</p> <p>arguments can be JIT functions, lambda functions, or values that can be used to initialize a Pandas Series.</p> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframejoin","title":"<code>pd.DataFrame.join</code>","text":"<ul> <li> <p><code>pandas.DataFrame.join(other, on=None, how='left', lsuffix='', rsuffix='', sort=False)</code> </p> <p>Supported Arguments</p> <ul> <li><code>other</code>: DataFrame</li> <li><code>on</code>: constant string column name, constant list/tuple of column names</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,1,3], \"B\": [4,5,6]})\n...   return df.join(on = \"A\", other=pd.DataFrame({\"C\": [-1,-2,-3], \"D\": [4,5,6]}))\n&gt;&gt;&gt; f()\nA  B     C     D\n0  1  4    -2     5\n1  1  5    -2     5\n2  3  6  &lt;NA&gt;  &lt;NA&gt;\n</code></pre> <p>Note</p> <p>Joined dataframes cannot have common columns. The output dataframe is not sorted by default for better parallel performance</p> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframemerge","title":"<code>pd.DataFrame.merge</code>","text":"<ul> <li> <p><code>pandas.DataFrame.merge(right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=True, indicator=False, validate=None)</code> </p> <p>Note</p> <p>See <code>pd.merge</code> for full list of supported arguments, and more examples.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,1,3], \"B\": [4,5,6]})\n...   return df.merge(pd.DataFrame({\"C\": [-1,-2,-3], \"D\": [4,4,6]}), left_on = \"B\", right_on = \"D\")\n&gt;&gt;&gt; f()\nA  B  C  D\n0  1  4 -1  4\n1  1  4 -2  4\n2  3  6 -3  6\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#time-series-related","title":"Time series-related","text":""},{"location":"api_docs/pandas/dataframe/#pddataframeshift","title":"<code>pd.DataFrame.shift</code>","text":"<ul> <li> <p><code>pandas.DataFrame.shift(periods=1, freq=None, axis=0, fill_value=NoDefault.no_default)</code> </p> <p>Supported Arguments</p> <ul> <li><code>periods</code>: Integer</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,1,3], \"B\": [4,5,6]})\n...   return df.shift(1)\n&gt;&gt;&gt; f()\nA    B\n0  NaN  NaN\n1  1.0  4.0\n2  1.0  5.0\n</code></pre> <p>Note</p> <p>Only supported for dataframes containing numeric, boolean, datetime.date and string types.</p> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#serialization-io-conversion","title":"Serialization, IO, Conversion","text":"<p>Also see S3 and HDFS configuration requirements and more on Scalable File I/O.</p>"},{"location":"api_docs/pandas/dataframe/#pddataframeto_csv","title":"<code>pd.DataFrame.to_csv</code>","text":"<ul> <li><code>pandas.DataFrame.to_csv</code> <ul> <li><code>compression</code> argument defaults to <code>None</code> in JIT code. This is the only supported value of this argument.</li> <li><code>mode</code> argument supports only the default value <code>\"w\"</code>.</li> <li><code>errors</code> argument supports only the default value <code>strict</code>.</li> <li><code>storage_options</code> argument supports only the default value <code>None</code>.</li> </ul> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframeto_json","title":"<code>pd.DataFrame.to_json</code>","text":"<ul> <li><code>pandas.DataFrame.to_json</code> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframeto_parquet","title":"<code>pd.DataFrame.to_parquet</code>","text":"<ul> <li> <p><code>pandas.DataFrame.to_parquet(path, engine='auto', compression='snappy', index=None, partition_cols=None, storage_options=None)</code> </p> <ul> <li><code>path</code> is a required argument and must be a string. When writing distributed dataframes, the path refers to a directory of parquet files.</li> <li><code>engine</code> argument only supports <code>\"auto\"</code> and <code>\"pyarrow\"</code>. Default: <code>\"auto\"</code> which uses the pyarrow engine.</li> <li><code>compression</code> argument must be one of: <code>\"snappy\"</code>, <code>\"gzip\"</code>, <code>\"brotli\"</code>, <code>None</code>. Default: <code>\"snappy\"</code>.</li> <li><code>index</code> argument must be a constant bool or <code>None</code>. Default: <code>None</code>.</li> <li><code>partition_cols</code> argument is supported in most cases, except when the columns in the DataFrame cannot be determined at compile time. This must be a list of column names or <code>None</code>. Default: <code>None</code>.</li> <li><code>storage_options</code> argument supports only the default value <code>None</code>.</li> <li><code>row_group_size</code> argument can be used to specify the maximum size of the row-groups in the generated parquet files; the actual size of the written row-groups may be smaller then this value. This must be an integer. If not specified, Bodo writes row-groups with 1M rows.</li> </ul> <p>Note</p> <p>Bodo writes multiple files in parallel (one per core), and the total number of row-groups across all files is roughly <code>max(num_cores, total_rows / row_group_size)</code>.   The size of the row groups can affect read performance significantly. In general, the dataset should have at least as many row-groups as the number of cores used for reading, but ideally a lot more.   At the same time, the row-groups shouldn't be too small since this can lead to overheads at read time.   For more details, refer to the parquet file format.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [1,1,3], \"B\": [4,5,6]})\n...   df.to_parquet(\"dataset.pq\")\n&gt;&gt;&gt; f()\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#pddataframeto_sql","title":"<code>pd.DataFrame.to_sql</code>","text":"<ul> <li><code>pandas.DataFrame.to_sql</code> <ul> <li>See Example Usage and more system specific instructions.</li> <li>Argument <code>con</code> is supported but only as a string form. SQLalchemy <code>connectable</code> is not supported.</li> <li>Argument <code>name</code>, <code>schema</code>, <code>if_exists</code>, <code>index</code>, <code>index_label</code>, <code>dtype</code>, <code>method</code> are supported.</li> <li>Argument <code>chunksize</code> is not supported.</li> </ul> </li> </ul>"},{"location":"api_docs/pandas/dataframe/#plotting","title":"Plotting","text":""},{"location":"api_docs/pandas/dataframe/#pddataframeplot","title":"<code>pd.DataFrame.plot</code>","text":"<ul> <li> <p><code>pandas.DataFrame.plot(x=None, y=None, kind=\"line\", figsize=None, xlabel=None, ylabel=None, title=None, legend=True, fontsize=None, xticks=None, yticks=None, ax=None)</code> </p> <p>Supported Arguments</p> <ul> <li><code>x</code>: Constant String column name, Constant integer</li> <li><code>y</code>: Constant String column name, Constant integer</li> <li><code>kind</code>: constant String (\"line\" or \"scatter\")</li> <li><code>figsize</code>: constant numeric tuple (width, height)</li> <li><code>xlabel</code>: constant String</li> <li><code>ylabel</code>: constant String</li> <li><code>title</code>: constant String</li> <li><code>legend</code>: boolean</li> <li><code>fontsize</code>: integer</li> <li><code>xticks</code>: Constant Tuple</li> <li><code>yticks</code>: Constant Tuple</li> <li><code>ax</code>: Matplotlib Axes Object</li> </ul> </li> </ul>"},{"location":"api_docs/pandas/dateoffsets/","title":"Date Offsets","text":"<p>Bodo supports a subset of the offset types in <code>pandas.tseries.offsets</code>:</p>"},{"location":"api_docs/pandas/dateoffsets/#dateoffset","title":"DateOffset","text":""},{"location":"api_docs/pandas/dateoffsets/#pdtseriesoffsetsdateoffset","title":"<code>pd.tseries.offsets.DateOffset</code>","text":"<p><code>pandas.tseries.offsets.DateOffset(n=1, normalize=False, years=None, months=None, weeks=None, days=None, hours=None, minutes=None, seconds=None, microseconds=None, nanoseconds=None, year=None, month=None, day=None, weekday=None, hour=None, minute=None, second=None, microsecond=None, nanosecond=None)</code> Supported Arguments</p> <ul> <li><code>n</code>: integer</li> <li><code>normalize</code>: boolean</li> <li><code>years</code>: integer</li> <li><code>months</code>: integer</li> <li><code>weeks</code>: integer</li> <li><code>days</code>: integer</li> <li><code>hours</code>:  integer</li> <li><code>minutes</code>: integer</li> <li><code>seconds</code>:  integer</li> <li><code>microseconds</code>:  integer</li> <li><code>nanoseconds</code>: integer</li> <li><code>year</code>:  integer</li> <li><code>month</code>:  integer</li> <li><code>weekday</code>: integer</li> <li><code>day</code>: integer</li> <li><code>hour</code>: integer</li> <li><code>minute</code>: integer</li> <li><code>second</code>: integer</li> <li><code>microsecond</code>: integer</li> <li><code>nanosecond</code>: integer</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n&gt;&gt;&gt; def f(ts):\n...     return ts + pd.tseries.offsets.DateOffset(n=4, normalize=True, weeks=11, hour=2)\n&gt;&gt;&gt; ts = pd.Timestamp(year=2020, month=10, day=30, hour=22)\n&gt;&gt;&gt; f(ts)\nTimestamp('2021-09-03 02:00:00')\n</code></pre>"},{"location":"api_docs/pandas/dateoffsets/#properties","title":"Properties","text":""},{"location":"api_docs/pandas/dateoffsets/#pdtseriesoffsetsdateoffsetnormalize","title":"pd.tseries.offsets.DateOffset.normalize`","text":"<ul> <li><code>pandas.tseries.offsets.DateOffset.normalize</code> </li> </ul>"},{"location":"api_docs/pandas/dateoffsets/#pdtseriesoffsetsdateoffsetn","title":"<code>pd.tseries.offsets.DateOffset.n</code>","text":"<ul> <li><code>pandas.tseries.offsets.DateOffset.n</code> </li> </ul>"},{"location":"api_docs/pandas/dateoffsets/#monthbegin","title":"MonthBegin","text":""},{"location":"api_docs/pandas/dateoffsets/#pdtseriesoffsetsmonthbegin","title":"<code>pd.tseries.offsets.MonthBegin</code>","text":"<ul> <li> <p><code>pandas.tseries.offsets.MonthBegin(n=1, normalize=False)</code> Supported Arguments</p> <ul> <li><code>n</code>: integer</li> <li><code>normalize</code>: boolean</li> </ul> <p>Example Usage <pre><code>&gt;&gt;&gt; @bodo.jit\n&gt;&gt;&gt; def f(ts):\n...     return ts + pd.tseries.offsets.MonthBegin(n=4, normalize=True)\n&gt;&gt;&gt; ts = pd.Timestamp(year=2020, month=10, day=30, hour=22)\n&gt;&gt;&gt; f(ts)\nTimestamp('2021-02-01 00:00:00')\n</code></pre></p> </li> </ul>"},{"location":"api_docs/pandas/dateoffsets/#monthend","title":"MonthEnd","text":""},{"location":"api_docs/pandas/dateoffsets/#pdtseriesoffsetsmonthend","title":"<code>pd.tseries.offsets.MonthEnd</code>","text":"<ul> <li> <p><code>pandas.tseries.offsets.MonthEnd(n=1, normalize=False)</code> Supported Arguments</p> <ul> <li><code>n</code>: integer</li> <li><code>normalize</code>: boolean</li> </ul> <p>Example Usage <pre><code>&gt;&gt;&gt; @bodo.jit\n&gt;&gt;&gt; def f(ts):\n...     return ts + pd.tseries.offsets.MonthEnd(n=4, normalize=False)\n&gt;&gt;&gt; ts = pd.Timestamp(year=2020, month=10, day=30, hour=22)\n&gt;&gt;&gt; f(ts)\nTimestamp('2021-01-31 22:00:00')\n</code></pre></p> </li> </ul>"},{"location":"api_docs/pandas/dateoffsets/#week","title":"Week","text":""},{"location":"api_docs/pandas/dateoffsets/#pdtseriesoffsetsweek","title":"<code>pd.tseries.offsets.Week</code>","text":"<ul> <li> <p><code>pandas.tseries.offsets.Week(n=1, normalize=False, weekday=None)</code> Supported Arguments</p> <ul> <li><code>n</code>: integer</li> <li><code>normalize</code>: boolean</li> <li><code>weekday</code>: integer</li> </ul> <p>Example Usage <pre><code>&gt;&gt;&gt; @bodo.jit\n&gt;&gt;&gt; def f(ts):\n...     return ts + pd.tseries.offsets.Week(n=4, normalize=True, weekday=5)\n&gt;&gt;&gt; ts = pd.Timestamp(year=2020, month=10, day=30, hour=22)\n&gt;&gt;&gt; f(ts)\nTimestamp('2020-11-21 00:00:00')\n</code></pre></p> </li> </ul>"},{"location":"api_docs/pandas/dateoffsets/#binary-operations","title":"Binary Operations","text":"<p>For all offsets, addition and subtraction with a scalar <code>datetime.date</code>, <code>datetime.datetime</code> or <code>pandas.Timestamp</code> is supported. Multiplication is also supported with a scalar integer.</p>"},{"location":"api_docs/pandas/general/","title":"General functions","text":""},{"location":"api_docs/pandas/general/#data-manipulations","title":"Data manipulations","text":""},{"location":"api_docs/pandas/general/#pdpivot","title":"<code>pd.pivot</code>","text":"<ul> <li> <p><code>pandas.pivot(data, values=None, index=None, columns=None)</code> </p> <p>Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>data</code></p> <ul> <li>DataFrame</li> </ul> <p><code>values</code> </p> <ul> <li>Constant Column Label or list of     labels</li> </ul> <p><code>index</code> </p> <ul> <li>Constant Column Label or list of     labels</li> </ul> <p><code>columns</code></p> <ul> <li>Constant Column Label</li> </ul> <p>Note</p> <p>The the number of columns and names of the output DataFrame won't be known at compile time. To update typing information on DataFrame you should pass it back to Python.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   df = pd.DataFrame({\"A\": [\"X\",\"X\",\"X\",\"X\",\"Y\",\"Y\"], \"B\": [1,2,3,4,5,6], \"C\": [10,11,12,20,21,22]})\n...   pivoted_tbl = pd.pivot(data, columns=\"A\", index=\"B\", values=\"C\")\n...   return pivoted_tbl\n&gt;&gt;&gt; f()\nA     X     Y\nB\n1  10.0   NaN\n2  11.0   NaN\n3  12.0   NaN\n4  20.0   NaN\n5   NaN  21.0\n6   NaN  22.0\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/general/#pdpivot_table","title":"<code>pd.pivot_table</code>","text":"<ul> <li> <p><code>pandas.pivot_table(data, values=None, index=None, columns=None, aggfunc='mean', fill_value=None, margins=False, dropna=True, margins_name='All', observed=False, sort=True)</code> </p> <p>Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>data</code></p> <ul> <li>DataFrame</li> </ul> <p><code>values</code> </p> <ul> <li>Constant Column Label or list of     labels</li> </ul> <p><code>index</code> </p> <ul> <li>Constant Column Label or list of     labels</li> </ul> <p><code>columns</code></p> <ul> <li>Constant Column Label</li> </ul> <p><code>aggfunc</code></p> <ul> <li>String Constant</li> </ul> <p>Note</p> <p>This code takes two different paths depending on if pivot values are annotated. When pivot values are annotated then output columns are set to the annotated values. For example, <code>@bodo.jit(pivots={'pt': ['small', 'large']})</code> declares the output pivot table <code>pt</code> will have columns called <code>small</code> and <code>large</code>.</p> <p>If pivot values are not annotated, then the number of columns and names of the output DataFrame won't be known at compile time. To update typing information on DataFrame you should pass it back to Python.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit(pivots={'pivoted_tbl': ['X', 'Y']})\n... def f():\n...   df = pd.DataFrame({\"A\": [\"X\",\"X\",\"X\",\"X\",\"Y\",\"Y\"], \"B\": [1,2,3,4,5,6], \"C\": [10,11,12,20,21,22]})\n...   pivoted_tbl = pd.pivot_table(df, columns=\"A\", index=\"B\", values=\"C\", aggfunc=\"mean\")\n...   return pivoted_tbl\n&gt;&gt;&gt; f()\nX     Y\nB\n1  10.0   NaN\n2  11.0   NaN\n3  12.0   NaN\n4  20.0   NaN\n5   NaN  21.0\n6   NaN  22.0\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/general/#pdcrosstab","title":"<code>pd.crosstab</code>","text":"<ul> <li> <p><code>pandas.crosstab(index, columns, values=None, rownames=None, colnames=None, aggfunc=None, margins=False, margins_name='All', dropna=True, normalize=False)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>index</code></p> <p>SeriesType</p> <p><code>columns</code></p> <p>SeriesType</p> <p>Note</p> <p>Annotation of pivot values is required. For example, <code>@bodo.jit(pivots={'pt': ['small', 'large']})</code> declares the output table <code>pt</code> will have columns called <code>small</code> and <code>large</code>.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit(pivots={\"pt\": [\"small\", \"large\"]})\n... def f(df):\n...   pt = pd.crosstab(df.A, df.C)\n...   return pt\n&gt;&gt;&gt; list_A = [\"foo\", \"foo\", \"bar\", \"bar\", \"bar\", \"bar\"]\n&gt;&gt;&gt; list_C = [\"small\", \"small\", \"large\", \"small\", \"small\", \"middle\"]\n&gt;&gt;&gt; df = pd.DataFrame({\"A\": list_A, \"C\": list_C})\n&gt;&gt;&gt; f(df)\nsmall  large\nindex\nfoo        2      0\nbar        2      1\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/general/#pdcut","title":"<code>pd.cut</code>","text":"<ul> <li> <p><code>pandas.cut(x, bins, right=True, labels=None, retbins=False, precision=3, include_lowest=False, duplicates=\"raise\", ordered=True)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>x</code></p> <p>Series or Array like</p> <p><code>bins</code></p> <p>Integer or Array like</p> <p><code>include_lowest</code></p> <p>Boolean</p> <p>Example Usage</p> <pre><code> &gt;&gt;&gt; @bodo.jit\n... def f(S):\n...   bins = 4\n...   include_lowest = True\n...   return pd.cut(S, bins, include_lowest=include_lowest)\n&gt;&gt;&gt; S = pd.Series(\n...    [-2, 1, 3, 4, 5, 11, 15, 20, 22],\n...    [\"a1\", \"a2\", \"a3\", \"a4\", \"a5\", \"a6\", \"a7\", \"a8\", \"a9\"],\n...    name=\"ABC\",\n... )\n&gt;&gt;&gt; f(S)\na1    (-2.025, 4.0]\na2    (-2.025, 4.0]\na3    (-2.025, 4.0]\na4    (-2.025, 4.0]\na5      (4.0, 10.0]\na6     (10.0, 16.0]\na7     (10.0, 16.0]\na8     (16.0, 22.0]\na9     (16.0, 22.0]\nName: ABC, dtype: category\nCategories (4, interval[float64, right]): [(-2.025, 4.0] &lt; (4.0, 10.0] &lt; (10.0, 16.0] &lt; (16.0, 22.0]]\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/general/#pdqcut","title":"<code>pd.qcut</code>","text":"<ul> <li> <p><code>pandas.qcut(x, q, labels=None, retbins=False, precision=3, duplicates=\"raise\")</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>x</code></p> <p>Series or Array like</p> <p><code>q</code></p> <p>Integer or Array like of floats</p> <p>Example Usage</p> <pre><code> &gt;&gt;&gt; @bodo.jit\n... def f(S):\n...   q = 4\n...   return pd.qcut(S, q)\n&gt;&gt;&gt; S = pd.Series(\n...      [-2, 1, 3, 4, 5, 11, 15, 20, 22],\n...      [\"a1\", \"a2\", \"a3\", \"a4\", \"a5\", \"a6\", \"a7\", \"a8\", \"a9\"],\n...      name=\"ABC\",\n... )\n&gt;&gt;&gt; f(S)\na1    (-2.001, 3.0]\na2    (-2.001, 3.0]\na3    (-2.001, 3.0]\na4       (3.0, 5.0]\na5       (3.0, 5.0]\na6      (5.0, 15.0]\na7      (5.0, 15.0]\na8     (15.0, 22.0]\na9     (15.0, 22.0]\nName: ABC, dtype: category\nCategories (4, interval[float64, right]): [(-2.001, 3.0] &lt; (3.0, 5.0] &lt; (5.0, 15.0] &lt; (15.0, 22.0]]\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/general/#pdmerge","title":"<code>pd.merge</code>","text":"<ul> <li> <p><code>pandas.merge(left, right, how=\"inner\", on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=(\"_x\", \"_y\"), copy=True, indicator=False, validate=None, _bodo_na_equal=True)</code> </p> <p>Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p>other requirements</p> <p><code>left</code></p> <p>DataFrame</p> <p><code>right</code></p> <p>DataFrame</p> <p><code>how</code></p> <p>String</p> <ul> <li>Must be one of     <code>\"inner\"</code>, <code>\"outer\"</code>,     <code>\"left\"</code>, <code>\"right\"</code></li> <li>Must be constant at     Compile Time</li> </ul> <p><code>on</code></p> <p>Column Name, List of Column Names, or General Merge Condition String (see merge-notes)</p> <ul> <li>Must be constant at     Compile Time</li> </ul> <p><code>left_on</code></p> <p>Column Name or List of Column Names</p> <ul> <li>Must be constant at     Compile Time </li> </ul> <p><code>right_on</code></p> <p>Column Name or List of Column Names</p> <ul> <li>Must be constant at     Compile Time </li> </ul> <p><code>left_index</code> </p> <p>Boolean </p> <ul> <li>Must be constant at     Compile Time</li> </ul> <p><code>right_index</code> </p> <p>Boolean </p> <ul> <li>Must be constant at     Compile Time</li> </ul> <p><code>suffixes</code> </p> <p>Tuple of Strings </p> <ul> <li>Must be constant at     Compile Time</li> </ul> <p><code>indicator</code> </p> <p>Boolean </p> <ul> <li>Must be constant at     Compile Time</li> </ul> <p><code>_bodo_na_equal</code></p> <p>Boolean</p> <ul> <li>Must be constant at     Compile Time</li> <li>This argument is     unique to Bodo and not     available in Pandas.     If False, Bodo won't     consider NA/nan keys     as equal, which     differs from Pandas.</li> </ul> <p>Important</p> <p>The argument <code>_bodo_na_equal</code> is unique to Bodo and not available in Pandas. If it is <code>False</code>, Bodo won't consider NA/nan keys as equal, which differs from Pandas.</p> </li> </ul>"},{"location":"api_docs/pandas/general/#merge-notes","title":"Merge Notes","text":"<ul> <li> <p>Output Ordering:</p> <p>The output dataframe is not sorted by default for better parallel performance (Pandas may preserve key order depending on <code>how</code>). One can use explicit sort if needed.</p> </li> <li> <p>General Merge Conditions:</p> <p>Within Pandas, the merge criteria supported by <code>pd.merge</code> are limited to equality between 1 or more pairs of keys. For some use cases, this is not sufficient and more generalized support is necessary. For example, with these limitations, a <code>left outer join</code> where <code>df1.A == df2.B &amp; df2.C &lt; df1.A</code> cannot be efficiently computed.</p> <p>Bodo supports these use cases by allowing users to pass general merge conditions to <code>pd.merge</code>. We plan to contribute this feature to Pandas to ensure full compatibility of Bodo and Pandas code.</p> <p>General merge conditions are performed by providing the condition as a string via the <code>on</code> argument. Columns in the left table are referred to by <code>left.{column name}</code> and columns in the right table are referred to by <code>right.{column name}</code>.</p> <p>Here's an example demonstrating the above:</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def general_merge(df1, df2):\n...   return df1.merge(df2, on=\"left.`A` == right.`B` &amp; right.`C` &lt; left.`A`\", how=\"left\")\n&gt;&gt;&gt; df1 = pd.DataFrame({\"col\": [2, 3, 5, 1, 2, 8], \"A\": [4, 6, 3, 9, 9, -1]})\n&gt;&gt;&gt; df2 = pd.DataFrame({\"B\": [1, 2, 9, 3, 2], \"C\": [1, 7, 2, 6, 5]})\n&gt;&gt;&gt; general_merge(df1, df2)\ncol  A     B     C\n0    2  4  &lt;NA&gt;  &lt;NA&gt;\n1    3  6  &lt;NA&gt;  &lt;NA&gt;\n2    5  3  &lt;NA&gt;  &lt;NA&gt;\n3    1  9     9     2\n4    2  9     9     2\n5    8 -1  &lt;NA&gt;  &lt;NA&gt;\n</code></pre> <p>These calls have a few additional requirements:</p> <ul> <li>The condition must be constant string.</li> <li>The condition must be of the form <code>cond_1 &amp; ... &amp; cond_N</code> where at least one <code>cond_i</code>   is a simple equality. This restriction will be removed in a future release.</li> <li>The columns specified in these conditions are limited to certain column types.   We currently support <code>boolean</code>, <code>integer</code>, <code>float</code>, <code>datetime64</code>, <code>timedelta64</code>, <code>datetime.date</code>,   and <code>string</code> columns.</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df1, df2):\n...   return pd.merge(df1, df2, how=\"inner\", on=\"key\")\n&gt;&gt;&gt; df1 = pd.DataFrame({\"key\": [2, 3, 5, 1, 2, 8], \"A\": np.array([4, 6, 3, 9, 9, -1], float)})\n&gt;&gt;&gt; df2 = pd.DataFrame({\"key\": [1, 2, 9, 3, 2], \"B\": np.array([1, 7, 2, 6, 5], float)})\n&gt;&gt;&gt; f(df1, df2)\nkey    A    B\n0    2  4.0  7.0\n1    2  4.0  5.0\n2    3  6.0  6.0\n3    1  9.0  1.0\n4    2  9.0  7.0\n5    2  9.0  5.0\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/general/#pdconcat","title":"<code>pd.concat</code>","text":"<ul> <li> <p><code>pandas.concat(objs, axis=0, join=\"outer\", join_axes=None, ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, sort=None, copy=True)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p>other requirements</p> <p><code>objs</code> </p> <p>List or Tuple of DataFrames/Series</p> <p><code>axis</code> </p> <p>Integer with either 0 or 1</p> <ul> <li>Must be constant at     Compile Time</li> </ul> <p><code>ignore_index</code> </p> <p>Boolean </p> <ul> <li>Must be constant at     Compile Time</li> </ul> <p>Important</p> <p>Bodo currently concatenates local data chunks for distributed datasets, which does not preserve global order of concatenated objects in output.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df1, df2):\n...     return pd.concat([df1, df2], axis=1)\n&gt;&gt;&gt; df1 = pd.DataFrame({\"A\": [3, 2, 1, -4, 7]})\n&gt;&gt;&gt; df2 = pd.DataFrame({\"B\": [3, 25, 1, -4, -24]})\n&gt;&gt;&gt; f(df1, df2)\nA   B\n0  3   3\n1  2  25\n2  1   1\n3 -4  -4\n4  7 -24\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/general/#pdget_dummies","title":"<code>pd.get_dummies</code>","text":"<ul> <li> <p><code>pandas.get_dummies(data, prefix=None, prefix_sep=\"_\", dummy_na=False, columns=None, sparse=False, drop_first=False, dtype=None)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p>other requirements</p> <p><code>data</code></p> <p>Array or Series with Categorical dtypes</p> <ul> <li>Categories must be     known at compile     time.</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return pd.get_dummies(S)\n&gt;&gt;&gt; S = pd.Series([\"CC\", \"AA\", \"B\", \"D\", \"AA\", None, \"B\", \"CC\"]).astype(\"category\")\n&gt;&gt;&gt; f(S)\nAA  B  CC  D\n0   0  0   1  0\n1   1  0   0  0\n2   0  1   0  0\n3   0  0   0  1\n4   1  0   0  0\n5   0  0   0  0\n6   0  1   0  0\n7   0  0   1  0\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/general/#pdunique","title":"<code>pd.unique</code>","text":"<ul> <li> <p><code>pandas.unique(values)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>values</code></p> <p>Series or 1-d array with Categorical dtypes</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return pd.unique(S)\n&gt;&gt;&gt; S = pd.Series([1, 2, 1, 3, 2, 1])\n&gt;&gt;&gt; f(S)\narray([1, 2, 3])\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/general/#top-level-missing-data","title":"Top-level missing data","text":""},{"location":"api_docs/pandas/general/#pdisna","title":"<code>pd.isna</code>","text":"<ul> <li> <p><code>pandas.isna(obj)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>obj</code></p> <p>DataFrame, Series, Index, Array, or Scalar </p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return pd.isna(df)\n&gt;&gt;&gt; df = pd.DataFrame(\n...    {\"A\": [\"AA\", np.nan, \"\", \"D\", \"GG\"], \"B\": [1, 8, 4, -1, 2]},\n...    [1.1, -2.1, 7.1, 0.1, 3.1],\n... )\n&gt;&gt;&gt; f(df)\nA      B\n1.1  False  False\n-2.1   True  False\n7.1  False  False\n0.1  False  False\n3.1  False  False\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/general/#pdisnull","title":"<code>pd.isnull</code>","text":"<ul> <li> <p><code>pandas.isnull(obj)</code> </p> <p>Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>obj</code></p> <p>DataFrame, Series, Index, Array, or Scalar </p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return pd.isnull(df)\n&gt;&gt;&gt; df = pd.DataFrame(\n...    {\"A\": [\"AA\", np.nan, \"\", \"D\", \"GG\"], \"B\": [1, 8, 4, -1, 2]},\n...    [1.1, -2.1, 7.1, 0.1, 3.1],\n... )\n&gt;&gt;&gt; f(df)\nA      B\n1.1  False  False\n-2.1   True  False\n7.1  False  False\n0.1  False  False\n3.1  False  False\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/general/#pdnotna","title":"<code>pd.notna</code>","text":"<ul> <li> <p><code>pandas.notna(obj)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>obj</code></p> <p>DataFrame, Series, Index, Array, or Scalar </p> <p>Example Usage</p> <pre><code> &gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return pd.notna(df)\n&gt;&gt;&gt; df = pd.DataFrame(\n...    {\"A\": [\"AA\", np.nan, \"\", \"D\", \"GG\"], \"B\": [1, 8, 4, -1, 2]},\n...    [1.1, -2.1, 7.1, 0.1, 3.1],\n... )\n&gt;&gt;&gt; f(df)\nA     B\n1.1   True  True\n-2.1  False  True\n7.1   True  True\n0.1   True  True\n3.1   True  True\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/general/#pdnotnull","title":"<code>pd.notnull</code>","text":"<ul> <li> <p><code>pandas.notnull(obj)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>obj</code></p> <p>DataFrame, Series, Index, Array, or Scalar </p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return pd.notnull(df)\n&gt;&gt;&gt; df = pd.DataFrame(\n...    {\"A\": [\"AA\", np.nan, \"\", \"D\", \"GG\"], \"B\": [1, 8, 4, -1, 2]},\n...    [1.1, -2.1, 7.1, 0.1, 3.1],\n... )\n&gt;&gt;&gt; f(df)\nA     B\n1.1   True  True\n-2.1  False  True\n7.1   True  True\n0.1   True  True\n3.1   True  True\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/general/#top-level-conversions","title":"Top-level conversions","text":""},{"location":"api_docs/pandas/general/#pdto_numeric","title":"<code>pd.to_numeric</code>","text":"<ul> <li> <p><code>pandas.to_numeric(arg, errors=\"raise\", downcast=None)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p>other requirements</p> <p><code>arg</code></p> <p>Series or Array</p> <p><code>downcast</code></p> <p>String and one of (<code>'integer'</code>, <code>'signed'</code>, <code>'unsigned'</code>, <code>'float'</code>)</p> <ul> <li>Must be constant at     Compile Time</li> </ul> <p>Note</p> <ul> <li>Output type is float64 by default</li> <li>Unlike Pandas, Bodo does not dynamically determine output type,   and does not downcast to the smallest numerical type.</li> <li><code>downcast</code> parameter should be used for type annotation of output.</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return pd.to_numeric(S, errors=\"coerce\", downcast=\"integer\")\n&gt;&gt;&gt; S = pd.Series([\"1\", \"3\", \"12\", \"4\", None, \"-555\"])\n&gt;&gt;&gt; f(S)\n0       1\n1       3\n2      12\n3       4\n4    &lt;NA&gt;\n5    -555\ndtype: Int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/general/#top-level-dealing-with-datetime-and-timedelta-like","title":"Top-level dealing with datetime and timedelta like","text":""},{"location":"api_docs/pandas/general/#pdto_datetime","title":"<code>pd.to_datetime</code>","text":"<ul> <li> <p><code>pandas.to_datetime(arg, errors='raise', dayfirst=False, yearfirst=False, utc=None, format=None, exact=True, unit=None, infer_datetime_format=False, origin='unix', cache=True)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p>other requirements</p> <p><code>arg</code></p> <p>Series, Array or scalar of integers or strings</p> <p><code>errors</code></p> <p>String and one of ('ignore', 'raise', 'coerce')</p> <p><code>dayfirst</code></p> <p>Boolean</p> <p><code>yearfirst</code></p> <p>Boolean</p> <p><code>utc</code></p> <p>Boolean</p> <p><code>format</code></p> <p>String matching Pandas strftime /strptime</p> <p><code>exact</code></p> <p>Boolean</p> <p><code>unit</code></p> <p>String</p> <ul> <li>Must be a valid     Pandas timedelta     unit</li> </ul> <p><code>infer  _datetime_format</code></p> <p>Boolean </p> <p><code>origin</code> </p> <p>Scalar string or timestamp value</p> <p><code>cache</code></p> <p>Boolean</p> <p>Note</p> <ul> <li>The function is not optimized.</li> <li>Bodo doesn't support Timezone-Aware datetime values</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(val):\n...     return pd.to_datetime(val, format=\"%Y-%d-%m\")\n&gt;&gt;&gt; val = \"2016-01-06\"\n&gt;&gt;&gt; f(val)\nTimestamp('2016-06-01 00:00:00')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/general/#pdto_timedelta","title":"<code>pd.to_timedelta</code>","text":"<ul> <li> <p><code>pandas.to_timedelta(arg, unit=None, errors='raise')</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p>other requirements</p> <p><code>arg</code></p> <p>Series, Array or scalar of integers or strings</p> <p><code>unit</code></p> <p>String</p> <ul> <li>Must be a valid Pandas     timedelta unit</li> </ul> <p>Note</p> <p>Passing string data as <code>arg</code> is not optimized.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return pd.to_timedelta(S, unit=\"D\")\n&gt;&gt;&gt; S = pd.Series([1.0, 2.2, np.nan, 4.2], [3, 1, 0, -2], name=\"AA\")\n&gt;&gt;&gt; f(val)\n3   1 days 00:00:00\n1   2 days 04:48:00\n0               NaT\n-2   4 days 04:48:00\nName: AA, dtype: timedelta64[ns]\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/general/#pddate_range","title":"<code>pd.date_range</code>","text":"<ul> <li> <p><code>pandas.date_range(start=None, end=None, periods=None, freq=None, tz=None, normalize=False, name=None, closed=None, **kwargs)</code></p> <p>Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p>other requirements</p> <p><code>start</code> </p> <p>String or Timestamp</p> <p><code>end</code> </p> <p>String or Timestamp</p> <p><code>periods</code></p> <p>Integer</p> <p><code>freq</code></p> <p>String</p> <ul> <li>Must be a valid     Pandas     frequ ency</li> </ul> <p><code>name</code></p> <p>String</p> <p>Note</p> <ul> <li>Exactly three of <code>start</code>, <code>end</code>, <code>periods</code>, and <code>freq</code> must   be provided.</li> <li>Bodo Does Not support <code>kwargs</code>, even for compatibility.</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...     return pd.date_range(start=\"2018-04-24\", end=\"2018-04-27\", periods=3)\n&gt;&gt;&gt; f()\nDatetimeIndex(['2018-04-24 00:00:00', '2018-04-25 12:00:00',\n'2018-04-27 00:00:00'],\ndtype='datetime64[ns]', freq=None)\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/general/#pdtimedelta_range","title":"<code>pd.timedelta_range</code>","text":"<ul> <li> <p><code>pandas.timedelta_range(start=None, end=None, periods=None, freq=None, name=None, closed=None)</code> </p> <p>Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p>other requirements</p> <p><code>start</code> </p> <p>String or Timedelta</p> <p><code>end</code> </p> <p>String or Timedelta</p> <p><code>periods</code></p> <p>Integer</p> <p><code>freq</code></p> <p>String</p> <ul> <li>Must be a valid     Pandas     frequ ency</li> </ul> <p><code>name</code></p> <p>String</p> <p><code>closed</code></p> <p>String and one of ('left', 'right')</p> <p>Note</p> <ul> <li>Exactly three of <code>start</code>, <code>end</code>, <code>periods</code>, and <code>freq</code> must   be provided.</li> <li>This function is not parallelized yet.</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...     return pd.timedelta_range(start=\"1 day\", end=\"11 days 1 hour\", periods=3)\n&gt;&gt;&gt; f()\nTimedeltaIndex(['1 days 00:00:00', '6 days 00:30:00', '11 days 01:00:00'], dtype='timedelta64[ns]', freq=None)\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/groupby/","title":"GroupBy","text":""},{"location":"api_docs/pandas/groupby/#pddataframegroupby","title":"<code>pd.DataFrame.groupby</code>","text":"<ul> <li> <p><code>pandas.DataFrame.groupby(by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=NoDefault.no_default, observed=False, dropna=True)</code> </p> <p>Supported Arguments</p> <ul> <li><code>by</code>: Column label or list of column labels<ul> <li>Must be constant at Compile Time</li> <li>This argument is required</li> </ul> </li> <li><code>as_index</code>: Boolean<ul> <li>Must be constant at Compile Time</li> </ul> </li> <li><code>dropna</code>: Boolean<ul> <li>Must be constant at Compile Time</li> </ul> </li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return df.groupby(\"B\", dropna=True, as_index=False).count()\n&gt;&gt;&gt; df = pd.DataFrame(\n...      {\n...          \"A\": [1, 2, 24, None] * 5,\n...          \"B\": [\"421\", \"f31\"] * 10,\n...          \"C\": [1.51, 2.421, 233232, 12.21] * 5\n...      }\n... )\n&gt;&gt;&gt; f(df)\nB   A   C\n0  421  10  10\n1  f31   5  10\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/groupby/#pdseriesgroupby","title":"<code>pd.Series.groupby</code>","text":"<ul> <li> <p><code>pandas.Series.groupby(by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=NoDefault.no_default, observed=False, dropna=True)</code> </p> <p>Supported Arguments</p> <ul> <li><code>by</code>: Array-like or Series data. This is not supported with Decimal or Categorical data.<ul> <li>Must be constant at Compile Time</li> </ul> </li> <li><code>level</code>: integer<ul> <li>Must be constant at Compile Time</li> <li>Only <code>level=0</code> is supported and not with MultiIndex.</li> </ul> </li> </ul> <p>Important</p> <p>You must provide exactly one of <code>by</code> and <code>level</code></p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S, by_series):\n...     return S.groupby(by_series).count()\n&gt;&gt;&gt; S = pd.Series([1, 2, 24, None] * 5)\n&gt;&gt;&gt; by_series = pd.Series([\"421\", \"f31\"] * 10)\n&gt;&gt;&gt; f(S, by_series)\n421    10\nf31     5\nName: , dtype: int64\n</code></pre> <p>Note</p> <p><code>Series.groupby</code> doesn't currently keep the name of the original Series.</p> </li> </ul>"},{"location":"api_docs/pandas/groupby/#pdcoregroupbygroupbyapply","title":"<code>pd.core.groupby.Groupby.apply</code>","text":"<ul> <li> <p><code>pandas.core.groupby.Groupby.apply(func, *args, **kwargs)</code> </p> <p>Supported Arguments</p> <ul> <li><code>func</code>: JIT function, callable defined within a JIT function that returns a DataFrame or Series<ul> <li>Additional arguments for <code>func</code> can be passed as additional arguments.</li> </ul> </li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df, y):\n...     return df.groupby(\"B\", dropna=True).apply(lambda group, y: group.sum(axis=1) + y, y=y)\n&gt;&gt;&gt; df = pd.DataFrame(\n...      {\n...          \"A\": [1, 2, 24, None] * 5,\n...          \"B\": [\"421\", \"f31\"] * 10,\n...          \"C\": [1.51, 2.421, 233232, 12.21] * 5\n...      }\n... )\n&gt;&gt;&gt; y = 4\n&gt;&gt;&gt; f(df, y)\nB\n421  0          6.510\n2          8.421\n4     233260.000\n6         16.210\n8          6.510\n10         8.421\n12    233260.000\n14        16.210\n16         6.510\n18         8.421\nf31  1     233260.000\n3         16.210\n5          6.510\n7          8.421\n9     233260.000\n11        16.210\n13         6.510\n15         8.421\n17    233260.000\n19        16.210\ndtype: float64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/groupby/#pdcoregroupbygroupbyagg","title":"<code>pd.core.groupby.Groupby.agg</code>","text":"<ul> <li> <p><code>pandas.core.groupby.Groupby.agg(func, *args, **kwargs)</code> </p> <p>Supported Arguments</p> <ul> <li><code>func</code>: JIT function, callable defined within a JIT function, constant dictionary mapping column name to a function<ul> <li>Additional arguments for <code>func</code> can be passed as additional arguments.</li> </ul> </li> </ul> <p>Note</p> <ul> <li>Passing a list of functions is also supported if only one output column is selected.</li> <li>Output column names can be specified using keyword arguments and <code>pd.NamedAgg()</code>.</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return df.groupby(\"B\", dropna=True).agg({\"A\": lambda x: max(x)})\n&gt;&gt;&gt; df = pd.DataFrame(\n...      {\n...          \"A\": [1, 2, 24, None] * 5,\n...          \"B\": [\"421\", \"f31\"] * 10,\n...          \"C\": [1.51, 2.421, 233232, 12.21] * 5\n...      }\n... )\n&gt;&gt;&gt; f(df)\nA\nB\n421  24.0\nf31   2.0\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/groupby/#pdcoregroupbydataframegroupbyaggregate","title":"<code>pd.core.groupby.DataFrameGroupby.aggregate</code>","text":"<ul> <li> <p><code>pandas.core.groupby.DataFrameGroupby.aggregate(func, *args, **kwargs)</code> </p> <p>Supported Arguments</p> <ul> <li><code>func</code>: JIT function, callable defined within a JIT function, constant dictionary mapping column name to a function<ul> <li>Additional arguments for <code>func</code> can be passed as additional arguments.</li> </ul> </li> </ul> <p>Note</p> <ul> <li>Passing a list of functions is also supported if only one output column is selected.</li> <li>Output column names can be specified using keyword arguments and <code>pd.NamedAgg()</code>.</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return df.groupby(\"B\", dropna=True).agg({\"A\": lambda x: max(x)})\n&gt;&gt;&gt; df = pd.DataFrame(\n...      {\n...          \"A\": [1, 2, 24, None] * 5,\n...          \"B\": [\"421\", \"f31\"] * 10,\n...          \"C\": [1.51, 2.421, 233232, 12.21] * 5\n...      }\n... )\n&gt;&gt;&gt; f(df)\nA\nB\n421  24.0\nf31   2.0\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/groupby/#pdcoregroupbydataframegroupbytransform","title":"<code>pd.core.groupby.DataFrameGroupby.transform</code>","text":"<ul> <li> <p><code>pandas.core.groupby.DataFrameGroupby.transform(func, *args, engine=None, engine_kwargs=None, **kwargs)</code> </p> <p>Supported Arguments</p> <ul> <li><code>func</code>: Constant string, Python function from the builtins module that matches a supported operation<ul> <li>Numpy functions cannot be provided.</li> </ul> </li> </ul> <p>Note</p> <p>The supported builtin functions are <code>'count'</code>, <code>'first'</code>, <code>'last'</code>, <code>'min'</code>, <code>'max'</code>, <code>'mean'</code>, <code>'median'</code>, <code>'nunique'</code>, <code>'prod'</code>, <code>'std'</code>, <code>'sum'</code>, and <code>'var'</code></p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return df.groupby(\"B\", dropna=True).transform(max)\n&gt;&gt;&gt; df = pd.DataFrame(\n...      {\n...          \"A\": [1, 2, 24, None] * 5,\n...          \"B\": [\"421\", \"f31\"] * 10,\n...          \"C\": [1.51, 2.421, 233232, 12.21] * 5\n...      }\n... )\n&gt;&gt;&gt; f(df)\nA          C\n0   24.0  233232.00\n1    2.0      12.21\n2   24.0  233232.00\n3    2.0      12.21\n4   24.0  233232.00\n5    2.0      12.21\n6   24.0  233232.00\n7    2.0      12.21\n8   24.0  233232.00\n9    2.0      12.21\n10  24.0  233232.00\n11   2.0      12.21\n12  24.0  233232.00\n13   2.0      12.21\n14  24.0  233232.00\n15   2.0      12.21\n16  24.0  233232.00\n17   2.0      12.21\n18  24.0  233232.00\n19   2.0      12.21\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/groupby/#pdcoregroupbygroupbypipe","title":"<code>pd.core.groupby.Groupby.pipe</code>","text":"<ul> <li> <p><code>pandas.core.groupby.Groupby.pipe(func, *args, **kwargs)</code> </p> <p>Supported Arguments</p> <ul> <li><code>func</code>: JIT function, callable defined within a JIT function.<ul> <li>Additional arguments for <code>func</code> can be passed as additional arguments.</li> </ul> </li> </ul> <p>Note</p> <p><code>func</code> cannot be a tuple</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df, y):\n...     return df.groupby(\"B\").pipe(lambda grp, y: grp.sum() - y, y=y)\n&gt;&gt;&gt; df = pd.DataFrame(\n...      {\n...          \"A\": [1, 2, 24, None] * 5,\n...          \"B\": [\"421\", \"f31\"] * 10,\n...          \"C\": [1.51, 2.421, 233232, 12.21] * 5\n...      }\n... )\n&gt;&gt;&gt; y = 5\n&gt;&gt;&gt; f(df, y)\nA            C\nB\n421  120.0  1166162.550\nf31    5.0       68.155\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/groupby/#pdcoregroupbygroupbycount","title":"<code>pd.core.groupby.Groupby.count</code>","text":"<ul> <li> <p><code>pandas.core.groupby.Groupby.count()</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return df.groupby(\"B\").count()\n&gt;&gt;&gt; df = pd.DataFrame(\n...      {\n...          \"A\": [1, 2, 24, None] * 5,\n...          \"B\": [\"421\", \"f31\"] * 10,\n...          \"C\": [1.51, 2.421, 233232, 12.21] * 5\n...      }\n... )\n&gt;&gt;&gt; f(df)\nA   C\nB\n421  10  10\nf31   5  10\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/groupby/#pdcoregroupbygroupbycumsum","title":"<code>pd.core.groupby.Groupby.cumsum</code>","text":"<ul> <li> <p><code>pandas.core.groupby.Groupby.cumsum(axis=0)</code> </p> <p>Note</p> <p><code>cumsum</code> is only supported on numeric columns and is not supported on boolean columns</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return df.groupby(\"B\").cumsum()\n&gt;&gt;&gt; df = pd.DataFrame(\n...      {\n...          \"A\": [1, 2, 24, None] * 5,\n...          \"B\": [\"421\", \"f31\"] * 10,\n...          \"C\": [1.51, 2.421, 233232, 12.21] * 5\n...      }\n... )\n&gt;&gt;&gt; f(df)\nA            C\n0     1.0        1.510\n1     2.0        2.421\n2    25.0   233233.510\n3     NaN       14.631\n4    26.0   233235.020\n5     4.0       17.052\n6    50.0   466467.020\n7     NaN       29.262\n8    51.0   466468.530\n9     6.0       31.683\n10   75.0   699700.530\n11    NaN       43.893\n12   76.0   699702.040\n13    8.0       46.314\n14  100.0   932934.040\n15    NaN       58.524\n16  101.0   932935.550\n17   10.0       60.945\n18  125.0  1166167.550\n19    NaN       73.155\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/groupby/#pdcoregroupbygroupbyfirst","title":"<code>pd.core.groupby.Groupby.first</code>","text":"<ul> <li> <p><code>pandas.core.groupby.Groupby.first(numeric_only=False, min_count=-1)</code> </p> <p>Note</p> <p><code>first</code> is not supported on columns with nested array types</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return df.groupby(\"B\").first()\n&gt;&gt;&gt; df = pd.DataFrame(\n...      {\n...          \"A\": [1, 2, 24, None] * 5,\n...          \"B\": [\"421\", \"f31\"] * 10,\n...          \"C\": [1.51, 2.421, 233232, 12.21] * 5\n...      }\n... )\n&gt;&gt;&gt; f(df)\nA      C\nB\n421  1.0  1.510\nf31  2.0  2.421\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/groupby/#pdcoregroupbygroupbyhead","title":"<code>pd.core.groupby.Groupby.head</code>","text":"<ul> <li> <p><code>pandas.core.groupby.Groupby.head(n=5)</code> </p> <p>Supported Arguments</p> <ul> <li><code>n</code>: Non-negative integer<ul> <li>Must be constant at Compile Time</li> </ul> </li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return df.groupby(\"B\").head()\n&gt;&gt;&gt; df = pd.DataFrame(\n...      {\n...          \"A\": [1, 2, 24, None] * 5,\n...          \"B\": [\"421\", \"f31\"] * 10,\n...          \"C\": [1.51, 2.421, 233232, 12.21] * 5\n...      }\n... )\n&gt;&gt;&gt; f(df)\nA    B           C\n0   1.0  421       1.510\n1   2.0  f31       2.421\n2  24.0  421  233232.000\n3   NaN  f31      12.210\n4   1.0  421       1.510\n5   2.0  f31       2.421\n6  24.0  421  233232.000\n7   NaN  f31      12.210\n8   1.0  421       1.510\n9   2.0  f31       2.421\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/groupby/#pdcoregroupbygroupbylast","title":"<code>pd.core.groupby.Groupby.last</code>","text":"<ul> <li> <p><code>pandas.core.groupby.Groupby.last(numeric_only=False, min_count=-1)</code> </p> <p>Note</p> <p><code>last</code> is not supported on columns with nested array types</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return df.groupby(\"B\").last()\n&gt;&gt;&gt; df = pd.DataFrame(\n...      {\n...          \"A\": [1, 2, 24, None] * 5,\n...          \"B\": [\"421\", \"f31\"] * 10,\n...          \"C\": [1.51, 2.421, 233232, 12.21] * 5\n...      }\n... )\n&gt;&gt;&gt; f(df)\nA          C\nB\n421  24.0  233232.00\nf31   2.0      12.21\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/groupby/#pdcoregroupbygroupbymax","title":"<code>pd.core.groupby.Groupby.max</code>","text":"<ul> <li> <p><code>pandas.core.groupby.Groupby.max(numeric_only=False, min_count=-1)</code> </p> <p>Note</p> <ul> <li><code>max</code> is not supported on columns with nested array types.</li> <li>Categorical columns must be ordered.</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return df.groupby(\"B\").max()\n&gt;&gt;&gt; df = pd.DataFrame(\n...      {\n...          \"A\": [1, 2, 24, None] * 5,\n...          \"B\": [\"421\", \"f31\"] * 10,\n...          \"C\": [1.51, 2.421, 233232, 12.21] * 5\n...      }\n... )\n&gt;&gt;&gt; f(df)\nA          C\nB\n421  24.0  233232.00\nf31   2.0      12.21\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/groupby/#pdcoregroupbygroupbymean","title":"<code>pd.core.groupby.Groupby.mean</code>","text":"<ul> <li> <p><code>pandas.core.groupby.Groupby.mean(numeric_only=NoDefault.no_default)</code> </p> <p>Note</p> <p><code>mean</code> is only supported on numeric columns and is not supported on boolean column</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return df.groupby(\"B\").mean()\n&gt;&gt;&gt; df = pd.DataFrame(\n...      {\n...          \"A\": [1, 2, 24, None] * 5,\n...          \"B\": [\"421\", \"f31\"] * 10,\n...          \"C\": [1.51, 2.421, 233232, 12.21] * 5\n...      }\n... )\n&gt;&gt;&gt; f(df)\nA            C\nB\n421  12.5  116616.7550\nf31   2.0       7.3155\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/groupby/#pdcoregroupbygroupbymedian","title":"<code>pd.core.groupby.Groupby.median</code>","text":"<ul> <li> <p><code>pandas.core.groupby.Groupby.median(numeric_only=NoDefault.no_default)</code> </p> <p>Note</p> <p><code>median</code> is only supported on numeric columns and is not supported on boolean column</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return df.groupby(\"B\").median()\n&gt;&gt;&gt; df = pd.DataFrame(\n...      {\n...          \"A\": [1, 2, 24, None] * 5,\n...          \"B\": [\"421\", \"f31\"] * 10,\n...          \"C\": [1.51, 2.421, 233232, 12.21] * 5\n...      }\n... )\n&gt;&gt;&gt; f(df)\nA            C\nB\n421  12.5  116616.7550\nf31   2.0       7.3155\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/groupby/#pdcoregroupbygroupbymin","title":"<code>pd.core.groupby.Groupby.min</code>","text":"<ul> <li> <p><code>pandas.core.groupby.Groupby.min(numeric_only=False, min_count=-1)</code> </p> <p>Note</p> <ul> <li><code>min</code> is not supported on columns with nested array types</li> <li>Categorical columns must be ordered.</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return df.groupby(\"B\").min()\n&gt;&gt;&gt; df = pd.DataFrame(\n...      {\n...          \"A\": [1, 2, 24, None] * 5,\n...          \"B\": [\"421\", \"f31\"] * 10,\n...          \"C\": [1.51, 2.421, 233232, 12.21] * 5\n...      }\n... )\n&gt;&gt;&gt; f(df)\nA      C\nB\n421  1.0  1.510\nf31  2.0  2.421\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/groupby/#pdcoregroupbygroupbyprod","title":"<code>pd.core.groupby.Groupby.prod</code>","text":"<ul> <li> <p><code>pandas.core.groupby.Groupby.prod(numeric_only=NoDefault.no_default, min_count=0)</code> </p> <p>Note</p> <p><code>prod</code> is not supported on columns with nested array types</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return df.groupby(\"B\").prod()\n&gt;&gt;&gt; df = pd.DataFrame(\n...      {\n...          \"A\": [1, 2, 24, None] * 5,\n...          \"B\": [\"421\", \"f31\"] * 10,\n...          \"C\": [1.51, 2.421, 233232, 12.21] * 5\n...      }\n... )\n&gt;&gt;&gt; f(df)\nA             C\nB\n421  7962624.0  5.417831e+27\nf31       32.0  2.257108e+07\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/groupby/#pdcoregroupbygroupbyrolling","title":"<code>pd.core.groupby.Groupby.rolling</code>","text":"<ul> <li> <p><code>pandas.core.groupby.Groupby.rolling(window, min_periods=None, center=False, win_type=None, on=None, axis=0, closed=None, method='single')</code> </p> <p>Supported Arguments</p> <ul> <li><code>window</code>: Integer, String, Datetime, Timedelta</li> <li><code>min_periods</code>: Integer</li> <li><code>center</code>: Boolean</li> <li><code>on</code>: Column label<ul> <li>Must be constant at Compile Time</li> </ul> </li> </ul> <p>Note</p> <p>This is equivalent to performing the DataFrame API on each groupby. All operations of the rolling API can be used with groupby.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return df.groupby(\"B\").rolling(2).mean\n&gt;&gt;&gt; df = pd.DataFrame(\n...      {\n...          \"A\": [1, 2, 24, None] * 5,\n...          \"B\": [\"421\", \"f31\"] * 10,\n...          \"C\": [1.51, 2.421, 233232, 12.21] * 5\n...      }\n... )\n&gt;&gt;&gt; f(df)\nA            C\nB\n421 0    NaN          NaN\n2    NaN          NaN\n4   12.5  116616.7550\n6    NaN       7.3155\n8   12.5  116616.7550\n10   NaN       7.3155\n12  12.5  116616.7550\n14   NaN       7.3155\n16  12.5  116616.7550\n18   NaN       7.3155\nf31 1   12.5  116616.7550\n3    NaN       7.3155\n5   12.5  116616.7550\n7    NaN       7.3155\n9   12.5  116616.7550\n11   NaN       7.3155\n13  12.5  116616.7550\n15   NaN       7.3155\n17  12.5  116616.7550\n19   NaN       7.3155\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/groupby/#pdcoregroupbygroupbysize","title":"<code>pd.core.groupby.Groupby.size</code>","text":"<ul> <li> <p><code>pandas.core.groupby.Groupby.size()</code> </p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return df.groupby(\"B\").size()\n&gt;&gt;&gt; df = pd.DataFrame(\n...      {\n...          \"A\": [1, 2, 24, None] * 5,\n...          \"B\": [\"421\", \"f31\"] * 10,\n...          \"C\": [1.51, 2.421, 233232, 12.21] * 5\n...      }\n... )\n&gt;&gt;&gt; f(df)\nB\n421    10\nf31    10\ndtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/groupby/#pdcoregroupbygroupbystd","title":"<code>pd.core.groupby.Groupby.std</code>","text":"<ul> <li> <p><code>pandas.core.groupby.Groupby.std(ddof=1)</code> </p> <p>Note</p> <p><code>std</code> is only supported on numeric columns and is not supported on boolean column</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return df.groupby(\"B\").std()\n&gt;&gt;&gt; df = pd.DataFrame(\n...      {\n...          \"A\": [1, 2, 24, None] * 5,\n...          \"B\": [\"421\", \"f31\"] * 10,\n...          \"C\": [1.51, 2.421, 233232, 12.21] * 5\n...      }\n... )\n&gt;&gt;&gt; f(df)\nA              C\nB\n421  12.122064  122923.261366\nf31   0.000000       5.159256\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/groupby/#pdcoregroupbygroupbysum","title":"<code>pd.core.groupby.Groupby.sum</code>","text":"<ul> <li> <p><code>pandas.core.groupby.Groupby.sum(numeric_only=NoDefault.no_default, min_count=0)</code> </p> <p>Note</p> <p><code>sum</code> is not supported on columns with nested array types</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return df.groupby(\"B\").sum()\n&gt;&gt;&gt; df = pd.DataFrame(\n...      {\n...          \"A\": [1, 2, 24, None] * 5,\n...          \"B\": [\"421\", \"f31\"] * 10,\n...          \"C\": [1.51, 2.421, 233232, 12.21] * 5\n...      }\n... )\n&gt;&gt;&gt; f(df)\nA            C\nB\n421  125.0  1166167.550\nf31   10.0       73.155\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/groupby/#pdcoregroupbygroupbyvar","title":"<code>pd.core.groupby.Groupby.var</code>","text":"<ul> <li> <p><code>pandas.core.groupby.Groupby.var(ddof=1)</code> </p> <p>Note</p> <p><code>var</code> is only supported on numeric columns and is not supported on boolean column</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return df.groupby(\"B\").var()\n&gt;&gt;&gt; df = pd.DataFrame(\n...      {\n...          \"A\": [1, 2, 24, None] * 5,\n...          \"B\": [\"421\", \"f31\"] * 10,\n...          \"C\": [1.51, 2.421, 233232, 12.21] * 5\n...      }\n... )\n&gt;&gt;&gt; f(df)\nA             C\nB\n421  146.944444  1.511013e+10\nf31    0.000000  2.661792e+01\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/groupby/#pdcoregroupbydataframegroupbyidxmax","title":"<code>pd.core.groupby.DataFrameGroupby.idxmax</code>","text":"<ul> <li> <p><code>pandas.core.groupby.DataFrameGroupby.idxmax(axis=0, skipna=True)</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return df.groupby(\"B\").idxmax()\n&gt;&gt;&gt; df = pd.DataFrame(\n...      {\n...          \"A\": [1, 2, 24, None] * 5,\n...          \"B\": [\"421\", \"f31\"] * 10,\n...          \"C\": [1.51, 2.421, 233232, 12.21] * 5\n...      }\n... )\n&gt;&gt;&gt; f(df)\nA  C\nB\n421  2  2\nf31  1  3\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/groupby/#pdcoregroupbydataframegroupbyidxmin","title":"<code>pd.core.groupby.DataFrameGroupby.idxmin</code>","text":"<ul> <li> <p><code>pandas.core.groupby.DataFrameGroupby.idxmin(axis=0, skipna=True)</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return df.groupby(\"B\").idxmin()\n&gt;&gt;&gt; df = pd.DataFrame(\n...      {\n...          \"A\": [1, 2, 24, None] * 5,\n...          \"B\": [\"421\", \"f31\"] * 10,\n...          \"C\": [1.51, 2.421, 233232, 12.21] * 5\n...      }\n... )\n&gt;&gt;&gt; f(df)\nA  C\nB\n421  0  0\nf31  1  1\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/groupby/#pdcoregroupbydataframegroupbynunique","title":"<code>pd.core.groupby.DataFrameGroupby.nunique</code>","text":"<ul> <li> <p><code>pandas.core.groupby.DataFrameGroupby.nunique(dropna=True)</code> </p> <p>Supported Arguments</p> <ul> <li><code>dropna</code>: boolean</li> </ul> <p>Note</p> <p><code>nunique</code> is not supported on columns with nested array types</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return df.groupby(\"B\").nunique()\n&gt;&gt;&gt; df = pd.DataFrame(\n...      {\n...          \"A\": [1, 2, 24, None] * 5,\n...          \"B\": [\"421\", \"f31\"] * 10,\n...          \"C\": [1.51, 2.421, 233232, 12.21] * 5\n...      }\n... )\n&gt;&gt;&gt; f(df)\nA  C\nB\n421  2  2\nf31  1  2\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/groupby/#pdcoregroupbydataframegroupbyshift","title":"<code>pd.core.groupby.DataFrameGroupby.shift</code>","text":"<ul> <li> <p><code>pandas.core.groupby.DataFrameGroupby.shift(periods=1, freq=None, axis=0, fill_value=None)</code> </p> <p>Note</p> <p><code>shift</code> is not supported on columns with nested array types</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return df.groupby(\"B\").shift()\n&gt;&gt;&gt; df = pd.DataFrame(\n...      {\n...          \"A\": [1, 2, 24, None] * 5,\n...          \"B\": [\"421\", \"f31\"] * 10,\n...          \"C\": [1.51, 2.421, 233232, 12.21] * 5\n...      }\n... )\n&gt;&gt;&gt; f(df)\nA           C\n0    NaN         NaN\n1    NaN         NaN\n2    1.0       1.510\n3    2.0       2.421\n4   24.0  233232.000\n5    NaN      12.210\n6    1.0       1.510\n7    2.0       2.421\n8   24.0  233232.000\n9    NaN      12.210\n10   1.0       1.510\n11   2.0       2.421\n12  24.0  233232.000\n13   NaN      12.210\n14   1.0       1.510\n15   2.0       2.421\n16  24.0  233232.000\n17   NaN      12.210\n18   1.0       1.510\n19   2.0       2.421\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/groupby/#pdcoregroupbyseriesgroupbyvalue_counts","title":"<code>pd.core.groupby.SeriesGroupBy.value_counts</code>","text":"<ul> <li> <p><code>pandas.core.groupby.SeriesGroupby.value_counts(normalize=False, sort=True, ascending=False, bins=None, dropna=True)</code> </p> <p>Supported Arguments</p> <ul> <li><code>ascending</code>: boolean<ul> <li>Must be constant at Compile Time</li> </ul> </li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.groupby(level=0).value_counts()\n&gt;&gt;&gt; S = pd.Series([1, 2, 24, None] * 5, index = [\"421\", \"f31\"] * 10)\n&gt;&gt;&gt; f(S)\n421  1.0     5\n24.0    5\nf31  2.0     5\nName: , dtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/","title":"Index objects","text":""},{"location":"api_docs/pandas/indexapi/#index","title":"Index","text":""},{"location":"api_docs/pandas/indexapi/#properties","title":"Properties","text":""},{"location":"api_docs/pandas/indexapi/#pdindexname","title":"<code>pd.Index.name</code>","text":"<ul> <li> <p><code>pandas.Index.name</code> </p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.name\n&gt;&gt;&gt; I = pd.Index([1,2,3], name = \"hello world\")\n&gt;&gt;&gt; f(I)\n\"hello world\"\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexnames","title":"<code>pd.Index.names</code>","text":"<ul> <li> <p><code>pandas.Index.names</code> </p> <p>Important</p> <p>Bodo returns a tuple instead of a FrozenList.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.names\n&gt;&gt;&gt; I = pd.MultiIndex.from_product([[1, 2], [\"A\", \"B\"]], names=[\"C1\", \"C2\"])\n&gt;&gt;&gt; f(I)\n('C1', 'C2')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexshape","title":"<code>pd.Index.shape</code>","text":"<ul> <li> <p><code>pandas.Index.shape</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.shape\n&gt;&gt;&gt; I = pd.Index([1,2,3])\n&gt;&gt;&gt; f(I)\n(3,)\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexsize","title":"<code>pd.Index.size</code>","text":"<ul> <li> <p><code>pandas.Index.size</code> </p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.size\n&gt;&gt;&gt; I = pd.Index([1,7,8,6])\n&gt;&gt;&gt; f(I)\n4\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexempty","title":"<code>pd.Index.empty</code>","text":"<ul> <li> <p><code>pandas.Index.empty</code> </p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.empty\n&gt;&gt;&gt; I = pd.Index([\"A\", \"B\", \"C\"])\n&gt;&gt;&gt; f(I)\nFalse\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexis_monotonic_increasing","title":"<code>pd.Index.is_monotonic_increasing</code>","text":"<ul> <li> <p><code>pandas.Index.is_monotonic_increasing and pandas.Index.is_monotonic</code> </p> <p>Unsupported Index Types</p> <ul> <li>StringIndex</li> <li>BinaryIndex</li> <li>IntervalIndex</li> <li>CategoricalIndex</li> <li>PeriodIndex</li> <li>MultiIndex</li> </ul> <p>Example Usage <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.is_monotonic_increasing\n&gt;&gt;&gt; I = pd.Index([1,2,3])\n&gt;&gt;&gt; f(I)\nTrue\n&gt;&gt;&gt; @bodo.jit\n... def g(I):\n...   return I.is_monotonic\n&gt;&gt;&gt; I = pd.Index(1,2,3])\n&gt;&gt;&gt; g(I)\nTrue\n</code></pre></p> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexis_monotonic_decreasing","title":"<code>pd.Index.is_monotonic_decreasing</code>","text":"<ul> <li> <p><code>pandas.Index.is_monotonic_decreasing</code> </p> <p>Unsupported Index Types</p> <ul> <li>StringIndex</li> <li>BinaryIndex</li> <li>IntervalIndex</li> <li>CategoricalIndex</li> <li>PeriodIndex</li> <li>MultiIndex</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.is_monotonic_decreasing\n&gt;&gt;&gt; I = pd.Index([1,2,3])\n&gt;&gt;&gt; f(I)\nFalse\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexvalues","title":"<code>pd.Index.values</code>","text":"<ul> <li> <p><code>pandas.Index.values</code> </p> <p>Unsupported Index Types</p> <ul> <li>MultiIndex</li> <li>IntervalIndex</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.values\n&gt;&gt;&gt; I = pd.Index([1,2,3])\n&gt;&gt;&gt; f(I)\n[1 2 3]\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexnbytes","title":"<code>pd.Index.nbytes</code>","text":"<ul> <li> <p><code>pandas.Index.nbytes</code> </p> <p>Unsupported Index Types</p> <ul> <li>MultiIndex</li> <li>IntervalIndex</li> </ul> <p>Important</p> <p>Currently, Bodo upcasts all numeric index data types to 64 bitwidth.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.nbytes\n&gt;&gt;&gt; I1 = pd.Index([1,2,3,4,5,6], dtype = np.int64)\n&gt;&gt;&gt; f(I1)\n48\n&gt;&gt;&gt; I2 = pd.Index([1,2,3], dtype = np.int64)\n&gt;&gt;&gt; f(I2)\n24\n&gt;&gt;&gt; I3 = pd.Index([1,2,3], dtype = np.int32)\n&gt;&gt;&gt; f(I3)\n24\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexndim","title":"<code>pd.Index.ndim</code>","text":"<ul> <li> <p><code>pandas.Index.ndim</code> </p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.ndim\n&gt;&gt;&gt; I = pd.Index([1,2,3,4])\n&gt;&gt;&gt; f(I)\n1\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexnlevels","title":"<code>pd.Index.nlevels</code>","text":"<ul> <li> <p><code>pandas.Index.nlevels</code> </p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.nlevels\n&gt;&gt;&gt; I = pd.MultiIndex.from_arrays([[1, 2, 3, 4],[\"A\", \"A\", \"B\", \"B\"]])\n&gt;&gt;&gt; f(I)\n2\n</code></pre> </li> </ul> <p>#### <code>pd.Index.dtype</code></p> <ul> <li> <p><code>pandas.Index.dtype</code> </p> <p>Unsupported Index Types</p> <ul> <li>PeriodIndex</li> <li>IntervalIndex</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.dtype\n&gt;&gt;&gt; I = pd.Index([1,2,3,4])\n&gt;&gt;&gt; f(I)\ndtype('int64')\n</code></pre> </li> </ul> <p>#### <code>pd.Index.inferred_type</code></p> <ul> <li> <p><code>pandas.Index.inferred_type</code> </p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.dtype\n&gt;&gt;&gt; I = pd.Index([\"A\", \"E\", \"I\", \"O\", \"U\"])\n&gt;&gt;&gt; f(I)\n'string'\n</code></pre> </li> </ul> <p>#### <code>pd.Index.is_all_dates</code></p> <ul> <li> <p><code>pandas.Index.is_all_dates</code> </p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.is_all_dates\n&gt;&gt;&gt; I = pd.date_range(\"2018-01-01\", \"2018-01-06\")\n&gt;&gt;&gt; f(I)\nTrue\n</code></pre> </li> </ul> <p>#### <code>pd.Index.T</code></p> <ul> <li> <p><code>pandas.Index.T</code> </p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.T\n&gt;&gt;&gt; I = pd.Index([\"A\", \"E\", \"I\", \"O\", \"U\"])\n&gt;&gt;&gt; f(I)\nIndex([\"A\", \"E\", \"I\", \"O\", \"U\"], dtype='object')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#type-information","title":"Type information","text":""},{"location":"api_docs/pandas/indexapi/#pdindexis_numeric","title":"<code>pd.Index.is_numeric</code>","text":"<ul> <li> <p><code>pandas.Index.is_numeric()</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.is_numeric()\n&gt;&gt;&gt; I = pd.Index([1, 2, 3])\n&gt;&gt;&gt; f(I)\nTrue\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexis_integer","title":"<code>pd.Index.is_integer</code>","text":"<ul> <li> <p><code>pandas.Index.is_integer()</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.is_integer()\n&gt;&gt;&gt; I = pd.Index([1, 2, 3])\n&gt;&gt;&gt; f(I)\nTrue\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexis_floating","title":"<code>pd.Index.is_floating</code>","text":"<ul> <li> <p><code>pandas.Index.is_floating()</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.is_floating()\n&gt;&gt;&gt; I = pd.Index([1, 2, 3])\n&gt;&gt;&gt; f(I)\nFalse\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexis_boolean","title":"<code>pd.Index.is_boolean</code>","text":"<ul> <li> <p><code>pandas.Index.is_boolean()</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.is_boolean()\n&gt;&gt;&gt; I = pd.Index([1, 2, 3])\n&gt;&gt;&gt; f(I)\nFalse\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexis_categorical","title":"<code>pd.Index.is_categorical</code>","text":"<ul> <li> <p><code>pandas.Index.is_categorical()</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.is_categorical()\n&gt;&gt;&gt; I = pd.Index([1, 2, 3])\n&gt;&gt;&gt; f(I)\nFalse\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexis_interval","title":"<code>pd.Index.is_interval</code>","text":"<ul> <li> <p><code>pandas.Index.is_interval()</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.is_interval()\n&gt;&gt;&gt; I = pd.Index([1, 2, 3])\n&gt;&gt;&gt; f(I)\nFalse\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexis_object","title":"<code>pd.Index.is_object</code>","text":"<ul> <li> <p><code>pandas.Index.is_object()</code> </p> <p>Important</p> <p>Currently, Bodo diverges from the Pandas API for Indices of boolean values. Bodo always returns True, whereas Pandas returns False if the index was constructed from a pd.array of booleans.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.is_object()\n&gt;&gt;&gt; I = pd.Index([1, 2, 3])\n&gt;&gt;&gt; f(I)\nFalse\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#modifications-and-computations","title":"Modifications and computations","text":""},{"location":"api_docs/pandas/indexapi/#pdindexcopy","title":"<code>pd.Index.copy</code>","text":"<ul> <li> <p><code>pandas.Index.copy(name=None, deep=False, dtype=None, names=None)</code> Unsupported Index Types</p> <ul> <li>MultiIndex</li> <li>IntervalIndex</li> </ul> <p>Supported arguments</p> <ul> <li><code>name</code></li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.copy(name=\"new_name\")\n&gt;&gt;&gt; I = pd.Index([1,2,3], name = \"origial_name\")\n&gt;&gt;&gt; f(I)\nInt64Index([1, 2, 3], dtype='int64', name='new_name')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexget_loc","title":"<code>pd.Index.get_loc</code>","text":"<ul> <li> <p><code>pandas.Index.get_loc(key, method=None, tolerance=None)</code> </p> <p>Note</p> <p>Should be about as fast as standard python, maybe slightly slower.</p> <p>Unsupported Index Types</p> <ul> <li>CategoricalIndex</li> <li>MultiIndex</li> <li>IntervalIndex</li> </ul> <p>Supported Arguments</p> <ul> <li><code>key</code>: must be of same type as the index</li> </ul> <p>Important</p> <ul> <li>Only works for index with unique values (scalar return).</li> <li>Only works with replicated Index</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.get_loc(2)\n&gt;&gt;&gt; I = pd.Index([1,2,3])\n&gt;&gt;&gt; f(I)\n1\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindextake","title":"<code>pd.Index.take</code>","text":"<ul> <li> <p><code>pandas.Index.take(indices, axis=0, allow_fill=True, fill_value=None, **kwargs)</code> </p> <p>Supported Arguments</p> <ul> <li><code>indices</code>:  can be boolean Array like, integer Array like, or slice</li> </ul> <p>Unsupported Index Types</p> <ul> <li>MultiIndex</li> <li>IntervalIndex</li> </ul> <p>Important</p> <p>Bodo Does Not support <code>kwargs</code>, even for compatibility.</p> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexmin","title":"<code>pd.Index.min</code>","text":"<ul> <li> <p><code>pandas.Index.min(axis=None, skipna=True, args, *kwargs)</code> </p> <p>Supported Arguments: None</p> <p>Supported Index Types</p> <ul> <li>NumericIndex</li> <li>RangeIndex</li> <li>CategoricalIndex</li> <li>TimedeltaIndex</li> <li>DatetimeIndex</li> </ul> <p>Important</p> <ul> <li>Bodo Does Not support <code>args</code> and <code>kwargs</code>, even for compatibility.</li> <li>For DatetimeIndex, will throw an error if all values in the index are null.</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.min()\n&gt;&gt;&gt; I = pd.Index(pd.date_range(start=\"2018-04-24\", end=\"2018-04-25\", periods=5))\n&gt;&gt;&gt; f(I)\n2018-04-24 00:00:00\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexmax","title":"<code>pd.Index.max</code>","text":"<ul> <li> <p><code>pandas.Index.max(axis=None, skipna=True, args, *kwargs)</code> </p> <p>Supported Arguments: None</p> <p>Supported Index Types</p> <ul> <li>NumericIndex</li> <li>RangeIndex</li> <li>CategoricalIndex</li> <li>TimedeltaIndex</li> <li>DatetimeIndex</li> </ul> <p>Important</p> <ul> <li>Bodo Does Not support <code>args</code> and <code>kwargs</code>, even for compatibility.</li> <li>For DatetimeIndex, will throw an error if all values in the index are null.</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.min()\n&gt;&gt;&gt; I = pd.Index(pd.date_range(start=\"2018-04-24\", end=\"2018-04-25\", periods=5))\n&gt;&gt;&gt; f(I)\n2018-04-25 00:00:00\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexrename","title":"<code>pd.Index.rename</code>","text":"<ul> <li> <p><code>pandas.Index.rename(name, inplace=False)</code> </p> <p>Supported Arguments</p> <ul> <li><code>name</code>: label or list of labels</li> </ul> <p>Unsupported Index Types</p> <ul> <li>MultiIndex</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I, name):\n...   return I.rename(name)\n&gt;&gt;&gt; I = pd.Index([\"a\", \"b\", \"c\"])\n&gt;&gt;&gt; f(I, \"new_name\")\nIndex(['a', 'b', 'c'], dtype='object', name='new_name')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexduplicated","title":"<code>pd.Index.duplicated</code>","text":"<ul> <li> <p><code>pandas.Index.duplicated(keep='first')</code> Supported Arguments: None</p> <p>Example Usage </p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.duplicated()\n&gt;&gt;&gt; idx = pd.Index(['a', 'b', None, 'a', 'c', None, 'd', 'b'])\n&gt;&gt;&gt; f(idx)\narray([False, False, False,  True, False,  True, False,  True])\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexdrop_duplicates","title":"<code>pd.Index.drop_duplicates</code>","text":"<ul> <li> <p><code>pandas.Index.drop_duplicates(keep='first')</code> Supported Arguments: None</p> <p>Unsupported Index Types</p> <ul> <li>MultiIndex</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.drop_duplicates()\n&gt;&gt;&gt; I = pd.Index([\"a\", \"b\", \"c\", \"a\", \"b\", \"c\"])\n&gt;&gt;&gt; f(I)\nIndex(['a', 'b', 'c'], dtype='object')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexisin","title":"<code>pd.Index.isin</code>","text":"<ul> <li> <p><code>pandas.Index.isin(values)</code> Supported Arguments</p> <ul> <li><code>values</code>: list-like or array-like of values</li> </ul> <p>Unsupported Index Types</p> <ul> <li>MultiIndex</li> <li>IntervalIndex</li> <li>PeriodIndex</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.isin([0, 2, 4])\n&gt;&gt;&gt; I = pd.Index([2, 4, 3, 4, 0, 3, 3, 5])\n&gt;&gt;&gt; f(I)\narray([ True,  True, False,  True,  True, False, False, False])\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexunique","title":"<code>pd.Index.unique</code>","text":"<ul> <li> <p><code>pandas.Index.unique()</code> Unsupported Index Types</p> <ul> <li>IntervalIndex</li> <li>PeriodIndex</li> <li>MultiIndex</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.unique()\n&gt;&gt;&gt; I = pd.Index([1, 5, 2, 1, 0, 1, 5, 2, 1, 3])\n&gt;&gt;&gt; f(I)\nInt64Index([1, 5, 2, 0, 3], dtype='int64')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexnunique","title":"<code>pd.Index.nunique</code>","text":"<ul> <li> <p><code>pandas.Index.nunique(dropna=True)</code> Supported Arguments:</p> <ul> <li><code>dropna</code>: can be True or False</li> </ul> <p>Unsupported Index Types</p> <ul> <li>IntervalIndex</li> <li>MultiIndex</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.nunique()\n&gt;&gt;&gt; I = pd.Index([1, 5, 2, 1, 0, 1, 5, 2, 1])\n&gt;&gt;&gt; f(I)\n4\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexsort_values","title":"<code>pd.Index.sort_values</code>","text":"<ul> <li> <p><code>pandas.Index.sort_values(return_indexer=False, ascending=True, na_position=\"last\", key=None)</code> </p> <p>Supported Arguments:</p> <ul> <li><code>ascending</code>: can be True or False</li> <li><code>na_position</code>: can be \"first\" or \"last\"</li> </ul> <p>Unsupported Index Types</p> <ul> <li>IntervalIndex</li> <li>PeriodIndex</li> <li>MultiIndex</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.sort_values()\n&gt;&gt;&gt; I = pd.Index([0, -1, 1, -5, 8, -13, -2, 3])\n&gt;&gt;&gt; f(I)\nInt64Index([-13, -5, -2, -1, 0, 1, 3, 8], dtype='int64')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexargsort","title":"<code>pd.Index.argsort</code>","text":"<ul> <li> <p><code>pandas.Index.argsort(args, *kwargs)</code> </p> <p>Supported Arguments: None</p> <p>Unsupported Index Types</p> <ul> <li>IntervalIndex</li> <li>MultiIndex</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.argsort()\n&gt;&gt;&gt; I = pd.Index([\"A\", \"L\", \"P\", \"H\", \"A\"])\n&gt;&gt;&gt; f(I)\narray([0, 4, 3, 1, 2])\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexall","title":"<code>pd.Index.all</code>","text":"<ul> <li> <p><code>pandas.Index.all(args, kwargs)      ***Supported Arguments**: None <p>Supported Index Types</p> <ul> <li>NumericIndex (only Integers or Booleans)</li> <li>RangeIndex</li> <li>StringIndex</li> <li>BinaryIndex</li> </ul> <p>!!! important       Bodo diverges from the Pandas API for StringIndex and BinaryIndex by always returning a boolean instead of sometimes returning a string.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.all()\n&gt;&gt;&gt; I = pd.Index([1, 4, 9, 0, 3])\n&gt;&gt;&gt; f(I)\nFalse\n</code></pre>"},{"location":"api_docs/pandas/indexapi/#pdindexany","title":"<code>pd.Index.any</code>","text":"<ul> <li> <p><code>pandas.Index.any(args, kwargs)      ***Supported Arguments**: None <p>Supported Index Types</p> <ul> <li>NumericIndex (only Integers or Booleans)</li> <li>RangeIndex</li> <li>StringIndex</li> <li>BinaryIndex</li> </ul> <p>!!! important       Bodo diverges from the Pandas API for StringIndex and BinaryIndex by always returning a boolean instead of sometimes returning a string.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.any()\n&gt;&gt;&gt; I = pd.Index([1, 4, 9, 0, 3])\n&gt;&gt;&gt; f(I)\nTrue\n</code></pre>"},{"location":"api_docs/pandas/indexapi/#pdindexargmax","title":"<code>pd.Index.argmax</code>","text":"<ul> <li> <p><code>pandas.Index.argmax(axis=None, skipna=True, args, kwargs)      ***Supported Arguments**: None <p>Unsupported Index Types</p> <ul> <li>IntervalIndex</li> <li>MultiIndex</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.argmax()\n&gt;&gt;&gt; I = pd.Index([1, 4, 9, 0, 3])\n&gt;&gt;&gt; f(I)\n2\n</code></pre>"},{"location":"api_docs/pandas/indexapi/#pdindexargmin","title":"<code>pd.Index.argmin</code>","text":"<ul> <li> <p><code>pandas.Index.argmin(axis=None, skipna=True, args, kwargs)      ***Supported Arguments**: None <p>Unsupported Index Types</p> <ul> <li>IntervalIndex</li> <li>MultiIndex</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.argmin()\n&gt;&gt;&gt; I = pd.Index([1, 4, 9, 0, 3])\n&gt;&gt;&gt; f(I)\n3\n</code></pre>"},{"location":"api_docs/pandas/indexapi/#pdindexwhere","title":"<code>pd.Index.where</code>","text":"<ul> <li> <p><code>pandas.Index.where(cond, other=None)</code> Supported Arguments:</p> <ul> <li><code>cond</code>: can be a Series or 1-dim array of booleans</li> <li><code>other</code>: can be a scalar, non-categorical Series, 1-dim numpy array or StringArray with a matching type for the Index</li> </ul> <p>Unsupported Index Types</p> <ul> <li>IntervalIndex</li> <li>MultiIndex</li> </ul> <p>Important</p> <p>Only supported for CategoricalIndex if the elements of other are the same as (or a subset of) the categories of the CategoricalIndex.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I, C, O):\n...   return I.where(C, O)\n&gt;&gt;&gt; I = pd.Index([\"A\", \"B\", \"C\", \"D\", \"E\"])\n&gt;&gt;&gt; C = pd.array([True, False, True, True, False])\n&gt;&gt;&gt; O = pd.Series([\"a\", \"e\", \"i\", \"o\", \"u\")\n&gt;&gt;&gt; f(I, C, O)\nIndex(['A', 'e', 'C', 'D', 'u'], dtype='object')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexputmask","title":"<code>pd.Index.putmask</code>","text":"<ul> <li> <p><code>pandas.Index.putmask(cond, other=None)</code> Supported Arguments:</p> <ul> <li><code>cond</code>: can be a Series or 1-dim array of booleans</li> <li><code>other</code>: can be a scalar, non-categorical Series, 1-dim numpy array or StringArray with a matching type for the Index</li> </ul> <p>Unsupported Index Types</p> <ul> <li>IntervalIndex</li> <li>MultiIndex</li> </ul> <p>Important</p> <p>Only supported for CategoricalIndex if the elements of other are the same as (or a subset of) the categories of the CategoricalIndex.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I, C, O):\n...   return I.putmask(C, O)\n&gt;&gt;&gt; I = pd.Index([\"A\", \"B\", \"C\", \"D\", \"E\"])\n&gt;&gt;&gt; C = pd.array([True, False, True, True, False])\n&gt;&gt;&gt; O = pd.Series([\"a\", \"e\", \"i\", \"o\", \"u\")\n&gt;&gt;&gt; f(I, C, O)\nIndex(['a', 'B', 'i', 'o', 'E'], dtype='object')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexunion","title":"<code>pd.Index.union</code>","text":"<ul> <li> <p><code>pandas.Index.union(other, sort=None)</code> Supported Arguments:</p> <ul> <li><code>other</code>: can be an Index, Series, or 1-dim numpy array with a matching type for the Index</li> </ul> <p>Supported Index Types</p> <ul> <li>NumericIndex</li> <li>StringIndex</li> <li>BinaryIndex</li> <li>RangeIndex</li> <li>DatetimeIndex</li> <li>TimedeltaIndex</li> </ul> <p>Important</p> <p>Bodo diverges from the Pandas API for Index.union() in several ways: duplicates are removed, the order of elements may be different, the shortcuts for returning the same Index are removed, and a NumericIndex is always returned instead of a RangeIndex.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit(distributed=[\"I\", \"J\"])\n... def f(I, J):\n...    return I.union(J)\n&gt;&gt;&gt; I = pd.Index([1, 2, 3, 4, 5])\n&gt;&gt;&gt; J = pd.Index([2, 4, 6, 8, 10, 12])\n&gt;&gt;&gt; f(I, J)\nInt64Index([1, 2, 3, 4, 5, 6, 8, 10, 12], dtype='int64')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexintersection","title":"<code>pd.Index.intersection</code>","text":"<ul> <li> <p><code>pandas.Index.intersection(other, sort=None)</code> Supported Arguments:</p> <ul> <li><code>other</code>: can be an Index, Series, or 1-dim numpy array with a matching type for the Index</li> </ul> <p>Supported Index Types</p> <ul> <li>NumericIndex</li> <li>StringIndex</li> <li>BinaryIndex</li> <li>RangeIndex</li> <li>DatetimeIndex</li> <li>TimedeltaIndex</li> </ul> <p>Important</p> <p>Bodo diverges from the Pandas API for Index.intersection() in several ways: the default is sort=None, and a NumericIndex is always returned instead of a RangeIndex.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit(distributed=[\"I\", \"J\"])\n... def f(I, J):\n...    return I.intersection(J)\n&gt;&gt;&gt; I = pd.Index([1, 2, 3, 4, 5])\n&gt;&gt;&gt; J = pd.Index([2, 4, 6, 8, 10, 12])\n&gt;&gt;&gt; f(I, J)\nInt64Index([2, 4], dtype='int64')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexdifference","title":"<code>pd.Index.difference</code>","text":"<ul> <li> <p><code>pandas.Index.difference(other, sort=None)</code> Supported Arguments:</p> <ul> <li><code>other</code>: can be an Index, Series, or 1-dim numpy array with a matching type for the Index</li> </ul> <p>Supported Index Types</p> <ul> <li>NumericIndex</li> <li>StringIndex</li> <li>BinaryIndex</li> <li>RangeIndex</li> <li>DatetimeIndex</li> <li>TimedeltaIndex</li> </ul> <p>Important</p> <p>Bodo diverges from the Pandas API for Index.difference() in several ways: the order of elements may be different and a NumericIndex is always returned instead of a RangeIndex.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit(distributed=[\"I\", \"J\"])\n... def f(I, J):\n...    return I.difference(J)\n&gt;&gt;&gt; I = pd.Index([1, 2, 3, 4, 5])\n&gt;&gt;&gt; J = pd.Index([2, 4, 6, 8, 10, 12])\n&gt;&gt;&gt; f(I, J)\nInt64Index([1, 3, 5], dtype='int64')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexsymmetric_difference","title":"<code>pd.Index.symmetric_difference</code>","text":"<ul> <li> <p><code>pandas.Index.symmetric_difference(other, sort=None)</code> Supported Arguments:</p> <ul> <li><code>other</code>: can be an Index, Series, or 1-dim numpy array with a matching type for the Index</li> </ul> <p>Supported Index Types</p> <ul> <li>NumericIndex</li> <li>StringIndex</li> <li>BinaryIndex</li> <li>RangeIndex</li> <li>DatetimeIndex</li> <li>TimedeltaIndex</li> </ul> <p>Important</p> <p>Bodo diverges from the Pandas API for Index.symmetric_difference() in several ways: the order of elements may be different and a NumericIndex is always returned instead of a RangeIndex.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit(distributed=[\"I\", \"J\"])\n... def f(I, J):\n...    return I.difference(J)\n&gt;&gt;&gt; I = pd.Index([1, 2, 3, 4, 5])\n&gt;&gt;&gt; J = pd.Index([2, 4, 6, 8, 10, 12])\n&gt;&gt;&gt; f(I, J)\nInt64Index([1, 3, 5, 6, 8, 10, 12], dtype='int64')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexrepeat","title":"<code>pd.Index.repeat</code>","text":"<ul> <li> <p><code>pandas.Index.repeat(repeats, axis=None)</code> Supported Arguments:</p> <ul> <li><code>repeat</code>: can be a non-negative integer or array of non-negative integers</li> </ul> <p>Supported Index Types</p> <ul> <li>NumericIndex</li> <li>StringIndex</li> <li>RangeIndex</li> <li>DatetimeIndex</li> <li>TimedeltaIndex</li> <li>CategoricalIndex</li> </ul> <p>Important</p> <p>If repeats is an integer array but its size is not the same as the length of I, undefined behavior may occur.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit(distributed=[\"I\"])\n... def f(I):\n...    return I.repeat(3)\n&gt;&gt;&gt; I = pd.Index([\"A\", \"B\", \"C\"])\n&gt;&gt;&gt; f(I)\nIndex(['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'], dtype='object')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#missing-values","title":"Missing values","text":""},{"location":"api_docs/pandas/indexapi/#pdindexisna","title":"<code>pd.Index.isna</code>","text":"<ul> <li> <p><code>pandas.Index.isna()</code> Unsupported Index Types</p> <ul> <li>MultiIndex</li> <li>IntervalIndex</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.isna()\n&gt;&gt;&gt; I = pd.Index([1,None,3])\n&gt;&gt;&gt; f(I)\n[False  True False]\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexisnull","title":"<code>pd.Index.isnull</code>","text":"<ul> <li> <p><code>pandas.Index.isnull()</code> Unsupported Index Types</p> <ul> <li>MultiIndex</li> <li>IntervalIndex</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.isnull()\n&gt;&gt;&gt; I = pd.Index([1,None,3])\n&gt;&gt;&gt; f(I)\n[False  True False]\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#conversion","title":"Conversion","text":""},{"location":"api_docs/pandas/indexapi/#pdindexmap","title":"<code>pd.Index.map</code>","text":"<ul> <li> <p><code>pandas.Index.map(mapper, na_action=None)</code> Unsupported Index Types</p> <ul> <li>MultiIndex</li> <li>IntervalIndex</li> </ul> <p>Supported Arguments</p> <ul> <li><code>mapper</code>: must be a function, function cannot return tuple type</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.map(lambda x: x + 2)\n&gt;&gt;&gt; I = pd.Index([1,None,3])\n&gt;&gt;&gt; f(I)\nFloat64Index([3.0, nan, 5.0], dtype='float64')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexto_series","title":"<code>pd.Index.to_series</code>","text":"<ul> <li> <p><code>pandas.Index.to_series(index=None, name=None)</code> Supported Arguments:</p> <ul> <li><code>index</code>: can be a Index, Series, 1-dim numpy array, list, or tuple</li> <li><code>name</code>: can be a string or int</li> </ul> <p>Unsupported Index Types</p> <ul> <li>IntervalIndex</li> <li>PeriodIndex</li> <li>MultiIndex</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I, J):\n...   return I.to_series(index=J)\n&gt;&gt;&gt; I = pd.Index([1, 4, 9, 0, 3])\n&gt;&gt;&gt; J = pd.Index([\"A\", \"B\", \"C\", \"D\", \"E\"])\n&gt;&gt;&gt; f(I, J)\nA    1\nB    4\nC    9\nD    0\nE    3\ndtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexto_frame","title":"<code>pd.Index.to_frame</code>","text":"<ul> <li> <p><code>pandas.Index.to_frame(index=True, name=None)</code> Supported Arguments:</p> <ul> <li><code>index</code>: can be a True or False</li> <li><code>name</code>: can be a string or int</li> </ul> <p>Unsupported Index Types</p> <ul> <li>IntervalIndex</li> <li>PeriodIndex</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.to_frame(index=False)\n&gt;&gt;&gt; I = pd.Index([\"A\", \"E\", \"I\", \"O\", \"U\", \"Y\"], name=\"vowels\")\n&gt;&gt;&gt; f(I)\nvowels\n0      A\n1      E\n2      I\n3      O\n4      U\n5      Y\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexto_numpy","title":"<code>pd.Index.to_numpy</code>","text":"<ul> <li> <p><code>pandas.Index.to_numpy(dtype=None, copy=True, na_value=None)</code> Supported Arguments:</p> <ul> <li><code>copy</code>: can be a True or False</li> </ul> <p>Unsupported Index Types</p> <ul> <li>PeriodIndex</li> <li>MultiIndex</li> </ul> <p>Important</p> <p>Sometimes Bodo returns a Pandas array instead of a np.ndarray. Cases include a NumericIndex of integers containing nulls, or a CategoricalIndex.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.numpy()\n&gt;&gt;&gt; I = pd.Index([1, 9, -1, 3, 0, 1, 6])\n&gt;&gt;&gt; f(I)\n[ 1  9 -1  3  0  1  6]\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindexto_list","title":"<code>pd.Index.to_list</code>","text":"<ul> <li> <p><code>pandas.Index.to_list()</code> Unsupported Index Types</p> <ul> <li>PeriodIndex</li> <li>IntervalIndex</li> <li>MultiIndex</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.to_list()\n&gt;&gt;&gt; I = pd.RangeIndex(5, -1, -1)\n&gt;&gt;&gt; f(I)\n[5, 4, 3, 2, 1, 0]\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdindextolist","title":"<code>pd.Index.tolist</code>","text":"<ul> <li> <p><code>pandas.Index.tolist()</code> Unsupported Index Types</p> <ul> <li>PeriodIndex</li> <li>IntervalIndex</li> <li>DatetimeIndex</li> <li>TimedeltaIndex</li> <li>MultiIndex</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.tolist()\n&gt;&gt;&gt; I = pd.RangeIndex(5, -1, -1)\n&gt;&gt;&gt; f(I)\n[5, 4, 3, 2, 1, 0]\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#numeric-index","title":"Numeric Index","text":"<p>Numeric index objects <code>RangeIndex</code>, <code>Int64Index</code>, <code>UInt64Index</code> and <code>Float64Index</code> are supported as index to dataframes and series. Constructing them in Bodo functions, passing them to Bodo functions (unboxing), and returning them from Bodo functions (boxing) are also supported.</p>"},{"location":"api_docs/pandas/indexapi/#pdrangeindex","title":"<code>pd.RangeIndex</code>","text":"<ul> <li> <p><code>pandas.RangeIndex(start=None, stop=None, step=None, dtype=None, copy=False, name=None)</code> </p> <p>Supported Arguments</p> <ul> <li><code>start</code>: integer</li> <li><code>stop</code>: integer</li> <li><code>step</code>: integer</li> <li><code>name</code>: String</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   return pd.RangeIndex(0, 10, 2)\n&gt;&gt;&gt; f(I)\nRangeIndex(start=0, stop=10, step=2)\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdint64index","title":"<code>pd.Int64Index</code>","text":"<ul> <li><code>pandas.Int64Index(data=None, dtype=None, copy=False, name=None)</code> Example Usage <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n... return pd.Int64Index(np.arange(3))\n&gt;&gt;&gt; f()\nInt64Index([0, 1, 2], dtype='int64')\n</code></pre></li> </ul>"},{"location":"api_docs/pandas/indexapi/#pduint64index","title":"<code>pd.UInt64Index</code>","text":"<ul> <li><code>pandas.UInt64Index(data=None, dtype=None, copy=False, name=None)</code> Example Usage <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n... return pd.UInt64Index([1,2,3])\n&gt;&gt;&gt; f()\nUInt64Index([0, 1, 2], dtype='uint64')\n</code></pre></li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdfloat64index","title":"<code>pd.Float64Index</code>","text":"<ul> <li> <p><code>pandas.Float64Index(data=None, dtype=None, copy=False, name=None)</code> Supported Arguments</p> <ul> <li><code>data</code>: list or array</li> <li><code>copy</code>: Boolean</li> <li><code>name</code>: String</li> </ul> <p>Example Usage <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n... return pd.Float64Index(np.arange(3))\n&gt;&gt;&gt; f()\nFloat64Index([0.0, 1.0, 2.0], dtype='float64')\n</code></pre></p> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#datetimeindex","title":"DatetimeIndex","text":"<p><code>DatetimeIndex</code> objects are supported. They can be constructed, boxed/unboxed, and set as index to dataframes and series.</p>"},{"location":"api_docs/pandas/indexapi/#pddatetimeindex","title":"<code>pd.DateTimeIndex</code>","text":"<ul> <li> <p><code>pandas.DatetimeIndex</code> </p> <p>Supported Arguments</p> <ul> <li><code>data</code>: array-like of datetime64, Integer, or strings</li> </ul> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#date-fields","title":"Date fields","text":""},{"location":"api_docs/pandas/indexapi/#pddatetimeindexyear","title":"<code>pd.DateTimeIndex.year</code>","text":"<ul> <li><code>pandas.DatetimeIndex.year</code> Example Usage <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.year\n&gt;&gt;&gt; I = pd.DatetimeIndex(pd.date_range(start=\"2019-12-31 02:32:45\", end=\"2020-01-01 19:12:05\", periods=5))\n&gt;&gt;&gt; f(I)\nInt64Index([2019, 2019, 2019, 2020, 2020], dtype='int64')\n</code></pre></li> </ul>"},{"location":"api_docs/pandas/indexapi/#pddatetimeindexmonth","title":"<code>pd.DateTimeIndex.month</code>","text":"<ul> <li><code>pandas.DatetimeIndex.month</code> Example Usage <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.month\n&gt;&gt;&gt; I = pd.DatetimeIndex(pd.date_range(start=\"2019-12-31 02:32:45\", end=\"2020-01-01 19:12:05\", periods=5))\n&gt;&gt;&gt; f(I)\nInt64Index([12, 12, 12, 1, 1], dtype='int64')\n</code></pre></li> </ul>"},{"location":"api_docs/pandas/indexapi/#pddatetimeindexday","title":"<code>pd.DateTimeIndex.day</code>","text":"<ul> <li><code>pandas.DatetimeIndex.day</code> Example Usage <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.day\n&gt;&gt;&gt; I = pd.DatetimeIndex(pd.date_range(start=\"2019-12-31 02:32:45\", end=\"2020-01-01 19:12:05\", periods=5))\n&gt;&gt;&gt; f(I)\nInt64Index([31, 31, 31, 1, 1], dtype='int64')\n</code></pre></li> </ul>"},{"location":"api_docs/pandas/indexapi/#pddatetimeindexhour","title":"<code>pd.DateTimeIndex.hour</code>","text":"<ul> <li><code>pandas.DatetimeIndex.hour</code> Example Usage <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.hour\n&gt;&gt;&gt; I = pd.DatetimeIndex(pd.date_range(start=\"2019-12-31 02:32:45\", end=\"2020-01-01 19:12:05\", periods=5))\n&gt;&gt;&gt; f(I)\nInt64Index([2, 12, 22, 9, 19], dtype='int64')\n</code></pre></li> </ul>"},{"location":"api_docs/pandas/indexapi/#pddatetimeindexminute","title":"<code>pd.DateTimeIndex.minute</code>","text":"<ul> <li> <p><code>pandas.DatetimeIndex.minute</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.minute\n&gt;&gt;&gt; I = pd.DatetimeIndex(pd.date_range(start=\"2019-12-31 02:32:45\", end=\"2020-01-01 19:12:05\", periods=5))\n&gt;&gt;&gt; f(I)\nInt64Index([32, 42, 52, 2, 12], dtype='int64')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pddatetimeindexsecond","title":"<code>pd.DateTimeIndex.second</code>","text":"<ul> <li> <p><code>pandas.DatetimeIndex.second</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.second\n&gt;&gt;&gt; I = pd.DatetimeIndex(pd.date_range(start=\"2019-12-31 02:32:45\", end=\"2020-01-01 19:12:05\", periods=5))\n&gt;&gt;&gt; f(I)\nInt64Index([45, 35, 25, 15, 5], dtype='int64')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pddatetimeindexmicrosecond","title":"<code>pd.DateTimeIndex.microsecond</code>","text":"<ul> <li> <p><code>pandas.DatetimeIndex.microsecond</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.microsecond\n&gt;&gt;&gt; I = pd.DatetimeIndex(pd.date_range(start=\"2019-12-31 01:01:01\", end=\"2019-12-31 01:01:02\", periods=5))\n&gt;&gt;&gt; f(I)\nInt64Index([0, 250000, 500000, 750000, 0], dtype='int64')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pddatetimeindexnanosecond","title":"<code>pd.DateTimeIndex.nanosecond</code>","text":"<ul> <li> <p><code>pandas.DatetimeIndex.nanosecond</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.nanosecond\n&gt;&gt;&gt; I = pd.DatetimeIndex(pd.date_range(start=\"2019-12-31 01:01:01.0000001\", end=\"2019-12-31 01:01:01.0000002\", periods=5))\n&gt;&gt;&gt; f(I)\nInt64Index([100, 125, 150, 175, 200], dtype='int64')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pddatetimeindexdate","title":"<code>pd.DateTimeIndex.date</code>","text":"<ul> <li> <p><code>pandas.DatetimeIndex.date</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.date\n&gt;&gt;&gt; I = pd.DatetimeIndex(pd.date_range(start=\"2019-12-31 02:32:45\", end=\"2020-01-01 19:12:05\", periods=5))\n&gt;&gt;&gt; f(I)\n[datetime.date(2019, 12, 31) datetime.date(2019, 12, 31) datetime.date(2019, 12, 31) datetime.date(2020, 1, 1) datetime.date(2020, 1, 1)]\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pddatetimeindexdayofyear","title":"<code>pd.DateTimeIndex.dayofyear</code>","text":"<ul> <li> <p><code>pandas.DatetimeIndex.dayofyear</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.dayofyear\n&gt;&gt;&gt; I = pd.DatetimeIndex(pd.date_range(start=\"2019-12-31 02:32:45\", end=\"2020-01-01 19:12:05\", periods=5))\n&gt;&gt;&gt; f(I)\nInt64Index([365, 365, 365, 1, 1], dtype='int64')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pddatetimeindexday_of_year","title":"<code>pd.DateTimeIndex.day_of_year</code>","text":"<ul> <li> <p><code>pandas.DatetimeIndex.day_of_year</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.day_of_year\n&gt;&gt;&gt; I = pd.DatetimeIndex(pd.date_range(start=\"2019-12-31 02:32:45\", end=\"2020-01-01 19:12:05\", periods=5))\n&gt;&gt;&gt; f(I)\nInt64Index([365, 365, 365, 1, 1], dtype='int64')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pddatetimeindexdayofweek","title":"<code>pd.DateTimeIndex.dayofweek</code>","text":"<ul> <li> <p><code>pandas.DatetimeIndex.dayofweek</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.dayofweek\n&gt;&gt;&gt; I = pd.DatetimeIndex(pd.date_range(start=\"2019-12-31 02:32:45\", end=\"2020-01-01 19:12:05\", periods=5))\n&gt;&gt;&gt; f(I)\nInt64Index([1, 1, 1, 2, 2], dtype='int64')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pddatetimeindexday_of_week","title":"<code>pd.DateTimeIndex.day_of_week</code>","text":"<ul> <li> <p><code>pandas.DatetimeIndex.day_of_week</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.day_of_week\n&gt;&gt;&gt; I = pd.DatetimeIndex(pd.date_range(start=\"2019-12-31 02:32:45\", end=\"2020-01-01 19:12:05\", periods=5))\n&gt;&gt;&gt; f(I)\nInt64Index([1, 1, 1, 2, 2], dtype='int64')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pddatetimeindexis_leap_year","title":"<code>pd.DateTimeIndex.is_leap_year</code>","text":"<ul> <li> <p><code>pandas.DatetimeIndex.is_leap_year</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.is_leap_year\n&gt;&gt;&gt; I = pd.DatetimeIndex(pd.date_range(start=\"2019-12-31 02:32:45\", end=\"2020-01-01 19:12:05\", periods=5))\n&gt;&gt;&gt; f(I)\n[Flase False False True True]\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pddatetimeindexis_month_start","title":"<code>pd.DateTimeIndex.is_month_start</code>","text":"<ul> <li> <p><code>pandas.DatetimeIndex.is_month_start</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.is_month_start\n&gt;&gt;&gt; I = pd.DatetimeIndex(pd.date_range(start=\"2019-12-31 02:32:45\", end=\"2020-01-01 19:12:05\", periods=5))\n&gt;&gt;&gt; f(I)\nInt64Index([0, 0, 0, 1, 1], dtype='int64')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pddatetimeindexis_month_end","title":"<code>pd.DateTimeIndex.is_month_end</code>","text":"<ul> <li> <p><code>pandas.DatetimeIndex.is_month_end</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.is_month_end\n&gt;&gt;&gt; I = pd.DatetimeIndex(pd.date_range(start=\"2019-12-31 02:32:45\", end=\"2020-01-01 19:12:05\", periods=5))\n&gt;&gt;&gt; f(I)\nInt64Index([1, 1, 1, 0, 0], dtype='int64')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pddatetimeindexis_quarter_start","title":"<code>pd.DateTimeIndex.is_quarter_start</code>","text":"<ul> <li> <p><code>pandas.DatetimeIndex.is_quarter_start</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.is_quarter_start\n&gt;&gt;&gt; I = pd.DatetimeIndex(pd.date_range(start=\"2019-12-31 02:32:45\", end=\"2020-01-01 19:12:05\", periods=5))\n&gt;&gt;&gt; f(I)\nInt64Index([0, 0, 0, 1, 1], dtype='int64')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pddatetimeindexis_quarter_end","title":"<code>pd.DateTimeIndex.is_quarter_end</code>","text":"<ul> <li> <p><code>pandas.DatetimeIndex.is_quarter_end</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.is_quarter_end\n&gt;&gt;&gt; I = pd.DatetimeIndex(pd.date_range(start=\"2019-12-31 02:32:45\", end=\"2020-01-01 19:12:05\", periods=5))\n&gt;&gt;&gt; f(I)\nInt64Index([1, 1, 1, 0, 0], dtype='int64')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pddatetimeindexis_year_start","title":"<code>pd.DateTimeIndex.is_year_start</code>","text":"<ul> <li> <p><code>pandas.DatetimeIndex.is_year_start</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.is_year_start\n&gt;&gt;&gt; I = pd.DatetimeIndex(pd.date_range(start=\"2019-12-31 02:32:45\", end=\"2020-01-01 19:12:05\", periods=5))\n&gt;&gt;&gt; f(I)\nInt64Index([0, 0, 0, 1, 1], dtype='int64')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pddatetimeindexis_year_end","title":"<code>pd.DateTimeIndex.is_year_end</code>","text":"<ul> <li> <p><code>pandas.DatetimeIndex.is_year_end</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.is_year_end\n\n&gt;&gt;&gt; I = pd.DatetimeIndex(pd.date_range(start=\"2019-12-31 02:32:45\", end=\"2020-01-01 19:12:05\", periods=5))\n&gt;&gt;&gt; f(I)\nInt64Index([1, 1, 1, 0, 0], dtype='int64')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pddatetimeindexweek","title":"<code>pd.DateTimeIndex.week</code>","text":"<ul> <li> <p><code>pandas.DatetimeIndex.week</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.week\n&gt;&gt;&gt; I = pd.DatetimeIndex(pd.date_range(start=\"2019-12-31 02:32:45\", end=\"2020-01-01 19:12:05\", periods=5))\n&gt;&gt;&gt; f(I)\nInt64Index([1, 1, 1, 1, 1], dtype='int64')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pddatetimeindexweekday","title":"<code>pd.DateTimeIndex.weekday</code>","text":"<ul> <li> <p><code>pandas.DatetimeIndex.weekday</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.weekday\n&gt;&gt;&gt; I = pd.DatetimeIndex(pd.date_range(start=\"2019-12-31 02:32:45\", end=\"2020-01-01 19:12:05\", periods=5))\n&gt;&gt;&gt; f(I)\nInt64Index([1, 1, 1, 2, 2], dtype='int64')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pddatetimeindexweekofyear","title":"<code>pd.DateTimeIndex.weekofyear</code>","text":"<ul> <li> <p><code>pandas.DatetimeIndex.weekofyear</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.weekofyear\n&gt;&gt;&gt; I = pd.DatetimeIndex(pd.date_range(start=\"2019-12-31 02:32:45\", end=\"2020-01-01 19:12:05\", periods=5))\n&gt;&gt;&gt; f(I)\nInt64Index([1, 1, 1, 1,1], dtype='int64')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pddatetimeindexquarter","title":"<code>pd.DateTimeIndex.quarter</code>","text":"<ul> <li> <p><code>pandas.DatetimeIndex.quarter</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.quarter\n&gt;&gt;&gt; I = pd.DatetimeIndex(pd.date_range(start=\"2019-12-31 02:32:45\", end=\"2020-01-01 19:12:05\", periods=5))\n&gt;&gt;&gt; f(I)\nInt64Index([4, 4, 4, 1, 1], dtype='int64')\n</code></pre> </li> </ul> <p>Subtraction of <code>Timestamp</code> from <code>DatetimeIndex</code> and vice versa is supported.</p> <p>Comparison operators <code>==</code>, <code>!=</code>, <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&lt;</code> between <code>DatetimeIndex</code> and a string of datetime are supported.</p>"},{"location":"api_docs/pandas/indexapi/#timedeltaindex","title":"TimedeltaIndex","text":"<p><code>TimedeltaIndex</code> objects are supported. They can be constructed, boxed/unboxed, and set as index to dataframes and series.</p>"},{"location":"api_docs/pandas/indexapi/#pdtimedeltaindex","title":"<code>pd.TimedeltaIndex</code>","text":"<ul> <li> <p><code>pandas.TimedeltaIndex(data=None, unit=None, freq=NoDefault.no_default, closed=None, dtype=dtype('&lt;m8[ns]'), copy=False, name=None)</code> Supported Arguments</p> <p>-<code>data</code>:  must be array-like of timedelta64ns or Ingetger.</p> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdtimedeltaindexdays","title":"<code>pd.TimedeltaIndex.days</code>","text":"<ul> <li> <p><code>pandas.TimedeltaIndex.days</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.days\n&gt;&gt;&gt; I = pd.TimedeltaIndex([pd.Timedelta(3, unit=\"D\"))])\n&gt;&gt;&gt; f(I)\nInt64Index([3], dtype='int64')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdtimedeltaindexseconds","title":"<code>pd.TimedeltaIndex.seconds</code>","text":"<ul> <li> <p><code>pandas.TimedeltaIndex.seconds</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.seconds\n&gt;&gt;&gt; I = pd.TimedeltaIndex([pd.Timedelta(-2, unit=\"S\"))])\n&gt;&gt;&gt; f(I)\nInt64Index([-2], dtype='int64')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdtimedeltaindexmicroseconds","title":"<code>pd.TimedeltaIndex.microseconds</code>","text":"<ul> <li> <p><code>pandas.TimedeltaIndex.microseconds</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.microseconds\n&gt;&gt;&gt; I = pd.TimedeltaIndex([pd.Timedelta(11, unit=\"micros\"))])\n&gt;&gt;&gt; f(I)\nInt64Index([11], dtype='int64')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#pdtimedeltaindexnanoseconds","title":"<code>pd.TimedeltaIndex.nanoseconds</code>","text":"<ul> <li> <p><code>pandas.TimedeltaIndex.nanoseconds</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   return I.nanoseconds\n&gt;&gt;&gt; I = pd.TimedeltaIndex([pd.Timedelta(7, unit=\"nanos\"))])\n&gt;&gt;&gt; f(I)\nInt64Index([7], dtype='int64')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/indexapi/#periodindex","title":"PeriodIndex","text":"<p><code>PeriodIndex</code> objects can be boxed/unboxed and set as index to dataframes and series. Operations on them will be supported in upcoming releases.</p>"},{"location":"api_docs/pandas/indexapi/#binaryindex","title":"BinaryIndex","text":"<p><code>BinaryIndex</code> objects can be boxed/unboxed and set as index to dataframes and series. Operations on them will be supported in upcoming releases.</p>"},{"location":"api_docs/pandas/indexapi/#multiindex","title":"MultiIndex","text":""},{"location":"api_docs/pandas/indexapi/#pdmultiindexfrom_product","title":"<code>pd.MultiIndex.from_product</code>","text":"<ul> <li><code>pandas.MultiIndex.from_product </code>     (iterables and names supported as tuples, no parallel support yet)</li> </ul>"},{"location":"api_docs/pandas/io/","title":"Input/Output","text":"<p>See more in File IO, such as S3 and HDFS configuration requirements.</p>"},{"location":"api_docs/pandas/io/#pdread_csv","title":"pd.read_csv","text":"<ul> <li><code>pandas.read_csv</code> <ul> <li>example usage and more system specific instructions</li> <li><code>filepath_or_buffer</code> should be a string and is required. It     could be pointing to a single CSV file, or a directory     containing multiple partitioned CSV files (must have <code>csv</code> file     extension inside directory).</li> <li>Arguments <code>sep</code>, <code>delimiter</code>, <code>header</code>, <code>names</code>, <code>index_col</code>,     <code>usecols</code>, <code>dtype</code>, <code>nrows</code>, <code>skiprows</code>, <code>chunksize</code>,     <code>parse_dates</code>, and <code>low_memory</code> are supported.</li> <li>Argument <code>anon</code> of <code>storage_options</code> is supported for S3     filepaths.</li> <li>Either <code>names</code> and <code>dtype</code> arguments should be provided to     enable type inference, or <code>filepath_or_buffer</code> should be     inferrable as a constant string. This is required so bodo can     infer the types at compile time, see compile time constants</li> <li><code>names</code>, <code>usecols</code>, <code>parse_dates</code> should be constant lists.</li> <li><code>dtype</code> should be a constant dictionary of strings and types.</li> <li><code>skiprows</code> must be an integer or list of integers and if it is     not a constant, <code>names</code> must be provided to enable type     inference.</li> <li><code>chunksize</code> is supported for uncompressed files only.</li> <li><code>low_memory</code> internally process file in chunks while parsing. In     Bodo this is set to <code>False</code> by default.</li> <li>When set to <code>True</code>, Bodo parses file in chunks but     like Pandas the entire file is read into a single DataFrame     regardless.</li> <li>If you want to load data in chunks, use the <code>chunksize</code>     argument.</li> <li>When a CSV file is read in parallel (distributed mode) and each     process reads only a portion of the file, reading columns that     contain line breaks is not supported.</li> <li> <p><code>_bodo_read_as_dict</code> is a Bodo specific argument which forces      the specified string columns to be read with dictionary-encoding.     Dictionary-encoding stores data in memory in an efficient     manner and is most effective when the column has many repeated values.     Read more about dictionary-encoded layout     here.</p> <p>For example: <pre><code>@bodo.jit()\ndef impl(f):\ndf = pd.read_csv(f, _bodo_read_as_dict=[\"A\", \"B\", \"C\"])\nreturn df\n</code></pre></p> </li> </ul> </li> </ul>"},{"location":"api_docs/pandas/io/#pdread_excel","title":"pd.read_excel","text":"<ul> <li><code>pandas.read_excel</code> <ul> <li>output dataframe cannot be parallelized automatically yet.</li> <li>only arguments <code>io</code>, <code>sheet_name</code>, <code>header</code>, <code>names</code>, <code>comment</code>,     <code>dtype</code>, <code>skiprows</code>, <code>parse_dates</code> are supported.</li> <li><code>io</code> should be a string and is required.</li> <li>Either <code>names</code> and <code>dtype</code> arguments should be provided to     enable type inference, or <code>io</code> should be inferrable as a     constant string. This is required so bodo can infer the types at     compile time, see compile time constants</li> <li><code>sheet_name</code>, <code>header</code>, <code>comment</code>, and <code>skiprows</code> should be     constant if provided.</li> <li><code>names</code> and <code>parse_dates</code> should be constant lists if provided.</li> <li><code>dtype</code> should be a constant dictionary of strings and types if     provided.</li> </ul> </li> </ul>"},{"location":"api_docs/pandas/io/#pdread_sql","title":"pd.read_sql","text":"<ul> <li><code>pandas.read_sql</code> <ul> <li>example usage and more system specific instructions</li> <li>Argument <code>sql</code> is supported but only as a string form.     SQLalchemy <code>Selectable</code> is not supported. There is     no restriction on the form of the sql request.</li> <li>Argument <code>con</code> is supported but only as a string form.     SQLalchemy <code>connectable</code> is not supported.</li> <li>Argument <code>index_col</code> is supported.</li> <li>Arguments <code>chunksize</code>, <code>column</code>, <code>coerce_float</code>, <code>params</code> are     not supported.</li> </ul> </li> </ul>"},{"location":"api_docs/pandas/io/#pdread_sql_table","title":"pd.read_sql_table","text":"<ul> <li><code>pandas.read_sql_table</code> <ul> <li>This API only supports reading Iceberg tables at the moment.</li> <li>See Iceberg Section for example usage and more system specific instructions.</li> <li>Argument <code>table_name</code> is supported and must be the name of an Iceberg Table.</li> <li>Argument <code>con</code> is supported but only as a string form in a URL format.     SQLalchemy <code>connectable</code> is not supported.     It should be the absolute path to a Iceberg warehouse.     If using a Hadoop-based directory catalog, it should start with the URL scheme <code>iceberg://</code>.     If using a Thrift Hive catalog, it should start with the URL scheme <code>iceberg+thrift://</code></li> <li>Argument <code>schema</code> is supported and currently required for Iceberg tables. It must be the name     of the database schema. For Iceberg Tables, this is the directory name     in the warehouse (specified by <code>con</code>) where your table exists.</li> <li>Arguments <code>index_col</code>, <code>coerce_float</code>, <code>parse_dates</code>, <code>columns</code> and <code>chunksize</code> are     not supported.</li> </ul> </li> </ul>"},{"location":"api_docs/pandas/io/#pdread_parquet","title":"pd.read_parquet","text":"<ul> <li> <p><code>pandas.read_parquet</code> </p> <ul> <li>example usage and more system specific instructions</li> <li>Arguments <code>path</code> and <code>columns</code> are supported. <code>columns</code> should     be a constant list of strings if provided.     <code>path</code> can be a string or list. If string, must be a path to a file     or a directory, or a glob string. If a list, must contain paths     to parquet files (not directories) or glob strings.</li> <li>Argument <code>anon</code> of <code>storage_options</code> is supported for S3     filepaths.</li> <li> <p>If <code>path</code> can be inferred as a constant (e.g. it is a function     argument), Bodo finds the schema from file at compilation time.     Otherwise, schema should be provided using the numba syntax.</p> <p>For example: <pre><code>@bodo.jit(locals={'df':{'A': bodo.float64[:],\n'B': bodo.string_array_type}})\ndef impl(f):\ndf = pd.read_parquet(f)\nreturn df\n</code></pre></p> </li> <li> <p><code>_bodo_input_file_name_col</code> is a Bodo specific argument.     When specified, a column with this     name is added to the dataframe consisting of the name of the file the     row was read from. This is similar to SparkSQL's      <code>input_file_name</code> function.</p> <p>For example: <pre><code>@bodo.jit()\ndef impl(f):\ndf = pd.read_parquet(f, _bodo_input_file_name_col=\"fname\")\nreturn df\n</code></pre></p> </li> <li> <p><code>_bodo_read_as_dict</code> is a Bodo specific argument which forces      the specified string columns to be read with dictionary-encoding.     Bodo automatically loads string columns using dictionary     encoding when it determines it would be beneficial based on      a heuristic.     Dictionary-encoding stores data in memory in an efficient     manner and is most effective when the column has many repeated values.     Read more about dictionary-encoded layout     here.</p> <p>For example: <pre><code>@bodo.jit()\ndef impl(f):\ndf = pd.read_parquet(f, _bodo_read_as_dict=[\"A\", \"B\", \"C\"])\nreturn df\n</code></pre></p> </li> </ul> </li> </ul>"},{"location":"api_docs/pandas/io/#pdread_json","title":"<code>pd.read_json</code>","text":"<ul> <li><code>pandas.read_json</code> <ul> <li>Example usage and more system specific instructions</li> <li>Only supports reading JSON Lines text file format     (<code>pd.read_json(filepath_or_buffer, orient='records', lines=True)</code>)     and regular multi-line JSON     file(<code>pd.read_json(filepath_or_buffer, orient='records', lines=False)</code>).</li> <li>Argument <code>filepath_or_buffer</code> is supported: it can point to a     single JSON file, or a directory containing multiple partitioned     JSON files. When reading a directory, the JSON files inside the     directory must be JSON Lines text file     format with <code>json</code> file extension.</li> <li>Argument <code>orient = 'records'</code> is used as default, instead of     Pandas' default <code>'columns'</code> for dataframes. <code>'records'</code> is the     only supported value for <code>orient</code>.</li> <li>Argument <code>typ</code> is supported. <code>'frame'</code> is the only supported     value for <code>typ</code>.</li> <li><code>filepath_or_buffer</code> must be inferrable as a constant string.     This is required so bodo can infer the types at compile time,     see compile time constants.</li> <li>Arguments <code>convert_dates</code>, <code>precise_float</code>, <code>lines</code> are     supported.</li> <li>Argument <code>anon</code> of <code>storage_options</code> is supported for S3     filepaths.</li> </ul> </li> </ul>"},{"location":"api_docs/pandas/series/","title":"Series","text":"<p>Bodo provides extensive Series support. However, operations between Series (+, -, /, ,*) do not implicitly align values based on their associated index values yet.</p>"},{"location":"api_docs/pandas/series/#pdseries","title":"<code>pd.Series</code>","text":"<ul> <li> <p><code>pandas.Series(data=None, index=None, dtype=None, name=None, copy=False, fastpath=False)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p>other requirements</p> <p><code>data</code></p> <ul> <li>Series type</li> <li>List type</li> <li>Array type</li> <li>Constant     Dictionary</li> <li>None</li> </ul> <p><code>index</code></p> <ul> <li>SeriesType</li> </ul> <p><code>dtype</code></p> <ul> <li>Numpy or Pandas     Type</li> <li>String name for     Numpy/Pandas Type</li> </ul> <ul> <li>Must be constant at     Compile Time</li> <li>String/Data Type must     be one of the     supported types (see     <code>Series.astype()</code>)</li> </ul> <p><code>name</code></p> <ul> <li>String</li> </ul> <p>Note</p> <p>If <code>data</code> is a Series and <code>index</code> is provided, implicit alignment is not performed yet.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...     return pd.Series(np.arange(1000), dtype=np.float64, name=\"my_series\")\n&gt;&gt;&gt; f()\n0        0.0\n1        1.0\n2        2.0\n3        3.0\n4        4.0\n...\n995    995.0\n996    996.0\n997    997.0\n998    998.0\n999    999.0\nName: my_series, Length: 1000, dtype: float64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#attributes","title":"Attributes","text":""},{"location":"api_docs/pandas/series/#pdseriesindex","title":"<code>pd.Series.index</code>","text":"<ul> <li> <p><code>pandas.Series.index</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.index\n&gt;&gt;&gt; S = pd.Series(np.arange(1000))\n&gt;&gt;&gt; f(S)\nRangeIndex(start=0, stop=1000, step=1)\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesvalues","title":"<code>pd.Series.values</code>","text":"<ul> <li> <p><code>pandas.Series.values</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.values\n&gt;&gt;&gt; S = pd.Series(np.arange(1000))\n&gt;&gt;&gt; f(S)\narray([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441,\n442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480,\n481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493,\n494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506,\n507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519,\n520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532,\n533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,\n546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558,\n559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571,\n572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584,\n585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597,\n598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610,\n611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623,\n624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636,\n637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649,\n650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662,\n663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675,\n676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688,\n689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701,\n702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714,\n715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727,\n728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740,\n741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753,\n754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766,\n767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779,\n780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792,\n793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805,\n806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818,\n819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831,\n832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844,\n845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857,\n858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870,\n871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883,\n884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896,\n897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909,\n910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922,\n923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935,\n936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948,\n949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961,\n962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974,\n975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987,\n988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999])\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesdtype","title":"<code>pd.Series.dtype</code>","text":"<ul> <li> <p><code>pandas.Series.dtype (object data</code>     types such as dtype of string series not supported yet)</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.dtype\n&gt;&gt;&gt; S = pd.Series(np.arange(1000))\n&gt;&gt;&gt; f(S)\ndtype('int64')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesshape","title":"<code>pd.Series.shape</code>","text":"<ul> <li> <p><code>pandas.Series.shape</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.shape\n&gt;&gt;&gt; S = pd.Series(np.arange(1000))\n&gt;&gt;&gt; f(S)\n(1000,)\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesnbytes","title":"<code>pd.Series.nbytes</code>","text":"<ul> <li> <p><code>pandas.Series.nbytes</code> </p> <p>Note</p> <p>This tracks the number of bytes used by Bodo which may differ from the Pandas values.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.nbytes\n&gt;&gt;&gt; S = pd.Series(np.arange(1000))\n&gt;&gt;&gt; f(S)\n8000\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesndim","title":"<code>pd.Series.ndim</code>","text":"<ul> <li> <p><code>pandas.Series.ndim</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.ndim\n&gt;&gt;&gt; S = pd.Series(np.arange(1000))\n&gt;&gt;&gt; f(S)\n1\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriessize","title":"<code>pd.Series.size</code>","text":"<ul> <li> <p><code>pandas.Series.size</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.size\n&gt;&gt;&gt; S = pd.Series(np.arange(1000))\n&gt;&gt;&gt; f(S)\n1000\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriest","title":"<code>pd.Series.T</code>","text":"<ul> <li> <p><code>pandas.Series.T</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.T\n&gt;&gt;&gt; S = pd.Series(np.arange(1000))\n&gt;&gt;&gt; f(S)\n0        0\n1        1\n2        2\n3        3\n4        4\n...\n995    995\n996    996\n997    997\n998    998\n999    999\nLength: 1000, dtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesmemory_usage","title":"<code>pd.Series.memory_usage</code>","text":"<ul> <li> <p><code>pandas.Series.memory_usage(index=True, deep=False)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p>other requirements</p> <p><code>index</code> </p> <ul> <li>Boolean </li> </ul> <p>Must be constant at Compile Time</p> <p>Note</p> <p>This tracks the number of bytes used by Bodo which may differ from the Pandas values.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.memory_usage()\n&gt;&gt;&gt; S = pd.Series(np.arange(1000))\n&gt;&gt;&gt; f(S)\n8024\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdserieshasnans","title":"<code>pd.Series.hasnans</code>","text":"<ul> <li> <p><code>pandas.Series.hasnans</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.hasnans\n&gt;&gt;&gt; S = pd.Series(np.arange(1000))\n&gt;&gt;&gt; f(S)\nFalse\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesempty","title":"<code>pd.Series.empty</code>","text":"<ul> <li> <p><code>pandas.Series.empty</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.empty\n&gt;&gt;&gt; S = pd.Series(np.arange(1000))\n&gt;&gt;&gt; f(S)\nFalse\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesdtypes","title":"<code>pd.Series.dtypes</code>","text":"<ul> <li> <p><code>pandas.Series.dtypes</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.dtypes\n&gt;&gt;&gt; S = pd.Series(np.arange(1000))\n&gt;&gt;&gt; f(S)\ndtype('int64')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesname","title":"<code>pd.Series.name</code>","text":"<ul> <li> <p><code>pandas.Series.name</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.name\n&gt;&gt;&gt; S = pd.Series(np.arange(1000), name=\"my_series\")\n&gt;&gt;&gt; f(S)\n'my_series'\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#conversion","title":"Conversion:","text":""},{"location":"api_docs/pandas/series/#pdseriesastype","title":"<code>pd.Series.astype</code>","text":"<ul> <li> <p><code>pandas.Series.astype(dtype, copy=True, errors=\"raise\", _bodo_nan_to_str=True)</code> </p> <p>Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p>other requirements</p> <p><code>dtype</code></p> <ul> <li>String (string     must be parsable     by <code>np.dtype</code>)</li> <li>Valid type (see     types)</li> <li>The following     functions: float,     int, bool, str</li> </ul> <p>Must be constant at Compile Time</p> <p><code>copy</code> </p> <ul> <li>Boolean </li> </ul> <p>Must be constant at Compile Time</p> <p><code>_bodo_nan_to_str</code></p> <ul> <li>Boolean</li> </ul> <ul> <li>Must be constant at     Compile Time</li> <li>Argument unique to     Bodo. When <code>True</code> NA     values in when     converting to string     are represented as NA     instead of a string     representation of the     NA value (i.e.     'nan'), the default     Pandas behavior.</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.astype(np.float32)\n&gt;&gt;&gt; S = pd.Series(np.arange(1000))\n&gt;&gt;&gt; f(S)\n0        0.0\n1        1.0\n2        2.0\n3        3.0\n4        4.0\n...\n995    995.0\n996    996.0\n997    997.0\n998    998.0\n999    999.0\nLength: 1000, dtype: float32\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriescopy","title":"<code>pd.Series.copy</code>","text":"<ul> <li> <p><code>pandas.Series.copy(deep=True)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>deep</code></p> <ul> <li>Boolean</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.copy()\n&gt;&gt;&gt; S = pd.Series(np.arange(1000))\n&gt;&gt;&gt; f(S)\n0        0\n1        1\n2        2\n3        3\n4        4\n...\n995    995\n996    996\n997    997\n998    998\n999    999\nLength: 1000, dtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesto_numpy","title":"<code>pd.Series.to_numpy</code>","text":"<ul> <li> <p><code>pandas.Series.to_numpy(dtype=None, copy=False, na_value=None)</code> Supported Arguments None</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.to_numpy()\n&gt;&gt;&gt; S = pd.Series(np.arange(1000))\n&gt;&gt;&gt; f(S)\narray([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441,\n442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480,\n481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493,\n494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506,\n507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519,\n520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532,\n533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,\n546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558,\n559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571,\n572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584,\n585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597,\n598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610,\n611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623,\n624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636,\n637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649,\n650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662,\n663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675,\n676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688,\n689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701,\n702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714,\n715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727,\n728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740,\n741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753,\n754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766,\n767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779,\n780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792,\n793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805,\n806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818,\n819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831,\n832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844,\n845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857,\n858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870,\n871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883,\n884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896,\n897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909,\n910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922,\n923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935,\n936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948,\n949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961,\n962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974,\n975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987,\n988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999])\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriestolist","title":"<code>pd.Series.tolist</code>","text":"<ul> <li> <p><code>pandas.Series.tolist()</code> </p> <p>Note</p> <p>Calling <code>tolist</code> on a non-float array with NA values with cause a runtime exception.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.tolist()\n&gt;&gt;&gt; S = pd.Series(np.arange(50))\n&gt;&gt;&gt; f(S)\n[0,\n1,\n2,\n3,\n4,\n5,\n6,\n7,\n8,\n9,\n10,\n11,\n12,\n13,\n14,\n15,\n16,\n17,\n18,\n19,\n20,\n21,\n22,\n23,\n24,\n25,\n26,\n27,\n28,\n29,\n30,\n31,\n32,\n33,\n34,\n35,\n36,\n37,\n38,\n39,\n40,\n41,\n42,\n43,\n44,\n45,\n46,\n47,\n48,\n49]\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#indexing-iteration","title":"Indexing, iteration:","text":"<p>Location based indexing using <code>[]</code>, <code>iat</code>, and <code>iloc</code> is supported. Changing values of existing string Series using these operators is not supported yet.</p>"},{"location":"api_docs/pandas/series/#pdseriesiat","title":"<code>pd.Series.iat</code>","text":"<ul> <li><code>pandas.Series.iat</code>  We only support indexing using <code>iat</code> using a pair of integers</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S, i):\n...   return S.iat[i]\n&gt;&gt;&gt; S = pd.Series(np.arange(1000))\n&gt;&gt;&gt; f(S, 27)\n27\n</code></pre>"},{"location":"api_docs/pandas/series/#pdseriesiloc","title":"<code>pd.Series.iloc</code>","text":"<ul> <li> <p><code>pandas.Series.iloc</code> </p> <ul> <li> <p>getitem:</p> <ul> <li><code>Series.iloc</code> supports single integer indexing (returns a     scalar) <code>S.iloc[0]</code></li> <li><code>Series.iloc</code> supports list/array/series of integers/bool     (returns a Series) <code>S.iloc[[0,1,2]]</code></li> <li><code>Series.iloc</code> supports integer slice (returns a Series)     <code>S.iloc[[0:2]]</code></li> </ul> </li> <li> <p>setitem:</p> <ul> <li>Supports the same cases as getitem but the array type must be     mutable (i.e. numeric array)</li> </ul> </li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S, idx):\n...   return S.iloc[idx]\n&gt;&gt;&gt; S = pd.Series(np.arange(1000))\n&gt;&gt;&gt; f(S, [1, 4, 29])\n1      1\n4      4\n29    29\ndtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesloc","title":"<code>pd.Series.loc</code>","text":"<ul> <li> <p><code>pandas.Series.loc</code> </p> <ul> <li> <p>getitem:</p> <ul> <li><code>Series.loc</code> supports list/array of booleans</li> <li><code>Series.loc</code> supports integer with RangeIndex</li> </ul> </li> <li> <p>setitem:</p> <ul> <li><code>Series.loc</code> supports list/array of booleans</li> </ul> </li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S, idx):\n...   return S.loc[idx]\n&gt;&gt;&gt; S = pd.Series(np.arange(1000))\n&gt;&gt;&gt; f(S, S &lt; 10)\n0    0\n1    1\n2    2\n3    3\n4    4\n5    5\n6    6\n7    7\n8    8\n9    9\ndtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#binary-operator-functions","title":"Binary operator functions:","text":""},{"location":"api_docs/pandas/series/#pdseriesadd","title":"<code>pd.Series.add</code>","text":"<ul> <li> <p><code>pandas.Series.add(other, level=None, fill_value=None, axis=0)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>other</code></p> <ul> <li>numeric scalar</li> <li>array with numeric data</li> <li>Series with numeric data</li> </ul> <p><code>fill_value</code></p> <ul> <li>numeric scalar</li> </ul> <p>Note</p> <p><code>Series.add</code> is only supported on Series of numeric data.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S, other):\n...   return S.add(other)\n&gt;&gt;&gt; S = pd.Series(np.arange(1, 1001))\n&gt;&gt;&gt; other = pd.Series(reversed(np.arange(1, 1001)))\n&gt;&gt;&gt; f(S, other)\n0      1001\n1      1001\n2      1001\n3      1001\n4      1001\n...\n995    1001\n996    1001\n997    1001\n998    1001\n999    1001\nLength: 1000, dtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriessub","title":"<code>pd.Series.sub</code>","text":"<ul> <li> <p><code>pandas.Series.sub(other, level=None, fill_value=None, axis=0)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>other</code></p> <ul> <li>numeric scalar</li> <li>array with numeric data</li> <li>Series with numeric data</li> </ul> <p><code>fill_value</code></p> <ul> <li>numeric scalar</li> </ul> <p>Note</p> <p><code>Series.sub</code> is only supported on Series of numeric data.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S, other):\n...   return S.sub(other)\n&gt;&gt;&gt; S = pd.Series(np.arange(1, 1001))\n&gt;&gt;&gt; other = pd.Series(reversed(np.arange(1, 1001)))\n&gt;&gt;&gt; f(S, other)\n0     -999\n1     -997\n2     -995\n3     -993\n4     -991\n...\n995    991\n996    993\n997    995\n998    997\n999    999\nLength: 1000, dtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesmul","title":"<code>pd.Series.mul</code>","text":"<ul> <li> <p><code>pandas.Series.mul(other, level=None, fill_value=None, axis=0)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>other</code></p> <ul> <li>numeric scalar</li> <li>array with numeric data</li> <li>Series with numeric data</li> </ul> <p><code>fill_value</code></p> <ul> <li>numeric scalar</li> </ul> <p>Note</p> <p><code>Series.mul</code> is only supported on Series of numeric data.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S, other):\n...   return S.mul(other)\n&gt;&gt;&gt; S = pd.Series(np.arange(1, 1001))\n&gt;&gt;&gt; other = pd.Series(reversed(np.arange(1, 1001)))\n&gt;&gt;&gt; f(S, other)\n0      1000\n1      1998\n2      2994\n3      3988\n4      4980\n...\n995    4980\n996    3988\n997    2994\n998    1998\n999    1000\nLength: 1000, dtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesdiv","title":"<code>pd.Series.div</code>","text":"<ul> <li> <p><code>pandas.Series.div(other, level=None, fill_value=None, axis=0)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>other</code></p> <ul> <li>numeric scalar</li> <li>array with numeric data</li> <li>Series with numeric data</li> </ul> <p><code>fill_value</code></p> <ul> <li>numeric scalar</li> </ul> <p>Note</p> <p><code>Series.div</code> is only supported on Series of numeric data.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S, other):\n...   return S.div(other)\n&gt;&gt;&gt; S = pd.Series(np.arange(1, 1001))\n&gt;&gt;&gt; other = pd.Series(reversed(np.arange(1, 1001)))\n&gt;&gt;&gt; f(S, other)\n0         0.001000\n1         0.002002\n2         0.003006\n3         0.004012\n4         0.005020\n...\n995     199.200000\n996     249.250000\n997     332.666667\n998     499.500000\n999    1000.000000\nLength: 1000, dtype: float64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriestruediv","title":"<code>pd.Series.truediv</code>","text":"<ul> <li> <p><code>pandas.Series.truediv(other, level=None, fill_value=None, axis=0)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>other</code></p> <ul> <li>numeric scalar</li> <li>array with numeric data</li> <li>Series with numeric data</li> </ul> <p><code>fill_value</code></p> <ul> <li>numeric scalar</li> </ul> <p>Note</p> <p><code>Series.truediv</code> is only supported on Series of numeric data.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S, other):\n...   return S.truediv(other)\n&gt;&gt;&gt; S = pd.Series(np.arange(1, 1001))\n&gt;&gt;&gt; other = pd.Series(reversed(np.arange(1, 1001)))\n&gt;&gt;&gt; f(S, other)\n0         0.001000\n1         0.002002\n2         0.003006\n3         0.004012\n4         0.005020\n...\n995     199.200000\n996     249.250000\n997     332.666667\n998     499.500000\n999    1000.000000\nLength: 1000, dtype: float64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesfloordiv","title":"<code>pd.Series.floordiv</code>","text":"<ul> <li> <p><code>pandas.Series.floordiv(other, level=None, fill_value=None, axis=0)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>other</code></p> <ul> <li>numeric scalar</li> <li>array with numeric data</li> <li>Series with numeric data</li> </ul> <p><code>fill_value</code></p> <ul> <li>numeric scalar</li> </ul> <p>Note</p> <p><code>Series.floordiv</code> is only supported on Series of numeric data.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S, other):\n...   return S.floordiv(other)\n&gt;&gt;&gt; S = pd.Series(np.arange(1, 1001))\n&gt;&gt;&gt; other = pd.Series(reversed(np.arange(1, 1001)))\n&gt;&gt;&gt; f(S, other)\n0         0\n1         0\n2         0\n3         0\n4         0\n...\n995     199\n996     249\n997     332\n998     499\n999    1000\nLength: 1000, dtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesmod","title":"<code>pd.Series.mod</code>","text":"<ul> <li> <p><code>pandas.Series.mod(other, level=None, fill_value=None, axis=0)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>other</code></p> <ul> <li>numeric scalar</li> <li>array with numeric data</li> <li>Series with numeric data</li> </ul> <p><code>fill_value</code></p> <ul> <li>numeric scalar</li> </ul> <p>Note</p> <p><code>Series.mod</code> is only supported on Series of numeric data.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S, other):\n...   return S.mod(other)\n&gt;&gt;&gt; S = pd.Series(np.arange(1, 1001))\n&gt;&gt;&gt; other = pd.Series(reversed(np.arange(1, 1001)))\n&gt;&gt;&gt; f(S, other)\n0      1\n1      2\n2      3\n3      4\n4      5\n..\n995    1\n996    1\n997    2\n998    1\n999    0\nLength: 1000, dtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriespow","title":"<code>pd.Series.pow</code>","text":"<ul> <li> <p><code>pandas.Series.pow(other, level=None, fill_value=None, axis=0)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>other</code></p> <ul> <li>numeric scalar</li> <li>array with numeric data</li> <li>Series with numeric data</li> </ul> <p><code>fill_value</code></p> <ul> <li>numeric scalar</li> </ul> <p>Note</p> <p><code>Series.pow</code> is only supported on Series of numeric data.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S, other):\n...   return S.pow(other)\n&gt;&gt;&gt; S = pd.Series(np.arange(1, 1001))\n&gt;&gt;&gt; other = pd.Series(reversed(np.arange(1, 1001)))\n&gt;&gt;&gt; f(S, other)\n0                        1\n1                        0\n2     -5459658280481875879\n3                        0\n4      3767675092665006833\n...\n995        980159361278976\n996           988053892081\n997              994011992\n998                 998001\n999                   1000\nLength: 1000, dtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesradd","title":"<code>pd.Series.radd</code>","text":"<ul> <li> <p><code>pandas.Series.radd(other, level=None, fill_value=None, axis=0)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>other</code></p> <ul> <li>numeric scalar</li> <li>array with numeric data</li> <li>Series with numeric data</li> </ul> <p><code>fill_value</code></p> <ul> <li>numeric scalar</li> </ul> <p>Note</p> <p><code>Series.radd</code> is only supported on Series of numeric data.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S, other):\n...   return S.radd(other)\n&gt;&gt;&gt; S = pd.Series(np.arange(1, 1001))\n&gt;&gt;&gt; other = pd.Series(reversed(np.arange(1, 1001)))\n&gt;&gt;&gt; f(S, other)\n0      1001\n1      1001\n2      1001\n3      1001\n4      1001\n...\n995    1001\n996    1001\n997    1001\n998    1001\n999    1001\nLength: 1000, dtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesrsub","title":"<code>pd.Series.rsub</code>","text":"<ul> <li> <p><code>pandas.Series.rsub(other, level=None, fill_value=None, axis=0)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>other</code></p> <ul> <li>numeric scalar</li> <li>array with numeric data</li> <li>Series with numeric data</li> </ul> <p><code>fill_value</code></p> <ul> <li>numeric scalar</li> </ul> <p>Note</p> <p><code>Series.rsub</code> is only supported on Series of numeric data.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S, other):\n...   return S.rsub(other)\n&gt;&gt;&gt; S = pd.Series(np.arange(1, 1001))\n&gt;&gt;&gt; other = pd.Series(reversed(np.arange(1, 1001)))\n&gt;&gt;&gt; f(S, other)\n0      999\n1      997\n2      995\n3      993\n4      991\n...\n995   -991\n996   -993\n997   -995\n998   -997\n999   -999\nLength: 1000, dtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesrmul","title":"<code>pd.Series.rmul</code>","text":"<ul> <li> <p><code>pandas.Series.rmul(other, level=None, fill_value=None, axis=0)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>other</code></p> <ul> <li>numeric scalar</li> <li>array with numeric data</li> <li>Series with numeric data</li> </ul> <p><code>fill_value</code></p> <ul> <li>numeric scalar</li> </ul> <p>Note</p> <p><code>Series.rmul</code> is only supported on Series of numeric data.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S, other):\n...   return S.rmul(other)\n&gt;&gt;&gt; S = pd.Series(np.arange(1, 1001))\n&gt;&gt;&gt; other = pd.Series(reversed(np.arange(1, 1001)))\n&gt;&gt;&gt; f(S, other)\n0      1000\n1      1998\n2      2994\n3      3988\n4      4980\n...\n995    4980\n996    3988\n997    2994\n998    1998\n999    1000\nLength: 1000, dtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesrdiv","title":"<code>pd.Series.rdiv</code>","text":"<ul> <li> <p><code>pandas.Series.rdiv(other, level=None, fill_value=None, axis=0)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>other</code></p> <ul> <li>numeric scalar</li> <li>array with numeric data</li> <li>Series with numeric data</li> </ul> <p><code>fill_value</code></p> <ul> <li>numeric scalar</li> </ul> <p>Note</p> <p><code>Series.rdiv</code> is only supported on Series of numeric data.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S, other):\n...   return S.rdiv(other)\n&gt;&gt;&gt; S = pd.Series(np.arange(1, 1001))\n&gt;&gt;&gt; other = pd.Series(reversed(np.arange(1, 1001)))\n&gt;&gt;&gt; f(S, other)\n0      1000.000000\n1       499.500000\n2       332.666667\n3       249.250000\n4       199.200000\n...\n995       0.005020\n996       0.004012\n997       0.003006\n998       0.002002\n999       0.001000\nLength: 1000, dtype: float64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesrtruediv","title":"<code>pd.Series.rtruediv</code>","text":"<ul> <li> <p><code>pandas.Series.rtruediv(other, level=None, fill_value=None, axis=0)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>other</code></p> <ul> <li>numeric scalar</li> <li>array with numeric data</li> <li>Series with numeric data</li> </ul> <p><code>fill_value</code></p> <ul> <li>numeric scalar</li> </ul> <p>Note</p> <p><code>Series.rtruediv</code> is only supported on Series of numeric data.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S, other):\n...   return S.rtruediv(other)\n&gt;&gt;&gt; S = pd.Series(np.arange(1, 1001))\n&gt;&gt;&gt; other = pd.Series(reversed(np.arange(1, 1001)))\n&gt;&gt;&gt; f(S, other)\n0      1000.000000\n1       499.500000\n2       332.666667\n3       249.250000\n4       199.200000\n...\n995       0.005020\n996       0.004012\n997       0.003006\n998       0.002002\n999       0.001000\nLength: 1000, dtype: float64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesrfloordiv","title":"<code>pd.Series.rfloordiv</code>","text":"<ul> <li> <p><code>pandas.Series.rfloordiv(other, level=None, fill_value=None, axis=0)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>other</code></p> <ul> <li>numeric scalar</li> <li>array with numeric data</li> <li>Series with numeric data</li> </ul> <p><code>fill_value</code></p> <ul> <li>numeric scalar</li> </ul> <p>Note</p> <p><code>Series.rfloordiv</code> is only supported on Series of numeric data.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S, other):\n...   return S.rfloordiv(other)\n&gt;&gt;&gt; S = pd.Series(np.arange(1, 1001))\n&gt;&gt;&gt; other = pd.Series(reversed(np.arange(1, 1001)))\n&gt;&gt;&gt; f(S, other)\n0      1000\n1       499\n2       332\n3       249\n4       199\n...\n995       0\n996       0\n997       0\n998       0\n999       0\nLength: 1000, dtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesrmod","title":"<code>pd.Series.rmod</code>","text":"<ul> <li> <p><code>pandas.Series.rmod(other, level=None, fill_value=None, axis=0)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>other</code></p> <ul> <li>numeric scalar</li> <li>array with numeric data</li> <li>Series with numeric data</li> </ul> <p><code>fill_value</code></p> <ul> <li>numeric scalar</li> </ul> <p>Note</p> <p><code>Series.rmod</code> is only supported on Series of numeric data.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S, other):\n...   return S.rmod(other)\n&gt;&gt;&gt; S = pd.Series(np.arange(1, 1001))\n&gt;&gt;&gt; other = pd.Series(reversed(np.arange(1, 1001)))\n&gt;&gt;&gt; f(S, other)\n0      0\n1      1\n2      2\n3      1\n4      1\n..\n995    5\n996    4\n997    3\n998    2\n999    1\nLength: 1000, dtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesrpow","title":"<code>pd.Series.rpow</code>","text":"<ul> <li> <p><code>pandas.Series.rpow(other, level=None, fill_value=None, axis=0)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>other</code></p> <ul> <li>numeric scalar</li> <li>array with numeric data</li> <li>Series with numeric data</li> </ul> <p><code>fill_value</code></p> <ul> <li>numeric scalar</li> </ul> <p>Note</p> <p><code>Series.rpow</code> is only supported on Series of numeric data.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S, other):\n...   return S.rpow(other)\n&gt;&gt;&gt; S = pd.Series(np.arange(1, 1001))\n&gt;&gt;&gt; other = pd.Series(reversed(np.arange(1, 1001)))\n&gt;&gt;&gt; f(S, other)\n0                     1000\n1                   998001\n2                994011992\n3             988053892081\n4          980159361278976\n...\n995    3767675092665006833\n996                      0\n997   -5459658280481875879\n998                      0\n999                      1\nLength: 1000, dtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriescombine","title":"<code>pd.Series.combine</code>","text":"<ul> <li> <p><code>pandas.Series.combine(other, func, fill_value=None)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p>other requirements</p> <p><code>other</code> </p> <ul> <li>Array</li> <li>Series</li> </ul> <p><code>func</code></p> <ul> <li>Function that     takes two scalar     arguments and     returns a scalar     value.</li> </ul> <p><code>fill_value</code></p> <ul> <li>scalar</li> </ul> <p>Must be provided if the Series lengths aren't equal and the dtypes aren't floats.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S, other):\n...   return S.combine(other, lambda a, b: 2 * a + b)\n&gt;&gt;&gt; S = pd.Series(np.arange(1, 1001))\n&gt;&gt;&gt; other = pd.Series(reversed(np.arange(1, 1001)))\n&gt;&gt;&gt; f(S, other)\n0      1002\n1      1003\n2      1004\n3      1005\n4      1006\n...\n995    1997\n996    1998\n997    1999\n998    2000\n999    2001\nLength: 1000, dtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesround","title":"<code>pd.Series.round</code>","text":"<ul> <li> <p><code>pandas.Series.round(decimals=0)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>other</code></p> <ul> <li>Series with numeric data</li> </ul> <p>Note</p> <p><code>Series.round</code> is only supported on Series of numeric data.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...   return S.round(2)\n&gt;&gt;&gt; S = pd.Series(np.linspace(100, 1000))\n&gt;&gt;&gt; f(S)\n0      100.00\n1      118.37\n2      136.73\n3      155.10\n4      173.47\n5      191.84\n6      210.20\n7      228.57\n8      246.94\n9      265.31\n10     283.67\n11     302.04\n12     320.41\n13     338.78\n14     357.14\n15     375.51\n16     393.88\n17     412.24\n18     430.61\n19     448.98\n20     467.35\n21     485.71\n22     504.08\n23     522.45\n24     540.82\n25     559.18\n26     577.55\n27     595.92\n28     614.29\n29     632.65\n30     651.02\n31     669.39\n32     687.76\n33     706.12\n34     724.49\n35     742.86\n36     761.22\n37     779.59\n38     797.96\n39     816.33\n40     834.69\n41     853.06\n42     871.43\n43     889.80\n44     908.16\n45     926.53\n46     944.90\n47     963.27\n48     981.63\n49    1000.00\ndtype: float64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdserieslt","title":"<code>pd.Series.lt</code>","text":"<ul> <li> <p><code>pandas.Series.lt(other, level=None, fill_value=None, axis=0)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>other</code></p> <ul> <li>numeric scalar</li> <li>array with numeric data</li> <li>Series with numeric data</li> </ul> <p><code>fill_value</code></p> <ul> <li>numeric scalar</li> </ul> <p>Note</p> <p><code>Series.lt</code> is only supported on Series of numeric data.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S, other):\n...   return S.lt(other)\n&gt;&gt;&gt; S = pd.Series(np.arange(1, 1001))\n&gt;&gt;&gt; other = pd.Series(reversed(np.arange(1, 1001)))\n&gt;&gt;&gt; f(S, other)\n0       True\n1       True\n2       True\n3       True\n4       True\n...\n995    False\n996    False\n997    False\n998    False\n999    False\nLength: 1000, dtype: bool\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesgt","title":"<code>pd.Series.gt</code>","text":"<ul> <li> <p><code>pandas.Series.gt(other, level=None, fill_value=None, axis=0)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>other</code></p> <ul> <li>numeric scalar</li> <li>array with numeric data</li> <li>Series with numeric data</li> </ul> <p><code>fill_value</code></p> <ul> <li>numeric scalar</li> </ul> <p>Note</p> <p><code>Series.gt</code> is only supported on Series of numeric data.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S, other):\n...   return S.gt(other)\n&gt;&gt;&gt; S = pd.Series(np.arange(1, 1001))\n&gt;&gt;&gt; other = pd.Series(reversed(np.arange(1, 1001)))\n&gt;&gt;&gt; f(S, other)\n0      False\n1      False\n2      False\n3      False\n4      False\n...\n995     True\n996     True\n997     True\n998     True\n999     True\nLength: 1000, dtype: bool\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesle","title":"<code>pd.Series.le</code>","text":"<ul> <li> <p><code>pandas.Series.le(other, level=None, fill_value=None, axis=0)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>other</code></p> <ul> <li>numeric scalar</li> <li>array with numeric data</li> <li>Series with numeric data</li> </ul> <p><code>fill_value</code></p> <ul> <li>numeric scalar</li> </ul> <p>Note</p> <p><code>Series.le</code> is only supported on Series of numeric data.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S, other):\n...   return S.le(other)\n&gt;&gt;&gt; S = pd.Series(np.arange(1, 1001))\n&gt;&gt;&gt; other = pd.Series(reversed(np.arange(1, 1001)))\n&gt;&gt;&gt; f(S, other)\n0       True\n1       True\n2       True\n3       True\n4       True\n...\n995    False\n996    False\n997    False\n998    False\n999    False\nLength: 1000, dtype: bool\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesge","title":"<code>pd.Series.ge</code>","text":"<ul> <li> <p><code>pandas.Series.ge(other, level=None, fill_value=None, axis=0)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>other</code></p> <ul> <li>numeric scalar</li> <li>array with numeric data</li> <li>Series with numeric data</li> </ul> <p><code>fill_value</code></p> <ul> <li>numeric scalar</li> </ul> <p>Note</p> <p><code>Series.ge</code> is only supported on Series of numeric data.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S, other):\n...   return S.ge(other)\n&gt;&gt;&gt; S = pd.Series(np.arange(1, 1001))\n&gt;&gt;&gt; other = pd.Series(reversed(np.arange(1, 1001)))\n&gt;&gt;&gt; f(S, other)\n0      False\n1      False\n2      False\n3      False\n4      False\n...\n995     True\n996     True\n997     True\n998     True\n999     True\nLength: 1000, dtype: bool\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesne","title":"<code>pd.Series.ne</code>","text":"<ul> <li> <p><code>pandas.Series.ne(other, level=None, fill_value=None, axis=0)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>other</code></p> <ul> <li>numeric scalar</li> <li>array with numeric data</li> <li>Series with numeric data</li> </ul> <p><code>fill_value</code></p> <ul> <li>numeric scalar</li> </ul> <p>Note</p> <p><code>Series.ne</code> is only supported on Series of numeric data.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S, other):\n...   return S.ne(other)\n&gt;&gt;&gt; S = pd.Series(np.arange(1, 1001))\n&gt;&gt;&gt; other = pd.Series(reversed(np.arange(1, 1001)))\n&gt;&gt;&gt; f(S, other)\n0      True\n1      True\n2      True\n3      True\n4      True\n...\n995    True\n996    True\n997    True\n998    True\n999    True\nLength: 1000, dtype: bool\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdserieseq","title":"<code>pd.Series.eq</code>","text":"<ul> <li> <p><code>pandas.Series.eq(other, level=None, fill_value=None, axis=0)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>other</code></p> <ul> <li>numeric scalar</li> <li>array with numeric data</li> <li>Series with numeric data</li> </ul> <p><code>fill_value</code></p> <ul> <li>numeric scalar</li> </ul> <p>Note</p> <p><code>Series.eq</code> is only supported on Series of numeric data.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S, other):\n...   return S.eq(other)\n&gt;&gt;&gt; S = pd.Series(np.arange(1, 1001))\n&gt;&gt;&gt; other = pd.Series(reversed(np.arange(1, 1001)))\n&gt;&gt;&gt; f(S, other)\n0      False\n1      False\n2      False\n3      False\n4      False\n...\n995    False\n996    False\n997    False\n998    False\n999    False\nLength: 1000, dtype: bool\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesdot","title":"<code>pd.Series.dot</code>","text":"<ul> <li> <p><code>pandas.Series.dot(other)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>other</code></p> <ul> <li>Series with numeric data</li> </ul> <p>Note</p> <p><code>Series.dot</code> is only supported on Series of numeric data.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S, other):\n...   return S.dot(other)\n&gt;&gt;&gt; S = pd.Series(np.arange(1, 1001))\n&gt;&gt;&gt; other = pd.Series(reversed(np.arange(1, 1001)))\n&gt;&gt;&gt; f(S, other)\n167167000\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#function-application-groupby-window","title":"Function application, GroupBy &amp; Window","text":""},{"location":"api_docs/pandas/series/#pdseriesapply","title":"<code>pd.Series.apply</code>","text":"<ul> <li> <p><code>pandas.Series.applyf(func, convert_dtype=True, args=(), **kwargs)</code></p> <p>Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p>other requirements</p> <p><code>func</code></p> <ul> <li>JIT function or     callable defined     within a JIT     function</li> <li>Numpy ufunc</li> <li>Constant String     which is the name     of a supported     Series method or     Numpy ufunc</li> </ul> <ul> <li>Additional arguments     for <code>func</code> can be     passed as additional     arguments.</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...   return S.apply(lambda x: x ** 0.75)\n&gt;&gt;&gt; S = pd.Series(np.arange(100))\n&gt;&gt;&gt; f(S)\n0      0.000000\n1      1.000000\n2      1.681793\n3      2.279507\n4      2.828427\n...\n95    30.429352\n96    30.669269\n97    30.908562\n98    31.147239\n99    31.385308\nLength: 100, dtype: float64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesmap","title":"<code>pd.Series.map</code>","text":"<ul> <li> <p><code>pandas.Series.map(arg, na_action=None)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>arg</code></p> <ul> <li>Dictionary</li> <li>JIT function or callable defined     within a JIT function</li> <li>Constant String which refers to a     supported Series method or Numpy     ufunc</li> <li>Numpy ufunc</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...   return S.map(lambda x: x ** 0.75)\n&gt;&gt;&gt; S = pd.Series(np.arange(100))\n&gt;&gt;&gt; f(S)\n0      0.000000\n1      1.000000\n2      1.681793\n3      2.279507\n4      2.828427\n...\n95    30.429352\n96    30.669269\n97    30.908562\n98    31.147239\n99    31.385308\nLength: 100, dtype: float64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesgroupby","title":"<code>pd.Series.groupby</code>","text":"<ul> <li> <p><code>pandas.Series.groupby(by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=NoDefault.no_default, observed=False, dropna=True)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p>other requirements</p> <p><code>by</code></p> <ul> <li>Array-like or     Series data. This     is not supported     with Decimal or     Categorical data.</li> </ul> <ul> <li>Must be constant at     Compile Time</li> </ul> <p><code>level</code></p> <ul> <li>integer</li> </ul> <ul> <li>Must be constant at     Compile Time</li> <li>Only <code>level=0</code> is     supported and not     with MultiIndex.</li> </ul> <p>You must provide exactly one of <code>by</code> and <code>level</code></p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S, by_series):\n...     return S.groupby(by_series).count()\n&gt;&gt;&gt; S = pd.Series([1, 2, 24, None] * 5)\n&gt;&gt;&gt; by_series = pd.Series([\"421\", \"f31\"] * 10)\n&gt;&gt;&gt; f(S, by_series)\n&gt;\n421    10\nf31     5\nName: , dtype: int64\n</code></pre> <p>Note</p> <p><code>Series.groupby</code> doesn't currently keep the name of the original Series.</p> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesrolling","title":"<code>pd.Series.rolling</code>","text":"<ul> <li> <p><code>pandas.Series.rolling(window, min_periods=None, center=False, win_type=None, on=None, axis=0, closed=None, method='single')</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>window</code></p> <ul> <li>Integer</li> <li>String representing a Time Offset</li> <li>Timedelta</li> </ul> <p><code>min_periods</code></p> <ul> <li>Integer</li> </ul> <p><code>center</code></p> <ul> <li>Boolean</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.rolling(2).mean()\n&gt;&gt;&gt; S = pd.Series(np.arange(100))\n&gt;&gt;&gt; f(S)\n0      NaN\n1      0.5\n2      1.5\n3      2.5\n4      3.5\n...\n95    94.5\n96    95.5\n97    96.5\n98    97.5\n99    98.5\nLength: 100, dtype: float64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriespipe","title":"<code>pd.Series.pipe</code>","text":"<ul> <li> <p><code>pandas.Series.pipe(func, *args, **kwargs)</code></p> <p>Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p>other requirements</p> <p><code>func</code></p> <ul> <li>JIT function or     callable defined     within a JIT     function.</li> </ul> <ul> <li>Additional arguments     for <code>func</code> can be     passed as additional     arguments.</li> </ul> <p>Note</p> <p><code>func</code> cannot be a tuple</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     def g(row, y):\n...         return row + y\n...\n...     def f(row):\n...         return row * 2\n...\n...     return S.pipe(h).pipe(g, y=32)\n&gt;&gt;&gt; S = pd.Series(np.arange(100))\n&gt;&gt;&gt; f(S)\n0      32\n1      34\n2      36\n3      38\n4      40\n...\n95    222\n96    224\n97    226\n98    228\n99    230\nLength: 100, dtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#computations-descriptive-stats","title":"Computations / Descriptive Stats","text":"<p>Statistical functions below are supported without optional arguments unless support is explicitly mentioned.</p>"},{"location":"api_docs/pandas/series/#pdseriesabs","title":"<code>pd.Series.abs</code>","text":"<ul> <li> <p><code>pandas.Series.abs()</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.abs()\n&gt;&gt;&gt; S = (pd.Series(np.arange(100)) % 7) - 2\n&gt;&gt;&gt; f(S)\n0     2\n1     1\n2     0\n3     1\n4     2\n..\n95    2\n96    3\n97    4\n98    2\n99    1\nLength: 100, dtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesall","title":"<code>pd.Series.all</code>","text":"<ul> <li> <p><code>pandas.Series.all(axis=0, bool_only=None, skipna=True, level=None)</code> Supported Arguments None</p> <p>Note</p> <p>Bodo does not accept any additional arguments for Numpy compatibility</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.all()\n&gt;&gt;&gt; S = pd.Series(np.arange(100)) % 7\n&gt;&gt;&gt; f(S)\nFalse\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesany","title":"<code>pd.Series.any</code>","text":"<ul> <li> <p><code>pandas.Series.any(axis=0, bool_only=None, skipna=True, level=None)</code> Supported Arguments None</p> <p>Note</p> <p>Bodo does not accept any additional arguments for Numpy compatibility</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.any()\n&gt;&gt;&gt; S = pd.Series(np.arange(100)) % 7\n&gt;&gt;&gt; f(S)\nTrue\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesautocorr","title":"<code>pd.Series.autocorr</code>","text":"<ul> <li> <p><code>pandas.Series.autocorr(lag=1)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>lag</code></p> <ul> <li>Integer</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.autocorr(3)\n&gt;&gt;&gt; S = pd.Series(np.arange(100)) % 7\n&gt;&gt;&gt; f(S)\n-0.49872171657407155\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesbetween","title":"<code>pd.Series.between</code>","text":"<ul> <li> <p><code>pandas.Series.between(left, right, inclusive='both')</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p>other requirements</p> <p><code>left</code> </p> <ul> <li>Scalar matching     the Series type</li> </ul> <p><code>right</code> </p> <ul> <li>Scalar matching     the Series type</li> </ul> <p><code>inclusive</code> </p> <ul> <li>One of (\"both\",     \"neither\")</li> </ul> <ul> <li>Must be constant at     Compile Time</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.between(3, 5, \"both\")\n&gt;&gt;&gt; S = pd.Series(np.arange(100)) % 7\n&gt;&gt;&gt; f(S)\n0     False\n1     False\n2     False\n3      True\n4      True\n...\n95     True\n96     True\n97    False\n98    False\n99    False\nLength: 100, dtype: bool\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriescorr","title":"<code>pd.Series.corr</code>","text":"<ul> <li> <p><code>pandas.Series.corr(other, method='pearson', min_periods=None)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>other</code></p> <ul> <li>Numeric Series or Array</li> </ul> <p>Note</p> <p>Series type must be numeric</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S, other):\n...     return S.cov(other)\n&gt;&gt;&gt; S = pd.Series(np.arange(100)) % 7\n&gt;&gt;&gt; other = pd.Series(np.arange(100)) % 10\n&gt;&gt;&gt; f(S, other)\n0.004326329627279103\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriescount","title":"<code>pd.Series.count</code>","text":"<ul> <li> <p><code>pandas.Series.count(level=None)</code> Supported Arguments None</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.count()\n&gt;&gt;&gt; S = pd.Series(np.arange(100)) % 7\n&gt;&gt;&gt; f(S)\n100\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriescov","title":"<code>pd.Series.cov</code>","text":"<ul> <li> <p><code>pandas.Series.cov(other, min_periods=None, ddof=1)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>other</code></p> <ul> <li>Numeric Series or Array</li> </ul> <p><code>ddof</code></p> <ul> <li>Integer</li> </ul> <p>Note</p> <p>Series type must be numeric</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S, other):\n...     return S.cov(other)\n&gt;&gt;&gt; S = pd.Series(np.arange(100)) % 7\n&gt;&gt;&gt; other = pd.Series(np.arange(100)) % 10\n&gt;&gt;&gt; f(S, other)\n0.025252525252525252\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriescummin","title":"<code>pd.Series.cummin</code>","text":"<ul> <li> <p><code>pandas.Series.cummin(axis=None, skipna=True)</code> Supported Arguments None</p> <p>Note</p> <ul> <li>Series type must be numeric</li> <li>Bodo does not accept any additional arguments for Numpy compatibility</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.cummin()\n&gt;&gt;&gt; S = pd.Series(np.arange(100)) % 7\n&gt;&gt;&gt; f(S)\n0     0\n1     0\n2     0\n3     0\n4     0\n..\n95    0\n96    0\n97    0\n98    0\n99    0\nLength: 100, dtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriescummax","title":"<code>pd.Series.cummax</code>","text":"<ul> <li> <p><code>pandas.Series.cummax(axis=None, skipna=True)</code> Supported Arguments None</p> <p>Note</p> <ul> <li>Series type must be numeric</li> <li>Bodo does not accept any additional arguments for Numpy compatibility</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.cummax()\n&gt;&gt;&gt; S = pd.Series(np.arange(100)) % 7\n&gt;&gt;&gt; f(S)\n0     0\n1     1\n2     2\n3     3\n4     4\n..\n95    6\n96    6\n97    6\n98    6\n99    6\nLength: 100, dtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriescumprod","title":"<code>pd.Series.cumprod</code>","text":"<ul> <li> <p><code>pandas.Series.cumprod(axis=None, skipna=True)</code> Supported Arguments None</p> <p>Note</p> <ul> <li>Series type must be numeric</li> <li>Bodo does not accept any additional arguments for Numpy compatibility</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.cumprod()\n&gt;&gt;&gt; S = (pd.Series(np.arange(10)) % 7) + 1\n&gt;&gt;&gt; f(S)\n0        1\n1        2\n2        6\n3       24\n4      120\n5      720\n6     5040\n7     5040\n8    10080\n9    30240\ndtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriescumsum","title":"<code>pd.Series.cumsum</code>","text":"<ul> <li> <p><code>pandas.Series.cumsum(axis=None, skipna=True)</code> Supported Arguments None</p> <p>Note</p> <ul> <li>Series type must be numeric</li> <li>Bodo does not accept any additional arguments for Numpy compatibility</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.cumsum()\n&gt;&gt;&gt; S = pd.Series(np.arange(100)) % 7\n&gt;&gt;&gt; f(S)\n0       0\n1       1\n2       3\n3       6\n4      10\n...\n95    283\n96    288\n97    294\n98    294\n99    295\nLength: 100, dtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesdescribe","title":"<code>pd.Series.describe</code>","text":"<ul> <li> <p><code>pandas.Series.describe(percentiles=None, include=None, exclude=None, datetime_is_numeric=False)</code> Supported Arguments None</p> <p>Note</p> <p>Bodo only supports numeric and datetime64 types and assumes <code>datetime_is_numeric=True</code></p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.describe()\n&gt;&gt;&gt; S = pd.Series(np.arange(100)) % 7\n&gt;&gt;&gt; f(S)\ncount    100.000000\nmean       2.950000\nstd        2.021975\nmin        0.000000\n25%        1.000000\n50%        3.000000\n75%        5.000000\nmax        6.000000\ndtype: float64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesdiff","title":"<code>pd.Series.diff</code>","text":"<ul> <li> <p><code>pandas.Series.diff(periods=1)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>periods</code></p> <ul> <li>Integer</li> </ul> <p>Note</p> <p>Bodo only supports numeric and datetime64 types</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.diff(3)\n&gt;&gt;&gt; S = pd.Series(np.arange(100)) % 7\n&gt;&gt;&gt; f(S)\n0     NaN\n1     NaN\n2     NaN\n3     3.0\n4     3.0\n...\n95    3.0\n96    3.0\n97    3.0\n98   -4.0\n99   -4.0\nLength: 100, dtype: float64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdserieskurt","title":"<code>pd.Series.kurt</code>","text":"<ul> <li> <p><code>pandas.Series.kurt(axis=None, skipna=None, level=None, numeric_only=None)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>skipna</code></p> <ul> <li>Boolean</li> </ul> <p>Note</p> <ul> <li>Series type must be numeric</li> <li>Bodo does not accept any additional arguments to pass to the function</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.kurt()\n&gt;&gt;&gt; S = pd.Series(np.arange(100)) % 7\n&gt;&gt;&gt; f(S)\n-1.269562153611973\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesmad","title":"<code>pd.Series.mad</code>","text":"<ul> <li> <p><code>pandas.Series.mad(axis=None, skipna=None, level=None)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>skipna</code></p> <ul> <li>Boolean</li> </ul> <p>Note</p> <p>Series type must be numeric</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.mad()\n&gt;&gt;&gt; S = pd.Series(np.arange(100)) % 7\n&gt;&gt;&gt; f(S)\n1.736\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesmax","title":"<code>pd.Series.max</code>","text":"<ul> <li> <p><code>pandas.Series.max(axis=None, skipna=None, level=None, numeric_only=None)</code> Supported Arguments None</p> <p>Note</p> <ul> <li>Series type must be numeric</li> <li>Bodo does not accept any additional arguments to pass to the function</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.max()\n&gt;&gt;&gt; S = pd.Series(np.arange(100)) % 7\n&gt;&gt;&gt; f(S)\n6\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesmean","title":"<code>pd.Series.mean</code>","text":"<ul> <li> <p><code>pandas.Series.mean(axis=None, skipna=None, level=None, numeric_only=None)</code> Supported Arguments None</p> <p>Note</p> <ul> <li>Series type must be numeric</li> <li>Bodo does not accept any additional arguments to pass to the function</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.mean()\n&gt;&gt;&gt; S = pd.Series(np.arange(100)) % 7\n&gt;&gt;&gt; f(S)\n2.95\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesmedian","title":"<code>pd.Series.median</code>","text":"<ul> <li> <p><code>pandas.Series.median(axis=None, skipna=None, level=None, numeric_only=None)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>skipna</code></p> <ul> <li>Boolean</li> </ul> <p>Note</p> <ul> <li>Series type must be numeric</li> <li>Bodo does not accept any additional arguments to pass to the function</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.median()\n&gt;&gt;&gt; S = pd.Series(np.arange(100)) % 7\n&gt;&gt;&gt; f(S)\n3.0\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesmin","title":"<code>pd.Series.min</code>","text":"<ul> <li> <p><code>pandas.Series.min(axis=None, skipna=None, level=None, numeric_only=None)</code> Supported Arguments None</p> <p>Note</p> <ul> <li>Series type must be numeric</li> <li>Bodo does not accept any additional arguments to pass to the function</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.min()\n&gt;&gt;&gt; S = pd.Series(np.arange(100)) % 7\n&gt;&gt;&gt; f(S)\n0\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesnlargest","title":"<code>pd.Series.nlargest</code>","text":"<ul> <li> <p><code>pandas.Series.nlargest(n=5, keep='first')</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>n</code></p> <ul> <li>Integer</li> </ul> <p>Note</p> <p>Series type must be numeric</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.nlargest(20)\n&gt;&gt;&gt; S = pd.Series(np.arange(100)) % 7\n&gt;&gt;&gt; f(S)\n20    6\n27    6\n41    6\n34    6\n55    6\n13    6\n83    6\n90    6\n6     6\n69    6\n48    6\n76    6\n62    6\n97    6\n19    5\n5     5\n26    5\n61    5\n12    5\n68    5\ndtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesnsmallest","title":"<code>pd.Series.nsmallest</code>","text":"<ul> <li> <p><code>pandas.Series.nsmallest(n=5, keep='first')</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>n</code></p> <ul> <li>Integer</li> </ul> <p>Note</p> <p>Series type must be numeric</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.nsmallest(20)\n&gt;&gt;&gt; S = pd.Series(np.arange(100)) % 7\n&gt;&gt;&gt; f(S)\n63    0\n7     0\n56    0\n98    0\n77    0\n91    0\n49    0\n42    0\n35    0\n84    0\n28    0\n21    0\n70    0\n0     0\n14    0\n43    1\n1     1\n57    1\n15    1\n36    1\ndtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriespct_change","title":"<code>pd.Series.pct_change</code>","text":"<ul> <li> <p><code>pandas.Series.pct_change(periods=1, fill_method='pad', limit=None, freq=None)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>periods</code></p> <ul> <li>Integer</li> </ul> <p>Note</p> <ul> <li>Series type must be numeric</li> <li>Bodo does not accept any additional arguments to pass to shift</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.pct_change(3)\n&gt;&gt;&gt; S = (pd.Series(np.arange(100)) % 7) + 1\n&gt;&gt;&gt; f(S)\n0          NaN\n1          NaN\n2          NaN\n3     3.000000\n4     1.500000\n...\n95    1.500000\n96    1.000000\n97    0.750000\n98   -0.800000\n99   -0.666667\nLength: 100, dtype: float64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesprod","title":"<code>pd.Series.prod</code>","text":"<ul> <li> <p><code>pandas.Series.prod(axis=None, skipna=None, level=None, numeric_only=None)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>skipna</code></p> <ul> <li>Boolean</li> </ul> <p>Note</p> <ul> <li>Series type must be numeric</li> <li>Bodo does not accept any additional arguments to pass to the function</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.prod()\n&gt;&gt;&gt; S = (pd.Series(np.arange(20)) % 3) + 1\n&gt;&gt;&gt; f(S)\n93312\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesproduct","title":"<code>pd.Series.product</code>","text":"<ul> <li> <p><code>pandas.Series.product(axis=None, skipna=None, level=None, numeric_only=None)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>skipna</code></p> <ul> <li>Boolean</li> </ul> <p>Note</p> <ul> <li>Series type must be numeric</li> <li>Bodo does not accept any additional arguments to pass to the function</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.product()\n&gt;&gt;&gt; S = (pd.Series(np.arange(20)) % 3) + 1\n&gt;&gt;&gt; f(S)\n93312\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesquantile","title":"<code>pd.Series.quantile</code>","text":"<ul> <li> <p><code>pandas.Series.quantile(q=0.5, interpolation='linear')</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>q</code> </p> <ul> <li>Float in [0.0, 1.0]</li> <li>Iterable of floats in [0.0, 1.0]</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.quantile([0.25, 0.5, 0.75])\n&gt;&gt;&gt; S = pd.Series(np.arange(100)) % 7\n&gt;&gt;&gt; f(S)\n0.25    1.0\n0.50    3.0\n0.75    5.0\ndtype: float64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesrank","title":"<code>pd.Series.rank</code>","text":"<ul> <li> <p><code>pandas.Series.rank(axis=0, method='average', numeric_only=NoDefault.no_default, na_option='keep', ascending=True, pct=False)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>method</code></p> <ul> <li>String in {'average', 'min', 'max', 'first', 'dense'}</li> </ul> <p><code>na_option</code></p> <ul> <li>String in {'keep', 'top', 'bottom'}</li> </ul> <p><code>ascending</code></p> <ul> <li>Boolean</li> </ul> <p><code>pct</code></p> <ul> <li>Boolean</li> </ul> <p>Note</p> <ul> <li>Using <code>method='first'</code>  with <code>ascending=False</code> is currently unsupported.</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.rank(method='dense', na_option='bottom', pct=True)\n&gt;&gt;&gt; S = pd.Series([np.nan, 4, 2, 4, 8, np.nan])\n&gt;&gt;&gt; f(S)\n0    1.00\n1    0.50\n2    0.25\n3    0.50\n4    0.75\n5    1.00\ndtype: float64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriessem","title":"<code>pd.Series.sem</code>","text":"<ul> <li> <p><code>pandas.Series.sem(axis=None, skipna=None, level=None, ddof=1, numeric_only=None)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>skipna</code></p> <ul> <li>Boolean</li> </ul> <p><code>ddof</code></p> <ul> <li>Integer</li> </ul> <p>Note</p> <ul> <li>Series type must be numeric</li> <li>Bodo does not accept any additional arguments to pass to the function</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.sem()\n&gt;&gt;&gt; S = pd.Series(np.arange(100)) % 7\n&gt;&gt;&gt; f(S)\n0.20219752318917852\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesskew","title":"<code>pd.Series.skew</code>","text":"<ul> <li> <p><code>pandas.Series.skew(axis=None, skipna=None, level=None, numeric_only=None)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>skipna</code></p> <ul> <li>Boolean</li> </ul> <p>Note</p> <ul> <li>Series type must be numeric</li> <li>Bodo does not accept any additional arguments to pass to the function</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.skew()\n&gt;&gt;&gt; S = pd.Series(np.arange(100)) % 7\n&gt;&gt;&gt; f(S)\n0.032074996591991714\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstd","title":"<code>pd.Series.std</code>","text":"<ul> <li> <p><code>pandas.Series.std(axis=None, skipna=None, level=None, ddof=1, numeric_only=None)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>skipna</code></p> <ul> <li>Boolean</li> </ul> <p><code>ddof</code></p> <ul> <li>Integer</li> </ul> <p>Note</p> <ul> <li>Series type must be numeric</li> <li>Bodo does not accept any additional arguments to pass to the function</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.std()\n&gt;&gt;&gt; S = pd.Series(np.arange(100)) % 7\n&gt;&gt;&gt; f(S)\n2.021975231891785\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriessum","title":"<code>pd.Series.sum</code>","text":"<ul> <li> <p><code>pandas.Series.sum(axis=None, skipna=None, level=None, numeric_only=None, min_count=0)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>skipna</code></p> <ul> <li>Boolean</li> </ul> <p><code>min_count</code></p> <ul> <li>Integer</li> </ul> <p>Note</p> <ul> <li>Series type must be numeric</li> <li>Bodo does not accept any additional arguments to pass to the function</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.sum()\n&gt;&gt;&gt; S = pd.Series(np.arange(100)) % 7\n&gt;&gt;&gt; f(S)\n295\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesvar","title":"<code>pd.Series.var</code>","text":"<ul> <li> <p><code>pandas.Series.var(axis=None, skipna=None, level=None, ddof=1, numeric_only=None)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>skipna</code></p> <ul> <li>Boolean</li> </ul> <p><code>ddof</code></p> <ul> <li>Integer</li> </ul> <p>Note</p> <ul> <li>Series type must be numeric</li> <li>Bodo does not accept any additional arguments to pass to the function</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.var()\n&gt;&gt;&gt; S = pd.Series(np.arange(100)) % 7\n&gt;&gt;&gt; f(S)\n4.088383838383838\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdserieskurtosis","title":"<code>pd.Series.kurtosis</code>","text":"<ul> <li> <p><code>pandas.Series.kurtosis(axis=None, skipna=None, level=None, numeric_only=None)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>skipna</code></p> <ul> <li>Boolean</li> </ul> <p>Note</p> <ul> <li>Series type must be numeric</li> <li>Bodo does not accept any additional arguments to pass to the function</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.kurtosis()\n&gt;&gt;&gt; S = pd.Series(np.arange(100)) % 7\n&gt;&gt;&gt; f(S)\n-1.269562153611973\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesunique","title":"<code>pd.Series.unique</code>","text":"<ul> <li> <p><code>pandas.Series.unique()</code> </p> <p>Note</p> <p>The output is assumed to be \"small\" relative to input and is replicated. Use <code>Series.drop_duplicates()</code> if the output should remain distributed.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.unique()\n&gt;&gt;&gt; S = pd.Series(np.arange(100)) % 7\n&gt;&gt;&gt; f(S)\n[0 1 2 3 4 5 6]\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesnunique","title":"<code>pd.Series.nunique</code>","text":"<ul> <li> <p><code>pandas.Series.nunique(dropna=True)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>dropna</code></p> <ul> <li>Boolean</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.nunique()\n&gt;&gt;&gt; S = pd.Series(np.arange(100)) % 7\n&gt;&gt;&gt; f(S)\n7\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesis_monotonic","title":"<code>pd.Series.is_monotonic</code>","text":"<ul> <li> <p><code>++pandas.Series.is_monotonic</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.is_monotonic\n&gt;&gt;&gt; S = pd.Series(np.arange(100))\n&gt;&gt;&gt; f(S)\nTrue\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesis_monotonic_increasing","title":"<code>pd.Series.is_monotonic_increasing</code>","text":"<ul> <li> <p><code>++pandas.Series.is_monotonic_increasing</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.is_monotonic_increasing\n&gt;&gt;&gt; S = pd.Series(np.arange(100))\n&gt;&gt;&gt; f(S)\nTrue\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesis_monotonic_decreasing","title":"<code>pd.Series.is_monotonic_decreasing</code>","text":"<ul> <li> <p><code>++pandas.Series.is_monotonic_decreasing</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.is_monotonic_decreasing\n&gt;&gt;&gt; S = pd.Series(np.arange(100))\n&gt;&gt;&gt; f(S)\nFalse\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesvalue_counts","title":"<code>pd.Series.value_counts</code>","text":"<ul> <li> <p><code>pandas.Series.value_counts(normalize=False, sort=True, ascending=False, bins=None, dropna=True)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p>other requirements</p> <p><code>normalize</code> </p> <ul> <li>Boolean </li> </ul> <ul> <li>Must be constant at     Compile Time</li> </ul> <p><code>sort</code> </p> <ul> <li>Boolean </li> </ul> <ul> <li>Must be constant at     Compile Time</li> </ul> <p><code>ascending</code></p> <ul> <li>Boolean</li> </ul> <p><code>bins</code></p> <ul> <li>Integer</li> <li>Array-like of     integers</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.value_counts()\n&gt;&gt;&gt; S = pd.Series(np.arange(100)) % 7\n&gt;&gt;&gt; f(S)\n0    15\n1    15\n2    14\n3    14\n4    14\n5    14\n6    14\ndtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#reindexing-selection-label-manipulation","title":"Reindexing / Selection / Label manipulation","text":""},{"location":"api_docs/pandas/series/#pdseriesdrop_duplicates","title":"<code>pd.Series.drop_duplicates</code>","text":"<ul> <li> <p><code>pandas.Series.drop_duplicates(keep='first', inplace=False)</code> Supported Arguments None</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.drop_duplicates()\n&gt;&gt;&gt; S = pd.Series(np.arange(100)) % 10\n&gt;&gt;&gt; f(S)\n0    0\n1    1\n2    2\n3    3\n4    4\n5    5\n6    6\n7    7\n8    8\n9    9\ndtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesduplicated","title":"<code>pd.Series.duplicated</code>","text":"<ul> <li> <p><code>pandas.Series.duplicated(keep='first')</code> Supported Arguments None</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...  return S.duplicated()\n&gt;\n&gt;&gt;&gt; S = pd.Series([1, 2, 1, np.nan, 3, 2, np.nan, 4])\n0    False\n1    False\n2     True\n3    False\n4    False\n5     True\n6     True\n7    False\ndtype: bool\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesequals","title":"<code>pd.Series.equals</code>","text":"<ul> <li> <p><code>pandas.Series.equals(other)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>other</code></p> <ul> <li>Series</li> </ul> <p>Note</p> <p>Series and <code>other</code> must contain scalar values in each row</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S, other):\n...     return S.equals(other)\n&gt;&gt;&gt; S = pd.Series(np.arange(100)) % 10\n&gt;&gt;&gt; other = pd.Series(np.arange(100)) % 5\n&gt;&gt;&gt; f(S, other)\nFalse\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesfirst","title":"<code>pd.Series.first</code>","text":"<ul> <li> <p><code>pandas.Series.first(offset)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p>other requirements</p> <p><code>offset</code></p> <ul> <li>String or Offset     type</li> </ul> <ul> <li>String argument be a     valid frequency     alias</li> </ul> <p>Note</p> <p>Series must have a valid DatetimeIndex and is assumed to already be sorted. This function have undefined behavior if the DatetimeIndex is not sorted.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S, offset):\n...     return S.first(offset)\n&gt;&gt;&gt; S = pd.Series(np.arange(100), index=pd.date_range(start='1/1/2022', end='12/31/2024', periods=100))\n&gt;&gt;&gt; f(S, \"2M\")\n2022-01-01 00:00:00.000000000    0\n2022-01-12 01:27:16.363636363    1\n2022-01-23 02:54:32.727272727    2\n2022-02-03 04:21:49.090909091    3\n2022-02-14 05:49:05.454545454    4\n2022-02-25 07:16:21.818181818    5\ndtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdserieshead","title":"<code>pd.Series.head</code>","text":"<ul> <li> <p><code>pandas.Series.head(n=5)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>n</code></p> <ul> <li>Integer</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.head(10)\n&gt;&gt;&gt; S = pd.Series(np.arange(100))\n&gt;&gt;&gt; f(S)\n0    0\n1    1\n2    2\n3    3\n4    4\n5    5\n6    6\n7    7\n8    8\n9    9\ndtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesidxmax","title":"<code>pd.Series.idxmax</code>","text":"<ul> <li> <p><code>pandas.Series.idxmax(axis=0, skipna=True)</code> Supported Arguments None</p> <p>Note</p> <p>Bodo does not accept any additional arguments for Numpy compatibility</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.idxmax()\n&gt;&gt;&gt; S = pd.Series(np.arange(100))\n&gt;&gt;&gt; S[(S % 3 == 0)] = 100\n&gt;&gt;&gt; f(S)\n0\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesidxmin","title":"<code>pd.Series.idxmin</code>","text":"<ul> <li> <p><code>pandas.Series.idxmin(axis=0, skipna=True)</code> Supported Arguments None</p> <p>Note</p> <p>Bodo does not accept any additional arguments for Numpy compatibility</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.idxmin()\n&gt;&gt;&gt; S = pd.Series(np.arange(100))\n&gt;&gt;&gt; S[(S % 3 == 0)] = 100\n&gt;&gt;&gt; f(S)\n1\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesisin","title":"<code>pd.Series.isin</code>","text":"<ul> <li> <p><code>pandas.Series.isin(values)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>values</code></p> <ul> <li>Series</li> <li>Array</li> <li>List</li> </ul> <p>Note</p> <p><code>values</code> argument supports both distributed array/Series and replicated list/array/Series</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.isin([3, 11, 98])\n&gt;&gt;&gt; S = pd.Series(np.arange(100))\n&gt;&gt;&gt; f(S)\n0     False\n1     False\n2     False\n3      True\n4     False\n...\n95    False\n96    False\n97    False\n98     True\n99    False\nLength: 100, dtype: bool\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdserieslast","title":"<code>pd.Series.last</code>","text":"<ul> <li> <p><code>pandas.Series.last(offset)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p>other requirements</p> <p><code>offset</code></p> <ul> <li>String or Offset     type</li> </ul> <ul> <li>String argument be a     valid frequency     alias</li> </ul> <p>Note</p> <p>Series must have a valid DatetimeIndex and is assumed to already be sorted. This function have undefined behavior if the DatetimeIndex is not sorted.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S, offset):\n...     return S.last(offset)\n&gt;&gt;&gt; S = pd.Series(np.arange(100), index=pd.date_range(start='1/1/2022', end='12/31/2024', periods=100))\n&gt;&gt;&gt; f(S, \"2M\")\n2024-11-05 16:43:38.181818176    94\n2024-11-16 18:10:54.545454544    95\n2024-11-27 19:38:10.909090912    96\n2024-12-08 21:05:27.272727264    97\n2024-12-19 22:32:43.636363632    98\n2024-12-31 00:00:00.000000000    99\ndtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesrename","title":"<code>pd.Series.rename</code>","text":"<ul> <li> <p><code>pandas.Series.rename(index=None, , axis=None, copy=True, inplace=False, level=None, errors='ignore')      ***Supported Arguments** <p>argument</p> <p>datatypes</p> <p><code>index</code></p> <ul> <li>String</li> </ul> <p><code>axis</code></p> <ul> <li>Any value. Bodo ignores this     argument entirely, which is     consistent with Pandas.</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.rename(\"a\")\n&gt;&gt;&gt; S = pd.Series(np.arange(100))\n&gt;&gt;&gt; f(S)\n0      0\n1      1\n2      2\n3      3\n4      4\n..\n95    95\n96    96\n97    97\n98    98\n99    99\nName: a, Length: 100, dtype: int64\n</code></pre>"},{"location":"api_docs/pandas/series/#pdseriesreset_index","title":"<code>pd.Series.reset_index</code>","text":"<ul> <li> <p><code>pandas.Series.reset_index(level=None, drop=False, name=None, inplace=False)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p>other requirements</p> <p><code>level</code> </p> <ul> <li>Integer</li> <li>Boolean</li> </ul> <ul> <li>Must be constant at     Compile Time</li> </ul> <p><code>drop</code></p> <ul> <li>Boolean</li> </ul> <ul> <li>Must be constant at     Compile Time</li> <li>If <code>False</code>, Index     name must be known at     compilation time</li> </ul> <p>Note</p> <p>For MultiIndex case, only dropping all levels is supported.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.reset_index()\n&gt;&gt;&gt; S = pd.Series(np.arange(100), index=pd.RangeIndex(100, 200, 1, name=\"b\"))\n&gt;&gt;&gt; f(S)\nb   0\n0   100   0\n1   101   1\n2   102   2\n3   103   3\n4   104   4\n..  ...  ..\n95  195  95\n96  196  96\n97  197  97\n98  198  98\n99  199  99\n&gt;\n[100 rows x 2 columns]\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriestake","title":"<code>pd.Series.take</code>","text":"<ul> <li> <p><code>pandas.Series.take(indices, axis=0, is_copy=None)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p>other requirements</p> <p><code>indices</code></p> <ul> <li>Array like with     integer data</li> </ul> <ul> <li>To have distributed     data <code>indices</code> must     be an array with the     same distribution as     S.</li> </ul> <p>Note</p> <p>Bodo does not accept any additional arguments for Numpy compatibility</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.take([2, 7, 4, 19])\n&gt;&gt;&gt; S = pd.Series(np.arange(100))\n&gt;&gt;&gt; f(S)\n2      2\n7      7\n4      4\n19    19\ndtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriestail","title":"<code>pd.Series.tail</code>","text":"<ul> <li> <p><code>pandas.Series.tail(n=5)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>n</code></p> <ul> <li>Integer</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.tail(10)\n&gt;&gt;&gt; S = pd.Series(np.arange(100))\n&gt;&gt;&gt; f(S)\n90    90\n91    91\n92    92\n93    93\n94    94\n95    95\n96    96\n97    97\n98    98\n99    99\ndtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdserieswhere","title":"<code>pd.Series.where</code>","text":"<ul> <li> <p><code>pandas.Series.where(cond, other=nan, inplace=False, axis=None, level=None, errors='raise', try_cast=NoDefault.no_default)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>cond</code> </p> <ul> <li>boolean array</li> <li>1d bool numpy array</li> </ul> <p><code>other</code> </p> <ul> <li>1d numpy array</li> <li>scalar</li> </ul> <p>Note</p> <p>Series can contain categorical data if <code>other</code> is a scalar</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.where((S % 3) != 0, 0)\n&gt;&gt;&gt; S = pd.Series(np.arange(100))\n&gt;&gt;&gt; f(S)\n0      0\n1      1\n2      2\n3      0\n4      4\n..\n95    95\n96     0\n97    97\n98    98\n99     0\nLength: 100, dtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesmask","title":"<code>pd.Series.mask</code>","text":"<ul> <li> <p><code>pandas.Series.mask(cond, other=nan, inplace=False, axis=None, level=None, errors='raise', try_cast=NoDefault.no_default)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>cond</code> </p> <ul> <li>boolean array</li> <li>1d bool numpy array</li> </ul> <p><code>other</code> </p> <ul> <li>1d numpy array</li> <li>scalar</li> </ul> <p>Note</p> <p>Series can contain categorical data if <code>other</code> is a scalar</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.mask((S % 3) != 0, 0)\n&gt;&gt;&gt; S = pd.Series(np.arange(100))\n&gt;&gt;&gt; f(S)\n0      0\n1      0\n2      0\n3      3\n4      0\n..\n95     0\n96    96\n97     0\n98     0\n99    99\nLength: 100, dtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#missing-data-handling","title":"Missing data handling","text":""},{"location":"api_docs/pandas/series/#pdseriesbackfill","title":"<code>pd.Series.backfill</code>","text":"<ul> <li> <p><code>pandas.Series.backfill(axis=None, inplace=False, limit=None, downcast=None)</code> Supported Arguments None</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.backfill()\n&gt;&gt;&gt; S = pd.Series(pd.array([None, 1, None, -2, None, 5, None]))\n&gt;&gt;&gt; f(S)\n0       1\n1       1\n2      -2\n3      -2\n4       5\n5       5\n6    &lt;NA&gt;\ndtype: Int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesbfill","title":"<code>pd.Series.bfill</code>","text":"<ul> <li> <p><code>pandas.Series.bfill(axis=None, inplace=False, limit=None, downcast=None)</code> Supported Arguments None</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.bfill()\n&gt;&gt;&gt; S = pd.Series(pd.array([None, 1, None, -2, None, 5, None]))\n&gt;&gt;&gt; f(S)\n0       1\n1       1\n2      -2\n3      -2\n4       5\n5       5\n6    &lt;NA&gt;\ndtype: Int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesdropna","title":"<code>pd.Series.dropna</code>","text":"<ul> <li> <p><code>pandas.Series.dropna(axis=0, inplace=False, how=None)</code> Supported Arguments None</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.dropna()\n&gt;&gt;&gt; S = pd.Series(pd.array([None, 1, None, -2, None, 5, None]))\n&gt;&gt;&gt; f(S)\n1     1\n3    -2\n5     5\ndtype: Int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesffill","title":"<code>pd.Series.ffill</code>","text":"<ul> <li> <p><code>pandas.Series.ffill(axis=None, inplace=False, limit=None, downcast=None)</code> Supported Arguments None</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.ffill()\n&gt;&gt;&gt; S = pd.Series(pd.array([None, 1, None, -2, None, 5, None]))\n&gt;&gt;&gt; f(S)\n0    &lt;NA&gt;\n1       1\n2       1\n3      -2\n4      -2\n5       5\n6       5\ndtype: Int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesfillna","title":"<code>pd.Series.fillna</code>","text":"<ul> <li> <p><code>pandas.Series.fillna(value=None, method=None, axis=None, inplace=False, limit=None, downcast=None)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p>other requirements</p> <p><code>value</code></p> <ul> <li>Scalar</li> </ul> <p><code>method</code></p> <ul> <li>One of (\"bfill\",     \"backfill\",     \"ffill\", and     \"pad\")</li> </ul> <ul> <li>Must be constant at     Compile Time</li> </ul> <p><code>inplace</code> </p> <ul> <li>Boolean </li> </ul> <ul> <li>Must be constant at     Compile Time</li> </ul> <ul> <li>If <code>value</code> is provided then <code>method</code> must be <code>None</code> and     vice-versa</li> <li>If <code>method</code> is provided then <code>inplace</code> must be <code>False</code></li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.fillna(-1)\n&gt;&gt;&gt; S = pd.Series(pd.array([None, 1, None, -2, None, 5, None]))\n&gt;&gt;&gt; f(S)\n0    -1\n1     1\n2    -1\n3    -2\n4    -1\n5     5\n6    -1\ndtype: Int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesisna","title":"<code>pd.Series.isna</code>","text":"<ul> <li> <p><code>pandas.Series.isna()</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.isna()\n&gt;&gt;&gt; S = pd.Series(pd.array([None, 1, None, -2, None, 5, None]))\n&gt;&gt;&gt; f(S)\n0     True\n1    False\n2     True\n3    False\n4     True\n5    False\n6     True\ndtype: bool\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesisnull","title":"<code>pd.Series.isnull</code>","text":"<ul> <li> <p><code>pandas.Series.isnull()</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.isnull()\n&gt;&gt;&gt; S = pd.Series(pd.array([None, 1, None, -2, None, 5, None]))\n&gt;&gt;&gt; f(S)\n0     True\n1    False\n2     True\n3    False\n4     True\n5    False\n6     True\ndtype: bool\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesnotna","title":"<code>pd.Series.notna</code>","text":"<ul> <li> <p><code>pandas.Series.notna()</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.notna()\n&gt;&gt;&gt; S = pd.Series(pd.array([None, 1, None, -2, None, 5, None]))\n&gt;&gt;&gt; f(S)\n0    False\n1     True\n2    False\n3     True\n4    False\n5     True\n6    False\ndtype: bool\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesnotnull","title":"<code>pd.Series.notnull</code>","text":"<ul> <li> <p><code>pandas.Series.notnull()</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.notnull()\n&gt;&gt;&gt; S = pd.Series(pd.array([None, 1, None, -2, None, 5, None]))\n&gt;&gt;&gt; f(S)\n0    False\n1     True\n2    False\n3     True\n4    False\n5     True\n6    False\ndtype: bool\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriespad","title":"<code>pd.Series.pad</code>","text":"<ul> <li> <p><code>pandas.Series.pad(axis=None, inplace=False, limit=None, downcast=None)</code> Supported Arguments None</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.pad()\n&gt;&gt;&gt; S = pd.Series(pd.array([None, 1, None, -2, None, 5, None]))\n&gt;&gt;&gt; f(S)\n0    &lt;NA&gt;\n1       1\n2       1\n3      -2\n4      -2\n5       5\n6       5\ndtype: Int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesreplace","title":"<code>pd.Series.replace</code>","text":"<ul> <li> <p><code>pandas.Series.replace(to_replace=None, value=None, inplace=False, limit=None, regex=False, method='pad')</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p>other requirements</p> <p><code>to_replace</code></p> <ul> <li>Scalar</li> <li>List of Scalars</li> <li>Dictionary mapping     scalars of the     same type</li> </ul> <p><code>value</code></p> <ul> <li>Scalar</li> </ul> <p>If <code>to_replace</code> is not a scalar, value must be <code>None</code></p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S, replace_dict):\n...     return S.replace(replace_dict)\n&gt;&gt;&gt; S = pd.Series(pd.array([None, 1, None, -2, None, 5, None]))\n&gt;&gt;&gt; f(S, {1: -2, -2: 5, 5: 27})\n0    &lt;NA&gt;\n1      -2\n2    &lt;NA&gt;\n3       5\n4    &lt;NA&gt;\n5      27\n6    &lt;NA&gt;\ndtype: Int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#reshaping-sorting","title":"Reshaping, sorting","text":""},{"location":"api_docs/pandas/series/#pdseriesargsort","title":"<code>pd.Series.argsort</code>","text":"<ul> <li> <p><code>pandas.Series.argsort(axis=0, kind='quicksort', order=None)</code> Supported Arguments None</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.sort_values()\n&gt;&gt;&gt; S = pd.Series(np.arange(99, -1, -1), index=np.arange(100))\n&gt;&gt;&gt; f(S)\n0     99\n1     98\n2     97\n3     96\n4     95\n..\n95     4\n96     3\n97     2\n98     1\n99     0\nLength: 100, dtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriessort_values","title":"<code>pd.Series.sort_values</code>","text":"<ul> <li> <p><code>pandas.Series.sort_values(axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last', ignore_index=False, key=None)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p>other requirements</p> <p><code>ascending</code></p> <ul> <li>Boolean</li> </ul> <p><code>na_position</code> </p> <ul> <li>One of (\"first\",     \"last\")</li> </ul> <p>Must be constant at Compile Time</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.sort_values()\n&gt;&gt;&gt; S = pd.Series(np.arange(99, -1, -1), index=np.arange(100))\n&gt;&gt;&gt; f(S)\n99     0\n98     1\n97     2\n96     3\n95     4\n..\n4     95\n3     96\n2     97\n1     98\n0     99\nLength: 100, dtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriessort_index","title":"<code>pd.Series.sort_index</code>","text":"<ul> <li> <p><code>pandas.Series.sort_index(axis=0, level=None, ascending=True, inplace=False, kind='quicksort', na_position='last', sort_remaining=True, ignore_index=False, key=None)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p>other requirements</p> <p><code>ascending</code></p> <ul> <li>Boolean</li> </ul> <p><code>na_position</code> </p> <ul> <li>One of (\"first\",     \"last\")</li> </ul> <p>Must be constant at Compile Time</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.sort_index()\n&gt;&gt;&gt; S = pd.Series(np.arange(100), index=np.arange(99, -1, -1))\n&gt;&gt;&gt; f(S)\n0     99\n1     98\n2     97\n3     96\n4     95\n..\n95     4\n96     3\n97     2\n98     1\n99     0\nLength: 100, dtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesexplode","title":"<code>pd.Series.explode</code>","text":"<ul> <li> <p><code>pandas.Series.explode(ignore_index=False)</code> Supported Arguments None</p> <p>Note</p> <p>Bodo's output type may differ from Pandas because Bodo must convert to a nullable type at compile time.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.explode()\n&gt;&gt;&gt; S = pd.Series([np.arange(i) for i in range(10)])\n&gt;&gt;&gt; f(S)\n0    &lt;NA&gt;\n1       0\n2       0\n2       1\n3       0\n3       1\n3       2\n4       0\n4       1\n4       2\n4       3\n5       0\n5       1\n5       2\n5       3\n5       4\n6       0\n6       1\n6       2\n6       3\n6       4\n6       5\n7       0\n7       1\n7       2\n7       3\n7       4\n7       5\n7       6\n8       0\n8       1\n8       2\n8       3\n8       4\n8       5\n8       6\n8       7\n9       0\n9       1\n9       2\n9       3\n9       4\n9       5\n9       6\n9       7\n9       8\ndtype: Int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesrepeat","title":"<code>pd.Series.repeat</code>","text":"<ul> <li> <p><code>pandas.Series.repeat(repeats, axis=None)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>repeats</code></p> <ul> <li>Integer</li> <li>Array-like of integers the same     length as the Series</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.repeat(3)\n&gt;&gt;&gt; S = pd.Series(np.arange(100))\n&gt;&gt;&gt; f(S)\n0      0\n0      0\n0      0\n1      1\n1      1\n..\n98    98\n98    98\n99    99\n99    99\n99    99\nLength: 300, dtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#combining-comparing-joining-merging","title":"Combining / comparing / joining / merging","text":""},{"location":"api_docs/pandas/series/#pdseriesappend","title":"<code>pd.Series.append</code>","text":"<ul> <li> <p><code>pandas.Series.append(to_append, ignore_index=False, verify_integrity=False)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p>other requirements</p> <p><code>to_append</code></p> <ul> <li>Series</li> <li>List of Series</li> <li>Tuple of Series</li> </ul> <p><code>ignore_index</code> </p> <ul> <li>Boolean </li> </ul> <p>Must be constant at Compile Time</p> <p>Note</p> <p>Setting a name for the output Series is not supported yet</p> <p>Important</p> <p>Bodo currently concatenates local data chunks for distributed datasets, which does not preserve global order of concatenated objects in output.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S1, S2):\n...     return S1.append(S2)\n&gt;&gt;&gt; S = pd.Series(np.arange(100))\n&gt;&gt;&gt; f(S, S)\n0      0\n1      1\n2      2\n3      3\n4      4\n..\n95    95\n96    96\n97    97\n98    98\n99    99\nLength: 200, dtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#time-series-related","title":"Time series-related","text":""},{"location":"api_docs/pandas/series/#pdseriesshift","title":"<code>pd.Series.shift</code>","text":"<ul> <li> <p><code>pandas.Series.shift(periods=1, freq=None, axis=0, fill_value=None)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>periods</code></p> <ul> <li>Integer</li> </ul> <p>Note</p> <p>This data type for the series must be one of: -   Integer -   Float -   Boolean -   datetime.data -   datetime64 -   timedelta64 -   string</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.shift(1)\n&gt;&gt;&gt; S = pd.Series(np.arange(100))\n&gt;&gt;&gt; f(S)\n0      NaN\n1      0.0\n2      1.0\n3      2.0\n4      3.0\n...\n95    94.0\n96    95.0\n97    96.0\n98    97.0\n99    98.0\nLength: 100, dtype: float64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#datetime-properties","title":"Datetime properties","text":""},{"location":"api_docs/pandas/series/#pdseriesdtdate","title":"`pd.Series.dt.date","text":"<ul> <li> <p><code>++pandas.Series.dt.date</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.dt.date\n&gt;&gt;&gt; S = pd.Series(pd.date_range(start='1/1/2022', end='1/10/2022', periods=30))\n&gt;&gt;&gt; f(S)\n0     2022-01-01\n1     2022-01-01\n2     2022-01-01\n3     2022-01-01\n4     2022-01-02\n5     2022-01-02\n6     2022-01-02\n7     2022-01-03\n8     2022-01-03\n9     2022-01-03\n10    2022-01-04\n11    2022-01-04\n12    2022-01-04\n13    2022-01-05\n14    2022-01-05\n15    2022-01-05\n16    2022-01-05\n17    2022-01-06\n18    2022-01-06\n19    2022-01-06\n20    2022-01-07\n21    2022-01-07\n22    2022-01-07\n23    2022-01-08\n24    2022-01-08\n25    2022-01-08\n26    2022-01-09\n27    2022-01-09\n28    2022-01-09\n29    2022-01-10\ndtype: object\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesdtyear","title":"<code>pd.Series.dt.year</code>","text":"<ul> <li> <p><code>pandas.Series.dt.year</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.dt.year\n&gt;&gt;&gt; S = pd.Series(pd.date_range(start='1/1/2022', end='1/10/2025', periods=30))\n&gt;&gt;&gt; f(S)\n0     2022\n1     2022\n2     2022\n3     2022\n4     2022\n5     2022\n6     2022\n7     2022\n8     2022\n9     2022\n10    2023\n11    2023\n12    2023\n13    2023\n14    2023\n15    2023\n16    2023\n17    2023\n18    2023\n19    2023\n20    2024\n21    2024\n22    2024\n23    2024\n24    2024\n25    2024\n26    2024\n27    2024\n28    2024\n29    2025\ndtype: Int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesdtmonth","title":"<code>pd.Series.dt.month</code>","text":"<ul> <li> <p><code>pandas.Series.dt.month</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.dt.month\n&gt;&gt;&gt; S = pd.Series(pd.date_range(start='1/1/2022', end='1/10/2025', periods=30))\n&gt;&gt;&gt; f(S)\n0      1\n1      2\n2      3\n3      4\n4      6\n5      7\n6      8\n7      9\n8     11\n9     12\n10     1\n11     2\n12     4\n13     5\n14     6\n15     7\n16     9\n17    10\n18    11\n19    12\n20     2\n21     3\n22     4\n23     5\n24     7\n25     8\n26     9\n27    10\n28    12\n29     1\ndtype: Int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesdtday","title":"<code>pd.Series.dt.day</code>","text":"<ul> <li> <p><code>pandas.Series.dt.day</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.dt.day\n&gt;&gt;&gt; S = pd.Series(pd.date_range(start='1/1/2022', end='1/10/2025', periods=30))\n&gt;&gt;&gt; f(S)\n0      1\n1      8\n2     18\n3     25\n4      2\n5     10\n6     17\n7     24\n8      1\n9      9\n10    17\n11    24\n12     3\n13    11\n14    18\n15    26\n16     2\n17    10\n18    17\n19    25\n20     2\n21    11\n22    18\n23    26\n24     3\n25    10\n26    17\n27    25\n28     2\n29    10\ndtype: Int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesdthour","title":"<code>pd.Series.dt.hour</code>","text":"<ul> <li> <p><code>pandas.Series.dt.hour</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.dt.hour\n&gt;&gt;&gt; S = pd.Series(pd.date_range(start='1/1/2022', end='1/10/2025', periods=30))\n&gt;&gt;&gt; f(S)\n0      0\n1      2\n2      4\n3      7\n4      9\n5     12\n6     14\n7     17\n8     19\n9     22\n10     0\n11     3\n12     5\n13     8\n14    10\n15    13\n16    15\n17    18\n18    20\n19    23\n20     1\n21     4\n22     6\n23     9\n24    11\n25    14\n26    16\n27    19\n28    21\n29     0\ndtype: Int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesdtminute","title":"<code>pd.Series.dt.minute</code>","text":"<ul> <li> <p><code>pandas.Series.dt.minute</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.dt.minute\n&gt;&gt;&gt; S = pd.Series(pd.date_range(start='1/1/2022', end='1/10/2025', periods=30))\n&gt;&gt;&gt; f(S)\n0      0\n1     28\n2     57\n3     26\n4     55\n5     24\n6     53\n7     22\n8     51\n9     20\n10    49\n11    18\n12    47\n13    16\n14    45\n15    14\n16    43\n17    12\n18    41\n19    10\n20    39\n21     8\n22    37\n23     6\n24    35\n25     4\n26    33\n27     2\n28    31\n29     0\ndtype: Int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesdtsecond","title":"<code>pd.Series.dt.second</code>","text":"<ul> <li> <p><code>pandas.Series.dt.second</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.dt.second\n&gt;&gt;&gt; S = pd.Series(pd.date_range(start='1/1/2022', end='1/10/2025', periods=30))\n&gt;&gt;&gt; f(S)\n0      0\n1     57\n2     55\n3     53\n4     51\n5     49\n6     47\n7     45\n8     43\n9     41\n10    39\n11    37\n12    35\n13    33\n14    31\n15    28\n16    26\n17    24\n18    22\n19    20\n20    18\n21    16\n22    14\n23    12\n24    10\n25     8\n26     6\n27     4\n28     2\n29     0\ndtype: Int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesdtmicrosecond","title":"<code>pd.Series.dt.microsecond</code>","text":"<ul> <li> <p><code>pandas.Series.dt.microsecond</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.dt.microsecond\n&gt;&gt;&gt; S = pd.Series(pd.date_range(start='1/1/2022', end='1/10/2025', periods=30))\n&gt;&gt;&gt; f(S)\n0          0\n1     931034\n2     862068\n3     793103\n4     724137\n5     655172\n6     586206\n7     517241\n8     448275\n9     379310\n10    310344\n11    241379\n12    172413\n13    103448\n14     34482\n15    965517\n16    896551\n17    827586\n18    758620\n19    689655\n20    620689\n21    551724\n22    482758\n23    413793\n24    344827\n25    275862\n26    206896\n27    137931\n28     68965\n29         0\ndtype: Int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesdtnanosecond","title":"<code>pd.Series.dt.nanosecond</code>","text":"<ul> <li> <p><code>pandas.Series.dt.nanosecond</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.dt.nanosecond\n&gt;&gt;&gt; S = pd.Series(pd.date_range(start='1/1/2022', end='1/10/2025', periods=30))\n&gt;&gt;&gt; f(S)\n0       0\n1     483\n2     966\n3     448\n4     932\n5     416\n6     896\n7     380\n8     864\n9     348\n10    832\n11    312\n12    792\n13    280\n14    760\n15    248\n16    728\n17    208\n18    696\n19    176\n20    664\n21    144\n22    624\n23    104\n24    584\n25     80\n26    560\n27     40\n28    520\n29      0\ndtype: Int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesdtweek","title":"<code>pd.Series.dt.week</code>","text":"<ul> <li> <p><code>pandas.Series.dt.week</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.dt.week\n&gt;&gt;&gt; S = pd.Series(pd.date_range(start='1/1/2022', end='1/10/2025', periods=30))\n&gt;&gt;&gt; f(S)\n0     52\n1      6\n2     11\n3     17\n4     22\n5     27\n6     33\n7     38\n8     44\n9     49\n10     3\n11     8\n12    14\n13    19\n14    24\n15    30\n16    35\n17    41\n18    46\n19    52\n20     5\n21    11\n22    16\n23    21\n24    27\n25    32\n26    38\n27    43\n28    49\n29     2\ndtype: Int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesdtweekofyear","title":"<code>pd.Series.dt.weekofyear</code>","text":"<ul> <li> <p><code>pandas.Series.dt.weekofyear</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.dt.weekofyear\n&gt;&gt;&gt; S = pd.Series(pd.date_range(start='1/1/2022', end='1/10/2025', periods=30))\n&gt;&gt;&gt; f(S)\n0     52\n1      6\n2     11\n3     17\n4     22\n5     27\n6     33\n7     38\n8     44\n9     49\n10     3\n11     8\n12    14\n13    19\n14    24\n15    30\n16    35\n17    41\n18    46\n19    52\n20     5\n21    11\n22    16\n23    21\n24    27\n25    32\n26    38\n27    43\n28    49\n29     2\ndtype: Int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesdtday_of_week","title":"<code>pd.Series.dt.day_of_week</code>","text":"<ul> <li> <p><code>pandas.Series.dt.day_of_week</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.dt.day_of_week\n&gt;&gt;&gt; S = pd.Series(pd.date_range(start='1/1/2022', end='1/10/2025', periods=30))\n&gt;&gt;&gt; f(S)\n0     5\n1     1\n2     4\n3     0\n4     3\n5     6\n6     2\n7     5\n8     1\n9     4\n10    1\n11    4\n12    0\n13    3\n14    6\n15    2\n16    5\n17    1\n18    4\n19    0\n20    4\n21    0\n22    3\n23    6\n24    2\n25    5\n26    1\n27    4\n28    0\n29    4\ndtype: Int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesdtweekday","title":"<code>pd.Series.dt.weekday</code>","text":"<ul> <li> <p><code>pandas.Series.dt.weekday</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.dt.weekday\n&gt;&gt;&gt; S = pd.Series(pd.date_range(start='1/1/2022', end='1/10/2025', periods=30))\n&gt;&gt;&gt; f(S)\n0     5\n1     1\n2     4\n3     0\n4     3\n5     6\n6     2\n7     5\n8     1\n9     4\n10    1\n11    4\n12    0\n13    3\n14    6\n15    2\n16    5\n17    1\n18    4\n19    0\n20    4\n21    0\n22    3\n23    6\n24    2\n25    5\n26    1\n27    4\n28    0\n29    4\ndtype: Int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesdtdayofyear","title":"<code>pd.Series.dt.dayofyear</code>","text":"<ul> <li> <p><code>pandas.Series.dt.dayofyear</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.dt.dayofyear\n&gt;&gt;&gt; S = pd.Series(pd.date_range(start='1/1/2022', end='1/10/2025', periods=30))\n&gt;&gt;&gt; f(S)\n0       1\n1      39\n2      77\n3     115\n4     153\n5     191\n6     229\n7     267\n8     305\n9     343\n10     17\n11     55\n12     93\n13    131\n14    169\n15    207\n16    245\n17    283\n18    321\n19    359\n20     33\n21     71\n22    109\n23    147\n24    185\n25    223\n26    261\n27    299\n28    337\n29     10\ndtype: Int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesdtday_of_year","title":"<code>pd.Series.dt.day_of_year</code>","text":"<ul> <li> <p><code>pandas.Series.dt.day_of_year</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.dt.day_of_year\n&gt;&gt;&gt; S = pd.Series(pd.date_range(start='1/1/2022', end='1/10/2025', periods=30))\n&gt;&gt;&gt; f(S)\n0       1\n1      39\n2      77\n3     115\n4     153\n5     191\n6     229\n7     267\n8     305\n9     343\n10     17\n11     55\n12     93\n13    131\n14    169\n15    207\n16    245\n17    283\n18    321\n19    359\n20     33\n21     71\n22    109\n23    147\n24    185\n25    223\n26    261\n27    299\n28    337\n29     10\ndtype: Int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesdtquarter","title":"<code>pd.Series.dt.quarter</code>","text":"<ul> <li> <p><code>pandas.Series.dt.quarter</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.dt.quarter\n&gt;&gt;&gt; S = pd.Series(pd.date_range(start='1/1/2022', end='1/10/2025', periods=30))\n&gt;&gt;&gt; f(S)\n0     1\n1     1\n2     1\n3     2\n4     2\n5     3\n6     3\n7     3\n8     4\n9     4\n10    1\n11    1\n12    2\n13    2\n14    2\n15    3\n16    3\n17    4\n18    4\n19    4\n20    1\n21    1\n22    2\n23    2\n24    3\n25    3\n26    3\n27    4\n28    4\n29    1\ndtype: Int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesdtis_month_start","title":"<code>pd.Series.dt.is_month_start</code>","text":"<ul> <li> <p><code>pandas.Series.dt.is_month_start</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.dt.is_month_start\n&gt;&gt;&gt; SS = pd.Series(pd.date_range(start='1/1/2022', end='12/31/2024', periods=30))\n&gt;&gt;&gt; f(S)\n0      True\n1     False\n2     False\n3     False\n4      True\n5     False\n6     False\n7     False\n8     False\n9     False\n10    False\n11    False\n12    False\n13    False\n14    False\n15    False\n16    False\n17    False\n18    False\n19    False\n20    False\n21    False\n22    False\n23    False\n24    False\n25     True\n26    False\n27    False\n28    False\n29    False\ndtype: bool\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesdtis_month_end","title":"<code>pd.Series.dt.is_month_end</code>","text":"<ul> <li> <p><code>pandas.Series.dt.is_month_end</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.dt.is_month_end\n&gt;&gt;&gt; S = pd.Series(pd.date_range(start='1/1/2022', end='12/31/2024', periods=30))\n&gt;&gt;&gt; f(S)\n0     False\n1     False\n2     False\n3     False\n4     False\n5     False\n6     False\n7     False\n8     False\n9     False\n10    False\n11    False\n12    False\n13    False\n14    False\n15    False\n16    False\n17    False\n18    False\n19    False\n20    False\n21    False\n22    False\n23    False\n24    False\n25    False\n26    False\n27    False\n28    False\n29     True\ndtype: bool\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesdtis_quarter_start","title":"<code>pd.Series.dt.is_quarter_start</code>","text":"<ul> <li> <p><code>pandas.Series.dt.is_quarter_start</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.dt.is_quarter_start\n&gt;&gt;&gt; S = pd.Series(pd.date_range(start='1/1/2022', end='12/31/2024', periods=30))\n&gt;&gt;&gt; f(S)\n0      True\n1     False\n2     False\n3     False\n4     False\n5     False\n6     False\n7     False\n8     False\n9     False\n10    False\n11    False\n12    False\n13    False\n14    False\n15    False\n16    False\n17    False\n18    False\n19    False\n20    False\n21    False\n22    False\n23    False\n24    False\n25    False\n26    False\n27    False\n28    False\n29    False\ndtype: bool\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesdtis_quarter_end","title":"<code>pd.Series.dt.is_quarter_end</code>","text":"<ul> <li> <p><code>pandas.Series.dt.is_quarter_end</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.dt.is_quarter_end\n&gt;&gt;&gt; S = pd.Series(pd.date_range(start='1/1/2022', end='12/31/2024', periods=30))\n&gt;&gt;&gt; f(S)\n0     False\n1     False\n2     False\n3     False\n4     False\n5     False\n6     False\n7     False\n8     False\n9     False\n10    False\n11    False\n12    False\n13    False\n14    False\n15    False\n16    False\n17    False\n18    False\n19    False\n20    False\n21    False\n22    False\n23    False\n24    False\n25    False\n26    False\n27    False\n28    False\n29     True\ndtype: bool\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesdtis_year_start","title":"<code>pd.Series.dt.is_year_start</code>","text":"<ul> <li> <p><code>pandas.Series.dt.is_year_start</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.dt.is_year_start\n&gt;&gt;&gt; S = pd.Series(pd.date_range(start='1/1/2022', end='12/31/2024', periods=30))\n&gt;&gt;&gt; f(S)\n0      True\n1     False\n2     False\n3     False\n4     False\n5     False\n6     False\n7     False\n8     False\n9     False\n10    False\n11    False\n12    False\n13    False\n14    False\n15    False\n16    False\n17    False\n18    False\n19    False\n20    False\n21    False\n22    False\n23    False\n24    False\n25    False\n26    False\n27    False\n28    False\n29    False\ndtype: bool\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesdtis_year_end","title":"<code>pd.Series.dt.is_year_end</code>","text":"<ul> <li> <p><code>pandas.Series.dt.is_year_end</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.dt.is_year_end\n&gt;&gt;&gt; S = pd.Series(pd.date_range(start='1/1/2022', end='12/31/2024', periods=30))\n&gt;&gt;&gt; f(S)\n0     False\n1     False\n2     False\n3     False\n4     False\n5     False\n6     False\n7     False\n8     False\n9     False\n10    False\n11    False\n12    False\n13    False\n14    False\n15    False\n16    False\n17    False\n18    False\n19    False\n20    False\n21    False\n22    False\n23    False\n24    False\n25    False\n26    False\n27    False\n28    False\n29     True\ndtype: bool\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesdtdaysinmonth","title":"<code>pd.Series.dt.daysinmonth</code>","text":"<ul> <li> <p><code>pandas.Series.dt.daysinmonth</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.dt.daysinmonth\n&gt;&gt;&gt; S = pd.Series(pd.date_range(start='1/1/2022', end='12/31/2024', periods=30))\n&gt;&gt;&gt; f(S)\n0     31\n1     28\n2     31\n3     30\n4     30\n5     31\n6     31\n7     30\n8     31\n9     31\n10    31\n11    28\n12    31\n13    31\n14    30\n15    31\n16    31\n17    31\n18    30\n19    31\n20    31\n21    31\n22    30\n23    31\n24    30\n25    31\n26    30\n27    31\n28    30\n29    31\ndtype: Int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesdtdays_in_month","title":"<code>pd.Series.dt.days_in_month</code>","text":"<ul> <li> <p><code>pandas.Series.dt.days_in_month</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.dt.days_in_month\n&gt;&gt;&gt; S = pd.Series(pd.date_range(start='1/1/2022', end='12/31/2024', periods=30))\n&gt;&gt;&gt; f(S)\n0     31\n1     28\n2     31\n3     30\n4     30\n5     31\n6     31\n7     30\n8     31\n9     31\n10    31\n11    28\n12    31\n13    31\n14    30\n15    31\n16    31\n17    31\n18    30\n19    31\n20    31\n21    31\n22    30\n23    31\n24    30\n25    31\n26    30\n27    31\n28    30\n29    31\ndtype: Int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#datetime-methods","title":"Datetime methods","text":""},{"location":"api_docs/pandas/series/#pdseriesdtnormalize","title":"<code>pd.Series.dt.normalize</code>","text":"<ul> <li> <p><code>pandas.Series.dt.normalize()</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.dt.normalize()\n&gt;&gt;&gt; S = pd.Series(pd.date_range(start='1/1/2022', end='1/10/2022', periods=30))\n&gt;&gt;&gt; f(S)\n0    2022-01-01\n1    2022-01-01\n2    2022-01-01\n3    2022-01-01\n4    2022-01-02\n5    2022-01-02\n6    2022-01-02\n7    2022-01-03\n8    2022-01-03\n9    2022-01-03\n10   2022-01-04\n11   2022-01-04\n12   2022-01-04\n13   2022-01-05\n14   2022-01-05\n15   2022-01-05\n16   2022-01-05\n17   2022-01-06\n18   2022-01-06\n19   2022-01-06\n20   2022-01-07\n21   2022-01-07\n22   2022-01-07\n23   2022-01-08\n24   2022-01-08\n25   2022-01-08\n26   2022-01-09\n27   2022-01-09\n28   2022-01-09\n29   2022-01-10\ndtype: datetime64[ns]\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesdtstrftime","title":"<code>pd.Series.dt.strftime</code>","text":"<ul> <li> <p><code>pandas.Series.dt.strftime(date_format)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p>other requirements</p> <p><code>date_format</code></p> <ul> <li>String</li> </ul> <p>Must be a valid datetime format string</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.dt.strftime(\"%B %d, %Y, %r\")\n&gt;&gt;&gt; S = pd.Series(pd.date_range(start='1/1/2022', end='1/10/2022', periods=30))\n&gt;&gt;&gt; f(S)\n0     January 01, 2022, 12:00:00 AM\n1     January 01, 2022, 07:26:53 AM\n2     January 01, 2022, 02:53:47 PM\n3     January 01, 2022, 10:20:41 PM\n4     January 02, 2022, 05:47:35 AM\n5     January 02, 2022, 01:14:28 PM\n6     January 02, 2022, 08:41:22 PM\n7     January 03, 2022, 04:08:16 AM\n8     January 03, 2022, 11:35:10 AM\n9     January 03, 2022, 07:02:04 PM\n10    January 04, 2022, 02:28:57 AM\n11    January 04, 2022, 09:55:51 AM\n12    January 04, 2022, 05:22:45 PM\n13    January 05, 2022, 12:49:39 AM\n14    January 05, 2022, 08:16:33 AM\n15    January 05, 2022, 03:43:26 PM\n16    January 05, 2022, 11:10:20 PM\n17    January 06, 2022, 06:37:14 AM\n18    January 06, 2022, 02:04:08 PM\n19    January 06, 2022, 09:31:02 PM\n20    January 07, 2022, 04:57:55 AM\n21    January 07, 2022, 12:24:49 PM\n22    January 07, 2022, 07:51:43 PM\n23    January 08, 2022, 03:18:37 AM\n24    January 08, 2022, 10:45:31 AM\n25    January 08, 2022, 06:12:24 PM\n26    January 09, 2022, 01:39:18 AM\n27    January 09, 2022, 09:06:12 AM\n28    January 09, 2022, 04:33:06 PM\n29    January 10, 2022, 12:00:00 AM\ndtype: object\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesdtround","title":"<code>pd.Series.dt.round</code>","text":"<ul> <li> <p><code>pandas.Series.dt.round(freq, ambiguous='raise', nonexistent='raise')</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p>other requirements</p> <p><code>freq</code></p> <ul> <li>String</li> </ul> <p>Must be a valid fixed frequency alias</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.dt.round(\"H\")\n&gt;&gt;&gt; S = pd.Series(pd.date_range(start='1/1/2022', end='1/10/2022', periods=30))\n&gt;&gt;&gt; f(S)\n0    2022-01-01 00:00:00\n1    2022-01-01 07:00:00\n2    2022-01-01 15:00:00\n3    2022-01-01 22:00:00\n4    2022-01-02 06:00:00\n5    2022-01-02 13:00:00\n6    2022-01-02 21:00:00\n7    2022-01-03 04:00:00\n8    2022-01-03 12:00:00\n9    2022-01-03 19:00:00\n10   2022-01-04 02:00:00\n11   2022-01-04 10:00:00\n12   2022-01-04 17:00:00\n13   2022-01-05 01:00:00\n14   2022-01-05 08:00:00\n15   2022-01-05 16:00:00\n16   2022-01-05 23:00:00\n17   2022-01-06 07:00:00\n18   2022-01-06 14:00:00\n19   2022-01-06 22:00:00\n20   2022-01-07 05:00:00\n21   2022-01-07 12:00:00\n22   2022-01-07 20:00:00\n23   2022-01-08 03:00:00\n24   2022-01-08 11:00:00\n25   2022-01-08 18:00:00\n26   2022-01-09 02:00:00\n27   2022-01-09 09:00:00\n28   2022-01-09 17:00:00\n29   2022-01-10 00:00:00\ndtype: datetime64[ns]\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesdtfloor","title":"<code>pd.Series.dt.floor</code>","text":"<ul> <li> <p><code>pandas.Series.dt.floor(freq, ambiguous='raise', nonexistent='raise')</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p>other requirements</p> <p><code>freq</code></p> <ul> <li>String</li> </ul> <p>Must be a valid fixed frequency alias</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.dt.floor(\"H\")\n&gt;&gt;&gt; S = pd.Series(pd.date_range(start='1/1/2022', end='1/10/2022', periods=30))\n&gt;&gt;&gt; f(S)\n0    2022-01-01 00:00:00\n1    2022-01-01 07:00:00\n2    2022-01-01 14:00:00\n3    2022-01-01 22:00:00\n4    2022-01-02 05:00:00\n5    2022-01-02 13:00:00\n6    2022-01-02 20:00:00\n7    2022-01-03 04:00:00\n8    2022-01-03 11:00:00\n9    2022-01-03 19:00:00\n10   2022-01-04 02:00:00\n11   2022-01-04 09:00:00\n12   2022-01-04 17:00:00\n13   2022-01-05 00:00:00\n14   2022-01-05 08:00:00\n15   2022-01-05 15:00:00\n16   2022-01-05 23:00:00\n17   2022-01-06 06:00:00\n18   2022-01-06 14:00:00\n19   2022-01-06 21:00:00\n20   2022-01-07 04:00:00\n21   2022-01-07 12:00:00\n22   2022-01-07 19:00:00\n23   2022-01-08 03:00:00\n24   2022-01-08 10:00:00\n25   2022-01-08 18:00:00\n26   2022-01-09 01:00:00\n27   2022-01-09 09:00:00\n28   2022-01-09 16:00:00\n29   2022-01-10 00:00:00\ndtype: datetime64[ns]\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesdtceil","title":"<code>pd.Series.dt.ceil</code>","text":"<ul> <li> <p><code>pandas.Series.dt.ceil(freq, ambiguous='raise', nonexistent='raise')</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p>other requirements</p> <p><code>freq</code></p> <ul> <li>String</li> </ul> <p>Must be a valid fixed frequency alias</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.dt.ceil(\"H\")\n&gt;&gt;&gt; S = pd.Series(pd.date_range(start='1/1/2022', end='1/10/2022', periods=30))\n&gt;&gt;&gt; f(S)\n0    2022-01-01 00:00:00\n1    2022-01-01 08:00:00\n2    2022-01-01 15:00:00\n3    2022-01-01 23:00:00\n4    2022-01-02 06:00:00\n5    2022-01-02 14:00:00\n6    2022-01-02 21:00:00\n7    2022-01-03 05:00:00\n8    2022-01-03 12:00:00\n9    2022-01-03 20:00:00\n10   2022-01-04 03:00:00\n11   2022-01-04 10:00:00\n12   2022-01-04 18:00:00\n13   2022-01-05 01:00:00\n14   2022-01-05 09:00:00\n15   2022-01-05 16:00:00\n16   2022-01-06 00:00:00\n17   2022-01-06 07:00:00\n18   2022-01-06 15:00:00\n19   2022-01-06 22:00:00\n20   2022-01-07 05:00:00\n21   2022-01-07 13:00:00\n22   2022-01-07 20:00:00\n23   2022-01-08 04:00:00\n24   2022-01-08 11:00:00\n25   2022-01-08 19:00:00\n26   2022-01-09 02:00:00\n27   2022-01-09 10:00:00\n28   2022-01-09 17:00:00\n29   2022-01-10 00:00:00\ndtype: datetime64[ns]\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesdtmonth_name","title":"<code>pd.Series.dt.month_name</code>","text":"<ul> <li> <p><code>pandas.Series.dt.month_name(locale=None)</code> Supported Arguments None</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.dt.month_name()\n&gt;&gt;&gt; S = pd.Series(pd.date_range(start='1/1/2022', end='1/10/2025', periods=30))\n&gt;&gt;&gt; f(S)\n0       January\n1      February\n2         March\n3         April\n4          June\n5          July\n6        August\n7     September\n8      November\n9      December\n10      January\n11     February\n12        April\n13          May\n14         June\n15         July\n16    September\n17      October\n18     November\n19     December\n20     February\n21        March\n22        April\n23          May\n24         July\n25       August\n26    September\n27      October\n28     December\n29      January\ndtype: object\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesdtday_name","title":"<code>pd.Series.dt.day_name</code>","text":"<ul> <li> <p><code>pandas.Series.dt.day_name(locale=None)</code> Supported Arguments None</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.dt.day_name()\n&gt;&gt;&gt; S = pd.Series(pd.date_range(start='1/1/2022', end='1/10/2022', periods=30))\n&gt;&gt;&gt; f(S)\n0      Saturday\n1      Saturday\n2      Saturday\n3      Saturday\n4        Sunday\n5        Sunday\n6        Sunday\n7        Monday\n8        Monday\n9        Monday\n10      Tuesday\n11      Tuesday\n12      Tuesday\n13    Wednesday\n14    Wednesday\n15    Wednesday\n16    Wednesday\n17     Thursday\n18     Thursday\n19     Thursday\n20       Friday\n21       Friday\n22       Friday\n23     Saturday\n24     Saturday\n25     Saturday\n26       Sunday\n27       Sunday\n28       Sunday\n29       Monday\ndtype: object\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#string-handling","title":"String handling","text":""},{"location":"api_docs/pandas/series/#pdseriesstrcapitalize","title":"<code>pd.Series.str.capitalize</code>","text":"<ul> <li> <p><code>pandas.Series.str.capitalize()</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.str.capitalize()\n&gt;&gt;&gt; S = pd.Series([\"a\", \"ce\", \"Erw\", \"a3\", \"@\", \"a n\", \"^ Ef\"])\n&gt;&gt;&gt; f(S)\n0       A\n1      Ce\n2     Erw\n3      A3\n4       @\n5     A n\n6    ^ Ef\ndtype: object\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstrcat","title":"<code>pd.Series.str.cat</code>","text":"<ul> <li> <p><code>pandas.Series.str.cat(others=None, sep=None, na_rep=None, join='left')</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>others</code></p> <ul> <li>DataFrame</li> </ul> <p><code>sep</code> </p> <ul> <li>String </li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S, df):\n...     return S.str.cat(df, \",\")\n&gt;&gt;&gt; S = pd.Series([\"s1\", \"s2\", \"s3\", None, \"s5\"])\n&gt;&gt;&gt; df = pd.DataFrame({\"A\": [\"a1\", \"a2\", \"a3\", \"a4\", \"a5\"], \"B\": [\"b1\", \"b2\", None, \"b4\", \"b5\"]})\n&gt;&gt;&gt; f(S, df)\n0    s1,a1,b1\n1    s2,a2,b2\n2         NaN\n3         NaN\n4    s5,a5,b5\ndtype: object\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstrcenter","title":"<code>pd.Series.str.center</code>","text":"<ul> <li> <p><code>pandas.Series.str.center(width, fillchar=' ')</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>width</code></p> <ul> <li>Integer</li> </ul> <p><code>fillchar</code></p> <ul> <li>String with a single character</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.str.center(4)\n&gt;&gt;&gt; S = pd.Series([\"a\", \"ce\", \"Erw\", \"a3\", \"@\", \"a n\", \"^ Ef\"])\n&gt;&gt;&gt; f(S)\n0     a\n1     ce\n2    Erw\n3     a3\n4     @\n5    a n\n6    ^ Ef\ndtype: object\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstrcontains","title":"<code>pd.Series.str.contains</code>","text":"<ul> <li> <p><code>pandas.Series.str.contains(pat, case=True, flags=0, na=None, regex=True)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p>other requirements</p> <p><code>pat</code></p> <ul> <li>String</li> </ul> <p><code>case</code> </p> <ul> <li>Boolean </li> </ul> <p>Must be constant at Compile Time</p> <p><code>flags</code></p> <ul> <li>Integer</li> </ul> <p><code>regex</code> </p> <ul> <li>Boolean </li> </ul> <p>Must be constant at Compile Time</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.str.contains(\"a.+\")\n&gt;&gt;&gt; S = pd.Series([\"a\", \"ce\", \"Erw\", \"a3\", \"@\", \"a n\", \"^ Ef\"])\n&gt;&gt;&gt; f(S)\n0    False\n1    False\n2    False\n3     True\n4    False\n5     True\n6    False\ndtype: boolean\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstrcount","title":"<code>pd.Series.str.count</code>","text":"<ul> <li> <p><code>pandas.Series.str.count(pat, flags=0)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>pat</code></p> <ul> <li>String</li> </ul> <p><code>flags</code></p> <ul> <li>Integer</li> </ul> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.str.count(\"w\")\n&gt;&gt;&gt; S = pd.Series([\"a\", \"ce\", \"Erw\", \"a3\", \"@\", \"a n\", \"^ Ef\"])\n&gt;&gt;&gt; f(S)\n0    1\n1    2\n2    3\n3    2\n4    0\n5    2\n6    2\ndtype: Int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstrendswith","title":"<code>pd.Series.str.endswith</code>","text":"<ul> <li> <p><code>pandas.Series.str.endswith(pat, na=None)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>pat</code></p> <ul> <li>String</li> </ul> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.str.endswith(\"e\")\n&gt;&gt;&gt; S = pd.Series([\"a\", \"ce\", \"Erw\", \"a3\", \"@\", \"a n\", \"^ Ef\"])\n&gt;&gt;&gt; f(S)\n0    False\n1     True\n2    False\n3    False\n4    False\n5    False\n6    False\ndtype: boolean\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstrextract","title":"<code>pd.Series.str.extract</code>","text":"<ul> <li> <p><code>pandas.Series.str.extract(pat, flags=0, expand=True)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p>other requirements</p> <p><code>pat</code> </p> <ul> <li>String </li> </ul> <p>Must be constant at Compile Time</p> <p><code>flags</code> </p> <ul> <li>Integer </li> </ul> <p>Must be constant at Compile Time</p> <p><code>expand</code> </p> <ul> <li>Boolean </li> </ul> <p>Must be constant at Compile Time</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.str.extract(\"(a|e)\")\n&gt;&gt;&gt; S = pd.Series([\"a\", \"ce\", \"Erw\", \"a3\", \"@\", \"a n\", \"^ Ef\"])\n&gt;&gt;&gt; f(S)\n0\n0    a\n1    e\n2  NaN\n3    a\n4  NaN\n5    a\n6  NaN\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstrextractall","title":"<code>pd.Series.str.extractall</code>","text":"<ul> <li> <p><code>pandas.Series.str.extractall(pat, flags=0)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p>other requirements</p> <p><code>pat</code> </p> <ul> <li>String </li> </ul> <p>Must be constant at Compile Time</p> <p><code>flags</code> </p> <ul> <li>Integer </li> </ul> <p>Must be constant at Compile Time</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.str.extractall(\"(a|n)\")\n&gt;&gt;&gt; S = pd.Series([\"a\", \"ce\", \"Erw\", \"a3\", \"@\", \"a n\", \"^ Ef\"])\n&gt;&gt;&gt; f(S)\n0\nmatch\n0 0      a\n3 0      a\n5 0      a\n1      n\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstrfind","title":"<code>pd.Series.str.find</code>","text":"<ul> <li> <p><code>pandas.Series.str.find(sub, start=0, end=None)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>sub</code></p> <ul> <li>String</li> </ul> <p><code>start</code></p> <ul> <li>Integer</li> </ul> <p><code>end</code></p> <ul> <li>Integer</li> </ul> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.str.find(\"a3\", start=1)\n&gt;&gt;&gt; S = pd.Series([\"Aa3\", \"cea3\", \"14a3\", \" a3\", \"a3@\", \"a n3\", \"^ Ea3f\"])\n&gt;&gt;&gt; f(S)\n0     1\n1     2\n2     2\n3     1\n4    -1\n5    -1\n6     3\ndtype: Int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstrget","title":"<code>pd.Series.str.get</code>","text":"<ul> <li> <p><code>pandas.Series.str.get(i)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>i</code></p> <ul> <li>Integer</li> </ul> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.str.get(1)\n&gt;&gt;&gt; S = pd.Series([\"A\", \"ce\", \"14\", \" \", \"@\", \"a n\", \"^ Ef\"])\n&gt;&gt;&gt; f(S)\n0    NaN\n1      e\n2      4\n3    NaN\n4    NaN\n5\n6\ndtype: object\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstrjoin","title":"<code>pd.Series.str.join</code>","text":"<ul> <li> <p><code>pandas.Series.str.join(sep)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>sep</code></p> <ul> <li>String</li> </ul> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.str.join(\",\")\n&gt;&gt;&gt; S = pd.Series([[\"a\", \"fe\", \"@23\"], [\"a\", \"b\"], [], [\"c\"]])\n&gt;&gt;&gt; f(S)\n0    a,fe,@23\n1         a,b\n2\n3           c\ndtype: object\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstrlen","title":"<code>pd.Series.str.len</code>","text":"<ul> <li><code>pandas.Series.str.len()</code> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.str.len()\n&gt;&gt;&gt; S = pd.Series([\"A\", \"ce\", \"14\", \" \", \"@\", \"a n\", \"^ Ef\"])\n&gt;&gt;&gt; f(S)\n0    1\n1    2\n2    2\n3    1\n4    1\n5    3\n6    4\ndtype: Int64\n</code></pre></li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstrljust","title":"<code>pd.Series.str.ljust</code>","text":"<ul> <li> <p><code>pandas.Series.str.ljust(width, fillchar=' ')</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>width</code></p> <ul> <li>Integer</li> </ul> <p><code>fillchar</code></p> <ul> <li>String with a single character</li> </ul> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.str.ljust(5, fillchar=\",\")\n&gt;&gt;&gt; S = pd.Series([\"A\", \"ce\", \"14\", \" \", \"@\", \"a n\", \"^ Ef\"])\n&gt;&gt;&gt; f(S)\n0    A,,,,\n1    ce,,,\n2    14,,,\n3     ,,,,\n4    @,,,,\n5    a n,,\n6    ^ Ef,\ndtype: object\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstrlower","title":"<code>pd.Series.str.lower</code>","text":"<ul> <li><code>pandas.Series.str.lower()</code> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.str.lower()\n&gt;&gt;&gt; S = pd.Series([\"A\", \"ce\", \"14\", \" \", \"@\", \"a n\", \"^ Ef\"])\n&gt;&gt;&gt; f(S)\n0       a\n1      ce\n2      14\n3\n4       @\n5     a n\n6    ^ Ef\ndtype: object\n</code></pre></li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstrlstrip","title":"<code>pd.Series.str.lstrip</code>","text":"<ul> <li> <p><code>pandas.Series.str.lstrip(to_strip=None)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>to_strip</code></p> <ul> <li>String</li> </ul> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.str.lstrip(\"c\")\n&gt;&gt;&gt; S = pd.Series([\"A\", \"ce\", \"14\", \" \", \"@\", \"a n\", \"^ Ef\"])\n&gt;&gt;&gt; f(S)\n0       A\n1       e\n2      14\n3\n4       @\n5     a n\n6    ^ Ef\ndtype: object\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstrpad","title":"<code>pd.Series.str.pad</code>","text":"<ul> <li> <p><code>pandas.Series.str.pad(width, side='left', fillchar=' ')</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p>other requirements</p> <p><code>width</code></p> <ul> <li>Integer</li> </ul> <p><code>width</code></p> <ul> <li>One of (\"left\",     \"right\",     \"both\")</li> </ul> <p>Must be constant at Compile Time </p> <p><code>fillchar</code> </p> <ul> <li>String with a     single character</li> </ul> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.str.pad(5)\n&gt;&gt;&gt; S = pd.Series([\"A\", \"ce\", \"14\", \" \", \"@\", \"a n\", \"^ Ef\"])\n&gt;&gt;&gt; f(S)\n0        A\n1       ce\n2       14\n3\n4        @\n5      a n\n6     ^ Ef\ndtype: object\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstrrepeat","title":"<code>pd.Series.str.repeat</code>","text":"<ul> <li> <p><code>pandas.Series.str.repeat(repeats)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p>other requirements</p> <p><code>repeats</code></p> <ul> <li>Integer</li> <li>Array Like     containing     integers</li> </ul> <p>If <code>repeats</code> is array like, then it must be the same length as the Series.</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.str.repeat(2)\n&gt;&gt;&gt; S = pd.Series([\"A\", \"ce\", \"14\", \" \", \"@\", \"a n\", \"^ Ef\"])\n&gt;&gt;&gt; f(S)\n0          AA\n1        cece\n2        1414\n3\n4          @@\n5      a na n\n6    ^ Ef^ Ef\ndtype: object\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstrreplace","title":"<code>pd.Series.str.replace</code>","text":"<ul> <li> <p><code>pandas.Series.str.replace(pat, repl, n=- 1, case=None, flags=0, regex=None)</code> Supported Arguments </p> <ul> <li><code>regex</code></li> </ul> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.str.replace(\"(a|e)\", \"yellow\")\n&gt;&gt;&gt; S = pd.Series([\"A\", \"ce\", \"14\", \" \", \"@\", \"a n\", \"^ Ef\"])\n&gt;&gt;&gt; f(S)\n0           A\n1     cyellow\n2          14\n3\n4           @\n5    yellow n\n6        ^ Ef\ndtype: object\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstrrfind","title":"<code>pd.Series.str.rfind</code>","text":"<ul> <li> <p><code>pandas.Series.str.rfind(sub, start=0, end=None)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>sub</code></p> <ul> <li>String</li> </ul> <p><code>start</code></p> <ul> <li>Integer</li> </ul> <p><code>end</code></p> <ul> <li>Integer</li> </ul> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.str.rfind(\"a3\", start=1)\n&gt;&gt;&gt; S = pd.Series([\"Aa3\", \"cea3\", \"14a3\", \" a3\", \"a3@\", \"a n3\", \"^ Ea3f\"])\n&gt;&gt;&gt; f(S)\n0     1\n1     2\n2     2\n3     1\n4    -1\n5    -1\n6     3\ndtype: Int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstrrjist","title":"<code>pd.Series.str.rjist</code>","text":"<ul> <li> <p><code>pandas.Series.str.rjust(width, fillchar=' ')</code>      Supported arguments`:</p> <p>argument</p> <p>datatypes</p> <p><code>width</code></p> <ul> <li>Integer</li> </ul> <p><code>fillchar</code></p> <ul> <li>String with a single character</li> </ul> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.str.rjust(10)\n&gt;&gt;&gt; S = pd.Series([\"A\", \"ce\", \"14\", \" \", \"@\", \"a n\", \"^ Ef\"])\n&gt;&gt;&gt; f(S)\n0             A\n1            ce\n2            14\n3\n4             @\n5           a n\n6          ^ Ef\ndtype: object\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstrrestrip","title":"<code>pd.Series.str.restrip</code>","text":"<ul> <li> <p><code>pandas.Series.str.rstrip(to_strip=None)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>to_strip</code></p> <ul> <li>String</li> </ul> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.str.rstrip(\"n\")\n&gt;&gt;&gt; S = pd.Series([\"A\", \"ce\", \"14\", \" \", \"@\", \"a n\", \"^ Ef\"])\n&gt;&gt;&gt; f(S)\n0       A\n1      ce\n2      14\n3\n4       @\n5      a\n6    ^ Ef\ndtype: object\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstrslice","title":"<code>pd.Series.str.slice</code>","text":"<ul> <li> <p><code>pandas.Series.str.slice(start=None, stop=None, step=None)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>start</code></p> <ul> <li>Integer</li> </ul> <p><code>stop</code></p> <ul> <li>Integer</li> </ul> <p><code>step</code></p> <ul> <li>Integer</li> </ul> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.str.slice(1, 4)\n&gt;&gt;&gt; S = pd.Series([\"A\", \"ce\", \"14\", \" \", \"@\", \"a n\", \"^ Ef\"])\n&gt;&gt;&gt; f(S)\n0    A\n1    c\n2    1\n3\n4    @\n5    a\n6    #\ndtype: object\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstrslice_replace","title":"<code>pd.Series.str.slice_replace</code>","text":"<ul> <li> <p><code>pandas.Series.str.slice_replace(start=None, stop=None, repl=None)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>start</code></p> <ul> <li>Integer</li> </ul> <p><code>stop</code></p> <ul> <li>Integer</li> </ul> <p><code>repl</code></p> <ul> <li>String</li> </ul> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.str.slice_replace(1, 4)\n&gt;&gt;&gt; S = pd.Series([\"A\", \"ce\", \"14\", \" \", \"@\", \"a n\", \"^ Ef\"])\n&gt;&gt;&gt; f(S)\n0    A\n1    c\n2    1\n3\n4    @\n5    a\n6    #\ndtype: object\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstrsplit","title":"<code>pd.Series.str.split</code>","text":"<ul> <li> <p><code>pandas.Series.str.split(pat=None, n=-1, expand=False)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>pat</code></p> <ul> <li>String</li> </ul> <p><code>n</code></p> <ul> <li>Integer</li> </ul> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.str.split(\" \")\n&gt;&gt;&gt; S = pd.Series([\"A\", \"ce\", \"14\", \" \", \"@\", \"a n\", \"^ Ef\"])\n&gt;&gt;&gt; f(S)\n0        [A]\n1       [ce]\n2       [14]\n3       [, ]\n4        [@]\n5     [a, n]\n6    [#, Ef]\ndtype: object\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstrstartswith","title":"<code>pd.Series.str.startswith</code>","text":"<ul> <li> <p><code>pandas.Series.str.startswith(pat, na=None)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>pat</code></p> <ul> <li>String</li> </ul> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.str.startswith(\"A\")\n&gt;&gt;&gt; S = pd.Series([\"A\", \"ce\", \"14\", \" \", \"@\", \"a n\", \"^ Ef\"])\n&gt;&gt;&gt; f(S)\n0     True\n1    False\n2    False\n3    False\n4    False\n5    False\n6    False\ndtype: boolean\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstrstrip","title":"<code>pd.Series.str.strip</code>","text":"<ul> <li> <p><code>pandas.Series.str.strip(to_strip=None)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>to_strip</code></p> <ul> <li>String</li> </ul> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.str.strip(\"n\")\n&gt;&gt;&gt; S = pd.Series([\"A\", \"ce\", \"14\", \" \", \"@\", \"a n\", \"^ Ef\"])\n&gt;&gt;&gt; f(S)\n0       A\n1      ce\n2      14\n3\n4       @\n5      a\n6    ^ Ef\ndtype: object\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstrswapcase","title":"<code>pd.Series.str.swapcase</code>","text":"<ul> <li><code>pandas.Series.str.swapcase()</code> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.str.swapcase()\n&gt;&gt;&gt; S = pd.Series([\"A\", \"ce\", \"14\", \" \", \"@\", \"a n\", \"^ Ef\"])\n&gt;&gt;&gt; f(S)\n0       a\n1      CE\n2      14\n3\n4       @\n5     A N\n6    ^ Ef\ndtype: object\n</code></pre></li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstrtitle","title":"<code>pd.Series.str.title</code>","text":"<ul> <li><code>pandas.Series.str.title()</code> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.str.title()\n&gt;&gt;&gt; S = pd.Series([\"A\", \"ce\", \"14\", \" \", \"@\", \"a n\", \"^ Ef\"])\n&gt;&gt;&gt; f(S)\n0       A\n1      Ce\n2      14\n3\n4       @\n5     A N\n6    ^ Ef\ndtype: object\n</code></pre></li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstrupper","title":"<code>pd.Series.str.upper</code>","text":"<ul> <li><code>pandas.Series.str.upper()</code> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.str.upper()\n&gt;&gt;&gt; S = pd.Series([\"A\", \"ce\", \"14\", \" \", \"@\", \"a n\", \"^ Ef\"])\n&gt;&gt;&gt; f(S)\n0       A\n1      CE\n2      14\n3\n4       @\n5     A N\n6    ^ Ef\ndtype: object\n</code></pre></li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstrzfill","title":"<code>pd.Series.str.zfill</code>","text":"<ul> <li> <p><code>pandas.Series.str.zfill(width)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p><code>width</code></p> <ul> <li>Integer</li> </ul> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.str.zfill(5)\n&gt;&gt;&gt; S = pd.Series([\"A\", \"ce\", \"14\", \" \", \"@\", \"a n\", \"^ Ef\"])\n&gt;&gt;&gt; f(S)\n0    0000A\n1    000ce\n2    00014\n3    0000\n4    0000@\n5    00a n\n6    0^ Ef\ndtype: object\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstrisalnum","title":"<code>pd.Series.str.isalnum</code>","text":"<ul> <li><code>pandas.Series.str.isalnum()</code> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.str.isalnum()\n&gt;&gt;&gt; S = pd.Series([\"A\", \"ce\", \"14\", \" \", \"@\", \"a n\", \"^ Ef\"])\n&gt;&gt;&gt; f(S)\n0     True\n1     True\n2     True\n3    False\n4    False\n5    False\n6    False\ndtype: boolean\n</code></pre></li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstrisalpha","title":"<code>pd.Series.str.isalpha</code>","text":"<ul> <li><code>pandas.Series.str.isalpha()</code> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.str.isalpha()\n&gt;&gt;&gt; S = pd.Series([\"A\", \"ce\", \"14\", \" \", \"@\", \"a n\", \"^ Ef\"])\n&gt;&gt;&gt; f(S)\n0     True\n1     True\n2    False\n3    False\n4    False\n5    False\n6    False\ndtype: boolean\n</code></pre></li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstrisdigit","title":"<code>pd.Series.str.isdigit</code>","text":"<ul> <li><code>pandas.Series.str.isdigit()</code> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.str.isdigit()\n&gt;&gt;&gt; S = pd.Series([\"A\", \"ce\", \"14\", \" \", \"@\", \"a n\", \"^ Ef\"])\n&gt;&gt;&gt; f(S)\n0    False\n1    False\n2     True\n3    False\n4    False\n5    False\n6    False\ndtype: boolean\n</code></pre></li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstrisspace","title":"<code>pd.Series.str.isspace</code>","text":"<ul> <li><code>pandas.Series.str.isspace()</code> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.str.isspace()\n&gt;&gt;&gt; S = pd.Series([\"A\", \"ce\", \"14\", \" \", \"@\", \"a n\", \"^ Ef\"])\n&gt;&gt;&gt; f(S)\n0    False\n1    False\n2    False\n3     True\n4    False\n5    False\n6    False\ndtype: boolean\n</code></pre></li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstrislower","title":"<code>pd.Series.str.islower</code>","text":"<ul> <li><code>pandas.Series.str.islower()</code> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.str.islower()\n&gt;&gt;&gt; S = pd.Series([\"A\", \"ce\", \"14\", \"a3\", \"@\", \"a n\", \"^ Ef\"])\n&gt;&gt;&gt; f(S)\n0    False\n1     True\n2    False\n3     True\n4    False\n5     True\n6    False\ndtype: boolean\n</code></pre></li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstrisupper","title":"<code>pd.Series.str.isupper</code>","text":"<ul> <li><code>pandas.Series.str.isupper()</code> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.str.isupper()\n&gt;&gt;&gt; S = pd.Series([\"A\", \"ce\", \"14\", \"a3\", \"@\", \"a n\", \"^ Ef\"])\n&gt;&gt;&gt; f(S)\n0     True\n1    False\n2    False\n3    False\n4    False\n5    False\n6    False\ndtype: boolean\n</code></pre></li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstristitle","title":"<code>pd.Series.str.istitle</code>","text":"<ul> <li><code>pandas.Series.str.istitle()</code> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.str.istitle()\n&gt;&gt;&gt; S = pd.Series([\"A\", \"ce\", \"14\", \"a3\", \"@\", \"a n\", \"^ Ef\"])\n&gt;&gt;&gt; f(S)\n0     True\n1    False\n2    False\n3    False\n4    False\n5    False\n6     True\ndtype: boolean\n</code></pre></li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstrisnumeric","title":"<code>pd.Series.str.isnumeric</code>","text":"<ul> <li><code>pandas.Series.str.isnumeric()</code> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.str.isnumeric()\n&gt;&gt;&gt; S = pd.Series([\"A\", \"ce\", \"14\", \"a3\", \"@\", \"a n\", \"^ Ef\"])\n&gt;&gt;&gt; f(S)\n0    False\n1    False\n2     True\n3    False\n4    False\n5    False\n6    False\ndtype: boolean\n</code></pre></li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesstrisdecimal","title":"<code>pd.Series.str.isdecimal</code>","text":"<ul> <li><code>pandas.Series.str.isdecimal()</code> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.str.isdecimal()\n&gt;&gt;&gt; S = pd.Series([\"A\", \"ce\", \"14\", \"a3\", \"@\", \"a n\", \"^ Ef\"])\n&gt;&gt;&gt; f(S)\n0    False\n1    False\n2     True\n3    False\n4    False\n5    False\n6    False\ndtype: boolean\n</code></pre></li> </ul>"},{"location":"api_docs/pandas/series/#categorical-accessor","title":"Categorical accessor","text":""},{"location":"api_docs/pandas/series/#pdseriescatcodes","title":"<code>pd.Series.cat.codes</code>","text":"<ul> <li> <p><code>pandas.Series.cat.codes</code> </p> <p>Note</p> <p>If categories cannot be determined at compile time, then Bodo defaults to creating codes with an <code>int64</code>, which may differ from Pandas.</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.cat.codes\n&gt;&gt;&gt; S = pd.Series([\"a\", \"ce\", \"Erw\", \"a3\", \"@\"] * 10).astype(\"category\")\n&gt;&gt;&gt; f(S)\n0     2\n1     4\n2     1\n3     3\n4     0\n5     2\n6     4\n7     1\n8     3\n9     0\n10    2\n11    4\n12    1\n13    3\n14    0\n15    2\n16    4\n17    1\n18    3\n19    0\n20    2\n21    4\n22    1\n23    3\n24    0\n25    2\n26    4\n27    1\n28    3\n29    0\n30    2\n31    4\n32    1\n33    3\n34    0\n35    2\n36    4\n37    1\n38    3\n39    0\n40    2\n41    4\n42    1\n43    3\n44    0\n45    2\n46    4\n47    1\n48    3\n49    0\ndtype: int8\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#serialization-io-conversion","title":"Serialization / IO / Conversion","text":""},{"location":"api_docs/pandas/series/#pdseriesto_csv","title":"<code>pd.Series.to_csv</code>","text":"<ul> <li><code>pandas.Series.to_csv(path_or_buf=None, sep=',', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, mode='w', encoding=None, compression='infer', quoting=None, quotechar='\"', line_terminator=None, chunksize=None, date_format=None, doublequote=True, escapechar=None, decimal='.', errors='strict', storage_options=None)</code> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesto_dict","title":"<code>pd.Series.to_dict</code>","text":"<ul> <li> <p><code>pandas.Series.to_dict(into=) Supported Arguments None <p>Note</p> <ul> <li> <p>This method is not parallelized since dictionaries are not     parallelized.</p> </li> <li> <p>This method returns a typedDict, which maintains typing information if passing the dictionary between JIT code and regular Python. This can be converted to a regular Python dictionary by using the <code>dict</code> constructor.</p> </li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.to_dict()\n&gt;&gt;&gt; S = pd.Series(np.arange(10))\n&gt;&gt;&gt; dict(f(S))\n{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9}\n</code></pre>"},{"location":"api_docs/pandas/series/#pdseriesto_frame","title":"<code>pd.Series.to_frame</code>","text":"<ul> <li> <p><code>pandas.Series.to_frame(name=None)</code> Supported Arguments</p> <p>argument</p> <p>datatypes</p> <p>other requirements</p> <p><code>name</code> </p> <ul> <li>String </li> </ul> <p>Must be constant at Compile Time</p> <p>Note</p> <p>If <code>name</code> is not provided Series name must be a known constant</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(S):\n...     return S.to_frame(\"my_column\")\n&gt;&gt;&gt; S = pd.Series(np.arange(1000))\n&gt;&gt;&gt; f(S)\nmy_column\n0            0\n1            1\n2            2\n3            3\n4            4\n..         ...\n995        995\n996        996\n997        997\n998        998\n999        999\n</code></pre> </li> </ul> <p>[1000 rows x 1 columns]</p>"},{"location":"api_docs/pandas/series/#heterogeneous_series","title":"Heterogeneous Series","text":"<p>Bodo's Series implementation requires all elements to share a common data type. However, in situations where the size and types of the elements are constant at compile time, Bodo has some mixed type handling with its Heterogeneous Series type.</p> <p>Warning</p> <p>This type's primary purpose is for iterating through the rows of a DataFrame with different column types. You should not attempt to directly create Series with mixed types.</p> <p>Heterogeneous Series operations are a subset of those supported for Series and the supported operations are listed below. Please refer to series for detailed usage.</p>"},{"location":"api_docs/pandas/series/#attributes_1","title":"Attributes","text":""},{"location":"api_docs/pandas/series/#pdseriesindex_1","title":"pd.Series.index","text":"<ul> <li> <p><code>pandas.Series.index</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return df.apply(lambda row: len(row.index), axis=1)\n&gt;&gt;&gt; df = pd.DataFrame({\"A\": np.arange(100), \"B\": [\"A\", \"b\"] * 50})\n&gt;&gt;&gt; f(df)\n0     2\n1     2\n2     2\n3     2\n4     2\n..\n95    2\n96    2\n97    2\n98    2\n99    2\nLength: 100, dtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesvalues_1","title":"pd.Series.values","text":"<ul> <li> <p><code>pandas.Series.values</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return df.apply(lambda row: row.values, axis=1)\n&gt;&gt;&gt; df = pd.DataFrame({\"A\": np.arange(100), \"B\": [\"A\", \"b\"] * 50})\n&gt;&gt;&gt; f(df)\n0      (0, A)\n1      (1, b)\n2      (2, A)\n3      (3, b)\n4      (4, A)\n...\n95    (95, b)\n96    (96, A)\n97    (97, b)\n98    (98, A)\n99    (99, b)\nLength: 100, dtype: object\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesshape_1","title":"pd.Series.shape","text":"<ul> <li> <p><code>pandas.Series.shape</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return df.apply(lambda row: row.shape, axis=1)\n&gt;&gt;&gt; df = pd.DataFrame({\"A\": np.arange(100), \"B\": [\"A\", \"b\"] * 50})\n&gt;&gt;&gt; f(df)\n0     (2,)\n1     (2,)\n2     (2,)\n3     (2,)\n4     (2,)\n...\n95    (2,)\n96    (2,)\n97    (2,)\n98    (2,)\n99    (2,)\nLength: 100, dtype: object\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesndim_1","title":"pd.Series.ndim","text":"<ul> <li><code>pandas.Series.ndim</code> Example Usage</li> </ul> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return df.apply(lambda row: row.ndim, axis=1)\n&gt;&gt;&gt; df = pd.DataFrame({\"A\": np.arange(100), \"B\": [\"A\", \"b\"] * 50})\n&gt;&gt;&gt; f(df)\n0     1\n1     1\n2     1\n3     1\n4     1\n..\n95    1\n96    1\n97    1\n98    1\n99    1\nLength: 100, dtype: int64\n</code></pre>"},{"location":"api_docs/pandas/series/#pdseriessize_1","title":"pd.Series.size","text":"<ul> <li> <p><code>pandas.Series.size</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return df.apply(lambda row: row.size, axis=1)\n&gt;&gt;&gt; df = pd.DataFrame({\"A\": np.arange(100), \"B\": [\"A\", \"b\"] * 50})\n&gt;&gt;&gt; f(df)\n0     2\n1     2\n2     2\n3     2\n4     2\n..\n95    2\n96    2\n97    2\n98    2\n99    2\nLength: 100, dtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriest_1","title":"pd.Series.T","text":"<ul> <li> <p><code>pandas.Series.T</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return df.apply(lambda row: row.T.size, axis=1)\n&gt;&gt;&gt; df = pd.DataFrame({\"A\": np.arange(100), \"B\": [\"A\", \"b\"] * 50})\n&gt;&gt;&gt; f(df)\n0     2\n1     2\n2     2\n3     2\n4     2\n..\n95    2\n96    2\n97    2\n98    2\n99    2\nLength: 100, dtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesempty_1","title":"pd.Series.empty","text":"<ul> <li> <p><code>pandas.Series.empty</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return df.apply(lambda row: row.empty, axis=1)\n&gt;&gt;&gt; df = pd.DataFrame({\"A\": np.arange(100), \"B\": [\"A\", \"b\"] * 50})\n&gt;&gt;&gt; f(df)\n0     False\n1     False\n2     False\n3     False\n4     False\n...\n95    False\n96    False\n97    False\n98    False\n99    False\nLength: 100, dtype: boolean\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/series/#pdseriesname_1","title":"pd.Series.name","text":"<ul> <li> <p><code>pandas.Series.name</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return df.apply(lambda row: row.name, axis=1)\n&gt;&gt;&gt; df = pd.DataFrame({\"A\": np.arange(100), \"B\": [\"A\", \"b\"] * 50})\n&gt;&gt;&gt; f(df)\n0      0\n1      1\n2      2\n3      3\n4      4\n..\n95    95\n96    96\n97    97\n98    98\n99    99\nLength: 100, dtype: int64\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/timedelta/","title":"Timedelta","text":"<p>Timedelta functionality is documented in <code>pandas.Timedelta</code>.</p>"},{"location":"api_docs/pandas/timedelta/#pdtimedelta","title":"<code>pd.Timedelta</code>","text":"<ul> <li> <p><code>pandas.Timedelta(value=&lt;object object&gt;, unit=\"ns\", days=0, seconds=0, microseconds=0, milliseconds=0, minutes=0, hours=0, weeks=0)</code></p> <p>Supported Arguments</p> <ul> <li><code>value</code>: Integer (with constant string unit argument), String, Pandas Timedelta, datetime Timedelta</li> <li><code>unit</code>: Constant String. Only has an effect when passing an integer <code>value</code>, see here for allowed values.</li> <li><code>days</code>: Integer</li> <li><code>seconds</code>: Integer</li> <li><code>microseconds</code>: Integer</li> <li><code>milliseconds</code>: Integer</li> <li><code>minutes</code>: Integer</li> <li><code>hours</code>: Integer</li> <li><code>weeks</code>: Integer</li> </ul> <p>Example Usage <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   td1 = pd.Timedelta(\"10 Seconds\")\n...   td2 = pd.Timedelta(10, unit= \"W\")\n...   td3 = pd.Timedelta(days= 10, hours=2, microseconds= 23)\n...   return (td1, td2, td3)\n&gt;&gt;&gt; f()\n(Timedelta('0 days 00:00:10'), Timedelta('70 days 00:00:00'), Timedelta('10 days 02:00:00.000023'))\n</code></pre></p> </li> </ul>"},{"location":"api_docs/pandas/timedelta/#pdtimedeltacomponents","title":"<code>pd.Timedelta.components</code>","text":"<ul> <li><code>pandas.Timedelta.components</code> Example Usage <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   return pd.Timedelta(days=10, hours=2, minutes=7, seconds=3, milliseconds=13, microseconds=23).components\n&gt;&gt;&gt; f()\nComponents(days=10, hours=2, minutes=7, seconds=3, milliseconds=13, microseconds=23, nanoseconds=0)\n</code></pre></li> </ul>"},{"location":"api_docs/pandas/timedelta/#pdtimedeltadays","title":"<code>pd.Timedelta.days</code>","text":"<ul> <li><code>pandas.Timedelta.days</code> Example Usage <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   return pd.Timedelta(days=10, hours=2, minutes=7, seconds=3, milliseconds=13, microseconds=23).days\n&gt;&gt;&gt; f()\n10\n</code></pre></li> </ul>"},{"location":"api_docs/pandas/timedelta/#pdtimedeltadelta","title":"<code>pd.Timedelta.delta</code>","text":"<ul> <li><code>pandas.Timedelta.delta</code> Example Usage <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   return pd.Timedelta(microseconds=23).delta\n&gt;&gt;&gt; f()\n23000\n</code></pre></li> </ul>"},{"location":"api_docs/pandas/timedelta/#pdtimedeltamicroseconds","title":"<code>pd.Timedelta.microseconds</code>","text":"<ul> <li><code>pandas.Timedelta.microseconds</code> Example Usage <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   return pd.Timedelta(days=10, hours=2, minutes=7, seconds=3, milliseconds=13, microseconds=23).microseconds\n&gt;&gt;&gt; f()\n23\n</code></pre></li> </ul>"},{"location":"api_docs/pandas/timedelta/#pdtimedeltananoseconds","title":"<code>pd.Timedelta.nanoseconds</code>","text":"<ul> <li><code>pandas.Timedelta.nanoseconds</code> Example Usage <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   return pd.Timedelta(days=10, hours=2, minutes=7, seconds=3, milliseconds=13, microseconds=23).nanoseconds\n&gt;&gt;&gt; f()\n0\n</code></pre></li> </ul>"},{"location":"api_docs/pandas/timedelta/#pdtimedeltaseconds","title":"<code>pd.Timedelta.seconds</code>","text":"<ul> <li><code>pandas.Timedelta.seconds</code> Example Usage <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   return pd.Timedelta(\"10 nanoseconds\").nanoseconds\n&gt;&gt;&gt; f()\n10\n</code></pre></li> </ul>"},{"location":"api_docs/pandas/timedelta/#pdtimedeltavalue","title":"<code>pd.Timedelta.value</code>","text":"<ul> <li><code>pandas.Timedelta.value</code> Example Usage <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   return pd.Timedelta(\"13 nanoseconds\").value\n&gt;&gt;&gt; f()\n13\n</code></pre></li> </ul>"},{"location":"api_docs/pandas/timedelta/#pdtimedeltaceil","title":"<code>pd.Timedelta.ceil</code>","text":"<ul> <li> <p><code>pandas.Timedelta.ceil(freq)</code> </p> <p>Supported Arguments</p> <ul> <li><code>freq</code>: String</li> </ul> <p>Example Usage <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   return pd.Timedelta(days=10, hours=2, minutes=7, seconds=3, milliseconds=13, microseconds=23).ceil(\"D\")\n&gt;&gt;&gt; f()\n11 days 00:00:00\n</code></pre></p> </li> </ul>"},{"location":"api_docs/pandas/timedelta/#pdtimedeltafloor","title":"<code>pd.Timedelta.floor</code>","text":"<ul> <li> <p><code>pandas.Timedelta.floor</code> Supported Arguments</p> <ul> <li><code>freq</code>: String</li> </ul> <p>Example Usage <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   return pd.Timedelta(days=10, hours=2, minutes=7, seconds=3, milliseconds=13, microseconds=23).floor(\"D\")\n&gt;&gt;&gt; f()\n10 days 00:00:00\n</code></pre></p> </li> </ul>"},{"location":"api_docs/pandas/timedelta/#pdtimedeltaround","title":"<code>pd.Timedelta.round</code>","text":"<ul> <li> <p><code>pandas.Timedelta.round</code> Supported Arguments</p> <ul> <li><code>freq</code>: String</li> </ul> <p>Example Usage <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   return (pd.Timedelta(days=10, hours=12).round(\"D\"), pd.Timedelta(days=10, hours=13).round(\"D\"))\n&gt;&gt;&gt; f()\n(Timedelta('10 days 00:00:00'), Timedelta('11 days 00:00:00'))\n</code></pre></p> </li> </ul>"},{"location":"api_docs/pandas/timedelta/#pdtimedeltato_numpy","title":"<code>pd.Timedelta.to_numpy</code>","text":"<ul> <li><code>pandas.Timedelta.to_numpy()</code> Example Usage <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   return pd.Timedelta(days=10, hours=2, minutes=7, seconds=3, milliseconds=13, microseconds=23).to_numpy()\n&gt;&gt;&gt; f()\n871623013023000 nanoseconds\n</code></pre></li> </ul>"},{"location":"api_docs/pandas/timedelta/#pdtimedeltato_pytimedelta","title":"<code>pd.Timedelta.to_pytimedelta</code>","text":"<ul> <li><code>pandas.Timedelta.to_pytimedelta()</code> Example Usage <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   return pd.Timedelta(days=10, hours=2, minutes=7, seconds=3, milliseconds=13, microseconds=23).to_pytimedelta()\n&gt;&gt;&gt; f()\n10 days, 2:07:03.013023\n</code></pre></li> </ul>"},{"location":"api_docs/pandas/timedelta/#pdtimedeltato_timedelta64","title":"<code>pd.Timedelta.to_timedelta64</code>","text":"<ul> <li> <p><code>pandas.Timedelta.to_timedelta64()</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   return pd.Timedelta(days=10, hours=2, minutes=7, seconds=3, milliseconds=13, microseconds=23).to_timedelta64()\n&gt;&gt;&gt; f()\n871623013023000 nanoseconds\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/timedelta/#pdtimedeltatotal_seconds","title":"<code>pd.Timedelta.total_seconds</code>","text":"<ul> <li><code>pandas.Timedelta.total_seconds()</code> Example Usage <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   return pd.Timedelta(days=10, hours=2, minutes=7, seconds=3, milliseconds=13, microseconds=23).total_seconds()\n&gt;&gt;&gt; f()\n871623.013023\n</code></pre></li> </ul>"},{"location":"api_docs/pandas/timestamp/","title":"Timestamp","text":"<p>Timestamp functionality is documented in <code>pandas.Timestamp</code>.</p>"},{"location":"api_docs/pandas/timestamp/#pdtimestamp","title":"<code>pd.Timestamp</code>","text":"<ul> <li> <p><code>pandas.Timestamp(ts_input=&lt;object object&gt;, freq=None, tz=None, unit=None, year=None, month=None, day=None, hour=None, minute=None, second=None, microsecond=None, nanosecond=None, tzinfo=None, *, fold=None) <p>Supported Arguments</p> <ul> <li><code>ts_input</code>: string, integer, timestamp, datetimedate</li> <li><code>unit</code>: constant string</li> <li><code>year</code>: integer</li> <li><code>month</code>: integer</li> <li><code>day</code>: integer</li> <li><code>hour</code>: integer</li> <li><code>minute</code>: integer</li> <li><code>second</code>: integer</li> <li><code>microsecond</code>: integer</li> <li><code>nanosecond</code>: integer</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   return I.copy(name=\"new_name\")\n...   ts1 = pd.Timestamp('2021-12-09 09:57:44.114123')\n...   ts2 = pd.Timestamp(year=2021, month=12, day=9, hour = 9, minute=57, second=44, microsecond=114123)\n...   ts3 = pd.Timestamp(100, unit=\"days\")\n...   ts4 = pd.Timestamp(datetime.date(2021, 12, 9), hour = 9, minute=57, second=44, microsecond=114123)\n...   return (ts1, ts2, ts3, ts4)\n&gt;&gt;&gt; f()\n(Timestamp('2021-12-09 09:57:44.114123'), Timestamp('2021-12-09 09:57:44.114123'), Timestamp('1970-04-11 00:00:00'), Timestamp('2021-12-09 09:57:44.114123'))\n</code></pre>"},{"location":"api_docs/pandas/timestamp/#pdtimestampday","title":"<code>pd.Timestamp.day</code>","text":"<ul> <li> <p><code>pandas.Timestamp.day</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   ts2 = pd.Timestamp(year=2021, month=12, day=9, hour = 9, minute=57, second=44, microsecond=114123)\n...   return ts2.day\n&gt;&gt;&gt; f()\n9\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/timestamp/#pdtimestamphour","title":"<code>pd.Timestamp.hour</code>","text":"<ul> <li> <p><code>pandas.Timestamp.hour</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   ts2 = pd.Timestamp(year=2021, month=12, day=9, hour = 9, minute=57, second=44, microsecond=114123)\n...   return ts2.hour\n&gt;&gt;&gt; f()\n9\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/timestamp/#pdtimestampmicrosecond","title":"<code>pd.Timestamp.microsecond</code>","text":"<ul> <li> <p><code>pandas.Timestamp.microsecond</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   ts2 = pd.Timestamp(year=2021, month=12, day=9, hour = 9, minute=57, second=44, microsecond=114123)\n...   return ts2.microsecond\n&gt;&gt;&gt; f()\n114123\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/timestamp/#pdtimestampmonth","title":"<code>pd.Timestamp.month</code>","text":"<ul> <li> <p><code>pandas.Timestamp.month</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   ts2 = pd.Timestamp(year=2021, month=12, day=9, hour = 9, minute=57, second=44, microsecond=114123)\n...   return ts2.month\n&gt;&gt;&gt; f()\nmonth\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/timestamp/#pdtimestampnanosecond","title":"<code>pd.Timestamp.nanosecond</code>","text":"<ul> <li> <p><code>pandas.Timestamp.nanosecond</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   ts2 = pd.Timestamp(12, unit=\"ns\")\n...   return ts2.nanosecond\n&gt;&gt;&gt; f()\n12\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/timestamp/#pdtimestampsecond","title":"<code>pd.Timestamp.second</code>","text":"<ul> <li> <p><code>pandas.Timestamp.second</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   ts2 = pd.Timestamp(year=2021, month=12, day=9, hour = 9, minute=57, second=44, microsecond=114123)\n...   return ts2.second\n&gt;&gt;&gt; f()\n44\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/timestamp/#pdtimestampyear","title":"<code>pd.Timestamp.year</code>","text":"<ul> <li> <p><code>pandas.Timestamp.year</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   ts2 = pd.Timestamp(year=2021, month=12, day=9, hour = 9, minute=57, second=44, microsecond=114123)\n...   return ts2.year\n&gt;&gt;&gt; f()\n2021\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/timestamp/#pdtimestampdayofyear","title":"<code>pd.Timestamp.dayofyear</code>","text":"<ul> <li> <p><code>pandas.Timestamp.dayofyear</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   ts2 = pd.Timestamp(year=2021, month=12, day=9, hour = 9, minute=57, second=44, microsecond=114123)\n...   return ts2.dayofyear\n&gt;&gt;&gt; f()\n343\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/timestamp/#pdtimestampday_of_year","title":"<code>pd.Timestamp.day_of_year</code>","text":"<ul> <li> <p><code>pandas.Timestamp.day_of_year</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   ts2 = pd.Timestamp(year=2021, month=12, day=9, hour = 9, minute=57, second=44, microsecond=114123)\n...   return ts2.day_of_year\n&gt;&gt;&gt; f()\n343\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/timestamp/#pdtimestampdayofweek","title":"<code>pd.Timestamp.dayofweek</code>","text":"<ul> <li> <p><code>pandas.Timestamp.dayofweek</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   ts2 = pd.Timestamp(year=2021, month=12, day=9, hour = 9, minute=57, second=44, microsecond=114123)\n...   return ts2.day_of_year\n&gt;&gt;&gt; f()\n343\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/timestamp/#pdtimestampday_of_week","title":"<code>pd.Timestamp.day_of_week</code>","text":"<ul> <li> <p><code>pandas.Timestamp.day_of_week</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   ts2 = pd.Timestamp(year=2021, month=12, day=9, hour = 9, minute=57, second=44, microsecond=114123)\n...   return ts2.day_of_week\n&gt;&gt;&gt; f()\n3\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/timestamp/#pdtimestampdays_in_month","title":"<code>pd.Timestamp.days_in_month</code>","text":"<ul> <li> <p><code>pandas.Timestamp.days_in_month</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   ts2 = pd.Timestamp(year=2021, month=12, day=9, hour = 9, minute=57, second=44, microsecond=114123)\n...   return ts2.days_in_month\n&gt;&gt;&gt; f()\n31\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/timestamp/#pdtimestampdaysinmonth","title":"<code>pd.Timestamp.daysinmonth</code>","text":"<ul> <li> <p><code>pandas.Timestamp.daysinmonth</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   ts2 = pd.Timestamp(year=2021, month=12, day=9, hour = 9, minute=57, second=44, microsecond=114123)\n...   return ts2.daysinmonth\n&gt;&gt;&gt; f()\n31\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/timestamp/#pdtimestampis_leap_year","title":"<code>pd.Timestamp.is_leap_year</code>","text":"<ul> <li> <p><code>pandas.Timestamp.is_leap_year</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   ts1 = pd.Timestamp(year=2020, month=2,day=2)\n...   ts2 = pd.Timestamp(year=2021, month=12, day=9, hour = 9, minute=57, second=44, microsecond=114123)\n...   return (ts1.is_leap_year, ts2.is_leap_year)\n&gt;&gt;&gt; f()\n(True, False)\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/timestamp/#pdtimestampis_month_start","title":"<code>pd.Timestamp.is_month_start</code>","text":"<ul> <li> <p><code>pandas.Timestamp.is_month_start</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   ts1 = pd.Timestamp(year=2021, month=12, day=1)\n...   ts2 = pd.Timestamp(year=2021, month=12, day=2)\n...   return (ts1.is_month_start, ts2.is_month_start)\n&gt;&gt;&gt; f()\n(True, False)\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/timestamp/#pdtimestampis_month_end","title":"<code>pd.Timestamp.is_month_end</code>","text":"<ul> <li> <p><code>pandas.Timestamp.is_month_end</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   ts1 = pd.Timestamp(year=2021, month=12, day=31)\n...   ts2 = pd.Timestamp(year=2021, month=12, day=30)\n...   return (ts1.is_month_end, ts2.is_month_end)\n&gt;&gt;&gt; f()\n(True, False)\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/timestamp/#pdtimestampis_quarter_start","title":"<code>pd.Timestamp.is_quarter_start</code>","text":"<ul> <li> <p><code>pandas.Timestamp.is_quarter_start</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   ts1 = pd.Timestamp(year=2021, month=9, day=30)\n...   ts2 = pd.Timestamp(year=2021, month=10, day=1)\n...   return (ts1.is_quarter_start, ts2.is_quarter_start)\n&gt;&gt;&gt; f()\n(False, True)\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/timestamp/#pdtimestampis_quarter_end","title":"<code>pd.Timestamp.is_quarter_end</code>","text":"<ul> <li> <p><code>pandas.Timestamp.is_quarter_end</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   ts1 = pd.Timestamp(year=2021, month=9, day=30)\n...   ts2 = pd.Timestamp(year=2021, month=10, day=1)\n...   return (ts1.is_quarter_start, ts2.is_quarter_start)\n&gt;&gt;&gt; f()\n(True, False)\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/timestamp/#pdtimestampis_year_start","title":"<code>pd.Timestamp.is_year_start</code>","text":"<ul> <li> <p><code>pandas.Timestamp.is_year_start</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   ts1 = pd.Timestamp(year=2021, month=12, day=31)\n...   ts2 = pd.Timestamp(year=2021, month=1, day=1)\n...   return (ts1.is_year_start, ts2.is_year_start)\n&gt;&gt;&gt; f()\n(False, True)\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/timestamp/#pdtimestampis_year_end","title":"<code>pd.Timestamp.is_year_end</code>","text":"<ul> <li> <p><code>pandas.Timestamp.is_year_end</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   ts1 = pd.Timestamp(year=2021, month=12, day=31)\n...   ts2 = pd.Timestamp(year=2021, month=1, day=1)\n...   return (ts1.is_year_end, ts2.is_year_end)\n&gt;&gt;&gt; f()\n(True, False)\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/timestamp/#pdtimestampquarter","title":"<code>pd.Timestamp.quarter</code>","text":"<ul> <li> <p><code>pandas.Timestamp.quarter</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   ts1 = pd.Timestamp(year=2021, month=12, day=1)\n...   ts2 = pd.Timestamp(year=2021, month=9, day=1)\n...   return (ts1.quarter, ts2.quarter)\n&gt;&gt;&gt; f()\n(4, 3)\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/timestamp/#pdtimestampweek","title":"<code>pd.Timestamp.week</code>","text":"<ul> <li> <p><code>pandas.Timestamp.week</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   ts1 = pd.Timestamp(year=2021, month=9, day=1)\n...   ts2 = pd.Timestamp(year=2021, month=9, day=20)\n...   return (ts1.week, ts2.week)\n&gt;&gt;&gt; f()\n(35, 38)\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/timestamp/#pdtimestampweekofyear","title":"<code>pd.Timestamp.weekofyear</code>","text":"<ul> <li> <p><code>pandas.Timestamp.weekofyear</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   ts1 = pd.Timestamp(year=2021, month=9, day=1)\n...   ts2 = pd.Timestamp(year=2021, month=9, day=20)\n...   return (ts1.weekofyear, ts2.weekofyear)\n&gt;&gt;&gt; f()\n(35, 38)\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/timestamp/#pdtimestampvalue","title":"<code>pd.Timestamp.value</code>","text":"<ul> <li> <p><code>pandas.Timestamp.value</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   return pd.Timestamp(12345, unit=\"ns\").value\n&gt;&gt;&gt; f()\n12345\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/timestamp/#pdtimestampceil","title":"<code>pd.Timestamp.ceil</code>","text":"<ul> <li> <p><code>pandas.Timestamp.ceil(freq, ambiguous='raise', nonexistent='raise')</code> Supported Arguments</p> <ul> <li><code>freq</code>: string</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   ts1 = pd.Timestamp(year=2021, month=12, day=9, hour = 9, minute=57, second=44, microsecond=114123)\n...   ts2 = pd.Timestamp(year=2021, month=12, day=9, hour = 9, minute=57, second=44, microsecond=114123).ceil(\"D\")\n...   return (ts1, ts2)\n&gt;&gt;&gt; f()\n(Timestamp('2021-12-09 09:57:44.114123'), Timestamp('2021-12-10 00:00:00'))\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/timestamp/#pdtimestampdate","title":"<code>pd.Timestamp.date</code>","text":"<ul> <li> <p><code>pandas.Timestamp.date()</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   ts1 = pd.Timestamp(year=2021, month=12, day=9, hour = 9, minute=57, second=44, microsecond=114123)\n...   ts2 = pd.Timestamp(year=2021, month=12, day=9, hour = 9, minute=57, second=44, microsecond=114123).date()\n...   return (ts1, ts2)\n&gt;&gt;&gt; f()\n(Timestamp('2021-12-09 09:57:44.114123'), datetime.date(2021, 12, 9))\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/timestamp/#pdtimestampday_name","title":"<code>pd.Timestamp.day_name</code>","text":"<ul> <li> <p><code>pandas.Timestamp.day_name(args, *kwargs)</code> </p> <p>Supported Arguments: None</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   day_1 = pd.Timestamp(year=2021, month=12, day=9).day_name()\n...   day_2 = pd.Timestamp(year=2021, month=12, day=10).day_name()\n...   day_3 = pd.Timestamp(year=2021, month=12, day=11).day_name()\n...   return (day_1, day_2, day_3)\n&gt;&gt;&gt; f()\n('Thursday', 'Friday', 'Saturday')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/timestamp/#pdtimestampfloor","title":"<code>pd.Timestamp.floor</code>","text":"<ul> <li> <p><code>pandas.Timestamp.floor(freq, ambiguous='raise', nonexistent='raise')</code> Supported Arguments</p> <ul> <li><code>freq</code>: string</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   ts1 = pd.Timestamp(year=2021, month=12, day=9, hour = 9, minute=57, second=44, microsecond=114123)\n...   ts2 = pd.Timestamp(year=2021, month=12, day=9, hour = 9, minute=57, second=44, microsecond=114123).ceil(\"D\")\n...   return (ts1, ts2)\n&gt;&gt;&gt; f()\n(Timestamp('2021-12-09 09:57:44.114123'), Timestamp('2021-12-09 00:00:00'))\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/timestamp/#pdtimestampisocalendar","title":"<code>pd.Timestamp.isocalendar</code>","text":"<ul> <li> <p><code>pandas.Timestamp.isocalendar()</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   ts1 = pd.Timestamp(year=2021, month=12, day=9, hour = 9, minute=57, second=44, microsecond=114123).isocalendar()\n...   return (ts1, ts2)\n&gt;&gt;&gt; f()\n(2021, 49, 4)\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/timestamp/#pdtimestampisoformat","title":"<code>pd.Timestamp.isoformat</code>","text":"<ul> <li> <p><code>pandas.Timestamp.isoformat()</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   ts1 = pd.Timestamp(year=2021, month=12, day=9, hour = 9, minute=57, second=44, microsecond=114123).isocalendar()\n...   return (ts1, ts2)\n&gt;&gt;&gt; f()\n'2021-12-09T09:57:44'\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/timestamp/#pdtimestampmonth_name","title":"<code>pd.Timestamp.month_name</code>","text":"<ul> <li> <p><code>pandas.Timestamp.month_name(locale=None)</code> Supported Arguments: None</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   return pd.Timestamp(year=2021, month=12, day=9).month_name()\n&gt;&gt;&gt; f()\n'December'\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/timestamp/#pdtimestampnormalize","title":"<code>pd.Timestamp.normalize</code>","text":"<ul> <li> <p><code>pandas.Timestamp.normalize()</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   ts1 = pd.Timestamp(year=2021, month=12, day=9, hour = 9, minute=57, second=44, microsecond=114123).normalize()\n...   return (ts1, ts2)\n&gt;&gt;&gt; f()\nTimestamp('2021-12-09 00:00:00')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/timestamp/#pdtimestampround","title":"<code>pd.Timestamp.round</code>","text":"<ul> <li> <p><code>pandas.Timestamp.round(freq, ambiguous='raise', nonexistent='raise')</code> Supported Arguments</p> <ul> <li><code>freq</code>: string</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   ts1 = pd.Timestamp(year=2021, month=12, day=9, hour = 12).round()\n...   ts2 = pd.Timestamp(year=2021, month=12, day=9, hour = 13).round()\n...   return (ts1, ts2)\n&gt;&gt;&gt; f()\n(Timestamp('2021-12-09 00:00:00'),Timestamp('2021-12-10 00:00:00'))\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/timestamp/#pdtimestampstrftime","title":"<code>pd.Timestamp.strftime</code>","text":"<ul> <li> <p><code>pandas.Timestamp.strftime(format)</code> Supported Arguments</p> <ul> <li><code>format</code>: string</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   return pd.Timestamp(year=2021, month=12, day=9, hour = 12).strftime('%Y-%m-%d %X')\n&gt;&gt;&gt; f()\n'2021-12-09 12:00:00'\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/timestamp/#pdtimestamptoordinal","title":"<code>pd.Timestamp.toordinal</code>","text":"<ul> <li> <p><code>pandas.Timestamp.toordinal()</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   return pd.Timestamp(year=2021, month=12, day=9).toordinal()\n&gt;&gt;&gt; f()\n738133\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/timestamp/#pdtimestampweekday","title":"<code>pd.Timestamp.weekday</code>","text":"<ul> <li> <p><code>pandas.Timestamp.weekday()</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   ts1 = pd.Timestamp(year=2021, month=12, day=9)\n...   ts2 = pd.Timestamp(year=2021, month=12, day=10)\n...   return (ts1.weekday(), ts2.weekday())\n&gt;&gt;&gt; f()\n(3, 4)\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/timestamp/#pdtimestampnow","title":"<code>pd.Timestamp.now</code>","text":"<ul> <li> <p><code>pandas.Timestamp.now(tz=None)</code> Supported Arguments:</p> <ul> <li><code>tz</code>: constant string, integer, or None</li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f():\n...   return pd.Timestamp.now()\n&gt;&gt;&gt; f()\nTimestamp('2021-12-10 10:54:06.457168')\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/window/","title":"Window","text":"<p>Rolling functionality is documented in <code>pandas.DataFrame.rolling</code>.</p>"},{"location":"api_docs/pandas/window/#pdcorewindowrollingrollingcount","title":"<code>pd.core.window.rolling.Rolling.count</code>","text":"<ul> <li> <p><code>pandas.core.window.rolling.Rolling.count()</code> Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   df = pd.DataFrame({\"A\": [1,2,3,4,5], \"B\": [6,7,None,9,10]})\n...   return df.rolling(3).count()\nA    B\n0  1.0  1.0\n1  2.0  2.0\n2  3.0  3.0\n3  3.0  2.0\n4  3.0  2.0\n5  3.0  2.0\n6  3.0  3.0\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/window/#pdcorewindowrollingrollingsum","title":"<code>pd.core.window.rolling.Rolling.sum</code>","text":"<ul> <li> <p><code>pandas.core.window.rolling.Rolling.sum(engine=None, engine_kwargs=None)</code> Supported Arguments: None</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   df = pd.DataFrame({\"A\": [1,2,3,4,5,6,7], \"B\": [8,9,10,None,11,12,13]})\n...   return df.rolling(3).sum()\nA     B\n0   NaN   NaN\n1   NaN   NaN\n2   6.0  27.0\n3   9.0   NaN\n4  12.0   NaN\n5  15.0   NaN\n6  18.0  36.0\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/window/#pdcorewindowrollingrollingmean","title":"<code>pd.core.window.rolling.Rolling.mean</code>","text":"<ul> <li> <p><code>pandas.core.window.rolling.Rolling.mean(engine=None, engine_kwargs=None)</code> Supported Arguments: None</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   df = pd.DataFrame({\"A\": [1,2,3,4,5,6,7], \"B\": [8,9,10,None,11,12,13]})\n...   return df.rolling(3).mean()\nA     B\n0  NaN   NaN\n1  NaN   NaN\n2  2.0   9.0\n3  3.0   NaN\n4  4.0   NaN\n5  5.0   NaN\n6  6.0  12.0\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/window/#pdcorewindowrollingrollingmedian","title":"<code>pd.core.window.rolling.Rolling.median</code>","text":"<ul> <li> <p><code>pandas.core.window.rolling.Rolling.median(engine=None, engine_kwargs=None)</code> Supported Arguments: None</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   df = pd.DataFrame({\"A\": [1,2,3,4,5,6,7], \"B\": [8,9,10,None,11,12,13]})\n...   return df.rolling(3).median()\nA     B\n0  NaN   NaN\n1  NaN   NaN\n2  2.0   9.0\n3  3.0   NaN\n4  4.0   NaN\n5  5.0   NaN\n6  6.0  12.0\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/window/#pdcorewindowrollingrollingvar","title":"<code>pd.core.window.rolling.Rolling.var</code>","text":"<ul> <li> <p><code>pandas.core.window.rolling.Rolling.var(ddof=1)</code> Supported Arguments: None</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   df = pd.DataFrame({\"A\": [1,2,3,4,5,6,7], \"B\": [8,9,10,None,11,12,13]})\n...   return df.rolling(3).var()\nA    B\n0  NaN  NaN\n1  NaN  NaN\n2  1.0  1.0\n3  1.0  NaN\n4  1.0  NaN\n5  1.0  NaN\n6  1.0  1.0\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/window/#pdcorewindowrollingrollingstd","title":"<code>pd.core.window.rolling.Rolling.std</code>","text":"<ul> <li> <p><code>pandas.core.window.rolling.Rolling.std(ddof=1)</code> Supported Arguments: None</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   df = pd.DataFrame({\"A\": [1,2,3,4,5,6,7], \"B\": [8,9,10,None,11,12,13]})\n...   return df.rolling(3).std()\nA    B\n0  NaN  NaN\n1  NaN  NaN\n2  1.0  1.0\n3  1.0  NaN\n4  1.0  NaN\n5  1.0  NaN\n6  1.0  1.0\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/window/#pdcorewindowrollingrollingmin","title":"<code>pd.core.window.rolling.Rolling.min</code>","text":"<ul> <li> <p><code>pandas.core.window.rolling.Rolling.min(engine=None, engine_kwargs=None)</code> Supported Arguments: None</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   df = pd.DataFrame({\"A\": [1,2,3,4,5,6,7], \"B\": [8,9,10,None,11,12,13]})\n...   return df.rolling(3).min()\nA     B\n0  NaN   NaN\n1  NaN   NaN\n2  1.0   8.0\n3  2.0   NaN\n4  3.0   NaN\n5  4.0   NaN\n6  5.0  11.0\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/window/#pdcorewindowrollingrollingmax","title":"<code>pd.core.window.rolling.Rolling.max</code>","text":"<ul> <li> <p><code>pandas.core.window.rolling.Rolling.max(engine=None, engine_kwargs=None)</code> Supported Arguments: None</p> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   df = pd.DataFrame({\"A\": [1,2,3,4,5,6,7], \"B\": [8,9,10,None,11,12,13]})\n...   return df.rolling(3).max()\nA     B\n0  NaN   NaN\n1  NaN   NaN\n2  3.0  10.0\n3  4.0   NaN\n4  5.0   NaN\n5  6.0   NaN\n6  7.0  13.0\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/window/#pdcorewindowrollingrollingcorr","title":"<code>pd.core.window.rolling.Rolling.corr</code>","text":"<ul> <li> <p><code>pandas.core.window.rolling.Rolling.corr(other=None, pairwise=None, ddof=1)</code> Supported Arguments</p> <ul> <li><code>other</code>: DataFrame or Series (cannot contain nullable Integer Types)<ul> <li>Required</li> <li>If called with a DataFrame, <code>other</code> must be a DataFrame. If called with a Series, <code>other</code> must be a Series.</li> </ul> </li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   df1 = pd.DataFrame({\"A\": [1,2,3,4,5,6,7]})\n...   df2 = pd.DataFrame({\"A\": [1,2,3,4,-5,-6,-7]})\n...   return df1.rolling(3).corr(df2)\nA\n0       NaN\n1       NaN\n2  1.000000\n3  1.000000\n4 -0.810885\n5 -0.907841\n6 -1.000000\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/window/#pdcorewindowrollingrollingcov","title":"<code>pd.core.window.rolling.Rolling.cov</code>","text":"<ul> <li> <p><code>pandas.core.window.rolling.Rolling.cov(other=None, pairwise=None, ddof=1)</code> Supported Arguments</p> <ul> <li><code>other</code>: DataFrame or Series (cannot contain nullable Integer Types)<ul> <li>Required</li> <li>If called with a DataFrame, <code>other</code> must be a DataFrame. If called with a Series, <code>other</code> must be a Series.</li> </ul> </li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   df1 = pd.DataFrame({\"A\": [1,2,3,4,5,6,7]})\n...   df2 = pd.DataFrame({\"A\": [1,2,3,4,-5,-6,-7]})\n...   return df1.rolling(3).cov(df2)\nA\n0  NaN\n1  NaN\n2  1.0\n3  1.0\n4 -4.0\n5 -5.0\n6 -1.0\n</code></pre> </li> </ul>"},{"location":"api_docs/pandas/window/#pdcorewindowrollingrollingapply","title":"<code>pd.core.window.rolling.Rolling.%%apply</code>","text":"<ul> <li> <p><code>pandas.core.window.rolling.apply(func, raw=False, engine=None, engine_kwargs=None, args=None, kwargs=None)</code> Supported Arguments</p> <ul> <li><code>func</code>: JIT function or callable defined within a JIT function<ul> <li>Must be constant at Compile Time</li> </ul> </li> <li><code>raw</code>: boolean<ul> <li>Must be constant at Compile Time</li> </ul> </li> </ul> <p>Example Usage</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(I):\n...   df = pd.DataFrame({\"A\": [1,2,3,4,-5,-6,-7]})\n...   return df.rolling(3).apply(lambda x: True if x.sum() &gt; 0 else False)\nA\n0  NaN\n1  NaN\n2  1.0\n3  1.0\n4  1.0\n5  0.0\n6  0.0\n</code></pre> </li> </ul>"},{"location":"bodo_parallelism/advanced/","title":"Advanced Parallelism Topics","text":"<p>This page discusses parallelism topics that are useful for performance tuning and advanced use cases.</p>"},{"location":"bodo_parallelism/advanced/#dist-flags","title":"Distributed Flags For JIT Functions","text":"<p>Bodo infers data distributions for inputs and outputs of JIT functions automatically. For example, all dataframe arguments and return values are distributed in this code:</p> <pre><code>@bodo.jit\ndef f():\ndf = pd.read_parquet(\"pd_example.pq\")\nreturn df\n@bodo.jit\ndef h(df):\ndf2 = df.groupby(\"A\").sum()\nreturn df2\n@bodo.jit\ndef g(df):\ndf3 = h(df)\nreturn df3\ndf = f()\ndf3 = g(df)\n</code></pre> <p>Bodo tracks distributions across JIT functions and between JIT and regular Python code (by setting metadata in regular Pandas dataframes). However, the user can specify distributions manunally as well. The above code is equivalent to:</p> <pre><code>@bodo.jit(distributed=[\"df\"])\ndef f():\ndf = pd.read_parquet(\"pd_example.pq\")\nreturn df\n@bodo.jit(distributed=[\"df\", \"df2\"])\ndef h(df):\ndf2 = df.groupby(\"A\").sum()\nreturn df2\n@bodo.jit(distributed=[\"df\", \"df3\"])\ndef g(df):\ndf3 = h(df)\nreturn df3\ndf = f()\ndf3 = g(df)\n</code></pre> <p>Generally, Bodo can handle distributions of most use cases automatically and we do not recommend setting distributions manually due to the possibility of human error. However, there are some advanced use cases where setting these flags may be desirable or necessary. For example, when a small dataframe is an input to a join, setting its distribution to replicated can improve parallel performance. In the example below, a small dataframe <code>df2</code> is an argument to a join on a large dataframe <code>df1</code>, and we specify <code>df2</code> as replicated for better parallel performance.  <pre><code>@bodo.jit(distributed=[\"df1\"], replicated=[\"df2\"])\ndef load_data():\ndf1 = pd.read_parquet(\"my_large_data.pq\")\ndf2 = pd.read_parquet(\"my_tiny_data.pq\")\nreturn df1, df2\n@bodo.jit\ndef merge_data():\ndf1, df2 = load_data()\ndf3 = df1.merge(df2, on=\"id\")\ndf3.to_parquet(\"my_merged_data.pq\")\nmerge_data()\n</code></pre></p> <p>Another potential use case is when we want to parallelize computation without distributing data, for applications such as parameter tuning and simulations. The example below creates some parameters, distributes them manually using <code>bodo.scatterv</code>, and performs some computation on each one using a <code>bodo.prange</code> parallel loop. The input dataframe <code>df</code> is replicated across processors since all of its values are needed for computations on each parameter. Functions <code>create_params</code> and <code>load_data</code> have <code>distributed=False</code> set, which makes all of their data structures and computations replicated across processors.</p> <p>See Also<p><code>bodo.scatterv</code>, <code>bodo.prange</code></p> </p> <pre><code>@bodo.jit(distributed=False)\ndef create_params():\nparams = [1, 3, 4, 5, 7, 8, 11, 15, 17, 21]\nparams2 = [a * 2 for a in params]\nreturn np.array(params + params2)\n@bodo.jit(distributed=False)\ndef load_data():\ndf = pd.read_parquet(\"my_large_data.pq\")\nreturn df\n@bodo.jit\ndef run_params():\nparams = create_params()\ndf = load_data()\nparams_dist = bodo.scatterv(params)\nn = len(params_dist)\nres = np.zeros(n)\nfor i in bodo.prange(n):\np = params_dist[i]\nres[i] = df.apply(lambda x, a: x.B % a, axis=1, a=p).sum()\nprint(res.max())\nrun_params()\n</code></pre>"},{"location":"bodo_parallelism/advanced/#indexing-operations-on-distributed-data","title":"Indexing Operations on Distributed Data","text":"<p>Distributed data is usually accessed and modified through high-level Pandas and Numpy APIs. However, in many cases, Bodo allows indexing operations on distributed data without code modification. Here are such cases that Bodo currently supports:</p> <ol> <li> <p>Getting values using boolean array indexing, e.g. <code>B = A[A &gt; 3]</code>.     The output can be distributed, but may be imbalanced     (<code>bodo.rebalance()</code> can be used if necessary).</p> </li> <li> <p>Getting values using a slice, e.g. <code>B = A[::2]</code>. The output can be     distributed, but may be imbalanced      (<code>bodo.rebalance()</code> can be used if necessary).</p> </li> <li> <p>Getting a value using a scalar index, e.g. <code>a = A[m]</code>. The output     can be replicated.</p> </li> <li> <p>Setting values using boolean array indexing, e.g. <code>A[A &gt; 3] = a</code>.     Only supports setting a scalar or lower-dimension value currently.</p> </li> <li> <p>Setting values using a slice, e.g. <code>A[::2] = a</code>. Only supports     setting a scalar or lower-dimension value currently.</p> </li> <li> <p>Setting a value using a scalar index, e.g. <code>A[m] = a</code>.</p> </li> </ol>"},{"location":"bodo_parallelism/advanced/#concatenation-reduction","title":"Concatenation Reduction","text":"<p>Some algorithms require generating variable-length output data per input data element. Bodo supports parallelizing this pattern, which we refer to as concatenation reduction. For example:</p> <pre><code>@bodo.jit\ndef impl(n):\ndf = pd.DataFrame()\nfor i in bodo.prange(n):\ndf = df.append(pd.DataFrame({\"A\": np.arange(i)}))\nreturn df\n</code></pre> <p>A common use case is simulation applications that generate possible outcomes based on parameters. For example:</p> <pre><code>@bodo.jit\ndef impl():\nparams = np.array([0.1, 0.2, 0.5, 1.0, 1.2, 1.5, ..., 100])\nparams = bodo.scatterv(params)\ndf = pd.DataFrame()\nfor i in bodo.prange(len(params)):\ndf = df.append(get_result(params[i]))\nreturn df\n</code></pre> <p>In this example, we chose to manually parallelize the parameter array for simplicity, since the workload is compute-heavy and the parameter data is relatively small.</p>"},{"location":"bodo_parallelism/advanced/#load-balancing-distributed-data","title":"Load Balancing Distributed Data","text":"<p>Some computations such as <code>filter</code>, <code>join</code> or <code>groupby</code> can result in imbalanced data chunks across cores for distributed data. This may result in some cores operating on nearly empty dataframes, and others on relatively large ones.</p> <p>Bodo provides <code>bodo.rebalance</code> to allow manual load balance if necessary. For example:</p> <pre><code>@bodo.jit(distributed={\"df\"})\ndef rebalance_example(df):\n    df = df[df[\"A\"] &gt; 3]\n    df = bodo.rebalance(df)\n    return df.sum()\n</code></pre> <p>In this case, we use <code>bodo.rebalance</code> to make sure the filtered dataframe has near-equal data chunk sizes across cores, which would accelerate later computations (<code>sum</code> in this case).</p> <p>We can also use the <code>dests</code> keyword to specify a subset of ranks to which bodo should distribute the data from all ranks.</p> <p>Example usage:</p> <pre><code>@bodo.jit(distributed={\"df\"})\ndef rebalance_example(df):\ndf = df[df[\"A\"] &gt; 3]\ndf = bodo.rebalance(df, dests=[0, 1])\nreturn df.sum()\n</code></pre>"},{"location":"bodo_parallelism/advanced/#explicit-parallel-loops","title":"Explicit Parallel Loops","text":"<p>Sometimes explicit parallel loops are required since a program cannot be written in terms of data-parallel operators easily. In this case, one can use Bodo's <code>prange</code> in place of <code>range</code> to specify that a loop can be parallelized. The user is required to make sure the loop does not have cross-iteration dependencies except for supported reductions. Currently, reductions using <code>+=</code>, <code>*=</code>, <code>min</code>, and <code>max</code> operators are supported. Iterations are simply divided between processes and executed in parallel, but reductions are handled using data exchange.</p> <p>The example below demonstrates a parallel loop with a reduction:</p> <pre><code>import bodo\nfrom bodo import prange\nimport numpy as np\n@bodo.jit\ndef prange_test(n):\nA = np.random.ranf(n)\ns = 0\nB = np.empty(n)\nfor i in prange(len(A)):\nbodo.parallel_print(\"rank\", bodo.get_rank())\n# A[i]: distributed data access with loop index\n# s: a supported sum reduction\ns += A[i]\n# write array with loop index\nB[i] = 2 * A[i]\nreturn s + B.sum()\nres = prange_test(10)\nprint(res)\n</code></pre> <p>Output: </p> <pre><code>[stdout:0]\nrank 0\nrank 0\nrank 0\n13.077183553245497\n[stdout:1]\nrank 1\nrank 1\nrank 1\n13.077183553245497\n[stdout:2]\nrank 2\nrank 2\n13.077183553245497\n[stdout:3]\nrank 3\nrank 3\n13.077183553245497\n</code></pre> <p>The user is also responsible for ensuring that control flow doesn't prevent the loop from being reduced. This can occur when operations are potentially applied unevenly or when the order the operation occurs in matters. This means that mixing reductions and control flow breaks such as <code>break</code> or <code>raise</code> are not supported.</p> <p>The below example shows what happens when control flow prevents a reduction from being parallelized:</p> <pre><code>import bodo\nfrom bodo import prange\nimport numpy as np\n@bodo.jit\ndef prange_test(n):\nA = np.random.ranf(n)\ns = 0\nfor i in prange(len(A)):\nif A[i] % 2 == 0:\ns *= 2\nelse:\ns += A[i]\nreturn s\nres = prange_test(10)\nprint(res)\n</code></pre> <p>Output: </p> <pre><code>numba.core.errors.UnsupportedRewriteError: Failed in bodo mode pipeline (step: convert to parfors)\nReduction variable s has multiple conflicting reduction operators.\n</code></pre>"},{"location":"bodo_parallelism/advanced/#integration-with-non-bodo-apis","title":"Integration with non-Bodo APIs","text":"<p>There are multiple methods for integration with APIs that Bodo does not support natively:</p> <ol> <li>Switch to python Object Mode inside jit functions</li> <li>Pass data in and out of jit functions</li> </ol>"},{"location":"bodo_parallelism/advanced/#passing-distributed-data","title":"Passing Distributed Data","text":"<p>Bodo can receive or return chunks of distributed data to allow flexible integration with any non-Bodo Python code. The following example passes chunks of data to interpolate with Scipy, and returns interpolation results back to jit function.</p> <pre><code>import scipy.interpolate\n@bodo.jit(distributed=[\"X\", \"Y\", \"X2\"])\ndef dist_pass_test(n):\nX = np.arange(n)\nY = np.exp(-X/3.0)\nX2 = np.arange(0, n, 0.5)\nreturn X, Y, X2\nX, Y, X2 = dist_pass_test(100)\n# clip potential out-of-range values\nX2 = np.minimum(np.maximum(X2, X[0]), X[-1])\nf = scipy.interpolate.interp1d(X, Y)\nY2 = f(X2)\n@bodo.jit(distributed={\"Y2\"})\ndef dist_pass_res(Y2):\nreturn Y2.sum()\nres = dist_pass_res(Y2)\nprint(res)\n</code></pre> <pre><code>[stdout:0] 6.555500504321469 \n[stdout:1] 6.555500504321469\n[stdout:2] 6.555500504321469 \n[stdout:3] 6.555500504321469\n</code></pre>"},{"location":"bodo_parallelism/advanced/#collections-of-distributed-data","title":"Collections of Distributed Data","text":"<p>List and dictionary collections can be used to hold distributed data structures:</p> <pre><code>@bodo.jit(distributed=[\"df\"])\ndef f():\nto_concat = []\nfor i in range(10):\nto_concat.append(pd.DataFrame({'A': np.arange(100), 'B': np.random.random(100)}))\ndf = pd.concat(to_concat)\nreturn df\nf()\n</code></pre> <p></p>"},{"location":"bodo_parallelism/advanced/#run_on_single_rank","title":"Run code on a single rank","text":"<p>In cases where some code needs to be run on a single MPI rank, you can do so in a python script as follows:</p> <pre><code>if bodo.get_rank() == 0:\n# Remove directory\nimport os, shutil\nif os.path.exists(\"data/data.pq\"):\nshutil.rmtree(\"data/data.pq\")\n# To synchronize all ranks before proceeding\nbodo.barrier()\n</code></pre> <p>When running code on an IPyParallel cluster using the <code>%%px</code> magic, you can do this instead:</p> <pre><code>%%px --targets 0\n# Install package\n!conda install pandas-datareader\n</code></pre> <p>An alias can be defined for convenience:</p> <pre><code>%alias_magic p0 px -p \"--targets 0\"\n</code></pre> <p>This can be used as any other magic:</p> <pre><code>%%p0\n# Install package\n!conda install pandas-datareader\n</code></pre>"},{"location":"bodo_parallelism/advanced/#run_on_each_node","title":"Run code once on each node","text":"<p>In cases where some code needs to be run once on each node in a multi-node cluster, such as a file system operation, installing packages, etc., it can be done as follows:</p> <pre><code>if bodo.get_rank() in bodo.get_nodes_first_ranks():\n# Remove directory on all nodes\nimport os, shutil\nif os.path.exists(\"data/data.pq\"):\nshutil.rmtree(\"data/data.pq\")\n# To synchronize all ranks before proceeding\nbodo.barrier()\n</code></pre> <p>The same can be done when running on an IPyParallel cluster using the <code>%%px</code> magic:</p> <pre><code>%%px\nif bodo.get_rank() in bodo.get_nodes_first_ranks():\n# Install package on all nodes\n!conda install pandas-datareader\n</code></pre> <p>Warning</p> <p>Running code on a single rank or a subset of ranks can lead to deadlocks. Ensure that your code doesn't include any MPI or Bodo functions.</p>"},{"location":"bodo_parallelism/bodo_parallelism_basics/","title":"Bodo Parallelism Basics","text":"<p>This page discusses Bodo's JIT compilation workflow and the parallelism model and APIs provided by Bodo.</p>"},{"location":"bodo_parallelism/bodo_parallelism_basics/#jit","title":"JIT (Just-in-time) Compilation Workflow","text":"<p>Bodo provides a just-in-time (JIT) compilation workflow using the <code>@bodo.jit</code> decorator, which replaces a Python function with a so-called <code>Dispatcher</code> object. Bodo compiles the function the first time a Dispatcher object is called and reuses the compiled version afterwards. The function is recompiled only if the same function is called with different argument types (not often in practice). All of this is completely transparent to the caller, and does not affect any Python code calling the function.</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import bodo\n&gt;&gt;&gt; @bodo.jit\n... def f(n, a):\n...   df = pd.DataFrame({\"A\": np.arange(n) + a})\n...   return df.head(3)\n... \n&gt;&gt;&gt; print(f)\nCPUDispatcher(&lt;function f at 0x100bec310&gt;)\n&gt;&gt;&gt; print(f(8, 1)) # compiles for (int, int) input types\nA\n0  1\n1  2\n2  3\n&gt;&gt;&gt; print(f(8, 2)) # same input types, no need to compile\nA\n0  2\n1  3\n2  4\n&gt;&gt;&gt; print(f(8, 2.2)) # compiles for (int, float) input types\nA\n0  2.2\n1  3.2\n2  4.2\n</code></pre> <p>Note</p> <p>In many cases, the binary that Bodo generates when compiling a function can be saved to disk and reused across program executions. See caching for more information.</p>"},{"location":"bodo_parallelism/bodo_parallelism_basics/#parallel-execution-model","title":"Parallel Execution Model","text":"<p>As we saw in the \"Getting Started\" tutorial, Bodo transforms functions for parallel execution. Bodo uses Message Passing Interface (MPI) that follows Single Program Multiple Data (SPMD) paradigm. In this model, the dispatcher does not launch processes or threads on the fly. Instead, all processes are launched at the beginning and run the same file using <code>mpiexec</code> command.</p> <p>Bodo parallelizes functions with the <code>bodo.jit</code> decorator by distributing the data across the processes. Each rank runs the same code on a chunk of the data, and Bodo automatically communicates the data between the ranks (as needed).</p> <p>For example, save the following code in a<code>test_bodo.py</code> and use <code>mpiexec</code> to launch 4 processes as follows:</p> <pre><code>import numpy as np\nimport pandas as pd\nimport bodo\n@bodo.jit\ndef f(n, a):\ndf = pd.DataFrame({\"A\": np.arange(n) + a})\nreturn df\nprint(f(8, 1))\n</code></pre> <pre><code>mpiexec -n 4 python test_bodo.py\n</code></pre> <p>Output:</p> <pre><code>   A\n2  3\n3  4\n   A\n6  7\n7  8\n   A\n4  5\n5  6\n   A\n0  1\n1  2\n</code></pre> <p>In this example, <code>mpiexec</code> launches 4 Python processes, each  executing the same <code>test_bodo.py</code> file. Since the function <code>f</code> is decorated with <code>bodo.jit</code> and Bodo can parallelize it, each process generates a chunk of the data in <code>np.arange</code>.</p> <p>Note how the prints, which are regular Python code executed outside of Bodo, run for each process.</p> <p>Warning</p> <ul> <li>Python codes outside of Bodo functions execute sequentially on every process.</li> <li>Bodo functions run in parallel assuming that Bodo is able to parallelize them. Otherwise, Bodo prints the following warning and runs sequentially on every process.</li> </ul> <pre><code>BodoWarning: No parallelism found for function\n</code></pre> <p>On Jupyter notebook, parallel execution happens in very much the same way. We start a set of MPI engines through <code>ipyparallel</code> and activate a client. See how to use bodo with jupyter notebooks for more information and examples.</p> <p>See Also</p> <p>Parallel APIs</p>"},{"location":"bodo_parallelism/bodo_parallelism_basics/#data-distribution","title":"Data Distribution","text":"<p>Bodo parallelizes computation by dividing data into separate chunks across processes. However, some data handled by a Bodo function may not be divided into chunks. There are are two main data distribution schemes:</p> <ul> <li>Replicated (REP): the data associated with the variable is the     same on every process.</li> <li>One-dimensional (1D): the data is divided into chunks, split along     one dimension (rows of a dataframe or first dimension of an array).</li> </ul> <p>Bodo determines distribution of variables automatically, using the nature of the computation that produces them. Let's see an example:</p> <pre><code>import bodo\nimport pandas as pd\n@bodo.jit\ndef mean_power_speed():\ndf = pd.read_parquet(\"data/cycling_dataset.pq\")\nm = df[[\"power\", \"speed\"]].mean()\nreturn m\nres = mean_power_speed()\nprint(res)\n</code></pre> <p>Save code in mean_power_speed.py and run it with <code>mpiexec</code> as follows:</p> <pre><code>mpiexec -n 4 python mean_power_speed.py\n</code></pre> <pre><code>[stdout:0]\npower    102.078421\nspeed      5.656851\ndtype: float64\n[stdout:1]\npower    102.078421\nspeed      5.656851\ndtype: float64\n[stdout:2]\npower    102.078421\nspeed      5.656851\ndtype: float64\n[stdout:3]\npower    102.078421\nspeed      5.656851\ndtype: float64\n</code></pre> <p>In this example, <code>df</code> is parallelized (each process reads a different chunk) but <code>m</code> is replicated, even though it is a Series. Semantically, it makes sense for the output of <code>mean</code> operation to be replicated on all processors, since it is a reduction and produces \"small\" data.</p>"},{"location":"bodo_parallelism/bodo_parallelism_basics/#distributed-diagnostics","title":"Distributed Diagnostics","text":"<p>The distributions found by Bodo can be printed either by setting the environment variable <code>BODO_DISTRIBUTED_DIAGNOSTICS=1</code> or calling <code>distributed_diagnostics()</code> on the compiled function. Let's examine the previous example's distributions by adding following line to <code>mean_power_speed</code> script:</p> <pre><code>mean_power_speed.distributed_diagnostics()\n</code></pre> <pre><code>python mean_power_speed.py\n</code></pre> <pre><code>Distributed analysis replicated return variable $30return_value.12. Set distributed flag for the original variable if distributed partitions should be returned.\n[stdout:0]\npython mean_power_speed.py             \npower    102.078421\nspeed      5.656851\ndtype: float64\nDistributed diagnostics for function mean_power_speed, /Users/mean_power_speed.py (3)\nData distributions:\n    pq_table.0                                                              1D_Block\n    pq_index.1                                                              1D_Block\n    data_74                                                                 REP\n    Parfor distributions:\n       0                    1D_Block\n       1                    1D_Block\n    Distributed listing for function mean_power_speed, /Users/hadia/Bodo/testing/mean_power_speed.py (3)\n    ---------------------------------------------------------------------| parfor_id/variable: distribution\n    @bodo.jit                                                            | \n    def mean_power_speed():                                              | \n        df = pd.read_parquet(\"Bodo-tutorial/data/cycling_dataset.pq\")----| pq_table.0: 1D_Block, pq_index.1: 1D_Block\n        m = df[[\"power\", \"speed\"]].mean()--------------------------------| #0: 1D_Block, #1: 1D_Block, data_74: REP\n        return m                                                         | \n    Setting distribution of variable 'impl_v48_data_74' to REP: output of np.asarray() call on non-array is REP\n</code></pre> <p>Bodo compiler optimizations rename the variables.  The output shows that <code>power</code> and <code>speed</code> columns of <code>df</code> are distributed (<code>1D_Block</code>), but <code>m</code> is replicated (<code>REP</code>).  This is because <code>df</code> is the output from <code>read_parquet</code> and input to <code>mean</code>, both of which can be distributed by Bodo.  <code>m</code> is the output from <code>mean</code>, which is replicated (available on every process).</p>"},{"location":"bodo_parallelism/not_supported/","title":"Unsupported Python Programs","text":"<p>Bodo compiles functions into efficient native parallel binaries, which requires all the operations used in the code to be supported by Bodo. This excludes the Python features discussed on this page.</p>"},{"location":"bodo_parallelism/not_supported/#typestability","title":"Type Stability","text":"<p>To enable type inference, the program should be type stable, which means Bodo should be able to assign a single type to every variable.</p>"},{"location":"bodo_parallelism/not_supported/#schemastability","title":"DataFrame Schema","text":"<p>Deterministic dataframe schemas, which are required in most data systems, is key for type stability. For example, variable <code>df</code> in example below could be either a single column dataframe or a two column one -- Bodo cannot determine it at compilation time:</p> <pre><code>@bodo.jit\ndef f(a):\ndf = pd.DataFrame({\"A\": [1, 2, 3]})\ndf2 = pd.DataFrame({\"A\": [1, 3, 4], \"C\": [-1, -2, -3]})\nif len(a) &gt; 3:\ndf = df.merge(df2)\nreturn df.mean()\nprint(f([2, 3]))\n# TypeError: Cannot unify dataframe((array(int64, 1d, C),), RangeIndexType(none), ('A',), False)\n# and dataframe((array(int64, 1d, C), array(int64, 1d, C)), RangeIndexType(none), ('A', 'C'), False) for 'df'\n</code></pre> <p>The error message means that Bodo cannot find a type that can unify the two types into a single type. This code can be refactored so that the <code>if</code> control flow is executed in regular Python context, but the rest of computation is in Bodo functions. For example, one could use two versions of the function:</p> <pre><code>@bodo.jit\ndef f1():\ndf = pd.DataFrame({\"A\": [1, 2, 3]})\nreturn df.mean()\n@bodo.jit\ndef f2():\ndf = pd.DataFrame({\"A\": [1, 2, 3]})\ndf2 = pd.DataFrame({\"A\": [1, 3, 4], \"C\": [-1, -2, -3]})\ndf = df.merge(df2)\nreturn df.mean()\na = [2, 3]\nif len(a) &gt; 3:\nprint(f1())\nelse:\nprint(f2())\n</code></pre> <p>Another common place where schema stability may be compromised is in passing non-constant list of key column names to dataframe operations such as <code>groupby</code>, <code>merge</code> and <code>sort_values</code>. In these operations, Bodo should be able to deduce the list of key column names at compile time in order to determine the output dataframe schema. For example, the program below is potentially type unstable since Bodo may not be able to infer <code>column_list</code> during compilation:</p> <pre><code>@bodo.jit\ndef f(a, i):\ncolumn_list = a[:i]  # some computation that cannot be inferred statically\ndf = pd.DataFrame({\"A\": [1, 2, 1], \"B\": [4, 5, 6]})\nreturn df.groupby(column_list).sum()\na = [\"A\", \"B\"]\ni = 1\nf(a, i)\n# BodoError: groupby(): 'by' parameter only supports a constant column label or column labels.\n</code></pre> <p>This code can be refactored so that the computation for <code>column_list</code> is performed in regular Python context, and the result is passed as a function argument:</p> <pre><code>@bodo.jit\ndef f(column_list):\ndf = pd.DataFrame({\"A\": [1, 2, 1], \"B\": [4, 5, 6]})\nreturn df.groupby(column_list).sum()\na = [\"A\", \"B\"]\ni = 1\ncolumn_list = a[:i]\nf(column_list)\n</code></pre> <p>In general, Bodo can infer constants from function arguments, global variables, and constant values in the program. Furthermore, Bodo supports implicitly inferring constant lists automatically for list addition and set difference operations such as:</p> <pre><code>df.groupby([\"A\"] + [\"B\"]).sum()\ndf.groupby(list(set(df.columns) - set([\"A\", \"C\"]))).sum()\n</code></pre> <p>Bodo will support inferring more implicit constant cases in the future (e.g. more list and set operations).</p> <p>Referring to dataframe columns (e.g. <code>[df[\"A\"]]</code>) requires constants for schema stability as well. <code>for</code> loops over dataframe column names such as below is not supported yet:</p> <pre><code>@bodo.jit\ndef f(df):\ns = 0\nfor c in df.columns:\ns += df[c].sum()\nreturn s\nf(pd.DataFrame({\"A\": [1, 2, 1], \"B\": [4, 5, 6]}))\n# BodoError: df[] getitem selecting a subset of columns requires providing constant column names. For more information, see https://docs.bodo.ai/latest/programming_with_bodo/require_constants.html\n</code></pre>"},{"location":"bodo_parallelism/not_supported/#variable-types-and-functions","title":"Variable Types and Functions","text":"<p>The example below is not type stable since variable <code>a</code> can be both a float and an array of floats:</p> <pre><code>if flag:\na = 1.0\nelse:\na = np.ones(10)\n</code></pre> <p>The use of <code>isinstance</code> operator of Python often means type instability and is not supported.</p> <p>Similarly, function calls should also be deterministic. The below example is not supported since the function <code>f</code> is not known in advance:</p> <pre><code>if flag:\nf = np.zeros\nelse:\nf = np.random.ranf\nA = f(10)\n</code></pre> <p>One can usually avoid these cases in analytics codes without significant effort.</p>"},{"location":"bodo_parallelism/not_supported/#accessing-individual-values-of-nullable-data","title":"Accessing individual values of nullable data","text":"<p>The type of null (NA) value for most nullable data arrays is different than regular values (except float data which stores <code>np.nan</code>). Therefore, accessing individual values (i.e. using <code>[[]]</code> with an integer index) may not be type stable. In these cases, Bodo assumes the value is not NA and returns an \"neutral\" value:</p> <pre><code>@bodo.jit\ndef f(S, i):\nreturn S.iloc[i]  # not type stable\nS = pd.Series([\"A\", None, \"CC\"])\nf(S, 1)  # returns \"\"\n</code></pre> <p>The solution is to check for NA values using <code>pd.isna</code> to handle NA values appropriately:</p> <pre><code>@bodo.jit\ndef f(S, i):\nif pd.isna(S.iloc[i]):\nreturn \"NA\"\nreturn S.iloc[i]\nS = pd.Series([\"A\", None, \"CC\"])\nf(S, 1)  # returns \"NA\"\n</code></pre> <p>We are working on making it possible to avoid stability issues automatically in most practical cases.</p>"},{"location":"bodo_parallelism/not_supported/#notsupportedpython","title":"Unsupported Python Constructs","text":"<p>Bodo relies on Numba for supporting basic Python features. Therefore, Python constructs that are not supported by Numba should be avoided in Bodo programs.</p> <p>Generally, these Python features are not supported:</p> <ul> <li>exceptions: <code>try .. except</code>, <code>raise</code></li> <li>context manager: <code>with</code></li> <li>list, set, dict and generator comprehensions</li> <li>async features</li> <li>class definition: <code>class</code></li> <li>jit functions cannot have <code>**kwargs</code></li> <li>functions can be passed as arguments but not returned</li> <li>lists of lists cannot be passed as arguments unless Numba typed-lists     are used.</li> <li>Numba typed-dicts     are currently required for passing dictionaries as argument to jit     functions.</li> </ul>"},{"location":"bodo_parallelism/not_supported/#heterogeneousdtype","title":"Heterogeneous types inside a data structure","text":"<ul> <li> <p><code>List</code> containing values of heterogeneous type:      <pre><code>myList = [1, \"a\", 0.1]\n</code></pre></p> </li> <li> <p><code>Dictionary</code> containing values of heterogeneous type</p> <pre><code>myDict = {\"A\": 1, \"B\": \"a\", \"C\": 0.1}\n</code></pre> </li> </ul>"},{"location":"bodo_parallelism/typing_considerations/","title":"Typing Considerations","text":"<p>This section discusses some supported Pandas datatypes, potential typing related issues, and ways to resolve them.</p>"},{"location":"bodo_parallelism/typing_considerations/#pandas-dtype","title":"Supported Pandas Data Types","text":"<p>Bodo supports the following data types as values in Pandas Dataframe and Series data structures. This represents all Pandas data types except <code>TZ-aware datetime</code>, <code>Period</code>, <code>Interval</code>, and <code>Sparse</code> (which will be supported in the future). Comparing to Spark, equivalents of all Spark data types are supported.</p> <ul> <li>Numpy booleans: <code>np.bool_</code>.</li> <li>Numpy integer data types: <code>np.int8</code>, <code>np.int16</code>, <code>np.int32</code>, <code>np.int64</code>, <code>np.uint8</code>, <code>np.uint16</code>, <code>np.uint32</code>, <code>np.uint64</code>.</li> <li>Numpy floating point data types: <code>np.float32</code>, <code>np.float64</code>.</li> <li>Numpy datetime data types: <code>np.dtype(\"datetime64[ns]\")</code> and <code>np.dtype(\"timedelta[ns]\")</code>. The resolution has to be <code>ns</code> currently, which covers most practical use cases.</li> <li>Numpy complex data types: <code>np.complex64</code> and <code>np.complex128</code>.</li> <li>Strings (including nulls).</li> <li><code>datetime.date</code> values (including nulls).</li> <li><code>datetime.timedelta</code> values (including nulls).</li> <li>Pandas nullable integers.</li> <li>Pandas nullable booleans.</li> <li>Pandas Categoricals.</li> <li>Lists of other data types.</li> <li>Tuples of other data types.</li> <li>Structs of other data types.</li> <li>Maps of other data types (each map is a set of key-value pairs). All keys should have the same type to ensure type stability. All values should have the same type as well.</li> <li><code>decimal.Decimal</code> values (including nulls). The decimal values are stored as fixed-precision Apache Arrow Decimal128 format, which is also similar to PySpark decimals. The decimal type has a <code>precision</code> (the maximum total number of digits) and a <code>scale</code> (the number of digits on the right of dot) attribute, specifying how the stored data is interpreted. For example, the (4, 2) case can store from -999.99 to 999.99. The precision can be up to 38, and the scale must be less or equal to precision. Arbitrary-precision Python <code>decimal.Decimal</code> values are converted with precision of 38 and scale of 18.</li> </ul> <p>In addition, it may be desirable to specify type annotations in some cases (e.g., file I/O array input types). Typically these types are array types and they all can be accessed directly from the <code>bodo</code> module. The following table can be used to select the necessary Bodo Type based upon the desired Python, Numpy, or Pandas type.</p> Bodo Type Name Equivalent Python, Numpy, or Pandas type <code>bodo.bool_[:]</code>, <code>bodo.int8[:]</code>, ..., <code>bodo.int64[:]</code>, <code>bodo.uint8[:]</code>, ..., <code>bodo.uint64[:]</code>, <code>bodo.float32[:]</code>, <code>bodo.float64[:]</code> One-dimensional Numpy array of the given type. A full list of supported Numpy types can be found here. A multidimensional can be specified by adding additional colons (e.g., <code>bodo.int32[:, :, :]</code> for a three-dimensional array). <code>bodo.string_array_type</code> Array of nullable strings <code>bodo.IntegerArrayType(integer_type)</code> Array of Pandas nullable integers of the given integer type.  e.g., <code>bodo.IntegerArrayType(bodo.int64)</code> <code>bodo.boolean_array_type</code> Array of Pandas nullable booleans <code>bodo.datetime64ns[:]</code> Array of Numpy datetime64 values <code>bodo.timedelta64ns[:]</code> Array of Numpy timedelta64 values <code>bodo.datetime_date_array_type</code> Array of datetime.date types <code>bodo.datetime_timedelta_array_type</code> Array of datetime.timedelta types <code>bodo.DecimalArrayType(precision, scale)</code> Array of Apache Arrow Decimal128 values with the given precision and scale.  e.g., <code>bodo.DecimalArrayType(38, 18)</code> <code>bodo.binary_array_type</code> Array of nullable bytes values <code>bodo.StructArrayType(data_types, field_names)</code> Array of a user defined struct with the given tuple of data types and field names.  e.g., <code>bodo.StructArrayType((bodo.int32[:], bodo.datetime64ns[:]), (\"a\", \"b\"))</code> <code>bodo.TupleArrayType(data_types)</code> Array of a user defined tuple with the given tuple of data types.  e.g., <code>bodo.TupleArrayType((bodo.int32[:], bodo.datetime64ns[:]))</code> <code>bodo.MapArrayType(key_arr_type, value_arr_type)</code> Array of Python dictionaries with the given key and value array types.  e.g., <code>bodo.MapArrayType(bodo.uint16[:], bodo.string_array_type)</code> <code>bodo.PDCategoricalDtype(cat_tuple, cat_elem_type, is_ordered_cat)</code> Pandas categorical type with the possible categories, each category's type, and if the categories are ordered.  e.g., <code>bodo.PDCategoricalDtype((\"A\", \"B\", \"AA\"), bodo.string_type, True)</code> <code>bodo.CategoricalArrayType(categorical_type)</code> Array of Pandas categorical values.  e.g., <code>bodo.CategoricalArrayType(bodo.PDCategoricalDtype((\"A\", \"B\", \"AA\"), bodo.string_type, True))</code> <code>bodo.DatetimeIndexType(name_type)</code> Index of datetime64 values with a given name type.  e.g., <code>bodo.DatetimeIndexType(bodo.string_type)</code> <code>bodo.NumericIndexType(data_type, name_type)</code> Index of <code>pd.Int64</code>, <code>pd.Uint64</code>, or <code>Float64</code> objects, based upon the given data_type and name type.  e.g., <code>bodo.NumericIndexType(bodo.float64, bodo.string_type)</code> <code>bodo.PeriodIndexType(freq, name_type)</code> pd.PeriodIndex with a given frequency and name type.  e.g., <code>bodo.PeriodIndexType('A', bodo.string_type)</code> <code>bodo.RangeIndexType(name_type)</code> RangeIndex with a given name type.  e.g., <code>bodo.RangeIndexType(bodo.string_type)</code> <code>bodo.StringIndexType(name_type)</code> Index of strings with a given name type.  e.g., <code>bodo.StringIndexType(bodo.string_type)</code> <code>bodo.BinaryIndexType(name_type)</code> Index of binary values with a given name type.  e.g., <code>bodo.BinaryIndexType(bodo.string_type)</code> <code>bodo.TimedeltaIndexType(name_type)</code> Index of timedelta64 values with a given name type. e.g., <code>bodo.TimedeltaIndexType(bodo.string_type)</code> <code>bodo.SeriesType(dtype=data_type, index=index_type, name_typ=name_type)</code> Series with a given data type, index type, and name type.  e.g., <code>bodo.SeriesType(bodo.float32, bodo.DatetimeIndexType(bodo.string_type), bodo.string_type)</code> <code>bodo.DataFrameType(data_types_tuple, index_type, column_names)</code> DataFrame with a tuple of data types, an index type, and the names of the columns.  e.g., <code>bodo.DataFrameType((bodo.int64[::1], bodo.float64[::1]), bodo.RangeIndexType(bodo.none), (\"A\", \"B\"))</code>"},{"location":"bodo_parallelism/typing_considerations/#require_constants","title":"Compile Time Constants","text":"<p>Unlike regular Python, which is dynamically typed, Bodo needs to be able to type all functions at compile time. While in most cases, the output types depend solely on the input types, some APIs require knowing exact values in order to produce accurate types.</p> <p>As an example, consider the <code>iloc</code> DataFrame API. This API can be used to selected a subset of rows and columns by passing integers or slices of integers. A Bodo JIT version of a function calling this API might look like:</p> <pre><code>import numpy as np\nimport pandas as pd\nimport bodo\n@bodo.jit\ndef df_iloc(df, rows, columns):\nreturn df.iloc[rows, columns]\ndf = pd.DataFrame({'A': np.arange(100), 'B': [\"A\", \"B\", \"C\", \"D\"]* 25})\nprint(df_iloc(df, slice(1, 4), 0))\n</code></pre> <p>If we try to run this file, we will get an error message:</p> <pre><code>$ python iloc_example.py\nTraceback (most recent call last):\nFile \"iloc_example.py\", line 10, in &lt;module&gt;\n   df_iloc(df, slice(1, 4), 0)\nFile \"/my_path/bodo/numba_compat.py\", line 1195, in _compile_for_args\n   raise error\nbodo.utils.typing.BodoError: idx2 in df.iloc[idx1, idx2] should be a constant integer or constant list of integers\nFile \"iloc_example.py\", line 7:\ndef df_iloc(df, rows, columns):\n   return df.iloc[rows, columns]\n</code></pre> <p>The relevant part of the error message is <code>idx2 in df.iloc[idx1, idx2] should be a constant integer or constant list of integers</code>.</p> <p>This error is thrown because depending on the value of <code>columns</code>, Bodo selects different columns with different types. When <code>columns=0</code> Bodo will need to compile code for numeric values, but when <code>columns=1</code> Bodo needs to compile code for strings, so it cannot properly type this function.</p> <p>To resolve this issue, you will need to replace <code>columns</code> with a literal integer. If instead the Bodo function is written as:</p> <pre><code>import numpy as np\nimport pandas as pd\nimport bodo\n@bodo.jit\ndef df_iloc(df, rows):\nreturn df.iloc[rows, 0]\ndf = pd.DataFrame({'A': np.arange(100), 'B': [\"A\", \"B\", \"C\", \"D\"]* 25})\nprint(df_iloc(df, slice(1, 4)))\n</code></pre> <p>Bodo now can see that the output DataFrame should have a single <code>int64</code> column and it is able to compile the code.</p> <p>Whenever a value needs to be known for typing purposes, Bodo will throw an error that indicates some argument requires <code>a constant value</code>. All of these can be resolved by making this value a literal. Alternatively, some APIs support other ways of specifying the output types, which will be indicated in the error message.</p>"},{"location":"bodo_parallelism/typing_considerations/#integer-na-issue-pandas","title":"Integer NA issue in Pandas","text":"<p>DataFrame and Series objects with integer data need special care due to integer NA issues in Pandas. By default, Pandas dynamically converts integer columns to floating point when missing values (NAs) are needed (which can result in loss of precision). This is because Pandas uses the NaN floating point value as NA, and Numpy does not support NaN values for integers. Bodo does not perform this conversion unless enough information is available at compilation time.</p> <p>Pandas introduced a new nullable integer data type that can solve this issue, which is also supported by Bodo. For example, this code reads column <code>A</code> into a nullable integer array (the capital <code>\"I\"</code> denotes nullable integer type):</p> <pre><code>@bodo.jit\ndef example(fname):\ndtype = {'A': 'Int64', 'B': 'float64'}\ndf = pd.read_csv(fname,\nnames=dtype.keys(),\ndtype=dtype,\n)\n...\n</code></pre>"},{"location":"bodo_parallelism/typing_considerations/#type-inference-for-object-data","title":"Type Inference for Object Data","text":"<p>Pandas stores some data types (e.g. strings) as object arrays which are untyped. Therefore, Bodo needs to infer the actual data type of object arrays when dataframes or series values are passed to JIT functions from regular Python. Bodo uses the first non-null value of the array to determine the type, and throws a warning if the array is empty or all nulls:</p> <pre><code>BodoWarning: Empty object array passed to Bodo, which causes ambiguity in typing. This can cause errors in parallel execution.\n</code></pre> <p>In this case, Bodo assumes the array is a string array which is the most common. However, this can cause errors if a distributed dataset is passed to Bodo, and some other processor has non-string data. This corner case can usually be avoided by load balancing the data across processors to avoid empty arrays.</p>"},{"location":"diagnostics_and_troubleshooting/Bodoerrors/","title":"Bodo Error Messages","text":"<p>This page lists some of the compilation error messages you may encounter with your jitted functions, reasons for them and suggestions on how to proceed with resolving them.</p>"},{"location":"diagnostics_and_troubleshooting/Bodoerrors/#unsupported-bodo-functionality","title":"Unsupported Bodo Functionality","text":"<ul> <li> <p><code>BodoError: &lt;functionality&gt; not supported yet</code></p> <p>As the error states, this message is encountered when you are attempting to call an as yet unsupported API within a jit function. For example :</p> <pre><code>@bodo.jit\ndef unsupported_func(pd_str_series):\nreturn pd_str_series.str.casefold()\n</code></pre> <p>would result in an unsupported <code>BodoError</code> as follows:</p> <pre><code>BodoError: Series.str.casefold not supported yet\n</code></pre> <p>Please submit a request for us to support your required functionality here. Also consider joining our community slack, where you can interact directly with fellow Bodo users to find a workaround for your requirements. For longer and more detailed discussions, please join our discourse.</p> <p>See Also</p> <p>Object Mode can be used to switch to Python interpreted context to be able to run your workload, but we strongly recommend trying to find a Bodo-native workaround.</p> </li> <li> <p><code>BodoError: &lt;operation&gt; : &lt;parameter_name&gt; parameter only supports default value</code></p> <p>Certain methods only support default parameter values for some of their parameters. Please see supported Pandas API for a list of supported pandas functionality and their respective parameters. We also have a list of supported Numpy , as well as ML operations.</p> </li> </ul>"},{"location":"diagnostics_and_troubleshooting/Bodoerrors/#typing-errors","title":"Typing Errors","text":"<ul> <li> <p><code>BodoError: &lt;operation&gt;: &lt;operand&gt; must be a compile time constant</code></p> <p>Bodo needs certain arguments to be known at compile time to produce an optimized binary. Please refer to the documentation on compile time constants for more details.</p> </li> <li> <p><code>BodoError: dtype &lt;DataType&gt; cannot be stored in arrays</code></p> <p>This error message is encountered when Bodo is unable to assign a supported type to elements of an array.</p> <p>Example:</p> <pre><code>@bodo.jit\ndef obj_in_array():\ndf = pd.DataFrame({'col1': [\"1\", \"2\"], 'col2': [3, 4]})\nreturn df.select_dtypes(include='object')\na = obj_in_array()\nprint(a)\n</code></pre> <p>Error: <pre><code>BodoError: dtype pyobject cannot be stored in arrays\n</code></pre></p> <p>In this example, we get this error because we attempted to get Bodo to recognize <code>col1</code> as a column with the datatype <code>object</code>, and the <code>object</code> type is too generic for Bodo. A workaround for this specific example would be to return <code>df.select_dtypes(exclude='int')</code>.</p> </li> <li> <p><code>Invalid Series.dt/Series.cat/Series.str, cannot handle conditional yet</code></p> <p>This error is encountered when there are conditional assignments of series functions <code>Series.dt</code>, <code>Series.cat</code> or <code>Series.str</code>, which Bodo cannot handle yet.</p> <p>Example:</p> <pre><code>@bodo.jit\ndef conditional_series_str(flag):\ns = pd.Series([\"Str_Series\"])\ns1 = pd.Series([\"Str_Series_1\"]).str\nif flag:\ns1 = s.str\nelse:\ns1 = s1\nreturn s1.split(\"_\")\n</code></pre> <p>Error:</p> <pre><code>BodoError: ...\n          Invalid Series.str, cannot handle conditional yet\n</code></pre> <p>When using these operations, you need to include the function and accessor together inside the control flow if it is absolutely necessary. For this specific case, we simply compute the <code>str.split</code> within the conditional:</p> <pre><code>@bodo.jit\ndef test_category(flag):\ns = pd.Series([\"A_Str_Series\"])\ns1 = pd.Series([\"test_series\"]).str\ns2 = None\nif flag:\ns2 = s.str.split(\"_\")\nelse:\ns2 = s1.split(\"_\")\nreturn s2\n</code></pre> </li> </ul>"},{"location":"diagnostics_and_troubleshooting/Bodoerrors/#unsupported-numba-errors","title":"Unsupported Numba Errors","text":"<ul> <li> <p><code>numba.core.errors.TypingError: Compilation error</code></p> <p>This is likely due to unsupported functionality. If you encounter this error, please provide us a minimum reproducer for this error here.</p> </li> <li> <p><code>numba.core.errors.TypingError: Unknown attribute &lt;attribute&gt; of type</code></p> <p>This is an uncaught error due to unsupported functionality. If you encounter this error, please provide us a minimum reproducer for this error here.</p> </li> </ul>"},{"location":"diagnostics_and_troubleshooting/compilation/","title":"Compilation Tips and Troubleshooting","text":""},{"location":"diagnostics_and_troubleshooting/compilation/#what-code-to-jit-compile","title":"What Code to JIT Compile","text":"<p>The general recommendation is to use Bodo JIT compilation only for code that is data and/or compute intensive (e.g. Pandas code on large dataframes). In other words:</p> <ul> <li>Only use Bodo for data processing and analytics code such as Pandas, Numpy, and Scikit-Learn      (see Bodo API reference for analytics APIs with JIT support).</li> <li>Refactor code that sets up infrastructure or performs initializations out of JIT functions.</li> </ul> <p>This reduces the risk of encountering unsupported features and also reduces compilation time. For example, the program below finds the input file name in regular Python, and uses Bodo JIT only for data load and processing:</p> <pre><code>def get_filename():\nif os.path.exists(\"input.parquet\"):\nreturn \"input.parquet\"\nif \"INPUT_FILE\" in os.environ:\nreturn os.environ[\"INPUT_FILE\"]\nraise Exception(\"Input file name not found\")\n@bodo.jit\ndef f(fname):\ndf = pd.read_parquet(fname)\nprint(df.sum())\nfname = get_filename()\nf(fname)\n</code></pre> <p>This recommendation is similar to Numba's What to compile.</p>"},{"location":"diagnostics_and_troubleshooting/compilation/#whycompilationerror","title":"Compilation Errors","text":"<p>First of all, let us understand why the code may fail to compile. There are three main kinds of issues:</p> <ol> <li>Some API is used that is not supported in Bodo JIT yet (see Bodo API Reference).</li> <li>Some Python construct or data structure is used that cannot be JIT compiled     (see Unsupported Python APIs).</li> <li>The code has type stability issues (see type stability).</li> </ol> <p>Below are some examples of the type of errors you may see due to these issues.</p>"},{"location":"diagnostics_and_troubleshooting/compilation/#unsupported-functions-or-methods","title":"Unsupported Functions or Methods","text":"<p>If a JIT function uses an unsupported function or method (e.g. in Pandas APIs), Bodo raises <code>BodoError</code> explaining that the method is not supported yet:</p> <pre><code>BodoError: &lt;method&gt; not supported yet\n</code></pre> <p>For example:</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return df.swapaxes(0, 1)\n...\n&gt;&gt;&gt; f(df)\nTraceback (most recent call last):\nFile \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nFile \"/Users/user/bodo/bodo/numba_compat.py\", line 1198, in _compile_for_args\nraise error\nbodo.utils.typing.BodoError: DataFrame.swapaxes() not supported yet\n</code></pre>"},{"location":"diagnostics_and_troubleshooting/compilation/#unsupported-attributes","title":"Unsupported Attributes","text":"<p>Attempting to access an unsupported attribute in Bodo JIT functions will result in a <code>BodoError</code> as follows:</p> <pre><code>BodoError: &lt;attribute&gt; not supported yet\n</code></pre> <p>For example:</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return df.flags\n...\n&gt;&gt;&gt; f(df)\nTraceback (most recent call last):\nFile \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nFile \"/Users/user/bodo/bodo/numba_compat.py\", line 1198, in _compile_for_args\nraise error\nbodo.utils.typing.BodoError: DataFrame.flags not supported yet\n</code></pre>"},{"location":"diagnostics_and_troubleshooting/compilation/#unsupported-arguments","title":"Unsupported Arguments","text":"<p>Supported APIs may not support all optional arguments. Supplying an unsupported argument will result in a <code>BodoError</code>:</p> <p><pre><code>BodoError: &lt;method&gt;: &lt;keyword&gt; argument not supported yet\n</code></pre> For example:</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return df.sort_index(key=lambda x: x.str.lower())\n...\n&gt;&gt;&gt; f(df)\nTraceback (most recent call last):\nFile \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nFile \"/Users/user/bodo/bodo/numba_compat.py\", line 1198, in _compile_for_args\nraise error\nbodo.utils.typing.BodoError: DataFrame.sort_index(): key parameter only supports default value None\n</code></pre>"},{"location":"diagnostics_and_troubleshooting/compilation/#type-stability-errors","title":"Type Stability Errors","text":"<p>Bodo needs to infer data types for all program variables for successful JIT compilation. A type stability issue arises when different program control flow paths assign values with different types to a variable. For example, variable <code>a</code> below could either be an integer or a string:</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(flag):\n...     if flag:\n...         a = 3\n...     else:\n...         a = \"A\"\n...     return a\n...\n&gt;&gt;&gt; f(True)\nTraceback (most recent call last):\nFile \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nFile \"/Users/user/bodo/bodo/numba_compat.py\", line 1163, in _compile_for_args\nerror_rewrite(e, \"typing\")\nFile \"/Users/user/bodo/bodo/numba_compat.py\", line 1043, in error_rewrite\nraise e.with_traceback(None)\nnumba.core.errors.TypingError: Cannot unify Literal[str](A) and Literal[int](3) for 'a.2', defined at &lt;stdin&gt; (7)\n</code></pre> <p>The error <code>TypingError: Cannot unify &lt;type1&gt; and &lt;type2&gt;</code> means that the two possible data types cannot be combined and therefore, the variable cannot have a single data type.</p> <p>Dataframe variables require their schema (column names and their types) to be consistent for type stability (see dataframe schema stability). For example, the dataframe variable <code>df</code> below could either have a single column (\"A\": integer) or two columns (\"A\": integer, \"B\": float) depending on the runtime value of <code>flag</code>, which results in a type stability error:</p> <pre><code>&gt;&gt;&gt; @bodo.jit\n... def f(flag):\n...     df = pd.DataFrame({\"A\": [1, 2, 3, 4]})\n...     if flag:\n...         df[\"B\"] = [1.2, 0.4, 0.7, 121.9]\n...     print(df)\n...\n&gt;&gt;&gt; f(True)\nTraceback (most recent call last):\nFile \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nFile \"/Users/user/bodo/bodo/numba_compat.py\", line 1163, in _compile_for_args\nerror_rewrite(e, \"typing\")\nFile \"/Users/user/bodo/bodo/numba_compat.py\", line 1043, in error_rewrite\nraise e.with_traceback(None)\nnumba.core.errors.TypingError: Cannot unify dataframe((array(int64, 1d, C),), RangeIndexType(none), ('A',), 1D_Block_Var, False) and dataframe((array(int64, 1d, C), array(float64, 1d, C)), RangeIndexType(none), ('A', 'B'), 1D_Block_Var, False) for 'df', defined at &lt;stdin&gt; (3)\n</code></pre> <p>Additionally, some function arguments need to be constant to ensure type stability. In certain cases where it is possible, Bodo may infer the constant values. In other cases, it may throw an error indicating that the argument should be constant. For instance, <code>axis</code> argument in <code>pd.concat</code> determines whether the output is a Series type or a dataframe type in the example below. Therefore, Bodo needs to know the value at compilation time for type inference. Otherwise, an error is thrown (passing <code>axis</code> as argument to the JIT function fixes the error in this case):</p> <p><pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import bodo\n&gt;&gt;&gt; @bodo.jit\n... def f(S1, S2, flag):\n...     axis = 0\n...     if flag:\n...         axis = 1\n...     return pd.concat([S1, S2], axis=axis)\n...\n&gt;&gt;&gt; S1 = pd.Series([1, 2, 3], name=\"A\")\n&gt;&gt;&gt; S2 = pd.Series([3, 4, 5], name=\"B\")\n&gt;&gt;&gt; f(S1, S2, False)\nTraceback (most recent call last):\nFile \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nFile \"/Users/ehsan/dev/bodo/bodo/numba_compat.py\", line 1198, in _compile_for_args\nraise error\nbodo.utils.typing.BodoError: pd.concat(): 'axis' should be a constant integer\n&gt;&gt;&gt; @bodo.jit\n... def f(S1, S2, axis):\n...     return pd.concat([S1, S2], axis=axis)\n...\n&gt;&gt;&gt; print(f(S1, S2, 0))\n0    1\n1    2\n2    3\n0    3\n1    4\n2    5\ndtype: int64\n</code></pre> See Bodo API reference for more details on argument requirements.</p>"},{"location":"diagnostics_and_troubleshooting/compilation/#troubleshooting-compilation-errors","title":"Troubleshooting Compilation Errors","text":"<p>Now that we understand what causes the error, let's fix it!</p> <p>For potential unsupported APIs, Python feature gaps or type stability issues try the following:</p> <ol> <li> <p>Make sure your code works in Python. In a lot of cases, a Bodo     decorated function does not compile, but it does not compile in     Python either.</p> </li> <li> <p>Refactor your code with supported operations if possible. For     instance, the <code>sort_index(key=lambda ...)</code> examble above can be     replaced with regular <code>sort_values</code>:</p> <pre><code>&gt;&gt;&gt; df = pd.DataFrame({\"a\": [1, 2, 3, 4]}, index=['A', 'b', 'C', 'd'])\n&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     return df.sort_index(key=lambda x: x.str.lower())\n...\n&gt;&gt;&gt; f(df)\nTraceback (most recent call last):\nFile \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nFile \"/Users/ehsan/dev/bodo/bodo/numba_compat.py\", line 1198, in _compile_for_args\nraise error\nbodo.utils.typing.BodoError: DataFrame.sort_index(): key parameter only supports default value None\n&gt;&gt;&gt; @bodo.jit\n... def f(df):\n...     df[\"key\"] = df.index.map(lambda a: a.lower())\n...     return df.sort_values(\"key\").drop(columns=\"key\")\n...\n&gt;&gt;&gt; f(df)\na\nA  1\nb  2\nC  3\nd  4\n</code></pre> </li> <li> <p>Refactor your code and use regular Python for unsupported     features.</p> <p>a.  Move the code causing issues to regular Python and pass     necessary data to JIT functions. b.  Use Object Mode to perform some computation within JIT     functions in regular Python if necessary (see Object Mode).</p> </li> <li> <p>Refactor your code to make it type stable (see     type stability). For example:</p> <pre><code>&gt;&gt;&gt; flag = True\n&gt;&gt;&gt; @bodo.jit\n... def f(flag):\n...     df = pd.read_parquet(\"in.parquet\")\n...     if flag:\n...             df[\"C\"] = 1\n...     df.to_parquet(\"out.parquet\")\n...\n&gt;&gt;&gt; f(flag)\nTraceback (most recent call last):\nFile \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nFile \"/Users/ehsan/dev/bodo/bodo/numba_compat.py\", line 1163, in _compile_for_args\nerror_rewrite(e, \"typing\")\nFile \"/Users/ehsan/dev/bodo/bodo/numba_compat.py\", line 1043, in error_rewrite\nraise e.with_traceback(None)\nnumba.core.errors.TypingError: Cannot unify dataframe((array(int64, 1d, C),), StringIndexType(none), ('a',), 1D_Block_Var, True) and dataframe((array(int64, 1d, C), array(int64, 1d, C)), StringIndexType(none), ('a', 'C'), 1D_Block_Var, True) for 'df', defined at &lt;stdin&gt; (3)\n&gt;&gt;&gt; @bodo.jit\n... def f1():\n...     df = pd.read_parquet(\"in.parquet\")\n...     return df\n...\n&gt;&gt;&gt; @bodo.jit\n... def f2(df):\n...     df[\"C\"] = 1\n...     return df\n...\n&gt;&gt;&gt; @bodo.jit\n... def f3(df):\n...     df.to_parquet(\"out.parquet\")\n...\n&gt;&gt;&gt; df = f1()\n&gt;&gt;&gt; if flag:\n...     df = f2(df)\n...\n&gt;&gt;&gt; f3(df)\n</code></pre> </li> </ol>"},{"location":"diagnostics_and_troubleshooting/compilation/#disabling-python-output-buffering","title":"Disabling Python Output Buffering","text":"<p>Sometimes standard output prints may not appear when the program fails, due to Python's I/O buffering. Therefore, setting <code>PYTHONUNBUFFERED</code> environment variable is recommended for debugging:</p> <pre><code>export PYTHONUNBUFFERED=1\n</code></pre>"},{"location":"diagnostics_and_troubleshooting/compilation/#requesting-unsupported-functionality-and-reporting-errors","title":"Requesting Unsupported Functionality and Reporting Errors","text":"<p>If you want to request a new feature, or report a bug you have found, please create an issue in ourFeedback repository. If you encounter an error which is not covered on this page, please report it to our Feedback repository as well.</p>"},{"location":"diagnostics_and_troubleshooting/verbose_mode/","title":"Verbose Mode","text":"<p>When compiling functions, Bodo introduces various optimizations to improve runtime performance. Since the success of certain optimizations can be essential, we provide the option to run Bodo in <code>verbose mode</code> and track certain optimizations at compile time. The information provided by <code>verbose mode</code> can help you better understand you workload's performance as well as how to debug the workload. Additionally, using Python's <code>logging</code> module alongside Bodo's <code>verbose mode</code> can be used to track optimizations across frequently running jobs.</p> <p>Note</p> <p>Currently all of our optimizations are tracked at compile time. This information is not stored if a function is cached.</p>"},{"location":"diagnostics_and_troubleshooting/verbose_mode/#example-usage","title":"Example Usage","text":"<p>To detect important optimizations, all you need to do is set a verbose level in the global scope of a Python file using <code>bodo.set_verbose_level(level)</code>. The verbose level is a positive integer, with greater values outputting more detailed information. The optimizations that are expected to be the most impactful are tracked at level 1, so in most situations you can just do <code>bodo. set_verbose_level(1)</code>. More information on the optimizations that are displayed is found in the <code>set_verbose_level</code> API reference. Now when Bodo compiles a function, <code>rank 0</code> will log important optimizations to <code>stderr</code> using Python's <code>logging</code> package.</p> <p>Below is an example using the <code>verbose mode</code> to verify that Bodo is only loading the 1 column from a parquet file that is actually needed as opposed to any additional columns.</p> <pre><code>bodo.set_verbose_level(1)\n@bodo.jit\ndef load_data(filename):\ndf = pd.read_parquet(filename)\nreturn df.id\nload_data(\"my_file.pq\")\n</code></pre> <pre><code>2022-03-24 11:50:21,656 - Bodo Default Logger - INFO -\n================================================================================\n---------------------------------Column Pruning---------------------------------\nFinish column pruning on read_parquet node:\nFile \"verbose_ex.py\", line 8:\ndef load_data(filename):\n    df = pd.read_parquet(filename)\n    ^\nColumns loaded ['id']\n================================================================================\n</code></pre> <p>You can also log this information to a valid <code>logging.Logger</code> instance with Bodo.</p> <p>Important</p> <p>The logger should be a variable set in a global scope.</p> <pre><code>bodo.set_verbose_level(1)\nlogger = logging.getLogger(\"myLogger\")\nlogger.setLevel(logging.INFO)\nlogger.addHandler(logging.FileHandler(\"example.log\"))\nbodo.set_bodo_verbose_logger(logger)\n@bodo.jit\ndef load_data(filename):\ndf = pd.read_parquet(filename)\nreturn df.id\nload_data(\"my_file.pq\")\n</code></pre>"},{"location":"diagnostics_and_troubleshooting/verbose_mode/#leveraging-optimizations-for-debugging","title":"Leveraging Optimizations for Debugging","text":"<p>Optimzation logging can be useful for diagnosing possible performance issues. Below is an example that shows the impact of printing a section of a DataFrame to inspect the result of <code>read_parquet</code>.</p> <pre><code>bodo.set_verbose_level(1)\n@bodo.jit\ndef load_data(filename):\ndf = pd.read_parquet(filename)\nprint(df.head(10))\nreturn df.id\nload_data(\"my_file.pq\")\n</code></pre> <pre><code>2022-03-25 11:22:24,619 - Bodo Default Logger - INFO -\n================================================================================\n---------------------------------Column Pruning---------------------------------\nFinish column pruning on read_parquet node:\nFile \"verbose_ex.py\", line 10:\ndef load_data(filename):\n    df = pd.read_parquet(filename)\n    ^\nColumns loaded ['id', 'Hectare', 'Date', 'Age', 'Primary Fur Color', 'Highlight Fur Color', 'Location', 'Specific Location', 'Running', 'Chasing', 'Climbing', 'Eating', 'Foraging', 'Other Activities', 'Kuks', 'Quaas', 'Moans', 'Tail flags', 'Tail twitches', 'Approaches', 'Indifferent', 'Runs from', 'Other Interactions']\n</code></pre> <p>Printing <code>df.head()</code> prints every column in the DataFrame, so Bodo must load all of the columns. In contrast, without this print, Bodo can load just a single column from the parquet file, so this increases both memory usage and execution time.</p> <p>In some situations the reason for an optimization failure may not be as straightforward as the example above. Even when the code is more complicated, the success/failure of optimizations can be an extremely useful first step to determine why performance is worse than expected.</p>"},{"location":"diagnostics_and_troubleshooting/verbose_mode/#user-apis","title":"User APIs","text":""},{"location":"diagnostics_and_troubleshooting/verbose_mode/#set_verbose_level","title":"set_verbose_level","text":"<ul> <li> <p><code>bodo.set_verbose_level(level)</code> </p> <p>Determines if compiled JIT functions should output logging information. Level 0 disables optimization logging and level 1 contains all of the most important operations.</p> <p>The optimizations currently displayed at each level are:</p> Verbose Level Optimizations 1 <ul><li>Column Pruning</li><li>Filter Pushdown</li><li>Dictionary Encoding</li><li>Limit Pushdown</li><li>BodoSQL generated IO time</li></ul> 2 <ul><li>Join column pruning</li></ul> <p>Arguments</p> <ul> <li>level: A non-negative integer for the logging granularity.</li> </ul> <p>Note: <code>bodo.set_verbose_level()</code> should not be used inside a JIT function.</p> </li> </ul>"},{"location":"diagnostics_and_troubleshooting/verbose_mode/#set_bodo_verbose_logger","title":"set_bodo_verbose_logger","text":"<ul> <li> <p><code>bodo.set_bodo_verbose_logger(logger)</code> </p> <p>Sets the logging location for Bodo verbose messages. Bodo will write to this logger on <code>rank 0</code> only, to prevent possible conflicts when writing to an output file. All messages are given with <code>logging.info</code>, so the logger should have an appropriate effect level.</p> <p>Arguments</p> <ul> <li><code>logger</code>: An instance of type <code>logging.Logger</code>.</li> </ul> <p>Note: <code>bodo.set_bodo_verbose_logger()</code> should not be used inside a JIT function.</p> </li> </ul>"},{"location":"help_and_reference/eula/","title":"End User License Agreement","text":"<p>THIS ONLINE END-USER LICENSE AGREEMENT (\"AGREEMENT\") IS A BINDING LEGAL CONTRACT BETWEEN YOU (THE USER) AND BODO INC. (\"WE\", \"US\", OR \"BODO\"). BY DOWNLOADING, INSTALLING, ACCESSING OR USING THE SOFTWARE, SERVICES, AND ANY OTHER MATERIALS MADE AVAILABLE BY BODO ON THIS SITE OR IN ANY OTHER FORMAT (COLLECTIVELY, THE \"SERVICES\"), YOU (A) AGREE TO BE BOUND BY THIS AGREEMENT; (B) ACKNOWLEDGE AND AGREE YOU HAVE INDEPENDENTLY EVALUATED THE DESIRABILITY OF USING THE SERVICES AND ARE NOT RELYING ON ANY REPRESENTATION, GUARANTEE, OR STATEMENT OTHER THAN AS EXPRESSLY PROVIDED IN THIS AGREEMENT; AND (C) REPRESENT YOU ARE LAWFULLY ABLE TO ENTER INTO CONTRACTS AND ARE OF THE LEGAL AGE OF MAJORITY IN THE JURISDICTION IN WHICH YOU RESIDE (AT LEAST EIGHTEEN YEARS OF AGE IN MANY COUNTRIES/JURISDICTIONS). IF THIS AGREEMENT IS BEING AGREED TO BY A COMPANY OR OTHER LEGAL ENTITY, THEN THE PERSON AGREEING TO THIS AGREEMENT ON BEHALF OF THAT COMPANY OR ENTITY REPRESENTS AND WARRANTS THAT HE OR SHE IS AUTHORIZED AND LAWFULLY ABLE TO BIND THAT COMPANY OR ENTITY TO THIS AGREEMENT.</p> <p>IF YOU DO NOT AGREE TO THIS AGREEMENT, YOU MAY NOT USE THE SERVICES.</p> <ol> <li> <p>Services. Subject to the terms and conditions of this Agreement     and, if applicable, your payment of all relevant fees, we grant you     a non-exclusive, non-transferable, limited license to access and use     our software services, content, and other materials provided by Bodo     or its third-party vendors through this Web site or in other format     (the \"Services\") for your internal use only. Certain     third-party services may have their own terms and conditions, which     will be presented to you in your use of the Services. Your use of     those third-party services will indicate your acceptance of the     additional terms and conditions. In connection with the Services, we     may afford you the ability to interface and interoperate with     certain third-party software and to upload data from that software.     This functionality is dependent on the operation of the third-party     software and is provided on an entirely as-is basis. We may change,     modify, or discontinue all or any portion of the Services at any     time, without prior notice.</p> </li> <li> <p>Restrictions. You may only use the Services as described in the     documentation we make generally available from time to time to our     customers for use of the Services (the \"Documentation\"). Any     breach of this Agreement by your employees or agents will constitute     a breach by you. Except as expressly authorized by this Agreement,     you will not (and will not allow any third-party to): (i) permit any     third-party to access and/or use the Services; (ii) decompile,     disassemble, or reverse engineer the Services, or attempt to derive     the source code, underlying ideas, algorithm or structure of     software provided to you in object code form; (iii) use the Services     or any of our Confidential Information (as defined below) to develop     a competing product or service; (iv) sell, transfer, assign,     distribute, rent, loan, lease, sublicense or otherwise make     available the software associated with the Services or its     functionality to third parties; (v) modify, translate or otherwise     create any derivative works of any software used and made available     by Bodo in connection with the Services; (vi) provide, lease, lend,     use for timesharing or service bureau purposes or otherwise use or     allow others to use the Services for the benefit of any third     party; (vii) use the Services, or allow the transfer, transmission,     export, or re-export of the Services, including by way of a \"deemed     export,\" in violation of any export control laws or regulations     administered by the U.S. Commerce Department or any other government     agency; or (viii) remove any copyright, trademark, proprietary     rights, disclaimer or warning notice included on or embedded in any     part of the Services or Documentation. Nothing in this Agreement     shall be construed to give you a right to use, or otherwise obtain     access to, any source code from which the software used in     connection with the Services or any portion thereof is compiled or     interpreted. Under no circumstances, will we be liable or     responsible for any use, or any results obtained by the use, of the     Services in conjunction with any other software or third-party     products. All such use will be at your sole risk.</p> </li> <li> <p>Proprietary Rights. You acknowledge that all Services are     protected by intellectual property rights of Bodo and its     vendors/licensors and that you have no rights to transfer or     reproduce the Services or prepare any derivative works with respect     to, or disclose Confidential Information pertaining to, the     Services. Under no circumstances will you be deemed to receive title     to any portion of any Services, title to which at all times will     vest exclusively in us and our licensors. This is not a \"work made     for hire\" agreement, as that term is defined in Section 101 of     Title 17 of the United States Code (\"the Copyright Act\"). You     will preserve all Services from any liens, encumbrances, and claims     of any individual or entity. You will not use any of our information     or data to contest the validity of any of our intellectual property     or our licensors. Any such use of our information and data will     constitute a material, non-curable breach of this Agreement. To the     extent you provide us with any content (e.g., graphics, logos,     artwork, text, data) for use in connection with the Services     (collectively, the \"Customer Content\"), you grant us a     non-exclusive, world-wide, royalty-free license to use the Customer     Content for purposes of performing this Agreement. You are     responsible for obtaining all rights, permissions, licenses, and     consents required to furnish the Customer Content to us for use as     described above. You are also responsible for preserving and making     adequate backups of the Customer Content and will not rely on us to     preserve or make adequate backups of data used in connection with     the Services, or to maintain a record of your usage of any part or     all of the Services. Your rights in and to the Services and related     software are limited to those expressly granted under this Agreement     and no other licenses are granted whether by implication, estoppel     or otherwise. Bodo reserves all rights, title and interest in and to     the Services and related software not expressly granted under this     Agreement.</p> </li> <li> <p>Third Party Software. The Services may come bundled with, or     otherwise include or be distributed with, third party software     licensed by a Bodo supplier and/or open source software provided     under an open source license (Open Source Software) (collectively,     \"Third Party Software\"). Notwithstanding anything to the     contrary herein, Third Party Software is licensed to you subject to     the terms and conditions of the software license agreement     accompanying such Third Party Software whether in the form of a     discrete agreement, click-through license, or electronic license     terms accepted at the time of installation and any additional terms     or agreements provided by the third party licensor (\"Third Party     License Terms\"). Use of the Third Party Software by you shall be     governed by such Third Party License Terms, or if no Third Party     License Terms apply, then the Third Party Software is provided to     you as-is, as available, for use in or with the Services and not     otherwise used separately. Copyright to Third Party Software is held     by the copyright holders indicated in the Third Party License Terms.</p> </li> <li> <p>Feedback. You may provide us with suggestions, comments or other     feedback (collectively, \"Feedback\") with respect to our     products and services, including the Services. Feedback is voluntary     and we are not required to hold it in confidence. We may use     Feedback for any purpose without obligation of any kind. To the     extent a license is required under your intellectual property rights     to make use of the Feedback, you grant us an irrevocable,     non-exclusive, perpetual, royalty-free license to use the Feedback     in connection with our business, products, and services, including     the enhancement of the Services.</p> </li> <li> <p>Aggregated Data. You grant us a non-exclusive, perpetual,     irrevocable, fully-paid-up, royalty free license to use data derived     from your use of the Services (the \"Aggregated Data\") for our     business purposes, including the provision of products and services     to our customers; provided the Aggregated Data is combined with     similar data from our other customers. \"Aggregated Data\" does     not include (directly or by inference) any information identifying     you or any identifiable individual. You further grant us the right     to (i) use the Aggregated Data in any aggregate or statistical     products or reports, (ii) transfer and/or disclose the Aggregated     Data upon a sale of our company or its assets or other form of     reorganization, (iii) disclose Aggregated Data in a summary report     that does not show, display or indicate customer specific or     customer identifying information, (iv) provide Aggregated Data to a     third party service provider, for analytical purposes, and (v) use     the Aggregated Data (without personally identifiable information) to     compare with other organizations within the same industry or group.     The Aggregated Data will not be considered your Confidential     Information.</p> </li> <li> <p>Fees. You will promptly pay Bodo all applicable fees and, as     described below, taxes associated with the Services. Except as     expressly provided otherwise in this Agreement, all fees (if any)     are non-refundable. Payments not made within such time period will     be subject to late charges equal to the lesser of (i) one and     one-half percent (1.5%) per month of the overdue amount or (ii) the     maximum amount permitted under applicable law. You are responsible     for paying all personal property, sales, use and other taxes     (excluding taxes based upon our net income) and license and     registration fees and other assessments or charges levied or imposed     by any governmental body or agency as a result of the execution or     performance of this Agreement, including your receipt of the     Services. On notice of not less than sixty (60) days, we may, in our     discretion, adjust any or all fees for the Services. You may     terminate this Agreement on written notice to us within thirty (30)     days of its receipt of our notice to adjust the fees; provided,     however, that if you do not object to the adjustment in writing     within the foregoing thirty (30) day period then you will be deemed     to have agreed to the adjustment.</p> </li> <li> <p>Your Warranties. You represent and warrant that (i) you have     full power, capacity, and authority to enter into this Agreement and     to grant the license in Section 4 (Proprietary Rights); and (ii)     your use of the Services will be in compliance with all applicable     local, state, and federal laws and regulations.</p> </li> <li> <p>Indemnification. You will defend and indemnify Bodo and hold it     and its affiliates, officers, directors, employees, and agents     harmless from any and all claims, actions, proceedings, losses,     deficiencies, damages, liabilities, costs, and expenses (including     but not limited to reasonable attorneys' fees and all related costs     and expenses) incurred by them as a result of any claim, judgment,     or adjudication related to or arising from any or all of the     following: (i) your use of the Services; (ii) breach of any of your     obligations, representations, or warranties in this Agreement;     or (iii) your failure to comply with applicable laws and     regulations.</p> </li> <li> <p>Beta Services. We may designate certain new functionality or     services to be made available in connection with the Services as     \"Beta Services.\" The Beta Services will not be ready for use     in a production environment. Because they will be at an early stage     of development, operation and use of the Beta Services may be     unpredictable and lead to erroneous results. You acknowledge and     agree that: (i) the Beta Services will be experimental and will not     have been fully tested; (ii) the Beta Services may not meet your     requirements; (iii) the use or operation of the Beta Services may     not be uninterrupted or error free; and (iv) your use of the Beta     Services will be for purposes of evaluating and testing the new     functionality and services and providing feedback to us. Your use of     the Beta Services will be subject to all of the terms and conditions     of this Agreement relating to the Services. You agree to promptly     report any errors, defects, or other deficiencies in the Beta     Services to us. NOTWITHSTANDING ANY OTHER PROVISION OF THIS     AGREEMENT, ALL BETA SERVICES ARE PROVIDED \"AS-IS\" AND     \"AS-AVAILABLE,\" WITHOUT WARRANTIES OF ANY KIND. You waive any and     all claims, now known or later discovered, that you may have against     us and our suppliers and licensors arising out of the Beta Services.</p> </li> <li> <p>Suspension or Termination of Services and Removal of Customer     Content. We may, in our sole discretion, suspend your access to     the Services for any of the following reasons: (i) to prevent     disruption of or damages to, or degradation of, the Services and our     systems; (ii) to comply with any law, regulation, court order, or     other governmental request; (iii) to otherwise protect us from     potential legal liability; (iv) to remove Customer Content that is     illegal, offensive, or otherwise inappropriate, in our sole     discretion, or (iv) in the event an invoice remains unpaid for more     than forty-five (45) or more days from the invoice date. We will     restore access to the Services as soon as the event giving rise to     suspension has been resolved. This Section will not be construed as     imposing any obligation or duty on us to monitor use of the     Services.</p> </li> <li> <p>Confidentiality. 12.1 \"Confidential Information\" means all     information or material which (i) gives a party some competitive     business advantage or the opportunity of obtaining such advantage or     the disclosure of which could be detrimental to the interests of     that party; or (ii) which from all the relevant circumstances should     reasonably be assumed to be confidential and proprietary. Each     party's Confidential Information will remain the sole and exclusive     property of that party. Confidential Information includes, but is     not limited to, the Services. Neither party will have any obligation     with respect to confidential information which: (i) is or becomes     generally known to the public by any means other than a breach of     the obligations of a receiving party; (ii) was previously known to     the receiving party or rightly received by the receiving party from     a third party; (iii) is independently developed by the receiving     party; or (iv) subject to disclosure under court order or other     lawful process.</p> <p>12.2 Treatment of Confidential Information. Each party recognizes the importance of the other party's Confidential Information. In particular, each party recognizes and agrees that the Confidential Information of the other is critical to their respective businesses and that neither party would enter into this Agreement without assurance that the information will be protected as provided in this Section 12 and elsewhere in this Agreement. Accordingly, each party agrees as follows:</p> <p>(a) Each party will hold any and all Confidential Information it     obtains in strictest confidence and will use and permit use of     Confidential Information solely as permitted under this     Agreement; and (b) Each party may disclose or provide access to its responsible     employees and agents or as otherwise permitted under this     Agreement, and may make copies, of Confidential Information only     to the extent permitted under this Agreement.</p> <p>12.3 Non-Exclusive Equitable Remedy. Each party acknowledges and agrees that due to the unique nature of the Confidential Information there can be no adequate remedy at law for any breach of its obligations hereunder, and therefore, that upon any such breach or any threat thereof, each party will be entitled to appropriate equitable relief from a court of competent jurisdiction in addition to whatever remedies either of them might have at law or equity.</p> <p>12.4 You agree not to use any Confidential Information of Bodo, and shall restrict your affiliates and sublicensees from using the Confidential Information of Bodo, for purposes of challenging the validity of such Confidential Information, or Bodo's ability to use and exploit such Confidential Information.</p> </li> <li> <p>Limited Warranty; Exclusive Remedy. During the Term, Bodo     warrants the Services will materially comply with the requirements     of this Agreement and Documentation. In the event of a breach of the     foregoing warranty, Bodo's sole and exclusive liability and your     sole and exclusive remedy will be to use reasonable efforts to     correct the non-conformity. In the event Bodo is unable through     reasonable efforts to correct the defective Service, you may elect     to terminate this Agreement and, if applicable, receive a prorated     refund of any pre-paid, unused recurring fees.</p> </li> <li> <p>Disclaimer of Warranties. EXCEPT AS PROVIDED IN SECTION 13     (LIMITED WARRANTY), THE SERVICES ARE PROVIDED \"AS IS\" AND     \"AS-AVAILABLE,\" WITH ALL FAULTS, AND WITHOUT WARRANTY OF ANY KIND.     BODO AND ITS VENDORS AND LICENSORS DISCLAIM ALL OTHER WARRANTIES,     EXPRESS OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED     WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE,     QUIET ENJOYMENT, QUALITY OF INFORMATION, OR TITLE/NON-INFRINGEMENT     AND ALL SUCH WARRANTIES ARE HEREBY SPECIFICALLY DISCLAIMED. YOU     EXPRESSLY AGREE AND ACKNOWLEDGE THAT USE OF SERVICES, IS AT YOUR     SOLE RISK. NO ORAL OR WRITTEN INFORMATION OR ADVICE GIVEN BY BODO OR     ITS AUTHORIZED REPRESENTATIVES WILL CREATE A WARRANTY OR IN ANY WAY     INCREASE THE SCOPE OF BODO'S OBLIGATIONS HEREUNDER.</p> <p>THE SERVICES MAY BE USED TO ACCESS AND TRANSFER INFORMATION OVER THE INTERNET. YOU ACKNOWLEDGE AND AGREE THAT BODO AND ITS VENDORS AND LICENSORS DO NOT OPERATE OR CONTROL THE INTERNET AND THAT: (I) VIRUSES, WORMS, TROJAN HORSES, OR OTHER UNDESIRABLE DATA OR SOFTWARE; OR (II) UNAUTHORIZED USERS (E.G., HACKERS) MAY ATTEMPT TO OBTAIN ACCESS TO AND DAMAGE THE CUSTOMER CONTENT, WEB-SITES, COMPUTERS, OR NETWORKS. WE WILL NOT BE RESPONSIBLE FOR THOSE ACTIVITIES.</p> </li> <li> <p>Limitation of Liability and Damages. NEITHER BODO NOR ITS     VENDORS AND LICENSORS WILL HAVE ANY LIABILITY TO YOU OR ANY THIRD     PARTY FOR ANY LOSS OF PROFITS, BUSINESS, DATA, OR OTHER INCIDENTAL,     CONSEQUENTIAL, OR SPECIAL LOSS OR DAMAGE, INCLUDING EXEMPLARY AND     PUNITIVE, OF ANY KIND OR NATURE RESULTING FROM OR ARISING OUT OF     THIS AGREEMENT, INCLUDING USE OF THE SERVICES EVEN IF BODO HAS BEEN     ADVISED OF THE POSSIBILITY OF SUCH DAMAGES. THE TOTAL LIABILITY OF     BODO AND ITS VENDORS AND LICENSORS TO YOU OR ANY THIRD PARTY ARISING     OUT OF THIS AGREEMENT OR USE OF THE SERVICES IN CONNECTION WITH ANY     CLAIM OR TYPE OF DAMAGE (WHETHER IN CONTRACT OR TORT) WILL NOT     EXCEED THE TOTAL FEES YOU PAID, IF ANY, DURING THE SIX (6) MONTHS     IMMEDIATELY PRECEDING THE EVENT GIVING RISE TO THE LIABILITY. THIS     LIMITATION OF LIABILITY WILL APPLY EVEN IF THE EXPRESS WARRANTIES     PROVIDED ABOVE FAIL OF THEIR ESSENTIAL PURPOSE.</p> </li> <li> <p>Term and Termination. Unless otherwise agreed by the parties,     the Agreement shall be on-going until terminated by either party on     thirty (30) days prior notice to the other party. In the event we     terminate this Agreement for reasons other than breach of contract,     any prepaid but unused fees will be refunded.</p> </li> <li> <p>Government Restrictions. Any software or other programming     provided by us in connection with this Agreement is commercial     computer software as described in DFARS 252.227-7014(a)(1) and FAR     2.101. If acquired by or on behalf of the United States Department     of Defense or any component thereof, the United States Government     acquires this commercial computer software and commercial computer     software documentation subject to the terms of this Agreement as     specified in DFARS 227.7202-3, Rights in Commercial Computer     Software or Commercial Computer Software Documentation. If acquired     by or on behalf of any civilian agency, the United States Government     acquires this commercial computer software and commercial computer     software documentation subject to the terms of this Agreement as     specified in FAR 12.212, Computer Software.</p> </li> <li> <p>USA Patriot Act Notice. The U.S. federal USA Patriot Act     (\"USA Patriot Act\") provides generally for the operator of a     communication host and law enforcement to be able to monitor any     content, upon request of the operator. We anticipate fully complying     with our obligations and availing ourselves of all rights under the     USA Patriot Act.</p> </li> <li> <p>General. Except for the payment of fees, if applicable, neither     party will be liable for any failure or delay in performance under     this Agreement which is due to any event beyond the reasonable     control of such party, including without limitation, fire,     explosion, unavailability of utilities or raw materials, Internet     delays and failures, telecommunications failures, unavailability of     components, labor difficulties, war, riot, act of God, export     control regulation, laws, judgments or government instructions. This     Agreement provides the entire agreement between the parties with     regard to its subject matter. Except as provided below, this     Agreement may not be amended without a writing signed by both     parties. We may, at any time and from time-to-time, change the terms     of this Agreement. Any changes will be posted on our Web site. In     addition, we may also send you a notice about the amended terms via     email. If you do not accept the terms of any modification, your only     recourse is to terminate this Agreement by sending a termination     notice us before the effective date of the amendments. The     termination will be effective on the date we receive the notice. The     most current version of the Agreement will be available on our Web     site and will supersede all previous versions of the Agreement. Your     continued use of the Services will constitute your acceptance of the     changes. This Agreement will be construed according to, and the     rights of the parties will be governed by, the law of the State of     California, without reference to its conflict of laws rules. Any     action at law or in equity arising out of or directly or indirectly     relating to this Agreement may be instituted only in the Federal or     state courts located in San Francisco, California. You consent and     submit to the personal jurisdiction of those courts for the purposes     of any action related to this Agreement, and to extra-territorial     service of process. No action, regardless of form, arising out of     this Agreement, may be brought by either party more than one (1)     year after the cause of action has arisen. You may not assign this     Agreement without the prior written consent of Bodo. If any of the     provisions of this Agreement are found or deemed by a court to be     invalid or unenforceable, they will be severable from the remainder     of this Agreement and will not cause the invalidity or     unenforceability of the remainder of this Agreement. Neither party     will by mere lapse of time without giving notice or taking other     action hereunder be deemed to have waived any breach by the other     party of any of the provisions of this Agreement. The following     provisions will survive termination or expiration of this Agreement:     4 (Proprietary Rights), 9 (Indemnification), 12 (Confidentiality),     13 (Limited Warranty; Exclusive Remedy); 14 (Disclaimer of     Warranties), 15 (Limitation of Liability and Damages), 17     (Government Restrictions), 18 (USA Patriot Act Notice), and 19     (General Provisions). This Agreement may be accepted in electronic     form (e.g., by an electronic or other means of demonstrating assent)     and your acceptance will be deemed binding between us. Neither of us     will contest the validity or enforceability of this Agreement and     any related documents, including under any applicable statute of     frauds, because they were accepted or signed in electronic form.</p> </li> </ol>"},{"location":"help_and_reference/releases/","title":"Release Notes","text":"<ul> <li>Bodo.ai 2023.1 Release</li> <li>Bodo.ai 2022.9 Release</li> <li>Bodo.ai 2022.8 Release</li> <li>Bodo.ai 2022.7 Release</li> <li>Bodo.ai 2022.6 Release</li> <li>Bodo.ai 2022.5 Release</li> <li>Bodo.ai 2022.4 Release</li> <li>Bodo.ai 2022.3 Release</li> <li>Bodo.ai 2022.2 Release</li> <li>Bodo.ai 2022.1 Release</li> <li>Bodo.ai 2021.12 Release</li> <li>Bodo.ai 2021.11 Release</li> <li>Bodo.ai 2021.10 Release</li> <li>Bodo.ai 2021.9 Release</li> <li>Bodo.ai 2021.8 Release</li> <li>Bodo.ai 2021.7 Release</li> <li>Bodo.ai 2021.5 Release</li> <li>Bodo.ai 2021.4 Release</li> <li>Bodo.ai 2021.3 Release</li> <li>Bodo.ai 2021.2 Release</li> <li>Bodo.ai 2021.1 Release</li> <li>Bodo.ai 2020.12 Release</li> <li>Bodo.ai 2020.11 Release</li> <li>Bodo.ai 2020.10 Release</li> <li>Bodo.ai 2020.9 Release</li> <li>Bodo.ai 2020.8 Release</li> <li>Bodo.ai 2020.7 Release</li> <li>Bodo.ai 2020.6 Release</li> <li>Bodo.ai 2020.5 Release</li> <li>Bodo.ai 2020.4 Release</li> <li>Bodo.ai 2020.2 Release</li> </ul>"},{"location":"installation_and_setup/","title":"Bodo Installation and Setup","text":"<p>We offer two options for installation and use of Bodo: the Bodo Platform (recommended), which is Bodo's proprietary cloud platform that is meticulously managed and consistently enhanced, or a local install for your on-premise needs.</p> <ul> <li>Bodo Platform</li> <li>Bodo On-Prem</li> </ul>"},{"location":"installation_and_setup/bodo_platform/","title":"Using Bodo Cloud Platform","text":""},{"location":"installation_and_setup/bodo_platform/#bodo_platform_concepts","title":"Bodo Cloud Platform Concepts","text":"<p>This page describes the fundamental concepts you need to know to use the Bodo Cloud Platform.</p>"},{"location":"installation_and_setup/bodo_platform/#organizations","title":"Organizations","text":"<p>Organizations on the Bodo Cloud Platform are tenants for billing and cloud resource management purposes. An organization can have multiple workspaces and cloud configurations, and users can be part of multiple organizations.</p> <p></p>"},{"location":"installation_and_setup/bodo_platform/#cloud-configurations","title":"Cloud-Configurations","text":"<p>A cloud-configuration is an entity used to store information about your AWS or Azure account. It consists of:</p> <ol> <li>Details regarding the trust relationship between the platform and your cloud provider account.    For AWS accounts, this is done through a cross-account IAM role.    For Azure account, this is done through a service principal (scoped to a specific resource group)    for the Bodo Platform application.    This gives the platform the ability to provision and manage cloud resources in your account.</li> <li>Details regarding metadata storage. The platform needs to store    certain metadata to carry out its functions, such as the state of your various cloud deployments, logs, etc.    On AWS, this data is stored in an S3 bucket and a DynamoDB table.    On Azure, this data is stored in a storage container.</li> </ol> <p></p>"},{"location":"installation_and_setup/bodo_platform/#workspaces","title":"Workspaces","text":"<p>A workspace on the Bodo Cloud Platform consists of:</p> <ol> <li>A shared filesystem where you can collaborate with your team on your projects.</li> <li>Networking infrastructure such as virtual networks, security groups and subnets in which    your compute clusters and Jupyter servers will be securely deployed.</li> </ol> <p>A workspace is tied to a particular cloud-configuration and has its own user-management i.e., you can have different subsets of users with different sets of roles and permissions in different workspaces within the same organization.</p> <p>Important</p> <p>If a user that is not part of the organization, is invited to a workspace in the organization, it is automatically added to the organization with minimal permissions.</p> <p></p> <p>To create a workspace, go to the \"Workspaces\" section in the sidebar and click on \"Create Workspace\". In the creation form, enter the name of the workspace, select the cloud-configuration to use for provisioning it and the region where it should be deployed, and click on \"Create Workspace\".</p> <p></p> <p>This will start the workspace deployment. When the workspace is in the \"READY\" state, click on the button next to it to enter it.</p> <p></p>"},{"location":"installation_and_setup/bodo_platform/#notebooks","title":"Notebooks","text":"<p>Jupyter servers act as your interface to both your shared file-system and your compute clusters. Users can execute code from their notebooks on the compute cluster from the Jupyter interface. A Jupyter server is automatically provisioned for your use when you first enter the workspace.</p> <p></p> <p>You can view and manage all the Jupyter servers in the \"Notebook Manager\" section of \"Workspace Settings\".</p> <p></p>"},{"location":"installation_and_setup/bodo_platform/#creating_clusters","title":"Creating Clusters","text":"<p>In the left bar click on Clusters (or click on the second step in the Onboarding list). This will take you to the Clusters page. At the top right corner, click on <code>Create Cluster</code> which opens the cluster creation form.</p> <p></p> <p>Cluster creation form:</p> <p></p> <p>First, choose a name for your cluster.</p> <p>Then, select the type of nodes in the cluster to be created from the Instance type dropdown list. EFA will be used if the instance type supports it.</p> <p></p> <p>Note</p> <p>If the Instance type dropdown list does not populate, either the credentials are not entered properly or they are not valid. Please see how to set your AWS or Azure credentials and make sure your credentials are valid.</p> <p>Next, enter the number of nodes for your cluster in Number of Instances. and choose the Bodo Version to be installed on your cluster. Typically the three latest Bodo Releases are available.</p> <p></p> <p>Then, select a value for Cluster auto pause. This is the amount of time of inactivity after which the platform will pause the cluster automatically.</p> <p></p> <p>Additionally, you can select a value for Cluster auto shutdown. Activity is determined through attached notebooks (see how to attach a notebook to a cluster) and jobs (see how to run a job). Therefore, if you don't plan to attach a notebook or a job to this cluster (and use it via <code>ssh</code> instead), it's recommended to set this to <code>Never</code>, since otherwise the cluster will be removed after the set time.</p> <p></p> <p>Finally click on <code>CREATE</code>. You will see that a new task for creating the cluster has been created. The status is updated to INPROGRESS when the task starts executing and cluster creation is in progress.</p> <p></p> <p>You can click on the <code>Details</code> drop down to monitor the progress for the cluster creation.</p> <p></p> <p>Once the cluster is successfully created and ready to use, the status is updated to FINISHED.</p> <p></p>"},{"location":"installation_and_setup/bodo_platform/#cluster-instance-type-and-size-recommendations","title":"Cluster Instance Type and Size Recommendations","text":"<p>If you were previously running a query on a Snowflake Warehouse this table provides a starting point for what instance type and size you can use to run the query using Bodo. Since this is only a starting point you should experiment to find the best configuration for your specific use case.</p> Snowflake Warehouse Size Bodo Cluster Spec XS 1 x c5n.2xlarge S 1 x r5n.4xlarge M 1 x r5n.8xlarge L 1 x r5n.24xlarge XL 2 x r5n.24xlarge 2XL 5 x r5n.24xlarge"},{"location":"installation_and_setup/bodo_platform/#attaching_notebook_to_cluster","title":"Attaching a Notebook to a Cluster","text":"<p>To attach a notebook to a cluster, select the cluster from the drop-down in the top-left.</p> <p></p> <p>To execute your code across the attached cluster, use IPyParallel magics <code>%%px</code> and <code>%autopx</code>.</p> <p></p> <p>Note that parallel execution is only allowed when the notebook is attached to a cluster. If you execute a cell without a cluster attached, the following warning will be shown:</p> <p></p>"},{"location":"installation_and_setup/bodo_platform/#instance_role_cluster","title":"Using your own Instance Role for a Cluster","text":""},{"location":"installation_and_setup/bodo_platform/#aws","title":"AWS","text":"<p>In cases where you want to access additional AWS resources from Bodo clusters e.g. S3 buckets, you can create an IAM Role in your AWS account and then register it as an Instance Role on the Bodo Platform which will allow you to access those resources from Bodo clusters without using AWS keys.</p> <p></p> <p>Note that, by default, Bodo creates an IAM role with necessary policies for each cluster. When you register your own role with the Bodo Platform, it will automatically attach the other required policies to this role.</p> <p>Here we walk through the process of setting up an IAM Role in AWS and then registering it as an Instance Role on the Bodo Platform. For this example, we will be creating a role with access to an S3 bucket in your AWS account:</p> <p>Step 1: Create an AWS IAM Role on the AWS Management Console: 1. Go to the IAM service.</p> <p></p> <ol> <li>In the left sidebar click on Roles.</li> </ol> <p></p> <ol> <li>Click on button <code>Create role</code>, then select:</li> <li>Trusted entity type: AWS service</li> <li>Common use cases: EC2</li> </ol> <p></p> <ol> <li>Click next, and then create new policy that will be attached to this role:</li> <li> <p>json policy: <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:ListBucket\"\n            ],\n            \"Resource\": [\n                \"arn:aws:s3:::&lt;private-s3-bucket-name&gt;\"\n            ]\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:PutObject\",\n                \"s3:GetObject\",\n                \"s3:DeleteObject\",\n                \"s3:PutObjectAcl\"\n            ],\n            \"Resource\": [\n                \"arn:aws:s3:::&lt;private-s3-bucket-name&gt;/*\"\n            ]\n        }\n    ]\n}\n</code></pre></p> </li> <li> <p>Go back to Create role, refresh list of policies and add the policy that was created.</p> </li> <li>Click Next, then in the Role name field, type a role name and click Create role.</li> <li>Copy the Role ARN from the role summary.</li> </ol> <p></p> <p>Step 2: Register your AWS IAM Role on the Bodo Platform as a new Instance Role:</p> <ol> <li>Click on the CREATE INSTANCE ROLE button and in the creation form, fill the following fields:</li> <li>Name: Name for the Instance Role </li> <li>Role ARN: AWS Role ARN from Step 1</li> <li>Description: Short description for Instance Role</li> </ol> <p></p> <ol> <li>Click on the Create button.</li> </ol> <p>The Instance Role will now be registered on the Platform. It can have one of two status-es: * Active: Instance Role is ready to use * Failed: Something went wrong while registering the Instance Role and it cannot be used. Some possible problems could be:    * The Platform wasn't able to find the specified Role.    * The Platform was not able to attach additional Bodo polices that are required for normal cluster operations.</p>"},{"location":"installation_and_setup/bodo_platform/#managing-packages-on-the-cluster-using-ipyparallel-magics-conda-and-pip","title":"Managing Packages on the cluster using IPyParallel magics - Conda and Pip","text":"<p>We recommend all packages to be installed using Conda as that is what we use in our environments. Any conda command can be run in parallel on all the nodes of your cluster using <code>%pconda</code>. To install a new package on all the nodes of your cluster you can use <code>%pconda install</code>. All conda install arguments work as expected, e.g. <code>-c conda-forge</code> to set the channel.</p> <pre><code>%pconda install -c conda-forge &lt;PACKAGE_NAME&gt;\n</code></pre> <p>To learn more about the packages installed on the cluster nodes <code>%pconda list</code>. <pre><code>%pconda list\n</code></pre></p> <p>To remove a conda package on all the nodes of your cluster, use <code>%pconda remove</code>.</p> <pre><code>%pconda remove &lt;PACKAGE_NAME&gt;\n</code></pre> <p></p> <p>Any pip command can be run in parallel on all the nodes of your cluster using <code>%ppip</code>.</p> <p>Example: <pre><code>%ppip install &lt;PACKAGE_NAME&gt;\n</code></pre></p> <p>To learn about the installed packages, you can use <code>%ppip show</code> to get the details of the package.</p> <pre><code>%ppip show &lt;PACKAGE_NAME&gt;\n</code></pre> <p>To remove the same package on all the nodes of your cluster, use <code>%ppip uninstall</code>.</p> <pre><code>%ppip uninstall &lt;PACKAGE_NAME&gt; -y\n</code></pre> <p></p>"},{"location":"installation_and_setup/bodo_platform/#running-shell-commands-on-the-cluster-using-ipyparallel-magics","title":"Running shell commands on the cluster using IPyParallel magics","text":"<p>Shell commands can be run in parallel on the nodes of your cluster using <code>%psh &lt;shell_command&gt;</code>.</p> <pre><code>%psh echo \"Hello World\"\n</code></pre> <p></p>"},{"location":"installation_and_setup/bodo_platform/#connecting_to_a_cluster","title":"Connecting to a Cluster","text":"<p>We recommend interacting with clusters primarily through Jupyter notebooks and Jobs. However, it may be necessary to connect directly to a cluster in some cases. In that case, you can connect through a notebook terminal.</p>"},{"location":"installation_and_setup/bodo_platform/#connecting-with-a-notebook-terminal","title":"Connecting with a Notebook Terminal","text":"<p>First, you need to create a cluster and attach a notebook to the cluster. This will create the ssh-key at <code>~/cluster_ssh_keys/id_rsa-&lt;CLUSTER-UUID&gt;</code>.</p> <p>Then, go the cluster tab and find your cluster. Click on <code>DETAILS</code> and copy the cluster <code>UUID</code> and <code>IP address</code> of the node you would like to connect to.</p> <p></p> <p>Next, go to the notebooks tab and select <code>OPEN NOTEBOOK</code>. In the Launcher, click on <code>Terminal</code>.</p> <p></p> <p>In the terminal you can connect to any of the cluster nodes by running <pre><code>ssh -i ~/cluster_ssh_keys/id_rsa-&lt;CLUSTER_UUID&gt; &lt;IP&gt;\n</code></pre></p> <p></p> <p>Through this terminal, you can interact with the <code>/shared</code> folder, which is shared by all the instances in the cluster and the Notebook instance. Verify your connection to interact directly with your cluster.</p>"},{"location":"installation_and_setup/bodo_platform/#verify_your_connection","title":"Verify your Connection","text":"<p>Once you have connected to a node in your cluster, you should verify that you can run operations across all the instances in the cluster.</p> <ol> <li>Verify the path to the hostfile for your cluster. You can find it by     running:     <pre><code>ls -la /shared/.hostfile-&lt;CLUSTER UUID&gt;\n</code></pre></li> <li> <p>Check that you can run a command across you cluster. To do this,     run:</p> <pre><code>mpiexec -n &lt;TOTAL_CORE_COUNT&gt; -f /shared/.hostfile-&lt;CLUSTER UUID&gt; hostname\n</code></pre> <p>This will print one line per each core in the cluster, with one unique hostname per cluster node.</p> <p>Your cluster's <code>TOTAL_CORE_COUNT</code> is usually half the number of vCPUs on each instance times the number of instances in your cluster. For example, if you have a 4 instance cluster of c5.4xlarge, then your <code>TOTAL_CORE_COUNT</code> is 32.</p> </li> <li> <p>Verify that you can run a python command across your cluster. For     example, run:</p> <pre><code>mpiexec -n &lt;TOTAL_CORE_COUNT&gt; -f /shared/.hostfile-&lt;CLUSTER_UUID&gt; python --version\n</code></pre> </li> </ol> <p>If all commands succeed, you should be able to execute workloads across your cluster. You can place scripts and small data that are shared across cluster nodes in <code>/shared</code>. However, external storage, such as S3, should be used for reading and writing large data.</p>"},{"location":"installation_and_setup/bodo_platform/#running-a-job","title":"Running a Job","text":"<p>Bodo Cloud Platform has support for running scheduled (and immediate) Python jobs without the need for Jupyter Notebooks. To create a Job, navigate to the Jobs page by selecting Jobs in the left bar.</p> <p></p> <p>This pages displays any  INPROGRESS jobs you have previously scheduled and allows you to schedule new Jobs. At the top right corner, click on <code>CREATE JOB</code>. This opens a job creation form.</p> <p>First, select a name for your job and specify the cluster on which you want to deploy your job. If you have an existing cluster that is not currently bound to a notebook or another job, you can select this cluster from the dropdown menu. Alternatively, you can create a cluster specifically for this job by selecting the <code>NEW</code> button next to the cluster dropdown menu. When creating a cluster specifically for a job, note that the cluster is only used for that job and is removed once the job completes. After selecting your cluster, indicate when you want your job to be executed in the Schedule section. Then, enter the Command that you want to execute inside this cluster.</p> <p>Note</p> <p>This command is automatically prepended with <code>mpiexec -n &lt;CORE_COUNT&gt; python</code>. For example, to run a file <code>ex.py</code> with the argument 1, you would enter the command <code>ex.py 1</code>.</p> <p>To specify your source code location, fill in the Path line with a valid Git URL that leads to a repository containing your code.</p> <p>Note</p> <p>When selecting a GitHub URL, you should select the URL available at the top of your web browser and NOT the path when cloning the repository, i.e. your path SHOULD NOT end in <code>.git</code>.</p> <p></p> <p>If you are cloning a private repository, you need to provide the platform with valid Git credentials to download your repository. To do so, select <code>Show advanced</code> in the bottom right of the form. Then in Workspace username, enter your Git username and in Workspace password enter either your password or a valid Github Access Token. The advanced options also allow you to specify a particular commit or branch with Workspace reference and to load other custom environment variables in Other.</p> <p>Note</p> <p>If your Github Account uses 2FA please use a Github Access Token to avoid any possible authentication issues.</p> <p>Once your form is complete, select <code>CREATE</code> to begin your job.</p> <p></p> <p>Once you've provided all the necessary details, select <code>CREATE</code> to begin your job. You will see a NEW task created in your jobs page.</p> <p>If you created a cluster specifically for this job, a new cluster will also appear in your clusters page.</p> <p>Your job will begin once it reaches its scheduled time and any necessary clusters have been created. Then your job will transition to being INPROGRESS.</p> <p>At this point your job will execute your desired command. Once it finishes executing, your job will transition to FINISHED status. You can find any stdout information that you may need by pressing <code>DETAILS</code> followed by <code>SHOW LOGS</code>. If a cluster was specifically created for this job, it will be deleted after the job finishes.</p> <p>Note</p> <p>Bodo DOES NOT preserve artifacts written to local storage. If you have any information that you need to persist and later review, you should write to external storage, such as Amazon S3. You may also write to stdout/stderr, but output logs may be truncated, so it should not be considered reliable for large outputs that need to be read later.</p>"},{"location":"installation_and_setup/bodo_platform/#troubleshooting","title":"Troubleshooting","text":"<p>Here are solutions to potential issues you may encounter while using the Bodo Cloud Platform. </p>"},{"location":"installation_and_setup/bodo_platform/#unexpected-number-of-ranks","title":"Unexpected number of ranks","text":"<p>If you are getting an unexpected number of ranks then the issue could be an inaccurate  MPI hostfile for the cluster. This is mostly likely to happen after scaling up a cluster.  You can update the hostfile using IPyParallel Magic <code>%update_hostfile</code> and then restart  the kernel to apply the changes.</p> <pre><code>%update_hostfile\n</code></pre> <p></p>"},{"location":"installation_and_setup/bodo_platform/#file-save-error","title":"File Save Error","text":"<p>If you get a file save error with message <code>invalid response: 413</code> make sure your notebook (<code>.ipynb</code>) file is less than 16MB in size. Bodo Platform does not support notebook files larger than 16MB in size. To reduce file size don't print large sections of text and clear output cells by clicking <code>Edit</code> &gt; <code>Clear All Outputs</code> in the notebook interface.</p>"},{"location":"installation_and_setup/bodo_platform/#account-locked-error","title":"Account Locked Error","text":"<p>When you login to the platform, if you get an account locked error with message <code>User is locked out. To unlock user, please contact your administrators</code>, this means that your account has been dormant (no login in more than 90 days). Please contact us to unlock your account.</p> <p>For AWS troubleshooting, refer to this guide.</p> <p>For Azure troubleshooting, refer to this guide.</p>"},{"location":"installation_and_setup/bodo_platform_aws/","title":"Bodo Managed Cloud Platform on AWS","text":""},{"location":"installation_and_setup/bodo_platform_aws/#registration","title":"Registration","text":"<p>a.  Subscribe through the AWS Marketplace.</p> <p>b.  After confirming your subscription, you'll be directed to Bodo     Platform's registration page.</p> <p>c.  Fill out the fields with your information. If this is your     individual account, use a unique name such as     firstname_lastname for the Organization Name     field.</p> <p>d.  Check the box for accepting terms and conditions and click on     <code>SIGN UP</code>:     </p> <p>e.  A page confirming that an activation link was sent to your email     will appear. Please open the email and click on the activation link:          Clicking on the confirmation link will take you to the bodo platform     page where you can use your newly created credentials to sign in:     </p>"},{"location":"installation_and_setup/bodo_platform_aws/#setting_aws_credentials","title":"Setting AWS Credentials","text":"<p>To use Bodo on AWS, you need to link your AWS account to the Bodo platform. This can be done using the Cloud Configuration page in the left bar as shown in the picture below:</p> <p></p> <p>To be able to use the Bodo Platform to launch clusters and notebooks, you must grant it permission to access your AWS account and provision the required resources in it. This can be done through two ways:</p>"},{"location":"installation_and_setup/bodo_platform_aws/#with","title":"1. With Access Keys","text":"<ol> <li> <p>Follow the instructions from AWS Account and Access Keys     guide     to create/retrieve your AWS access key ID and secret access key.</p> </li> <li> <p>Enter the Access Key ID and Secret created in the previous step.</p> </li> <li> <p>Select the region the where the metadata will be stored and click on     <code>CREATE</code>.</p> <p></p> <p>Note</p> <p>This has been tested using access keys that have <code>S3FullAccess</code>, <code>DynamoDBFullAccess</code> and <code>IAMFullAccess</code> permissions.   Access keys with limited permissions will not work.</p> <p>Note</p> <p>We will not save the provided Access Keys for security reasons.</p> </li> </ol>"},{"location":"installation_and_setup/bodo_platform_aws/#create_manually","title":"2. Manual Process","text":"<p>Open the Cloud Configuration Form and note down the <code>External ID</code>.</p> <p>We need to create 3 resources through the AWS Console and provide details about them in  the Cloud Configuration Form.</p> <p>Before that, Open the Cloud Configuration Form and note down the External ID.</p> <p></p> <p>Note</p> <p>The S3 bucket and the Dynamo DB table should be created in the same region.     Supported regions are: 'us-east-1', 'us-east-2', 'us-west-1' and 'us-west-2'.</p>"},{"location":"installation_and_setup/bodo_platform_aws/#setup_s3_bucket","title":"Setup S3 Bucket","text":"<ul> <li> <p>Setup S3 Bucket</p> <ol> <li> <p>In AWS console, go to S3 Management Console and click on <code>Create Bucket</code>.  </p> </li> <li> <p>In the creation form, enter the Bucket Name and select the AWS Region.     Note these down since you will need to enter them in the Cloud Configuration Form. </p> </li> <li> <p>All other fields can remain as it is by default and click on <code>Create Bucket</code>.</p> </li> </ol> </li> </ul>"},{"location":"installation_and_setup/bodo_platform_aws/#setup_dynamo_db","title":"Setup Dynamo DB table","text":"<ul> <li> <p>Setup Dynamo DB table</p> <ol> <li> <p>In AWS console, go to Dynamo DB page and click on <code>Create Table</code>.  </p> </li> <li> <p>In the table creation form, enter the Table name.      Note this down since you will need to enter it in the Cloud Configuration Form.</p> </li> <li> <p>Under Partition key, enter the partion key as LockID and select the type as String. This partion key must be created    for Bodo Platform to work.  </p> </li> <li> <p>All other fields can remain as it is by default and click on <code>Create Table</code>.</p> </li> </ol> </li> </ul>"},{"location":"installation_and_setup/bodo_platform_aws/#setup-iam-role","title":"Setup IAM role","text":"<ul> <li> <p>IAM role</p> <ol> <li> <p>Log in to the AWS Management     Console and navigate to the     IAM Service.</p> </li> <li> <p>Select the Roles tab in the sidebar, and click <code>Create Role</code>.</p> </li> <li> <p>In Select type of trusted entity, select <code>Another AWS Account</code>.</p> </li> <li> <p>Enter the Bodo Platform Account ID <code>481633624848</code> in the     Account ID field.</p> </li> <li> <p>Check the <code>Require external ID</code> option.</p> <p></p> <p>In the External ID field, copy over the External ID from the Cloud Configuration form on the Bodo Platform.</p> <p></p> </li> <li> <p>Click the <code>Next: Permissions</code> button.</p> </li> <li> <p>Click the <code>Next: Tags</code> button.</p> </li> <li> <p>Click the <code>Next: Review</code> button.</p> </li> <li> <p>In the Role name field, enter a role name, e.g.     <code>BodoPlatformUser</code>.</p> <p></p> </li> <li> <p>Click <code>Create Role</code>. You will be taken back to the list of IAM Roles     in your account.</p> </li> <li> <p>In the list of IAM Roles, click on the role you just created.</p> </li> <li> <p>Click on <code>Add inline policy</code>.</p> <p></p> </li> <li> <p>Click the <code>JSON</code> tab.</p> <p></p> </li> <li> <p>Bodo Cloud Platform requires a specific set of AWS permissions which     are documented in Bodo-Platform Policy.     Paste the contents of the linked JSON file into the policy editor.</p> </li> <li> <p><code>$$BUCKET_NAME$$</code> and <code>$$DYNAMO_ARN$$</code> placeholders needs to be updated in the Bodo Platform Policy      with the S3 Bucket name and Dynamo DB ARN respectively.</p> </li> <li> <p>Click on <code>Review policy</code>.</p> </li> <li> <p>In the Name field, add a policy name, e.g.     <code>Bodo-Platform-User-Policy</code>. Click on <code>Create policy</code>.     You will be taken back to the Role Summary.</p> </li> <li> <p>From the role summary, copy the <code>Role ARN</code>. This is the value that     you will enter into the Role ARN field on the Setting Page on     the Bodo Platform.</p> <p></p> </li> </ol> </li> </ul> <p>Once you have generated an IAM Role using the steps described above,  you can fill the remaining fields in the Cloud Configuration form on the Bodo Platform.</p> <ol> <li>Enter the Name of the configuration.</li> <li>Enter the S3 Bucket name.</li> <li>Enter the Dynamo DB Table name. </li> <li>Enter the Role ARN in the Role ARN field.</li> <li>Select a Region from the dropdown list.      This is the region of your S3 bucket and Dynamo DB table.</li> <li>Click on <code>CREATE</code>.</li> </ol> <p></p> <p>Important</p> <p>We highly recommend that you ensure sufficient limits on your AWS account to launch resources. See here for details on the resources required for Bodo Cloud Platform.</p>"},{"location":"installation_and_setup/bodo_platform_aws/#resources_created_in_aws_env","title":"Resources Created in Your AWS Environment","text":"<p>Bodo deploys cluster/notebook resources in your own AWS environment to ensure security of your data. Below is a list of AWS resources that the Bodo Platform creates in your account to enable clusters and notebooks.</p> AWS Service Purpose EC2 Instances Cluster/notebook workers EFS Shared file system for clusters VPC, Subnets, NAT Gateway, Elastic IP, ENI, Security Groups, ... Secure networking for clusters/notebooks S3 and Dynamo DB Resource states AWS Systems Manager Managing EC2 instances KMS Cluster secrets (e.g. SSH keys) IAM Role for Clusters Allow cluster workers to access resources above <p>Note</p> <p>These resources incur additional AWS infrastructure charges and are not included in the Bodo Platform charges.</p>"},{"location":"installation_and_setup/bodo_platform_aws/#using-bodo-platform","title":"Using Bodo Platform","text":"<p>Check the following link on how to use the Bodo Platform once the cloud credentials are added.</p> <p>Bodo Cloud Platform</p>"},{"location":"installation_and_setup/bodo_platform_aws/#aws_billing","title":"Billing","text":"<p>Users subscribed to the Bodo Platform through the AWS Marketplace will be charged for their use of the platform as part of their regular AWS bill. The platform charges are based on the type of instances deployed and the duration of their usage (to the nearest minute). The hourly rate for the supported instance types can be found on our website. For any cluster deployed through the platform, users are charged starting from when the cluster has been successfully deployed, until the time the user requests the cluster to be removed.</p> <p>Note</p> <p>Users are not charged in case of failures in cluster creation.</p> <p>As mentioned previously, the AWS resources set up by the platform in your AWS environment incur additional AWS infrastructure charges, and are not included in the Bodo Platform charges.</p>"},{"location":"installation_and_setup/bodo_platform_aws/#billing-alarms","title":"Billing Alarms","text":"<p>You can set up AWS alarms to monitor usage using cloudwatch alarms on AWS.</p> <p></p>"},{"location":"installation_and_setup/bodo_platform_aws/#steps-to-create-an-alarm-on-your-aws-account-for-all-ec2-usage","title":"Steps to create an alarm on your AWS account for all EC2 usage:","text":"<p>Steps to create an alarm on your AWS account for all EC2 usage:</p> <p></p> <ol> <li> <p>Select the region from which you would like to create the alarm and click <code>Create Alarm</code>. </p> </li> <li> <p>Click on the <code>Select metric</code> which would bring you to a search bar that allows you  to search and select the metric of your choice. Make sure to click on the check box of the  metric of your choice. In this example, we choose vCPU for monitoring EC2 usage. </p> </li> <li> <p>Set a reasonable number for the threshold for an alarm to go off based on your usage expectations. If you do not have this you can use the history of the metric to get an estimate. The history can be viewed by clicking on the expand button on the graph. You can toggle the time range by clicking on the available options (e.g. <code>1w</code> for 1 week) on the top panel. You can use the graph to set the desired threshold for your alarm. The  default period for the alarm threshold is 5 minutes but can be altered based on your requirement.  In this example above we set the alarm to become active, if the vCPU count is greater than 1000  for 5 minutes as the highest value found from the last week was ~850. Click <code>Next</code> at the bottom  of the page after you have set the threshold and period. </p> </li> <li> <p>You will now be asked to select the Simple Notification Service (SNS) Topic for this alarm. </p> <p>a. If you already have an existing SNS Topic you can choose it from the dropdown list  by clicking on the <code>Select an Existing SNS Topic</code> radio button. </p> <p>b. If you do not have an SNS Topic, then create a new SNS Topic by clicking on the  <code>Create New Topic</code> radio button. Fill in the form with an appropriate <code>Topic Name</code> and  provide the emails (Those who should be alerted by the alarm) in the  <code>Email endpoints that will receive the notification</code> tab.</p> <p>Once you have provided these details you can click on <code>Next</code> at the bottom of the page.</p> </li> <li> <p>You will now be required to fill out the details of the alarm itself, fill the fields with the  appropriate details and click <code>Next</code> at the bottom of the page. </p> </li> <li> <p>Finally, preview your alarm before you click on <code>Create Alarm</code> at the bottom of the page to create the Alarm.</p> </li> </ol>"},{"location":"installation_and_setup/bodo_platform_azure/","title":"Bodo Managed Cloud Platform on Azure","text":""},{"location":"installation_and_setup/bodo_platform_azure/#setting_azure_credentials","title":"Setting Azure Credentials","text":"<p>To use Bodo on Azure, you need to link your Azure account to the Bodo platform. This can be done using the Cloud Configuration page in the left bar as shown in the picture below:</p> <p></p> <p>In order to use the Bodo Platform to launch clusters and notebooks, you must grant it permission to access your Azure account and provision the required resources in it. You can do this by creating a Service Principal for the Bodo Platform application and assigning a role to it.</p>"},{"location":"installation_and_setup/bodo_platform_azure/#create_service_principal","title":"Create a Service Principal","text":"<p>Login to your Azure Portal. Click on the icon next to the search bar to open a Cloud-Shell. Execute the following command to create a service principal:</p> <pre><code>az ad sp create --id APP_ID\n</code></pre> <p>where <code>APP_ID</code> is the Application ID for Bodo-Platform which is displayed on the Cloud Configuration Form.</p> <p></p> <p>Once you have created a service principal, you need to assign a role to it. As shown below, go to the IAM section of your resource group and add a <code>Contributor</code> Role to the service principal you created for the Bodo Platform Application.</p> <p></p> <p>See Also</p> <p>Required Azure resource providers</p> <p>Once you have created the service principal and assigned a role to it, you are now ready to fill the Cloud Configuration Form on the Bodo Platform.</p> <p></p> <ol> <li> <p>Enter your Azure subscription ID in the Subscription ID field.     You can find this in the Subscription Overview.</p> <p></p> </li> <li> <p>Enter your Azure Tenant ID in the Tenant ID field. You can find     this in Azure AD.</p> <p></p> </li> <li> <p>Enter the name of the resource group where the infrastructure should be deployed.</p> </li> <li> <p>Select a region from the dropdown list. This region refers to the region of      the resource group mentioned in the previous step. We will also create a storage account and a blob container in this region to store metadata such as the state of the deployed infrastructure, logs, etc.</p> </li> <li> <p>Click on <code>CREATE</code>.</p> </li> </ol> <p>Note</p> <p>We highly recommend that you ensure sufficient limits on your Azure subscription to launch resources. See here for the resources required for Bodo Cloud Platform.</p>"},{"location":"installation_and_setup/bodo_platform_azure/#required_az_resource_providers","title":"Required Resource Providers on Azure subscription","text":"<p>Ensure that the following resource providers are registered on your Azure subscription:</p> <ul> <li>Microsoft.Authorization</li> <li>Microsoft.Compute</li> <li>Microsoft.KeyVault</li> <li>Microsoft.ManagedIdentity</li> <li>Microsoft.Network</li> <li>Microsoft.Resources</li> <li>Microsoft.Storage</li> </ul> <p></p>"},{"location":"installation_and_setup/bodo_platform_azure/#resources_created_in_azure_env","title":"Resources Created in Your Azure Environment","text":"<p>Bodo deploys cluster/notebook resources in your own Azure environment to ensure security of your data. Below is a list of Azure resources that the Bodo Platform creates in your account to enable clusters and notebooks.</p> Azure Service Purpose Virtual Machines Cluster/notebook workers Storage Accounts, File-Shares Shared file system for clusters Virtual Network with Subnets and NAT Gateway, Public IP, NIC, Proximity Placement Groups, Availability Sets, Security Groups, ... Secure networking for clusters/notebooks Blob Containers, Resource states KeyVault Cluster secrets (e.g. SSH keys) VM Identity for Clusters Allow cluster workers to access resources above <p>Note</p> <p>These resources incur additional Azure infrastructure charges and are not included in the Bodo Platform charges.</p>"},{"location":"installation_and_setup/bodo_platform_azure/#using-bodo-platform","title":"Using Bodo Platform","text":"<p>Check the following link on how to use the Bodo Platform once the cloud credentials are added.</p> <p>Bodo Cloud Platform</p>"},{"location":"installation_and_setup/enterprise/","title":"Configuring Bodo Enterprise Edition","text":"<p>Bodo Enterprise Edition allows unrestricted use of Bodo on any number of cores. Ensure you have installed Bodo before configuring Bodo Enterprise Edition.</p>"},{"location":"installation_and_setup/enterprise/#licensekey","title":"License Key","text":"<p>Bodo Enterprise Edition requires a license key to run. The key can be provided in two ways:</p> <ul> <li>Through the environment variable <code>BODO_LICENSE</code></li> <li>A file called <code>bodo.lic</code> in the current working directory</li> </ul> <p>In both cases, the file or environment variable must contain the key exactly as provided.</p> <p>If Bodo cannot find the license, you will only be able to run Bodo on up to 8 cores. If you try to run Bodo on more than 8 cores and if Bodo cannot find the license (the environment variable does not exist or is empty, and no license file is found), it will exit with the <code>Bodo license not found</code> error.</p> <p>If the contents of the license key are invalid, Bodo will exit with the <code>Invalid license</code> error. This typically means that the key is missing data or contains extraneous characters.</p> <p>Please make sure the license file has not been modified, or that the environment variable contains the key verbatim. Note that some shells might append extra characters when displaying the file contents. A good way to export the key is this:</p> <pre><code>export BODO_LICENSE=`cat bodo.lic`\n</code></pre>"},{"location":"installation_and_setup/enterprise/#automated-bodo_license-environment-variable-setup","title":"Automated <code>BODO_LICENSE</code> environment variable Setup","text":"<p>You can automate setting of the <code>BODO_LICENSE</code> environment variable in your <code>~/.bashrc</code> script (or the <code>~/.zshrc</code> script for macOS) using:</p> <pre><code>echo 'export BODO_LICENSE=\"&lt;COPY_PASTE_THE_LICENSE_HERE&gt;\"' &gt;&gt; ~/.bashrc\n</code></pre> <p>For more fine-grained control and usage with the Bodo <code>conda</code> environment as created when installing bodo, we recommend the following steps to automate setting the <code>BODO_LICENSE</code> environment variable (very similar to these steps):</p> <ol> <li> <p>Ensure that you are in the correct conda environment.</p> </li> <li> <p>Navigate to the <code>$CONDA_PREFIX</code> directory and create some additional     conda environment activation and deactivation steps:</p> <pre><code>cd $CONDA_PREFIX\nmkdir -p ./etc/conda/activate.d\nmkdir -p ./etc/conda/deactivate.d\ntouch ./etc/conda/activate.d/env_vars.sh\ntouch ./etc/conda/deactivate.d/env_vars.sh\n</code></pre> </li> <li> <p>Edit <code>./etc/conda/activate.d/env_vars.sh</code> as follows:</p> <pre><code>#!/bin/sh \nexport BODO_LICENSE=\"&lt;COPY_PASTE_THE_LICENSE_HERE&gt;\"\n</code></pre> </li> <li> <p>Similarly, edit <code>./etc/conda/deactivate.d/env_vars.sh</code> as follows:</p> <pre><code>#!/bin/sh\nunset BODO_LICENSE\n</code></pre> </li> <li> <p>Deactivate (<code>conda deactivate</code>) and reactivate the <code>Bodo</code> conda     environment (<code>conda activate Bodo</code>) to ensure that the environment     variable <code>BODO_LICENSE</code> is automatically added when the environment     is activated.</p> </li> </ol>"},{"location":"installation_and_setup/enterprise/#mpienterpriseclusters","title":"Using MPI in Clusters with Bodo Enterprise Edition","text":"<p>MPI can be configured on clusters easily. The cluster nodes need to have passwordless SSH enabled between them, and there should be a host file listing their addresses (see an example tutorial here). MPI usually needs to be configured to launch one process per physical core for best performance. This avoids potential resource contention between processes due to the high efficiency of MPI. For example, a cluster of four nodes, each with 16 physical cores, would use 64 MPI processes:</p> <pre><code>mpiexec -n 64 python example.py\n</code></pre> <p>For cloud instances, one physical core usually corresponds to two vCPUs. For example, an instance with 32 vCPUs has 16 physical cores.</p> <p>See Also</p> <p>Interactive Bodo Cluster Setup using IPyParallel</p>"},{"location":"installation_and_setup/enterprise/#passwordless_ssh","title":"Setting up passwordless SSH on your multi-node cluster","text":"<p>Using MPI on a multi-node cluster requires setting up passwordless SSH between the hosts. There are multiple ways to do this. Here is one way:</p> <ol> <li> <p>Generate an SSH key pair using a tool like <code>ssh-keygen</code>, for     instance:</p> <pre><code>ssh-keygen -b 2048 -f cluster_ssh_key -N \"\"\n</code></pre> </li> <li> <p>Copy over the generated private key (<code>cluster_ssh_key</code>) and public key (<code>cluster_ssh_key.pub</code>) to all the hosts and      store them in <code>~/.ssh/id_rsa</code> and <code>~/.ssh/id_rsa.pub</code> respectively.</p> </li> <li> <p>Add the public key to <code>~/.ssh/authorized_keys</code> on all hosts.</p> </li> <li> <p>To disable host key checking, add the following to <code>~/.ssh/config</code>     on each host:</p> <pre><code>Host *\n    StrictHostKeyChecking no\n</code></pre> </li> </ol>"},{"location":"installation_and_setup/install/","title":"Installing Bodo Community Edition","text":"<p>Bodo is available as a Python package on pip, and can be installed as follows:</p> <pre><code>pip install bodo\n</code></pre> <p>Bodo can also be installed as a using the <code>conda</code> command (see how to install conda below).  If you are installing bodo through conda, we recommend creating a <code>conda</code> environment and installing  Bodo and its dependencies in it as shown below:</p> <pre><code>conda create -n Bodo python=3.9 mamba -c conda-forge\nconda activate Bodo\nmamba install bodo -c bodo.ai -c conda-forge\n</code></pre> <p><code>mamba</code> is a drop-in replacement for <code>conda</code> that uses the same commands and configuration but is much faster.</p> <p>Bodo uses MPI for parallelization, which is automatically installed as part of the <code>conda</code> install command above. This command installs Bodo Community Edition by default, which is free and works on up to 8 cores. For information on Bodo Enterprise Edition and pricing, please contact us.</p> <p>See Also</p> <p>Configuring Bodo Enterprise Edition</p>","tags":["install"]},{"location":"installation_and_setup/install/#conda","title":"How to Install Conda","text":"<p>Install Conda using the instructions below.</p>","tags":["install"]},{"location":"installation_and_setup/install/#on-linux","title":"On Linux","text":"<pre><code>wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh\nchmod +x miniconda.sh\n./miniconda.sh -b\nexport PATH=$HOME/miniconda3/bin:$PATH\n</code></pre>","tags":["install"]},{"location":"installation_and_setup/install/#on-macos","title":"On MacOS","text":"<pre><code>curl https://repo.continuum.io/miniconda/Miniconda3-latest-MacOSX-x86_64.sh -L -o miniconda.sh\nchmod +x miniconda.sh\n./miniconda.sh -b\nexport PATH=$HOME/miniconda3/bin:$PATH\n</code></pre>","tags":["install"]},{"location":"installation_and_setup/install/#on-windows","title":"On Windows","text":"<pre><code>start /wait \"\" Miniconda3-latest-Windows-x86_64.exe /InstallationType=JustMe /RegisterPython=0 /S /D=%UserProfile%\\Miniconda3\n</code></pre> <p>Open the Anaconda Prompt to use Bodo (click Start, select Anaconda Prompt). You may use other terminals if you have already added Anaconda to your PATH.</p>","tags":["install"]},{"location":"installation_and_setup/install/#optionaldep","title":"Optional Dependencies","text":"<p>Some Bodo functionality may require other dependencies, as summarized in the table below. All optional dependencies except Hadoop can be installed using the commands</p> <pre><code>conda install gcsfs sqlalchemy snowflake-connector-python hdf5='1.10.*=*mpich*' openjdk -c conda-forge\n</code></pre> <p>and </p> <pre><code>pip install deltalake\n</code></pre> <p><code>mamba</code> is also useful if <code>conda</code> install commands are taking a long time to execute:</p> <pre><code>conda install mamba -c conda-forge\n</code></pre> <p> Functionality Dependency <code>pd.read_sql / df.to_sql</code> <code>sqlalchemy</code> <code>Snowflake I/O</code> <code>snowflake-connector-python</code> <code>GCS I/O</code> <code>gcsfs</code> <code>Delta Lake</code> <code>deltalake</code> <code>HDFS or ADLS Gen2</code> hadoop (only the Hadoop client is needed) <code>HDF5</code> <code>hdf5 (MPI version)</code> <p></p>","tags":["install"]},{"location":"installation_and_setup/install/#testinstall","title":"Testing your Installation","text":"<p>Once you have activated your <code>conda</code> environment and installed Bodo in it, you can test it using the example program below. This program has two functions:</p> <ul> <li>The function <code>gen_data</code> creates a sample dataset with 20,000 rows     and writes to a parquet file called <code>example1.pq</code>.</li> <li>The function <code>test</code> reads <code>example1.pq</code> and performs multiple     computations on it.</li> </ul> <pre><code>import bodo\nimport pandas as pd\nimport numpy as np\nimport time\n@bodo.jit\ndef gen_data():\nNUM_GROUPS = 30\nNUM_ROWS = 20_000_000\ndf = pd.DataFrame({\n\"A\": np.arange(NUM_ROWS) % NUM_GROUPS,\n\"B\": np.arange(NUM_ROWS)\n})\ndf.to_parquet(\"example1.pq\")\n@bodo.jit\ndef test():\ndf = pd.read_parquet(\"example1.pq\")\nt0 = time.time()\ndf2 = df.groupby(\"A\")[\"B\"].agg(\n(lambda a: (a==1).sum(), lambda a: (a==2).sum(), lambda a: (a==3).sum())\n)\nm = df2.mean()\nprint(\"Result:\", m, \"\\nCompute time:\", time.time() - t0, \"secs\")\ngen_data()\ntest()\n</code></pre> <p>Save this code in a file called <code>example.py</code>, and run it on a single core as follows:</p> <pre><code>python example.py\n</code></pre> <p>Alternatively, to run the code on four cores, you can use <code>mpiexec</code>:</p> <pre><code>mpiexec -n 8 python example.py\n</code></pre> <p>Note</p> <p>You may need to delete <code>example1.pq</code> between consecutive runs.</p> <p>See Also</p> <p>Interactive Bodo Cluster Setup using IPyParallel</p>","tags":["install"]},{"location":"installation_and_setup/ipyparallel/","title":"Interactive Bodo Cluster Setup using IPyParallel","text":"<p>Bodo can be used with IPyParallel to allow interactive code execution on a local or remote cluster.</p>"},{"location":"installation_and_setup/ipyparallel/#quickstart_local","title":"Getting started on your machine","text":"<p>Install IPyParallel, JupyterLab, and Bodo in your conda environment:</p> <pre><code>conda install bodo ipyparallel=8.1 jupyterlab=3 -c bodo.ai -c conda-forge\n</code></pre> <p>Start a JupyterLab server:</p> <pre><code>jupyter lab\n</code></pre> <p>Start a new notebook and run the following code in a cell to start an IPyParallel cluster:</p> <pre><code>import ipyparallel as ipp\nimport psutil;\nn = min(psutil.cpu_count(logical=False), 8)\nrc = ipp.Cluster(engines='mpi', n=n).start_and_connect_sync(activate=True)\n</code></pre> <p>This starts a local N-core MPI cluster on your machine, where N is the minimum of the number of cores on your machine and 8. You can now start using the <code>%%px</code> cell magic to parallelize your code execution, or use <code>%autopx</code> to run all cells on the IPyParallel cluster by default. Read more here.</p>"},{"location":"installation_and_setup/ipyparallel/#setupverify_local","title":"Verifying your setup","text":"<p>Run the following code to verify that your IPyParallel cluster is set up correctly:</p> <pre><code>%%px\nimport bodo\nprint(f\"Hello World from rank {bodo.get_rank()}. Total ranks={bodo.get_size()}\")\n</code></pre> <p>The correct output is:</p> <pre><code>Hello World from rank 0. Total ranks=N\nHello World from rank 1. Total ranks=N\n...\nHello World from rank N-1. Total ranks=N\n</code></pre> <p>Where N is the minimum of the number of cores on your machine and 8.</p>"},{"location":"installation_and_setup/ipyparallel/#quickstart_multiple_hosts","title":"Running on multiple hosts","text":"<p>To start an IPyParallel cluster across multiple hosts:</p> <ul> <li>Install IPyParallel and Bodo on all hosts:</li> </ul> <pre><code>conda install bodo ipyparallel=8.1 -c bodo.ai -c conda-forge\n</code></pre> <p>Note</p> <p><code>mamba</code> is a drop-in replacement for <code>conda</code> that uses the same commands and configuration but is much faster.     See here for detail.</p> <ul> <li>Install JupyterLab on one of the hosts. Let's call it the   controller node:</li> </ul> <pre><code>conda install jupyterlab=3 -c bodo.ai -c conda-forge\n</code></pre> <ul> <li> <p>Set up passwordless SSH between each of these hosts (this is needed   for <code>mpiexec</code>). See the section on passwordless ssh for instructions.</p> </li> <li> <p>The controller node must be able to connect to all engines via TCP   on any port. If you have a restricted network, please refer to the   IPyParallel   documentation   for other options such as SSH tunneling.</p> </li> <li> <p>Create a hostfile that contains list of IP addresses or host names   where you want to launch engines.</p> </li> </ul> <p>!!! note</p> <pre><code>  Make sure your hostfile is in the following format:\n  ```\n  ip_1 ip_2 ...\n  ```\n</code></pre> <p>You can find more information about <code>hostfiles</code> here.   It is important to note that other MPI systems and launchers (such   as QSUB/PBS) may use a different user interface for the allocation   of computational nodes.</p> <ul> <li>Create the default IPython profile on all nodes by executing the   following from the controller node:   <pre><code>mpiexec -ppn 1 -f &lt;PATH_TO_HOSTFILE&gt; ipython profile create\n</code></pre></li> </ul> <p>Now you can start a JupyterLab server on the controller node:</p> <pre><code>jupyter lab\n</code></pre> <p>Starting an IPyParallel cluster across multiple hosts requires setting a couple of additional configuration options. Start a new notebook and run the following code in a cell:</p> <pre><code>import ipyparallel as ipp\nc = ipp.Cluster(engines='mpi',\nn=8,  # Number of engines: Set this to the total number of physical cores in your cluster\ncontroller_ip='*',\ncontroller_args=[\"--nodb\"])\nc.engine_launcher_class.mpi_args = [\"-f\", &lt;PATH_TO_HOSTFILE&gt;]\nrc = c.start_and_connect_sync()\nview = rc.broadcast_view(block=True)\nview.activate()\n</code></pre> <p>You have now successfully started an IPyParallel cluster across multiple hosts.</p>"},{"location":"installation_and_setup/ipyparallel/#setupverify_multiple_hosts","title":"Verifying your setup","text":"<p>Run the following code to verify that your IPyParallel cluster is set up correctly:</p> <pre><code>%%px\nimport bodo\nimport socket\nprint(f\"Hello World from rank {bodo.get_rank()} on host {socket.gethostname()}. Total ranks={bodo.get_size()}\")\n</code></pre> <p>On a cluster with two hosts running 4 engines, the correct output is:</p> <pre><code>Hello World from rank 0 on host A. Total ranks=4\nHello World from rank 1 on host A. Total ranks=4\nHello World from rank 2 on host B. Total ranks=4\nHello World from rank 3 on host B. Total ranks=4\n</code></pre>"},{"location":"installation_and_setup/ipyparallel/#run_bodo_ipyparallel","title":"Running Bodo on your IPyParallel Cluster","text":"<p>You are now ready to run your Bodo code. Here is an example function with Bodo:</p> <pre><code>%%px\nimport bodo\n@bodo.jit\ndef process_data(n):\ndf = pd.DataFrame({\"A\": np.arange(n), \"B\": np.arange(n)**2})\ndf[\"C\"] = df.apply(lambda r: 2* r.A + r.B if r.A &gt; 10 else 0, axis=1)\nreturn df[\"C\"].sum()\nprocess_data(100000000)\n</code></pre>"},{"location":"installation_and_setup/ipyparallel/#run_from_python_script","title":"Running from a Python Script","text":"<p>You can run code on an IPyParallel cluster from a python script instead of IPython or JupyterLab as follows:</p> <ul> <li> <p>Setup the cluster using the same steps as above.</p> </li> <li> <p>Define the function you want to run on the cluster:</p> </li> </ul> <pre><code>import inspect\nimport bodo\n@bodo.jit\ndef process_data(n):\ndf = pd.DataFrame({\"A\": np.arange(n), \"B\": np.arange(n)**2})\ndf[\"C\"] = df.apply(lambda r: 2* r.A + r.B if r.A &gt; 10 else 0, axis=1)\nreturn df[\"C\"].sum()\nprocess_data(100000000)\n</code></pre> <ul> <li>We define a Python wrapper for <code>process_data</code> called <code>bodo_exec</code>   which will be sent to the engines to compute. This wrapper will call   the Bodo function on the engines, collect the result and send it   back to the client.</li> </ul> <pre><code>def bodo_exec(points):\nreturn process_data(points)\n</code></pre> <ul> <li>We can send the source code to be executed at the engines, using the   <code>execute</code> method of IPyParallel's <code>DirectView</code> object. After the   imports and code definitions are sent to the engines, the   computation is started by actually calling the <code>process_data</code>   function (now defined on the engines) and returning the result to   the client.</li> </ul> <pre><code>def main():\n# remote code execution: import required modules on engines\nview.execute(\"import pandas as pd\")\nview.execute(\"import numpy as np\")\nview.execute(\"import bodo\")\nview.execute(\"import time\")\n# send code of Bodo functions to engines\nbodo_funcs = [process_data]\nfor f in bodo_funcs:\n# get source code of Bodo function\nf_src = inspect.getsource(f)\n# execute the source code thus defining the function on engines\nview.execute(f_src).get()\npoints = 200000000\nar = view.apply(bodo_exec, points)\nresult = ar.get()\nprint(\"Result is\", result)\nrc.close()\nmain()\n</code></pre>"},{"location":"installation_and_setup/ipyparallel/#minimal-configuration-for-small-setups","title":"Minimal Configuration for Small Setups","text":"<p>IPyParallel starts several processes as part of its cluster. In particular, it launches 2 processes per engine, and few other processes for the controller. See IPyParallel documentation for more details. Note that the diagram does not include the broadcast scheduler (part of the controller), which accounts for <code>2<sup>depth+1</sup> - 1</code> processes. The default is a depth of <code>1</code>, which makes 3 processes.</p> <p>To keep the number of processes started by IPyParallel clusters minimal, for small setups such as running locally on your machine, we recommend running IPyParallel with the following configuration:</p> <pre><code>c = ipp.Cluster(engines=\"mpi\", n=4)\nc.config.ControllerLauncher.controller_args = [\n\"--IPController.broadcast_scheduler_depth=0\",\n\"--IPController.use_threads=True\",\n]\n</code></pre> <p>As the name suggests, this will run the schedulers in threads, hence decreasing the number of processes. The performance impact of this should be minimal for small setups. To further reduce the number of processes, you can also use: <code>py c.config.EngineLauncher.engine_args=[\"--IPEngine.enable_nanny=False\"]</code> which will only use 1 process per engine instead of 2. We do not recommend this, since it impacts prompt error-reporting and ability to send signals to the engines.</p>"},{"location":"installation_and_setup/ipyparallel/#useful-ipyparallel-references","title":"Useful IPyParallel References","text":"<ul> <li>IPyParallel Documentation</li> <li>Using MPI with IPython</li> <li>IPython Parallel in 2021</li> </ul>"},{"location":"installation_and_setup/platform_sdk/","title":"Bodo Platform SDK","text":"<p>Bodo Cloud Platform provides a simple SDK that can be integrated in CI/CD pipelines easily. For example, compute jobs can be orchestrated easily.</p>"},{"location":"installation_and_setup/platform_sdk/#getting-started","title":"Getting started","text":"<p>Install the latest Bodo SDK using:</p> <p><pre><code>pip install bodosdk\n</code></pre> The first step is to create an API Token in the Bodo Platform for Bodo SDK authentication. Navigate to API Tokens in the Admin Console to generate a token. Copy and save the token's Client ID and Secret Key and use them for BodoClient definition:</p> <pre><code>from bodosdk.models import WorkspaceKeys\nfrom bodosdk.client import get_bodo_client\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\n</code></pre> <p>To learn more about Bodo SDK, refer to this guide</p>"},{"location":"installation_and_setup/recommended_cluster_config/","title":"Recommended Cluster Configuration","text":"<p>This page describes best practices for configuring compute clusters for Bodo applications.</p>"},{"location":"installation_and_setup/recommended_cluster_config/#minimizing-communication-overheads","title":"Minimizing Communication Overheads","text":"<p>Communication across cores is usually the largest overhead in parallel applications including Bodo. To minimize it:</p> <ul> <li> <p>For a given number of physical cores, use fewer large nodes with high core count rather than many     small nodes with a low core count.</p> <p>This ensures that more cross core communication happens inside nodes. For example, a cluster with two <code>c5n.18xlarge</code> AWS instances will generally perform better than a cluster with four <code>c5n.9xlarge</code> instances, even though the two options have equivalent cost and compute power.</p> </li> <li> <p>Use node types that support high bandwidth networking.</p> <p>AWS instance types with <code>n</code> in their name, such as <code>c5n.18xlarge</code>, <code>m5n.24xlarge</code> and <code>r5n.24xlarge</code> provide high bandwidth. On Azure, use virtual machines that support  Accelerated Networking.</p> </li> <li> <p>Use instance types that support     RDMA     networking. </p> <p>Examples of such instance types are Elastic Fabric Adapter (EFA) (AWS) and Infiniband (Azure). In our empirical testing, we found that EFA can significantly accelerate inter-node communication during expensive operations such as shuffle (which is used in join, groupby, sorting and others).</p> <ul> <li> <p>List of AWS EC2 instance types that support EFA.     For more information about EFA refer to the section on     Recommended AWS Network Interface .</p> </li> <li> <p>RDMA capable Azure VM Sizes.</p> </li> </ul> </li> <li> <p>Ensure that the server nodes are located physically close to each     other.</p> <p>On AWS this can be done by adding all instances to a placement group with the <code>cluster</code> strategy. Similarly on Azure, you can use Proximity Placement Groups.</p> </li> </ul> <p>For most applications, we recommend using <code>c5n.18xlarge</code> instances on AWS for best performance. For memory intensive use cases <code>r5n.24xlarge</code> instances are a good alternative. Both instance types support 100 Gbps networking as well as EFA.</p>"},{"location":"installation_and_setup/recommended_cluster_config/#other-best-practices","title":"Other Best Practices","text":"<ul> <li> <p>Ensure that the file descriptor limit (<code>ulimit -n</code>) is set to a     large number like <code>65000</code>.</p> <p>This is especially useful when using IPyParallel which opens direct connections between <code>ipengine</code> and <code>ipcontroller</code> processes.</p> </li> <li> <p>Avoid unnecessary threading inside the application since it can     conflict with MPI parallelism. </p> <p>You can set the following environment variables in your shell (e.g. in <code>bashrc</code>) to avoid threading:</p> <pre><code>export OPENBLAS_NUM_THREADS=1\nexport OMP_NUM_THREADS=1\nexport MKL_NUM_THREADS=1\n</code></pre> </li> <li> <p>Use Intel MPI     for best performance.     See our recommended MPI settings for more     details.</p> </li> </ul>"},{"location":"installation_and_setup/recommended_mpi_settings/","title":"Recommended MPI Settings","text":"<p>These are our recommendations to tune your application environment and achieve the best possible performance with Bodo.</p> <p>Important</p> <p>These recommendations are only applicable when you are running your workload on a cluster. You do not need to do any of this on your laptop.</p> <p>Intel-MPI library is the preferred distribution for message passing interface (MPI) specification.</p> <p>Note that Bodo automatically installs <code>mpich</code>. Hence, after installing Intel-MPI, remove [mpich] using this command:</p> <pre><code>conda remove -y --force mpich mpi\n</code></pre> <p>Intel-MPI provides different tuning collective algorithms.</p> <p>Based on our internal benchmarking, we recommend setting these environment variables as follows:</p> <pre><code>export I_MPI_ADJUST_ALLREDUCE=4\nexport I_MPI_ADJUST_REDUCE=3\n</code></pre>"},{"location":"installation_and_setup/recommended_mpi_settings/#mpi-process-placement","title":"MPI Process Placement","text":"<p>Bodo assigns chunks of data and computation to MPI processes, also called ranks. For example, for a dataframe with a billion rows on a 1000-core cluster, the first one million rows are assigned to rank 0, the second one million rows to rank 1, and so on. MPI placement indicates how these ranks are assigned to physical cores across the cluster, and can significantly impact performance depending on hardware configuration and application behavior. We recommend trying block mapping and round-robin mapping options below for your application to achieve the best performance.</p>"},{"location":"installation_and_setup/recommended_mpi_settings/#block-mapping","title":"Block Mapping","text":"<p>In block mapping, cores of each node in the <code>hostfile</code> are filled with ranks before moving on to the next node. For example, for a cluster with 50-core nodes, the first 50 ranks will be on node 0, the second 50 ranks on node 1 and so on. This mapping has the advantage of fast communication between neighboring ranks on the same node.</p> <p>We provide instructions on setting block placement for MPICH and Intel MPI below. The following assumes the hostfile only contains a list of hosts (e.g. it does not specify number of processes per host) and the number of cores on each host is the same.</p> <p>Block Mapping with MPICH and Intel MPI:</p> <p><pre><code>mpiexec -n &lt;N&gt; -f &lt;hostfile&gt; -ppn &lt;P&gt; python bodo_file.py\n</code></pre> where <code>N</code> is the number of MPI processes, <code>hostfile</code> contains the list of hosts, and <code>P</code> the number of processes (cores) per node.</p>"},{"location":"installation_and_setup/recommended_mpi_settings/#round-robin-mapping","title":"Round-Robin Mapping","text":"<p>In round-robin mapping, MPI assigns one rank per node in hostfile and starts over when it reaches end of the host list. For example, for a cluster with 50-core nodes, rank 0 is assigned to node 0, rank 1 is assigned to node 1 and so on. Rank 50 is assigned to node 0, 51 to node 1, and so on. This mapping has the advantage of avoiding communication hotspots in the network and tends to make large shuffles faster.</p> <p>We provide instructions on setting round-robin placement for MPICH and Intel MPI below. The following assumes the hostfile only contains a list of hosts (e.g. it does not specify number of processes per host) and the number of cores on each host is the same.</p> <p>Round-Robin with MPICH:</p> <p><pre><code>mpiexec -n &lt;N&gt; -f &lt;hostfile&gt; python bodo_file.py\n</code></pre> Round-Robin with Intel MPI:</p> <pre><code>mpiexec -n &lt;N&gt; -f &lt;hostfile&gt; -rr python bodo_file.py\n</code></pre>"},{"location":"installation_and_setup/recommended_mpi_settings/#useful-references","title":"Useful References","text":"<ul> <li> <p>More information on controlling process placement with Intel MPI can be found here.</p> </li> <li> <p>See how to use the Hydra Process Manager for MPICH here.</p> </li> </ul>"},{"location":"installation_and_setup/recommended_mpi_settings/#recommended_aws_nic","title":"Recommended AWS Network Interface","text":"<p>Elastic Fabric Adapter (EFA) is a network interface for Amazon EC2 instances that has shown better inter-node communications at scale on AWS.</p> <p>To enable EFA with Intel-MPI on your cluster, follow instructions here.</p> <p>Some points to note in addition to the referenced instructions:</p> <ol> <li> <p>All instances must be in the same subnet. For more information, see     the \"EFA Limitations\" section     here.</p> </li> <li> <p>All instances must be part of a security group that allows all     inbound and outbound traffic to and from the security group itself.     Follow these     instructions     to set up the security group correctly.</p> </li> <li> <p>For use with Intel-MPI, a minimal installation of the EFA drivers is     sufficient and recommended:</p> <pre><code>sudo ./efa_installer.sh -y --minimal\n</code></pre> <p>Depending on where the drivers were downloaded from, you might need to include a <code>--no-verify</code> flag:</p> <pre><code>sudo ./efa_installer.sh -y --minimal --no-verify\n</code></pre> </li> </ol> <p>We recommend the following versions for the EFA installer and Intel-MPI:</p> <pre><code>EFA_INSTALLER_VERSION: 1.13.0\nIntel-MPI: v3.1 (2021.3.1.315)\n</code></pre> <p>Other version combinations are not guaranteed to work as they have not been tested.</p> <p>For EFA installer versions &gt;= 1.12.0, enabling fork is required by setting environment variable <code>FI_EFA_FORK_SAFE=1</code>.</p> <p>To confirm correct settings are enabled, run following <code>mpiexec</code> with <code>I_MPI_DEBUG=5</code> :</p> <pre><code>I_MPI_DEBUG=5 mpiexec -f hostfile -rr -n &lt;CORES&gt; python -u -c \"from mpi4py import MPI\"\n</code></pre> <p>Check that <code>libfabric provider</code> is <code>efa</code> and environment variables are set as shown below:</p> <pre><code>[0] MPI startup(): Intel(R) MPI Library, Version 2021.3.1  Build 20210719 (id: 48425b416)\n[0] MPI startup(): Copyright (C) 2003-2021 Intel Corporation.  All rights reserved.\n[0] MPI startup(): library kind: release\n[0] MPI startup(): libfabric version: 1.13.0rc1-impi\n[0] MPI startup(): libfabric provider: efa\n...\n[0] MPI startup(): I_MPI_ADJUST_ALLREDUCE=4\n[0] MPI startup(): I_MPI_ADJUST_REDUCE=3\n[0] MPI startup(): I_MPI_DEBUG=5\n</code></pre>"},{"location":"integrating_bodo/bodo-jobs/","title":"Batch Jobs","text":"<p> Supported on AWS \u00b7  Supported on Azure \u00b7</p> <p>Important</p> <p>This feature is only available on new workspaces. If you have an existing workspace where you would like to use Bodo batch jobs, please contact your Bodo customer success manager to upgrade your workspace.</p> <p>Bodo supports Python and SQL batch jobs. Batch jobs are useful for running data processing tasks, such as ETL, ELT, data preparation, and data analysis.  Bodo provides a simple API for creating Batch Job Definitions and then submitting Batch Job Runs for execution.</p>"},{"location":"integrating_bodo/bodo-jobs/#batch-job-definitions","title":"Batch Job Definitions","text":"<p>Batch job definitions are stored objects which can be used to run your data processing and analysis applications in a Bodo Platform workspace. You need to have an available workspace before creating a batch job definitions. Here are the main components of a batch job definition. For details on usage,  see Bodo Platform SDK. </p> <p>Note</p> <p>Currently, batch job functionality is only available through the Bodo Platform SDK. We will add UI support in the Bodo Platform for batch jobs in the future.</p>"},{"location":"integrating_bodo/bodo-jobs/#name","title":"Name","text":"<p>The name of the batch job definition. The name must be unique within the workspace. Each batch job definition is assigned a unique id (UUID).  If a batch job definition is deleted from the workspace, the name can be reused. However, the UUID of the new batch job definition will be different.</p>"},{"location":"integrating_bodo/bodo-jobs/#description","title":"Description","text":"<p>The description of the batch job definition. This is optional. </p>"},{"location":"integrating_bodo/bodo-jobs/#configuration","title":"Configuration","text":"<p>A batch job configuration is a JSON object that specifies the batch job's source, environment, and its execution logic. It includes the following fields:</p>"},{"location":"integrating_bodo/bodo-jobs/#source","title":"Source","text":"<p>The source of the batch job.</p> <ul> <li>Type  You need to specify the job source type. We currently support three types of sources: <code>WORKSPACE</code>, <code>GIT</code> and <code>S3</code>.</li> <li> <p>Definition  You need to specify the source definition. The source definition depends on the source type. </p> <ul> <li>Workspace: The batch job source is a file in the workspace (<code>bodofs</code>). You need to specify the file path in the workspace. </li> <li>Git: The batch job source is a file in a Git repository. You need to specify the Git repository URL and the file path in the repository.        You also need to provide a Git username and an access token for accessing the repository. If you want to check out a specific  branch or commit, you can specify the branch or commit <code>reference</code>. Otherwise, the default branch will be used.</li> <li>S3: The batch job source is a file in an S3 bucket. You need to specify the file path including the bucket name. You also need to provide a bucket region.</li> </ul> </li> </ul> Example source<pre><code>  {\n...\n\"source\": {\n\"type\": \"GIT\",\n\"sourceDef\": {\n\"token\": &lt;access token&gt;,\n\"repoUrl\": \"github.com/Bodo-inc/Bodo-examples.git\",\n\"username\": &lt;username&gt;,\n\"reference\": \"\"\n}\n}\n...\n}\n</code></pre>"},{"location":"integrating_bodo/bodo-jobs/#type","title":"Type","text":"<p>The type of the batch job. Currently, we support two types of batch jobs: Python(<code>PYTHON</code>) and SQL(<code>SQL</code>). </p>"},{"location":"integrating_bodo/bodo-jobs/#source-location","title":"Source Location","text":"<p>The relative path from the location in the job source to the <code>.py</code> or <code>.sql</code> file that contains the job script.</p> <p>Note</p> <p>For workspace jobs, when you write a job definition, the job will consider the path of the file in the workspace to be the concatenation of the source location and the file path in the source. For example, if the source location is <code>/shared/bodouser</code> and the file path is <code>myjob.py</code>, the path of the file is <code>/shared/bodouser/myjob.py</code>. If you don't provide a full path, the path of the file will be relative to the workspace working directory. </p>"},{"location":"integrating_bodo/bodo-jobs/#arguments","title":"Arguments","text":"<p>The arguments to the batch job. The arguments are passed to the batch job script as command line arguments for <code>.py</code> files.  Example arguments<pre><code>{\n\"args\": \"--arg1 value1 --arg2 value2\"\n}\n</code></pre></p>"},{"location":"integrating_bodo/bodo-jobs/#retry-strategy","title":"Retry Strategy","text":"<p>The retry strategy for the batch job. The retry strategy is a JSON object that specifies the retry policy for the batch job. It includes the following fields:</p> <ul> <li><code>num_retries</code> : The number of retries for the batch job. The default value is 0.</li> <li><code>delay_between_retries</code> : The retry interval in minutes. The default value is one minute.</li> <li><code>retry_on_timeout</code> : Whether to retry on job timeout. The default value is <code>false</code>.</li> </ul> Example retry strategy<pre><code>{\n\"retry_strategy\": {\n\"numRetries\": 3,\n\"delayBetweenRetries\": 5,\n\"retryOnTimeout\": true\n}\n}\n</code></pre>"},{"location":"integrating_bodo/bodo-jobs/#timeout","title":"Timeout","text":"<p>The timeout for the batch job in minutes. The default value is 60 minutes.  Note that the timeout applies to each individual retry attempt, and not the total execution time of a batch job run  with potentially multiple retries. </p>"},{"location":"integrating_bodo/bodo-jobs/#environment-variables","title":"Environment Variables","text":"<p>Key-value pairs of environment variables for the batch job. Default value is an empty dictionary.</p>"},{"location":"integrating_bodo/bodo-jobs/#cluster-configuration","title":"Cluster Configuration","text":"<p>The cluster configuration specifies the default cluster configuration for the batch job.</p> <p>It includes the following fields:</p> Example cluster configuration for AWS<pre><code>{\n\"cluster\": {\n\"instanceType\": \"c5n.18xlarge\",\n\"workersQuantity\": 2,\n\"bodoVersion\": \"2023.1\",\n\"acceleratedNetworking\": true\n}\n}\n</code></pre>"},{"location":"integrating_bodo/bodo-jobs/#cluster-instance-type","title":"Cluster Instance Type","text":"<p>The cluster instance type depending on the cloud service provider. </p>"},{"location":"integrating_bodo/bodo-jobs/#workers-quantity","title":"Workers Quantity","text":"<p>The number of workers in the cluster.</p>"},{"location":"integrating_bodo/bodo-jobs/#bodo-version","title":"Bodo Version","text":"<p>The Bodo version to use for the cluster.</p>"},{"location":"integrating_bodo/bodo-jobs/#accelerated-networking","title":"Accelerated Networking","text":"<p>Whether to use accelerated networking for the cluster.</p>"},{"location":"integrating_bodo/bodo-jobs/#running-a-batch-job","title":"Running a Batch Job","text":"<p>Once you've created a batch job definition, you can run it whenever you want. To submit a batch job run, you need to provide the following information:</p> Example batch job run submission<pre><code>{\n\"batchJobDefinitionUUID\": \"a55a4d71-3081-436b-86d7-ca5dfb49b51f\",\n\"clusterUUID\": \"ba72e653-312z-491b-9457-71d7bc096959\"\n}\n</code></pre>"},{"location":"integrating_bodo/bodo-jobs/#batch-job-id","title":"Batch Job ID","text":"<p>The ID of the batch job to run.</p>"},{"location":"integrating_bodo/bodo-jobs/#cluster-uuid","title":"Cluster UUID","text":"<p>The UUID of the cluster to run the batch job on. </p> <p>Note</p> <ul> <li>If you don't provide a cluster UUID, the batch job will run on a new cluster with the default cluster configuration provided by the associated definition.</li> <li>If neither a cluster UUID nor a cluster configuration is provided, an error will be thrown.</li> </ul>"},{"location":"integrating_bodo/bodo-jobs/#batch-job-run-status","title":"Batch Job Run Status","text":"<p>Batch jobs can have one of the following statuses. </p> <ul> <li><code>PENDING</code> - The batch job is pending.</li> <li><code>RUNNING</code> - The batch job is running.</li> <li><code>SUCCEEDED</code> - The batch job run succeeded.</li> <li><code>FAILED</code> - The batch job run failed.</li> <li><code>CANCELLED</code> - The batch job run was cancelled.</li> </ul> <p>Each batch job that is not <code>SUCCEEDED</code> also has a status reason associated with it. When the status is one of <code>PENDING</code>, <code>FAILED</code> or <code>CANCELLED</code>, the reason could be one of the following:</p> <ul> <li><code>Cancelled by user</code> - The batch job run was <code>CANCELLED</code> by the user.</li> <li><code>In queue</code> - The batch job is <code>PENDING</code> in the queue because there's potentially another batch job running on the same cluster. </li> <li><code>Recently submitted</code> - The batch job is <code>PENDING</code> because it was recently submitted. </li> <li><code>NonZeroExitCode</code> - The batch job run <code>FAILED</code> because the job script exited with a non-zero exit code.</li> <li><code>Timeout</code> - The batch job run <code>FAILED</code> because it timed out.</li> </ul>"},{"location":"integrating_bodo/bodo-jobs/#sql-batch-job","title":"Running a SQL Query as a Batch Job","text":"<p>Bodo supports running SQL queries as batch jobs without explicitly writing a batch job definition.  See Bodo Platform SDK for usage details.</p>"},{"location":"integrating_bodo/bodo-jobs/#queuing-batch-job-runs","title":"Queuing Batch Job Runs","text":"<p>If you submit a batch job run while there's another batch job running on the same cluster,  the new batch job will automatically be queued. Currently, at most 100 job runs can be queued on a cluster at a time. Note that you can queue job runs for different batch job definitions on the same cluster.</p>"},{"location":"integrating_bodo/bodo-jobs/#submitting-batch-job-runs-to-a-paused-cluster","title":"Submitting Batch Job Runs to a Paused Cluster","text":"<p>You can choose whether to allow a cluster to resume on submission of a job run. This is enabled by default. </p> <p>If you submit a batch job run to a paused cluster with auto-resume enabled, the cluster will be resumed automatically. If auto-resume is not enabled, then the job run submission will fail. </p>"},{"location":"integrating_bodo/data_visualization/","title":"Data Visualization","text":"<p>Bodo supports Matplotlib visualization natively inside JIT functions. This page specifies the supported Matplotlib APIs and classes. In general, these APIs support all arguments except for the restrictions specified in each section.</p>"},{"location":"integrating_bodo/data_visualization/#plotting-apis","title":"Plotting APIs","text":"<p>Currently, Bodo automatically supports the following plotting APIs.</p> <ul> <li><code>matplotlib.pyplot.plot</code></li> <li><code>matplotlib.pyplot.scatter</code></li> <li><code>matplotlib.pyplot.bar</code></li> <li><code>matplotlib.pyplot.contour</code></li> <li><code>matplotlib.pyplot.contourf</code></li> <li><code>matplotlib.pyplot.quiver</code></li> <li><code>matplotlib.pyplot.pie</code>      (<code>autopct</code> must be a constant boolean or omitted)</li> <li><code>matplotlib.pyplot.fill</code></li> <li><code>matplotlib.pyplot.fill_between</code></li> <li><code>matplotlib.pyplot.step</code></li> <li><code>matplotlib.pyplot.errorbar</code></li> <li><code>matplotlib.pyplot.barbs</code></li> <li><code>matplotlib.pyplot.eventplot</code></li> <li><code>matplotlib.pyplot.hexbin</code></li> <li><code>matplotlib.pyplot.xcorr</code>     (<code>autopct</code> must be a constant boolean or omitted)</li> <li><code>matplotlib.pyplot.imshow</code></li> <li><code>matplotlib.pyplot.plot</code></li> <li><code>matplotlib.pyplot.scatter</code></li> <li><code>matplotlib.pyplot.bar</code></li> <li><code>matplotlib.axes.Axes.contour</code></li> <li><code>matplotlib.axes.Axes.contourf</code></li> <li><code>matplotlib.axes.Axes.quiver</code></li> <li><code>matplotlib.axes.Axes.pie</code>     (<code>usevlines</code> must be a constant boolean or omitted)</li> <li><code>matplotlib.axes.Axes.fill</code></li> <li><code>matplotlib.axes.Axes.fill_between</code></li> <li><code>matplotlib.axes.Axes.step</code></li> <li><code>matplotlib.axes.Axes.errorbar</code></li> <li><code>matplotlib.axes.Axes.barbs</code></li> <li><code>matplotlib.axes.Axes.eventplot</code></li> <li><code>matplotlib.axes.Axes.hexbin</code></li> <li><code>matplotlib.axes.Axes.xcorr</code>     (<code>usevlines</code> must be a constant boolean or omitted)</li> <li><code>matplotlib.axes.Axes.imshow</code></li> </ul> <p>These APIs have the following restrictions:</p> <ul> <li>The data being plotted must be Numpy arrays and not Pandas data     structures.</li> <li>Use of lists is not currently supported. If you need to plot     multiple arrays use a tuple or a 2D Numpy array.</li> </ul> <p>These functions work by automatically gathering all of the data onto one machine and then plotting the data. If there is not enough memory on your machine, a sample of the data can be selected. The example code below demonstrates calling plot with a sample of the data:</p> <pre><code>import matplotlib.pyplot as plt\n%matplotlib inline\n@bodo.jit\ndef dist_plot(n):\nX = np.arange(n)\nY = np.exp(-X/3.0)\nplt.plot(X[::10], Y[::10]) # gather every 10th element\nplt.show()\ndist_plot(100)\n</code></pre> <pre><code>[output:0]\n</code></pre> <p></p>"},{"location":"integrating_bodo/data_visualization/#formatting-apis","title":"Formatting APIs","text":"<p>In addition to plotting, we also support a variety of formatting APIs to modify your figures.</p> <ul> <li><code>matplotlib.pyplot.gca</code></li> <li><code>matplotlib.pyplot.gcf</code></li> <li><code>matplotlib.pyplot.text</code></li> <li><code>matplotlib.pyplot.subplots</code>     (<code>nrows</code> and <code>ncols</code> must be constant integers)</li> <li><code>matplotlib.pyplot.suptitle</code></li> <li><code>matplotlib.pyplot.tight_layout</code></li> <li><code>matplotlib.pyplot.savefig</code></li> <li><code>matplotlib.pyplot.draw</code></li> <li><code>matplotlib.pyplot.show</code>      (Output is only displayed on rank 0)</li> <li><code>matplotlib.figure.Figure.suptitle</code></li> <li><code>matplotlib.figure.Figure.tight_layout</code></li> <li><code>matplotlib.figure.Figure.subplots</code>     (<code>nrows</code> and <code>ncols</code> must be constant integers)</li> <li><code>matplotlib.figure.Figure.show</code>     (Output is only displayed on rank 0)</li> <li><code>matplotlib.axes.Axes.annotate</code></li> <li><code>matplotlib.axes.Axes.text</code></li> <li><code>matplotlib.axes.Axes.set_xlabel</code></li> <li><code>matplotlib.axes.Axes.set_ylabel</code></li> <li><code>matplotlib.axes.Axes.set_xscale</code></li> <li><code>matplotlib.axes.Axes.set_yscale</code></li> <li><code>matplotlib.axes.Axes.set_xticklabels</code></li> <li><code>matplotlib.axes.Axes.set_yticklabels</code></li> <li><code>matplotlib.axes.Axes.set_xlim</code></li> <li><code>matplotlib.axes.Axes.set_ylim</code></li> <li><code>matplotlib.axes.Axes.set_xticks</code></li> <li><code>matplotlib.axes.Axes.set_yticks</code></li> <li><code>matplotlib.axes.Axes.set_axis_on</code></li> <li><code>matplotlib.axes.Axes.set_axis_off</code></li> <li><code>matplotlib.axes.Axes.draw</code></li> <li><code>matplotlib.axes.Axes.set_title</code></li> <li><code>matplotlib.axes.Axes.legend</code></li> <li><code>matplotlib.axes.Axes.grid</code></li> </ul> <p>In general these APIs support all arguments except for the restrictions specified. In addition, APIs have the following restrictions:</p> <ul> <li>Use of lists is not currently supported. If you need to provide a     list, please use a tuple instead.</li> <li>Formatting functions execute on all ranks by default. If you need     to execute further Matplotlib code on all of your processes,     please close any figures you opened inside Bodo.</li> </ul>"},{"location":"integrating_bodo/data_visualization/#matplotlib_classes","title":"Matplotlib Classes","text":"<p>Bodo supports the following Matplotlib classes when used with the previously mentioned APIs:</p> <ul> <li><code>matplotlib.figure.Figure</code></li> <li><code>matplotlib.axes.Axes</code></li> <li><code>matplotlib.text.Text</code></li> <li><code>matplotlib.text.Annotation</code></li> <li><code>matplotlib.lines.Line2D</code></li> <li><code>matplotlib.collections.PathCollection</code></li> <li><code>matplotlib.container.BarContainer</code></li> <li><code>matplotlib.contour.QuadContourSet</code></li> <li><code>matplotlib.quiver.Quiver</code></li> <li><code>matplotlib.patches.Wedge</code></li> <li><code>matplotlib.patches.Polygon</code></li> <li><code>matplotlib.collections.PolyCollection</code></li> <li><code>matplotlib.image.AxesImage</code></li> <li><code>matplotlib.container.ErrorbarContainer</code></li> <li><code>matplotlib.quiver.Barbs</code></li> <li><code>matplotlib.collections.EventCollection</code></li> <li><code>matplotlib.collections.LineCollection</code></li> </ul>"},{"location":"integrating_bodo/data_visualization/#working-with-unsupported-apis","title":"Working with Unsupported APIs","text":"<p>For other visualization functions, you can call them from regular Python and manually gather the data. If the data does not fit in a single machine's memory, you may need to take a sample. The example code below demonstrates gathering a portion of data in Bodo and calling polar (which Bodo doesn't support yet) in regular Python:</p> <pre><code>import bodo\nimport numpy as np\nimport matplotlib.pyplot as plt\n@bodo.jit()\ndef dist_gather_test(n):\nX = np.arange(n)\nY = 3 - np.cos(X)\nreturn bodo.gatherv(X[::10]), bodo.gatherv(Y[::10])  # gather every 10th element\nX_Sample, Y_Sample = dist_gather_test(1000)\nif bodo.get_rank() == 0:\nplt.polar(X_Sample, Y_Sample)\nplt.show()\n</code></pre>"},{"location":"integrating_bodo/database_catalog/","title":"Native SQL with Database Catalogs","text":"<p>Database Catalogs are configuration objects that grant BodoSQL access to load tables from a remote database.  Bodo platform now supports adding Database catalogs through the UI and provides users the option to write native SQL code to run on the tables in the connected remote database.  </p>"},{"location":"integrating_bodo/database_catalog/#adding-a-database-catalog","title":"Adding a Database Catalog","text":"<p> Supported On AWS \u00b7 material-microsoft-azure:{.azure} Supported on Azure </p> <p>In your workspaces view, navigate to the Catalogs section in the sidebar. Click on CREATE CATALOG and fill up the form with the required values.  </p> <p> </p> <p>Currently, we only support Snowflake Database Catalogs on the Bodo Platform.  </p> <p>Upon submitting the form, you will see that your Catalog has been created and is now available to use in your interactive notebook. </p> <p></p>"},{"location":"integrating_bodo/database_catalog/#using-database-catalogs-in-interactive-notebooks","title":"Using Database Catalogs in Interactive Notebooks","text":"<p> On AWS only \u00b7  Experimental </p> <p>When you create a code cell in your interactive notebook, you will notice a blue selector on the top right hand corner of the code cell. By default, this will be set to Parallel-Python. This means that any code written in this cell will execute on all cores of the attached cluster. </p> <p></p> <p>To enable running native SQL code, you can set the cell type in the blue selector to SQL, and you  will need to select your Catalog from the Catalog selector to the left of the cell type selector as shown in the  figure below. </p> <p></p> <p>The output of the SQL query is automatically saved in a distributed dataframe named LAST_SQL_OUTPUT. This dataframe will be overwritten every time a SQL query is run. </p> <p>Warning</p> <p>This is an experimental feature currently only available on AWS.</p>"},{"location":"integrating_bodo/database_catalog/#viewing-database-catalogs-data","title":"Viewing Database Catalogs Data","text":"<p>To view the connection data stored in a catalog first connect to a cluster and then run the following in a code cell:</p> <pre><code>import bodo_platform_utils\nbodo_platform_utils.catalog.get_data(\"catalog_name\")\n</code></pre> <p>Seealso</p> <p>Database Catalogs, BodoSDK Catalog API</p>"},{"location":"integrating_bodo/dl/","title":"Deep Learning","text":"<p>Bodo works seamlessly with Horovod to support large-scale distributed deep learning with PyTorch and TensorFlow.</p>"},{"location":"integrating_bodo/dl/#prerequisites","title":"Prerequisites","text":"<p>You will need to install Horovod and a deep learning framework in your Bodo conda environment. Horovod needs to be compiled and linked with the same MPI library that Bodo uses.</p>"},{"location":"integrating_bodo/dl/#installing-horovod-and-pytorch","title":"Installing Horovod and PyTorch","text":"<p>Here are simple instructions for installing Horovod and PyTorch in your Bodo environment without CUDA support:</p> <pre><code># Activate the Bodo conda environment\nconda install -c pytorch -c conda-forge -c defaults bokeh pytorch=1.5 torchvision=0.6\npip install horovod[pytorch]\n</code></pre> <p>For information on setting up Horovod in a conda environment with CUDA see here.</p>"},{"location":"integrating_bodo/dl/#how-it-works","title":"How it works","text":"<p>Bodo works seamlessly with Horovod for distributed deep learning. The main thing to consider if you are using GPUs for deep learning is that a Bodo application typically uses all CPU cores on a cluster (there is one worker or process per core), whereas for deep learning only a subset of Bodo workers are pinned to a GPU (one worker per GPU). This means that data processed and generated by Bodo will need to be distributed to the GPU workers before training.</p> <p>Note</p> <p>Bodo can automatically assign a subset of workers in your cluster to GPU devices, initialize Horovod with these workers, and distribute data for deep learning to these workers.</p> <p>To ensure that Bodo automatically handles all of the above call <code>bodo.dl.start()</code> before starting training and <code>bodo.dl.prepare_data(X)</code> to distribute the data.</p>"},{"location":"integrating_bodo/dl/#api","title":"API","text":""},{"location":"integrating_bodo/dl/#bododlstart","title":"bodo.dl.start","text":"<ul> <li> <p><code>bodo.dl.start(framework)</code></p> <p><code>framework</code> is a string specifying the DL framework to use (\"torch\" or \"tensorflow\"). Note that this must be called before starting deep learning. It initializes Horovod and pins workers to GPUs.</p> </li> </ul>"},{"location":"integrating_bodo/dl/#bododlprepare_data","title":"bodo.dl.prepare_data","text":"<ul> <li> <p><code>bodo.dl.prepare_data(X)</code></p> <p>Redistributes the given data to DL workers.</p> </li> </ul>"},{"location":"integrating_bodo/dl/#bododlend","title":"bodo.dl.end","text":"<ul> <li> <p><code>bodo.dl.end()</code></p> <p>On calling this function, non-DL workers will wait for DL workers. They will become idle to free up computational resources for DL workers. This has to be called by every process.</p> </li> </ul>"},{"location":"integrating_bodo/dl/#example","title":"Example","text":"<p>The code snippet below shows how deep learning can be integrated in a Bodo application:</p> <pre><code># Deep learning code in regular Python usign Horovod\ndef deep_learning(X, y):\n# Note: X and y have already been distributed by Bodo and there is no\n# need to partition data with Horovod\nif hvd.initialized():\n# do deep learning with Horovod and your DL framework of choice\n...\nuse_cuda = bodo.dl.is_cuda_available()\n...\nelse:\n# this rank does not participate in DL (not pinned to GPU)\npass\n@bodo.jit\ndef main()\n...\nX = ... # distributed NumPy array generated with Bodo\ny = ... # distributed NumPy array generated with Bodo\nbodo.dl.start(\"torch\")  # Initialize Horovod with PyTorch\nX = bodo.dl.prepare_data(X)\ny = bodo.dl.prepare_data(y)\nwith bodo.objmode:\ndeep_learning()  # DL user code\nbodo.dl.end()\n</code></pre> <p>As we can see, the deep learning code is not compiled by Bodo. It runs in Python (in <code>objmode</code> or outside Bodo jitted functions) and must use Horovod. Note that data coming from Bodo has already been partitioned and distributed by Bodo (in <code>bodo.dl.prepare_data</code>), and that you don't have to initialize Horovod.</p> <p>A full distributed training example with the MNIST dataset can be found here.</p>"},{"location":"integrating_bodo/front_end/","title":"Integrating Bodo with Front-End Tools","text":"<p>Bodo can be integrated with front-end tools to build real-time analytics dashboards. This page provides a walk-through of creating a Streamlit app with Bodo on your laptop or VM.</p> <p>All the code referenced on this page is available here, and the steps to running the app are provided below.</p>"},{"location":"integrating_bodo/front_end/#the-taxi-pickup-app","title":"The Taxi Pickup App","text":"<p>This app is based on a demo from the official Streamlit documentation, which explores a public Uber dataset for pickups and drop-offs in New York City.</p> <p>We will essentially read a parquet file into a dataframe,  convert the string <code>date/time</code> column to datetime data,  and return the dataframe to be plotted in the app:</p> <pre><code>def load_data_pandas(pq_file_path, date_col='date/time'):\ndata = pd.read_parquet(pq_file_path)\ndata[date_col] = pd.to_datetime(data[date_col])\nreturn data\n</code></pre>"},{"location":"integrating_bodo/front_end/#bodo-version-of-the-taxi-pickup-app","title":"Bodo version of the Taxi Pickup App","text":"<p>To run the app using Bodo, we will use the same process as running the app on an IPyParallel cluster. For this app, we want to visualize all the data, so in the Bodo version of this function, we disable automatic data distribution using the <code>returns_maybe_distributed</code> flag, and use <code>bodo.gatherv</code> to gather all the data onto a single process:</p> <pre><code>@bodo.jit(returns_maybe_distributed=False, cache=True)\ndef load_data_bodo(pq_file_path, date_col='date/time'):\ndata = pd.read_parquet(pq_file_path)\ndata[date_col] = pd.to_datetime(data[date_col])\nreturn bodo.gatherv(data)\n</code></pre> <p>We define a Python wrapper for <code>load_data_bodo</code> called <code>build_main</code>:</p> <pre><code>def build_main(pq_file_path, date_col='date/time'):\nop_df = load_data_bodo(pq_file_path, date_col='Date/Time')\nreturn op_df\n</code></pre> <p>Finally, we need a function to send the imports and code definitions to the mpi engines, call the <code>load_data_bodo</code> function, and then return the result to the client:</p> <pre><code>def initialize_bodo(pq_file_path, date_col='date/time'):\nt0 = time.time()\nclient = ipp.Client(profile='mpi')\ndview = client[:]\n# import libraries\ndview.execute(\"import numpy as np\")\ndview.execute(\"import pandas as pd\")\ndview.execute(\"import bodo\")\ndview.execute(\"import time\")\ndview.execute(\"import os\")\ndview.execute(\"import datetime as dt\")\ndview.execute(\"import sys\")\nbodo_funcs = [load_data_bodo]\nfor f in bodo_funcs:\n# get source code of Bodo function\nf_src = inspect.getsource(f)\n# execute the source code thereby defining the function on engines\ndview.execute(f_src).get()\nop_df = dview.apply(build_main, pq_file_path, 'Date/Time').get()\nt1 = time.time()\nprint(\"Total Exec + Compilation time:\", t1-t0)\nclient.close()\nreturn op_df[0]\n</code></pre>"},{"location":"integrating_bodo/front_end/#building-the-streamlit-visualization","title":"Building the Streamlit Visualization","text":"<p>We create the Streamlit App by adding the title, creating some headers and printing out some basic information about our app:</p> <pre><code>st.title('Scale up your datasets and make Pandas fly with Bodo!')\nst.subheader('Based on Streamlit example for Uber pickups in NYC')\nst.subheader(' - &gt; Basic Info')\nst.subheader('Number of physical cores/ranks available on system: %s' % psutil.cpu_count(logical=False))\n</code></pre> <p>We first run the Pandas app and see how long it takes:</p> <pre><code>t0 = time.time()\npdf = load_data_pandas(pq_file_path, date_col='Date/Time')\nt1 = time.time()\nst.subheader('Pandas df')\nst.subheader('Time taken for one op with Pandas:')\nst.subheader(t1-t0)\nst.write(pdf.head(2)) # print two rows to check output.\n</code></pre> <p>We do the same with Bodo:</p> <pre><code>t2 = time.time()\nbdf = initialize_bodo(pq_file_path, date_col='Date/Time')\nt3 = time.time()\nst.subheader('Bodo df')\nst.subheader('Total Compilation and Execution time taken for one op with Bodo:')\nst.subheader(t3-t2)\nst.write(bdf.head(2))\n</code></pre> <p>We can also visualize the data in a histogram showing the pickups by hour:</p> <pre><code>DATE_COLUMN = 'date/time'\nlowercase = lambda x: str(x).lower()\nbdf.rename(lowercase, axis='columns', inplace=True)\nst.subheader('Number of pickups by hour')\nhist_values = np.histogram(bdf[DATE_COLUMN].dt.hour, bins=24, range=(0,24))[0]\nst.bar_chart(hist_values)\n</code></pre>"},{"location":"integrating_bodo/front_end/#runtaxipickup","title":"Running the Taxi Pickup App","text":"<p>Clone the Bodo Examples repository and navigate to the <code>streamlit</code> directory. The directory has the following structure:</p> <pre><code>streamlit\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 app.py\n\u251c\u2500\u2500 config.py\n\u251c\u2500\u2500 environment.yml\n\u251c\u2500\u2500 pd_vs_Bodo.png\n\u251c\u2500\u2500 sample_parquet_file.pq\n</code></pre> <p>We have provided an <code>environment.yml</code> file to create a conda environment with all the required dependencies. The app code is stored in <code>app.py</code>, and some configuration parameters such as the input file, and path to current directory are set in <code>config.py</code>. We have provided a sample parquet file <code>sample_parquet_file.pq</code> to test the app with.</p> <p>Note</p> <p>Please ensure that the path to current directory is set in the <code>config.py</code> file.</p>"},{"location":"integrating_bodo/front_end/#start-the-ipyparallel-controller-and-engines","title":"Start the IPyParallel controller and engines","text":"<p>Create a conda environment from the provided <code>environment.yml</code> file, and activate the conda environment:</p> <pre><code>conda env create -f environment.yml\nconda activate stlbodo\n</code></pre> <p>Append the current directory to your Python Path:</p> <p><pre><code>export PYTHONPATH=\"${PYTHONPATH}:&lt;path_to_directory&gt;\"\n</code></pre> Now you can start ipcontroller: <pre><code>ipcontroller --profile mpi --ip '*'\n</code></pre> Open a new terminal and activate the <code>stlbodo</code> conda environment. You will need to append the current directory to your Python Path again. Use the following command to start a set of MPI engines:</p> <pre><code>mpiexec -n 4 python -m ipyparallel.engine --mpi --profile-dir ~/.ipython/profile_mpi --cluster-id '' --log-level=DEBUG\n</code></pre>"},{"location":"integrating_bodo/front_end/#run-the-streamlit-app","title":"Run the Streamlit App","text":"<p>Open another terminal and activate the <code>stlbodo</code> conda environment. Navigate to the <code>streamlit</code> directory, and then run:</p> <pre><code>streamlit run app.py\n</code></pre> <p>You should now be able to open up the app in a browser window and see the output for yourself. Note that it will take roughly around one and a half minute for the Pandas output to show up, and including compilation time, and following that, less than a minute for for the Bodo output and visualization to show up.</p> <p></p> <p>If you face any issues while running the app, please let us know through our Feedback repository, or join our community slack to communicate directly with Bodo engineers.</p>"},{"location":"integrating_bodo/kubernetes/","title":"Deploying Bodo with Kubernetes","text":"<p>This section demonstrates an example showing how to deploy a Bodo application with Kubernetes.  We deploy Bodo with the Kubeflow MPI-Operator, which enables  resiliency in the case of Node Failure for long running Bodo applications.</p>"},{"location":"integrating_bodo/kubernetes/#setting-up","title":"Setting Up","text":"<p>You need the following to deploy your Bodo application using Kubernetes:</p> <ul> <li> <p>Access to a Kubernetes cluster.</p> <p>For this example, we'll use AWS EKS. See the section below on creating an EKS cluster to see how we set it up.</p> </li> <li> <p>A Docker image containing the Bodo application scripts and their intended Bodo version made available on a Docker registry, so that Kubernetes can pull it.</p> <p>For this example, we created a Docker image using this Dockerfile and uploaded it to Docker Hub. It includes two Bodo applications:</p> <ul> <li><code>pi.py</code>: can be used to validate your setup.</li> <li><code>chicago_crimes.py</code>: can be used to test a use-case with Bodo on a larger dataset.</li> </ul> <p>You can use this as a base image for your own Docker image. If you want to use a private registry, you can follow the instructions here.</p> </li> </ul> <p>Warning</p> <p>Make sure to provide the correct CPU and Memory requests in the Helm or YAML file for your Bodo jobs. If correct values are not provided or the cluster doesn't have sufficient CPU or Memory required for the job, the job will be terminated and worker pods may keep respawning. You can get a good estimate of the CPU and Memory requirements by extrapolation from running the job locally on a smaller dataset.</p>"},{"location":"integrating_bodo/kubernetes/#ekskops","title":"Creating an EKS Cluster using KOPS","text":"<p>Here are the steps create an AWS EKS cluster using KOPS.</p> <ul> <li> <p>Install KOPS on your local machine:</p> <pre><code># Mac\nbrew install kops\n\n# Linux\ncurl -LO https://github.com/kubernetes/kops/releases/download/$(curl -s https://api.github.com/repos/kubernetes/kops/releases/latest | grep tag_name | cut -d '\"' -f 4)/kops-linux-amd64\nchmod +x kops-linux-amd64\nsudo mv kops-linux-amd64 /usr/local/bin/kops\n</code></pre> </li> <li> <p>Create a location to store your cluster configuration:</p> <p>First you need to create an S3 bucket to use as your <code>KOPS_STATE_STORE</code>.</p> <pre><code>export KOPS_CLUSTER_NAME=imesh.k8s.local\nexport KOPS_STATE_STORE=s3://&lt;your S3 bucket name&gt;\n</code></pre> </li> <li> <p>Create your cluster:</p> <p>The following code block creates a cluster of 2 nodes each with 4 cores . You can modify the <code>node-count</code> argument to change the number of instances. To change the number of worker nodes, update <code>node-size</code>. You can deploy the cluster in a different AWS region and availability zone by modifying the <code>zones</code> argument.</p> <pre><code>kops create cluster \\\n--node-count=2 \\\n--node-size=c5.2xlarge \\\n--master-size=c5.large \\\n--zones=us-east-2c \\\n--name=${KOPS_CLUSTER_NAME}\n</code></pre> <p>Tip</p> <p>The parameter <code>master-size</code> refers to the leader that manages K8s but doesn\u2019t do any Bodo computation, so you should keep the instance size small.</p> </li> <li> <p>Finish creating the cluster with the following command.</p> <pre><code>kops update cluster --name $KOPS_CLUSTER_NAME --yes --admin\n</code></pre> <p>Note</p> <p>This might take several minutes to finish.</p> </li> <li> <p>Verify that the cluster setup is finished by running:</p> <pre><code>kops validate cluster\n</code></pre> </li> </ul>"},{"location":"integrating_bodo/kubernetes/#deploying-bodo-on-a-kubernetes-cluster-using-helm","title":"Deploying Bodo on a Kubernetes Cluster Using Helm","text":"<p>You can deploy Bodo applications on a Kubernetes cluster using Helm by following the steps outlined below.</p> <ol> <li> <p>Clone the Bodo examples git repository.</p> <pre><code>git clone https://github.com/Bodo-inc/Bodo-examples.git\n</code></pre> </li> <li> <p>Set up Helm and run your application.</p> <p>First, check if Helm is already installed in your system using <pre><code>helm version\n</code></pre> If it is not installed, then you can use this guide to set up Helm in your system. To run the example Bodo application, navigate to the repository and run the following command <pre><code>helm install &lt;release-name&gt; &lt;helm-directory-path&gt;\n</code></pre> For instance, you can run the following for the <code>chicago_crimes</code> example. <pre><code>helm install bodo-job-chicago-crime Kubernetes/helm\n</code></pre> This command will install the MPI-Job CRD and deploy a MPIJob which runs the Chicago Crimes Example.</p> <p>To run the chart with your job specification, navigate to the Kubernetes/helm folder, edit the <code>values.yaml</code> file, and run the above command.</p> </li> <li> <p>Retrieve the results.</p> <p>When the job finishes running, your launcher pod will change its status to <code>completed</code>, and any information published to stdout can be found in the logs of the launcher pod:</p> <pre><code>PODNAME=$(kubectl get pods -o=name)\nkubectl logs -f ${PODNAME}\n</code></pre> </li> </ol>"},{"location":"integrating_bodo/kubernetes/#teardown","title":"Teardown","text":"<ul> <li>If you want to remove the job, run     <pre><code>helm uninstall &lt;release-name&gt;\n</code></pre></li> <li>If you want to delete the MPI-Operator CRD, run the command     <pre><code>kubectl delete -f Kubernetes/helm/crds/mpi-operator.yaml\n</code></pre></li> </ul>"},{"location":"integrating_bodo/kubernetes/#deploying-bodo-on-a-kubernetes-cluster-manually","title":"Deploying Bodo on a Kubernetes Cluster Manually","text":"<ol> <li> <p>Install MPIJob Custom Resource Definitions(CRD)</p> <p>The most up-to-date installation guide is available at MPI-Operator Github. This example was tested using v0.3.0, as shown below:</p> <pre><code>git clone https://github.com/kubeflow/mpi-operator --branch v0.3.0\ncd mpi-operator\nkubectl apply -f deploy/v2beta1/mpi-operator.yaml\n</code></pre> <p>You can check whether the MPI Job custom resource is installed via:</p> <pre><code>kubectl get crd\n</code></pre> <p>The output should include <code>mpijobs.kubeflow.org</code> like the following:</p> <pre><code>NAME                   CREATED AT\nmpijobs.kubeflow.org   2022-01-03T21:19:10Z\n</code></pre> </li> <li> <p>Run your Bodo application.</p> <ol> <li> <p>Define a kubernetes resource for your Bodo workload, such as the one defined in <code>mpijob.yaml</code>     that runs the Chicago Crimes example. You can modify it based on your cluster configuration:</p> <ol> <li>Update <code>spec.slotsPerWorker</code> with the number of physical cores (not vCPUs) on each node</li> <li>Set <code>spec.mpiReplicaSpecs.Worker.replicas</code> to the number of worker nodes in your cluster.</li> <li>Build the image using the Dockerfile or use <code>bodoaidocker/kube-mpioperator-minimal</code> and replace the image at <code>spec.mpiReplicaSpecs.Launcher.template.spec.containers.image</code> and <code>spec.mpiReplicaSpecs.Worker.template.spec.containers.image</code>.</li> <li>Check the container arguments is referring to the python file you have intended to run <pre><code> args:\n    - mpirun\n    - -n\n    - \"8\"\n- python\n    - /home/mpiuser/chicago_crimes.py\n</code></pre></li> <li>Lastly, make sure <code>-n</code> is equal to <code>spec.mpiReplicaSpecs.Worker.replicas</code> multiplied by <code>spec.slotsPerWorker</code>, i.e. the total number of physical cores on your worker nodes.</li> </ol> </li> <li> <p>Run the example by deploying it in your cluster with <code>kubectl create -f mpijob.yaml</code>. This should add 1 pod to each worker and a launcher pod to your master node.</p> </li> <li>View the generated pods by this deployment with <code>kubectl get pods</code>. You may inspect any logs by looking at the individual pod's logs.</li> </ol> </li> <li> <p>Retrieve the Results.</p> <p>When the job finishes running, your launcher pod will change its status to completed and any stdout information can be found in the logs of the launcher pod:</p> <pre><code>PODNAME=$(kubectl get pods -o=name)\nkubectl logs -f ${PODNAME}\n</code></pre> </li> </ol>"},{"location":"integrating_bodo/kubernetes/#teardown_1","title":"Teardown","text":"<ul> <li>When a job has finished running, you can remove it by running <code>kubectl delete -f mpijob.yaml</code>.</li> <li>If you want to delete the MPI-Operator crd, please follow the steps on the MPI-Operator Github repository.</li> </ul>"},{"location":"integrating_bodo/platform_sdk/","title":"Bodo Platform SDK","text":"<p>Bodo Cloud Platform provides a simple SDK to integrate into your CI/CD pipelines easily. For example, you can use Bodo SDK to orchestrate compute jobs based on your requirements.</p>"},{"location":"integrating_bodo/platform_sdk/#getting-started","title":"Getting started","text":"<p>Install the latest Bodo SDK using:</p> <pre><code>pip install bodosdk\n</code></pre> <p>The first step is to create an API Token in the Bodo Platform for Bodo SDK authentication. Navigate to API Tokens in the Admin Console to generate a token. Copy and save the token's Client ID and Secret Key and use them for BodoClient definition:</p> <pre><code>from bodosdk.models import WorkspaceKeys\nfrom bodosdk.client import get_bodo_client\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\n</code></pre> <p>Alternatively, set <code>BODO_CLIENT_ID</code> and <code>BODO_SECRET_KEY</code> environment variables to avoid requiring keys:</p> <pre><code>from bodosdk.client import get_bodo_client\nclient = get_bodo_client()\n</code></pre> <p>Other bodo client options</p> <ul> <li>print_logs - default False, if enabled all API calls will be printed</li> </ul> <pre><code>from bodosdk.client import get_bodo_client\nfrom bodosdk.models import WorkspaceKeys\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys, print_logs=True)\n</code></pre>"},{"location":"integrating_bodo/platform_sdk/#bodo-platform-batch-jobs","title":"Bodo Platform Batch jobs","text":"<p>See batch jobs for more information on Bodo Batch job concepts.</p>"},{"location":"integrating_bodo/platform_sdk/#create-batch-job-definition","title":"Create batch job definition","text":"<p><code>BodoClient.job.create_batch_job_definition(job_definition: CreateBatchJobDefinition)</code></p> <p>Creates batch job definition in the given workspace.</p> <ul> <li> <p>Example 1: Create batch job definition for a workspace source script</p> <pre><code>from bodosdk.models import WorkspaceKeys, CreateBatchJobDefinition, BatchJobDefinition\nfrom bodosdk.client import get_bodo_client\nfrom bodosdk.models.job import CreateBatchJobDefinition, JobConfig, JobSource, JobSourceType, SourceCodeType, \\\n    WorkspaceDef, RetryStrategy\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\nworkspace_source_def = JobSource(\ntype=JobSourceType.WORKSPACE,\ndefinition=WorkspaceDef(\npath=\"Example-path/batch-job-defs\",\n),\n)\nretry_strategy = RetryStrategy(\nnum_retries=1,\nretry_on_timeout=False,\ndelay_between_retries=2,\n)\njobConfig = JobConfig(\nsource=workspace_source_def,\nsource_code_type=SourceCodeType.PYTHON,\nsourceLocation=\"test.py\",\nargs=None,\nretry_strategy=retry_strategy,\ntimeout=10000,\nenv_vars=None,\n)\ncreateBatchJobDef = CreateBatchJobDefinition(\nname=\"test-job\",\nconfig=jobConfig,\ndescription=\"test-batch-job-description-attempt\",\ncluster_config={\n\"bodoVersion\": \"2023.1.3\",\n\"instance_type\": \"c5.2xlarge\",\n\"workers_quantity\": 2,\n\"accelerated_networking\": False,\n}, )\njobdef = client.job.create_batch_job_definition(createBatchJobDef)\n</code></pre> </li> <li> <p>Example 2: Create batch job definition for a git source script</p> </li> </ul> <pre><code>from bodosdk.models import WorkspaceKeys, CreateBatchJobDefinition, BatchJobDefinition\nfrom bodosdk.client import get_bodo_client\nfrom bodosdk.models.job import CreateBatchJobDefinition, JobConfig, JobSource, JobSourceType, SourceCodeType, \\\n    WorkspaceDef, RetryStrategy\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\ngit_source_def = JobSource(\ntype=JobSourceType.GIT,\ndefinition=GitDef(\nrepo_url='https://github.com/Bodo-inc/Bodo-examples.git',\nusername='XYZ',\ntoken='XYZ'\n),\n)\nretry_strategy = RetryStrategy(\nnum_retries=1,\nretry_on_timeout=False,\ndelay_between_retries=2,\n)\njobConfig = JobConfig(\nsource=git_source_def,\nsource_code_type=SourceCodeType.PYTHON,\nsourceLocation=\"test.py\",\nargs=None,\nretry_strategy=retry_strategy,\ntimeout=10000,\nenv_vars=None,\n)\ncreateBatchJobDef = CreateBatchJobDefinition(\nname=\"test-job\",\nconfig=jobConfig,\ndescription=\"test-batch-job-description-attempt\",\ncluster_config={\n\"bodoVersion\": \"2023.1.3\",\n\"instance_type\": \"c5.2xlarge\",\n\"workers_quantity\": 2,\n\"accelerated_networking\": False,\n}, )\njobdef = client.job.create_batch_job_definition(createBatchJobDef)\n</code></pre> <p></p>"},{"location":"integrating_bodo/platform_sdk/#list-batch-job-definitions","title":"List batch job definitions","text":"<p><code>BodoClient.job.list_batch_job_definitions()</code></p> <p>Lists all batch job definitions in the given workspace.</p> <p>Example:</p> <pre><code>from typing import List\nfrom bodosdk.models import PersonalKeys, WorkspaceKeys, JobConfig, SourceCodeType, RetryStrategy, JobSourceType,\nWorkspaceDef, CreateBatchJobDefinition\nfrom bodosdk.client import get_bodo_client\nfrom bodosdk.models.job import CreateJobRun, JobSource, JobRunStatus, BatchJobDefinitionResponse\nkeys = WorkspaceKeys(\nclient_id=\"XYZ\",\nsecret_key=\"XYZ\"\n)\nclient = get_bodo_client(keys)\njobdefs: List[BatchJobDefinitionResponse] = client.job.list_batch_job_definitions()\n</code></pre> <p></p>"},{"location":"integrating_bodo/platform_sdk/#get-batch-job-definition-by-id","title":"Get batch job definition by id","text":"<p><code>BodoClient.job.get_batch_job_definition(job_definition_id: str)</code></p> <p>Gets specific batch job definition by id.</p> <p>Example:</p> <pre><code>from typing import List\nfrom bodosdk.models import PersonalKeys, WorkspaceKeys, JobConfig, SourceCodeType, RetryStrategy, JobSourceType,\nWorkspaceDef, CreateBatchJobDefinition\nfrom bodosdk.client import get_bodo_client\nfrom bodosdk.models.job import CreateJobRun, JobSource, JobRunStatus, BatchJobDefinitionResponse\nkeys = WorkspaceKeys(\nclient_id=\"XYZ\",\nsecret_key=\"XYZ\"\n)\nclient = get_bodo_client(keys)\njobdef: BatchJobDefinitionResponse = client.job.get_batch_job_definition('04412S5b-300e-42db-84d4-5f22f7506594')\n</code></pre> <p></p>"},{"location":"integrating_bodo/platform_sdk/#get-batch-job-definition-by-name","title":"Get batch job definition by name","text":"<p><code>BodoClient.job.get_batch_job_definition_by_name(name: str)</code></p> <p>Gets specific batch job definition by id.</p> <p>Example:</p> <pre><code>from typing import List\nfrom bodosdk.models import PersonalKeys, WorkspaceKeys, JobConfig, SourceCodeType, RetryStrategy, JobSourceType,\nWorkspaceDef, CreateBatchJobDefinition\nfrom bodosdk.client import get_bodo_client\nfrom bodosdk.models.job import CreateJobRun, JobSource, JobRunStatus, BatchJobDefinitionResponse\nkeys = WorkspaceKeys(\nclient_id=\"XYZ\",\nsecret_key=\"XYZ\"\n)\nclient = get_bodo_client(keys)\njobdef: BatchJobDefinitionResponse = client.job.get_batch_job_definition('04412S5b-300e-42db-84d4-5f22f7506594')\n</code></pre> <p></p>"},{"location":"integrating_bodo/platform_sdk/#remove-batch-job-definition","title":"Remove batch job definition","text":"<p><code>BodoClient.job.remove_batch_job_definition(job_definition_id: str)</code></p> <p>Removes specific batch job definition by id.</p> <p>Example:</p> <pre><code>from bodosdk.models import PersonalKeys, WorkspaceKeys, JobConfig, SourceCodeType, RetryStrategy, JobSourceType,\nWorkspaceDef, CreateBatchJobDefinition\nfrom bodosdk.client import get_bodo_client\nfrom bodosdk.models.job import CreateJobRun, JobSource, JobRunStatus, BatchJobDefinitionResponse\nkeys = WorkspaceKeys(\nclient_id=\"XYZ\",\nsecret_key=\"XYZ\"\n)\nclient = get_bodo_client(keys)\nclient.job.remove_batch_job_definition('04412S5b-300e-42db-84d4-5f22f7506594')\n</code></pre> <p></p>"},{"location":"integrating_bodo/platform_sdk/#submit-a-batch-job-run","title":"Submit a batch job run","text":"<p><code>BodoClient.job.submit_batch_job_run(job_run: CreateJobRun)</code></p> <p>Submits a job run for a given batch job definition.</p> <p>Example:</p> <pre><code>from bodosdk.models import PersonalKeys, WorkspaceKeys, JobConfig, SourceCodeType, RetryStrategy, JobSourceType,\nWorkspaceDef, CreateBatchJobDefinition\nfrom bodosdk.client import get_bodo_client\nfrom bodosdk.models.job import CreateJobRun, JobSource, JobRunStatus, BatchJobDefinitionResponse\nkeys = WorkspaceKeys(\nclient_id=\"XYZ\",\nsecret_key=\"XYZ\"\n)\nclient = get_bodo_client(keys)\nclient.job.submit_batch_job_run(CreateJobRun(batchJobDefinitionUUID='04412S5b-300e-42db-84d4-5f22f7506594',\nclusterUUID='12936Q5z-109d-89yi-23c4-3d91u1219823'))\n</code></pre>"},{"location":"integrating_bodo/platform_sdk/#list-batch-job-runs","title":"List batch job runs","text":"<p><code>BodoClient.job.list_batch_job_runs()</code></p> Parameter Type Description Required <code>batch_job_id</code> <code>List[str]</code> List of Ids of the batch job definitions No <code>status</code> <code>List[JobRunStatus]</code> List of Job Run Statuses No <code>cluster_id</code> <code>List[str]</code> List of Ids of the clusters No <p>Lists all batch job runs in the given workspace filtered by given parameters.</p> <p>Example:</p> <pre><code>from bodosdk.models import PersonalKeys, WorkspaceKeys, JobConfig, SourceCodeType, RetryStrategy, JobSourceType,\nWorkspaceDef, CreateBatchJobDefinition\nfrom bodosdk.client import get_bodo_client\nfrom bodosdk.models.job import CreateJobRun, JobSource, JobRunStatus, BatchJobDefinitionResponse\nkeys = WorkspaceKeys(\nclient_id=\"XYZ\",\nsecret_key=\"XYZ\"\n)\nclient = get_bodo_client(keys)\njobruns = client.job.list_batch_job_runs(statuses=[JobRunStatus.FAILED],\ncluster_ids=['ba62e653-312a-490e-9457-71d7bc096959'])\n</code></pre> <p></p>"},{"location":"integrating_bodo/platform_sdk/#list-batch-job-runs-by-batch-job-name","title":"List batch job runs by batch job name","text":"<p><code>BodoClient.job.list_job_runs_by_batch_job_name()</code></p> Parameter Type Description Required <code>batch_job_names</code> <code>List[str]</code> List of Ids of the batch job definitions No <code>status</code> <code>List[JobRunStatus]</code> List of Job Run Statuses No <code>cluster_id</code> <code>List[str]</code> List of Ids of the clusters No <p>Lists all batch job runs in the given workspace filtered by given parameters.</p> <p>Example:</p> <pre><code>from bodosdk.models import PersonalKeys, WorkspaceKeys, JobConfig, SourceCodeType, RetryStrategy, JobSourceType,\nWorkspaceDef, CreateBatchJobDefinition\nfrom bodosdk.client import get_bodo_client\nfrom bodosdk.models.job import CreateJobRun, JobSource, JobRunStatus, BatchJobDefinitionResponse\nkeys = WorkspaceKeys(\nclient_id=\"XYZ\",\nsecret_key=\"XYZ\"\n)\nclient = get_bodo_client(keys)\njobruns = client.job.list_job_runs_by_batch_job_name(batch_job_names=['production-job-1'],\nstatuses=[JobRunStatus.FAILED],\ncluster_ids=['ba62e653-312a-490e-9457-71d7bc096959'])\n</code></pre> <p></p>"},{"location":"integrating_bodo/platform_sdk/#get-batch-job-run","title":"Get batch job run","text":"<p><code>BodoClient.job.get_batch_job_run(job_run_id: str)</code></p> <p>Gets specific batch job run by id.</p> <p>Example:</p> <pre><code>from bodosdk.models import PersonalKeys, WorkspaceKeys, JobConfig, SourceCodeType, RetryStrategy, JobSourceType,\nWorkspaceDef, CreateBatchJobDefinition\nfrom bodosdk.client import get_bodo_client\nkeys = WorkspaceKeys(\nclient_id=\"XYZ\",\nsecret_key=\"XYZ\"\n)\nclient = get_bodo_client(keys)\njobrun = client.job.get_batch_job_run('04412S5b-300e-42db-84d4-5f22f7506594')\n</code></pre> <p></p>"},{"location":"integrating_bodo/platform_sdk/#cancel-batch-job-run","title":"Cancel batch job run","text":"<p><code>BodoClient.job.cancel_batch_job_run(job_run_id: str)</code></p> <p>Cancels specific batch job run by id.</p> <p>Example:</p> <pre><code>from bodosdk.models import WorkspaceKeys\nfrom bodosdk.client import get_bodo_client\nkeys = WorkspaceKeys(\nclient_id=\"XYZ\",\nsecret_key=\"XYZ\"\n)\nclient = get_bodo_client(keys)\nclient.job.cancel_batch_job_run('04412S5b-300e-42db-84d4-5f22f7506594')\n</code></pre> <p></p>"},{"location":"integrating_bodo/platform_sdk/#cancel-all-job-runs-on-given-cluster-uuids","title":"Cancel all job runs on given cluster UUIDs","text":"<p><code>BodoClient.job.cancel_all_job_runs(cluster_uuid: Union[List[str], List[UUID]])</code></p> <p>Cancels all the job runs for a set of cluster UUIDs provided as a function parameter</p> <p>Example:</p> <pre><code>from bodosdk.models import WorkspaceKeys\nfrom bodosdk.client import get_bodo_client\nkeys = WorkspaceKeys(\nclient_id=\"XYZ\",\nsecret_key=\"XYZ\"\n)\nclient = get_bodo_client(keys)\nclient.job.cancel_all_job_runs(['04412S5b-300e-42db-84d4-5f22f7506594'])\n</code></pre>"},{"location":"integrating_bodo/platform_sdk/#check-batch-job-run-status","title":"Check batch job run status","text":"<p><code>BodoClient.job.check_job_run_status(job_run_id: str)</code></p> <p>Checks status of specific batch job run by id.</p> <p>Example:</p> <pre><code>from bodosdk.models import PersonalKeys, WorkspaceKeys, JobConfig, SourceCodeType, RetryStrategy, JobSourceType,\nWorkspaceDef, CreateBatchJobDefinition\nfrom bodosdk.client import get_bodo_client\nkeys = WorkspaceKeys(\nclient_id=\"XYZ\",\nsecret_key=\"XYZ\"\n)\nclient = get_bodo_client(keys)\nstatus = client.job.check_job_run_status('04412S5b-300e-42db-84d4-5f22f7506594')\n</code></pre> <p></p>"},{"location":"integrating_bodo/platform_sdk/#submit-sql-job-run","title":"Submit SQL job run","text":"<p><code>BodoClient.job.submit_sql_job_run(sql_job_details: CreateSQLJobRun)</code></p> <p>Submits a SQL query as a job run.</p> <p>Note</p> <p>This needs a database catalog to be configured in the workspace.</p> <p>Example:</p> <pre><code>from bodosdk.models import PersonalKeys, WorkspaceKeys, JobConfig, SourceCodeType, RetryStrategy, JobSourceType,\nWorkspaceDef, CreateBatchJobDefinition\nfrom bodosdk.client import get_bodo_client\nkeys = WorkspaceKeys(\nclient_id=\"XYZ\",\nsecret_key=\"XYZ\"\n)\nclient = get_bodo_client(keys)\njobrun = client.job.submit_sql_job_run(CreateSQLJobRun(\nclusterUUID=cluster.uuid,\ncatalog=\"SNOWFLAKE_CATALOG\",\nsqlQueryText=\"SELECT * FROM PUBLIC.TABLE LIMIT 10\"))\n</code></pre> <p></p>"},{"location":"integrating_bodo/platform_sdk/#job-run-waiter","title":"Job Run waiter","text":"<p><code>BodoClient.job.get_job_run_waiter()</code></p> <p>Returns a waiter object that waits until the job run uuid specified finishes. To wait for job run to be finished, invoke the waiter.wait() function, which can take the following parameters.</p> <pre><code>from typing import Callable\ndef wait(\nself,\nuuid,\non_success: Callable = None,\non_failure: Callable = None,\non_timeout: Callable = None,\ncheck_period=10,\ntimeout=None\n):\npass\n</code></pre> <p>By default returns job model if no callbacks is provided. There is option to pass callable objects as following parameters:</p> <ul> <li><code>on_success</code> - will be executed on succes, job object passed as argument</li> <li><code>on_failure</code> - will be executed on failure, job object passed as argument</li> <li><code>on_timeout</code> - will be executed on timeout, job_uuid passed as argument</li> </ul> <p>Other options are:</p> <ul> <li><code>check_period</code> - seconds between status checks</li> <li><code>timeout</code> - threshold in seconds after which Timeout error will be raised, <code>None</code> means no timeout</li> </ul> <p>Example 1. Success/Failure callbacks:</p> <pre><code>from bodosdk.models import WorkspaceKeys, CreateJobRun\nfrom bodosdk.client import get_bodo_client\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\ninput_job = CreateJobRun(clusterUUID='&lt;cluster-uuid&gt;', batchJobDefinitionUUID='&lt;batch-job-definition-uuid&gt;')\njob_run = client.job.submit_batch_job_run(input_job)\nwaiter = client.job.get_job_run_waiter()\ndef success_callback(job):\nprint(\"in success callback\", job.status)\ndef failure_callback(job):\nprint('in failure callback', job.status)\nresult = waiter.wait(job_run.uuid, on_success=success_callback, on_failure=failure_callback)\n</code></pre> <p>Example 2. Timeout callback:</p> <pre><code>from bodosdk.models import WorkspaceKeys, CreateJobRun\nfrom bodosdk.client import get_bodo_client\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\ninput_job = CreateJobRun(clusterUUID='&lt;cluster-uuid&gt;', batchJobDefinitionUUID='&lt;batch-job-definition-uuid&gt;')\njob_run = client.job.submit_batch_job_run(input_job)\nwaiter = client.job.get_job_run_waiter()\ndef timeout_callback(job_uuid):\nprint(f'Waiter timeout for {job_uuid}')\nreturn job_uuid\nresult = waiter.wait(job_run.status, on_timeout=timeout_callback, timeout=1)\n</code></pre>"},{"location":"integrating_bodo/platform_sdk/#cluster-resource","title":"Cluster resource","text":"<p>Module responsible for managing clusters in workspace.</p>"},{"location":"integrating_bodo/platform_sdk/#availability-zone-selection","title":"Availability Zone Selection","text":"<p>When creating a cluster, you can specify the availability zone in which the cluster will be created. However, cluster creation might fail if the availability zone does not have sufficient capacity to create the cluster. Even after the cluster is created, resuming or scaling it might fail if the availability zone does not have sufficient capacity to resume or scale the cluster.</p> <p>Bodo supports an <code>auto_az</code> flag in cluster creation which is by default set to <code>True</code>. When enabled create, scale and resume tasks attempt to automatically select an availability zone with sufficient capacity for said cluster. If you want to disable this behavior, set <code>auto_az</code> to <code>False</code> in the <code>ClusterDefinition</code> object.</p>"},{"location":"integrating_bodo/platform_sdk/#available-instance-types","title":"Available instance types","text":"<p><code>BodoClient.cluster.get_available_instance_types(region:str)</code></p> <p>Returns list of instance types available for given region</p> <pre><code>from bodosdk.models import WorkspaceKeys\nfrom bodosdk.client import get_bodo_client\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\ninstance_types = client.cluster.get_available_instance_types('us-west-2')\n</code></pre>"},{"location":"integrating_bodo/platform_sdk/#available-images","title":"Available images","text":"<p><code>BodoClient.cluster.get_available_images(region:str)</code></p> <p>Returns list of images available for given region</p> <pre><code>from bodosdk.models import WorkspaceKeys\nfrom bodosdk.client import get_bodo_client\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\nimages = client.cluster.get_available_images('us-west-2')\n</code></pre>"},{"location":"integrating_bodo/platform_sdk/#create-cluster","title":"Create cluster","text":"<p><code>BodoClient.cluster.create(cluster_definition: ClusterDefinition)</code></p> <p>Creates a cluster in the workspace based on the instance type, no of workers and whether the instance is a spot instance. The cluster can be configured to have an auto-pause and auto-stop time in minutes to pause and stop the cluster when there is no activity.</p> <p>If you choose to create a cluster with spot instances, please note:</p> <ul> <li>Spot instance clusters are only supported on AWS at this moment.</li> <li>Spot instance has lower cost at the expense of reliability. We recommend to use instance types with lower reclaim rate according to AWS spot instance advisor.</li> <li>Spot instance clusters cannot be paused/resumed. Please use stop/restart instead</li> <li>Auto pause on spot instance clusters is not allowed. Please use auto stop instead</li> </ul> <p>To create a regular cluster:</p> <pre><code>from bodosdk.models import WorkspaceKeys, ClusterDefinition\nfrom bodosdk.client import get_bodo_client\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\ncluster_definition = ClusterDefinition(\nname=\"test\",\ninstance_type=\"c5.large\",\nworkers_quantity=2,\nuse_spot_instance=False, \nauto_pause=100,\nimage_id=\"ami-038d89f8d9470c862\",\nbodo_version=\"2023.7\",\ndescription=\"my desc here\",\nauto_az=False,\n)\nresult_create = client.cluster.create(cluster_definition)\n</code></pre> <p>To create a spot instance cluster: <pre><code>from bodosdk.models import WorkspaceKeys, ClusterDefinition\nfrom bodosdk.client import get_bodo_client\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\ncluster_definition = ClusterDefinition(\nname=\"test-spot\",\ninstance_type=\"c5.large\",\nworkers_quantity=2,\nuse_spot_instance=True, \nauto_stop=100,\nauto_pause=0,\nimage_id=\"ami-038d89f8d9470c862\",\nbodo_version=\"2022.4\",\ndescription=\"my desc here\",\nauto_az=False,\n)\nresult_create = client.cluster.create(cluster_definition)\n</code></pre></p>"},{"location":"integrating_bodo/platform_sdk/#list-clusters","title":"List clusters","text":"<p><code>BodoClient.cluster.list()</code></p> <p>Returns list of all clusters in workspace</p> <pre><code>from bodosdk.models import WorkspaceKeys, ClusterResponse\nfrom bodosdk.client import get_bodo_client\nfrom typing import List\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\nclusters: List[ClusterResponse] = client.cluster.list()\n</code></pre>"},{"location":"integrating_bodo/platform_sdk/#get-cluster","title":"Get cluster","text":"<p><code>BodoClient.cluster.get(cluster_uuid)</code></p> <p>Returns cluser by uuid</p> <pre><code>from bodosdk.models import WorkspaceKeys, ClusterResponse\nfrom bodosdk.client import get_bodo_client\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\nclusters: ClusterResponse = client.cluster.get('&lt;CLUSTER-UUID&gt;')\n</code></pre>"},{"location":"integrating_bodo/platform_sdk/#remove-cluster","title":"Remove cluster","text":"<p><code>BodoClient.client.remove(cluster_uuid, force_remove=False, mark_as_terminated=False)</code></p> <p>Method removing cluster from platform</p> <ul> <li>force_remove: try to remove cluster even if something on cluster is happening</li> <li>mark_as_terminated: mark cluster as removed without removing resources, may be useful if cluster creation failed and   common removing is failing</li> </ul> <pre><code>from bodosdk.models import WorkspaceKeys\nfrom bodosdk.client import get_bodo_client\nfrom typing import List\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\nclient.cluster.remove('&lt;CLUSTER-UUID&gt;')\n</code></pre>"},{"location":"integrating_bodo/platform_sdk/#stop-cluster","title":"Stop cluster","text":"<p><code>BodoClient.cluster.stop(cluster_uuid)</code></p> <p>Stops any cluster activity. You will not incur any charges for stopped cluster. You can restart it again at any time.</p> <pre><code>from bodosdk.models import WorkspaceKeys\nfrom bodosdk.client import get_bodo_client\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\nclient.cluster.stop('&lt;CLUSTER-UUID&gt;')\n</code></pre>"},{"location":"integrating_bodo/platform_sdk/#restart-cluster","title":"Restart cluster","text":"<p><code>BodoClient.cluster.restart(cluster_uuid)</code></p> <p>Restarts cluster. You can restart cluster only if it is stopped.</p> <pre><code>from bodosdk.models import WorkspaceKeys\nfrom bodosdk.client import get_bodo_client\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\nclient.cluster.restart('&lt;CLUSTER-UUID&gt;')\n</code></pre>"},{"location":"integrating_bodo/platform_sdk/#scale-cluster","title":"Scale cluster","text":"<p><code>BodoClient.cluster.scale(scale_cluster: ScaleCluster)</code></p> <p>Changes number of nodes in cluster (AWS only)</p> <pre><code>from bodosdk.models import WorkspaceKeys, ScaleCluster, ClusterResponse\nfrom bodosdk.client import get_bodo_client\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\nNEW_WORKERS_QUANTITY = 3\nscale_cluster = ScaleCluster(\nuuid='&lt;CLUSTER-UUID&gt;',\nworkers_quantity=NEW_WORKERS_QUANTITY\n)\ncluster: ClusterResponse = client.cluster.scale(scale_cluster)\n</code></pre>"},{"location":"integrating_bodo/platform_sdk/#list-jobs-for-a-cluster","title":"List jobs for a cluster","text":"<p><code>BodoClient.cluster.list_jobs(uuid)</code></p> <p>Gets all jobs for cluster</p> <pre><code>from bodosdk.models import WorkspaceKeys, JobResponse\nfrom bodosdk.client import get_bodo_client\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\njobs: List[JobResponse] = client.cluster.list_jobs(uuid)\n</code></pre> <p>Get active jobs for cluster</p> <pre><code>from bodosdk.models import WorkspaceKeys, JobResponse, JobStatus\nfrom bodosdk.client import get_bodo_client\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\njobs: List[JobResponse] = client.cluster.list_jobs(uuid, status=[JobStatus.NEW, JobStatus.INPROGRESS])\n</code></pre>"},{"location":"integrating_bodo/platform_sdk/#modify-cluster-metadata","title":"Modify Cluster metadata","text":"<p><code>BodoClient.cluster.modify(ModifyCluster(...))</code> This function can be used to edit cluster metadata for a given cluster. The properties that we can edit are description, autopause time, autostop time, bodo-version, instance type, instance role, flag for auto availability zone selection and the number of workers. Changing the number of workers will kick off a scaling event on the cluster, which will resume the cluster if it is in paused state. The modify function also supports modifying a subset of property part if the ModifyCluster object like listed in the example below. The cluster modification can only happen when the cluster is in stopped state. The fields that aren't required to be modified are optional and don't necessarily have to be passed during the call to the API. Note: Disabling the <code>auto_az</code> flag without specifying an <code>availability_zone</code> in the same request might result in the cluster failing. So make sure to provide a fallback zone to avoid failures.</p> <pre><code>from bodosdk.models import WorkspaceKeys, ModifyCluster, ClusterResponse\nfrom bodosdk.client import get_bodo_client\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nrole_definition = CreateRoleDefinition(\nname=\"test-sdk-role-creation\",\ndescription=\"testing-instance-role-creation\",\ndata=InstanceRole(role_arn=\"arn:aws:iam::427443013497:role/testing_bucket_with_my_script\")\n)\nresult_create_role: CreateRoleResponse = client.instance_role.create(role_definition)\nclient = get_bodo_client(keys)\nmodify_cluster = ModifyCluster(\nuuid= &lt; cluster - uuid &gt;,\nauto_pause = 60,\nauto_shutdown = 0,\nworkers_quantity = 4,\ndescription = \"using the SDK\",\ninstance_type = \"c5.large\",\ninstance_role_uuid = result_create_role.uuid,\nbodo_version = \"2022.4\",\nauto_az = True,\n)\npartial_modify_cluster = ModifyCluster(\nuuid= &lt; cluster - uuid &gt;,\nautopause = 120,\n)\nnew_cluster: List[ClusterResponse] = client.cluster.modify(modify_cluster)\nnew_cluster_partial: List[ClusterResponse] = client.cluster.modify(partial_modify_cluster)\n</code></pre>"},{"location":"integrating_bodo/platform_sdk/#detach-custom-instance-role","title":"Detach Custom Instance Role","text":"<p>Replace the custom instance role with default role which is automatically created for a cluster</p> <pre><code>detach_custom_instance_role = ModifyCluster(\n    uuid=&lt;cluster-uuid&gt;,\n    instance_role_uuid='default',\n)\nnew_cluster_partial: List[ClusterResponse] = client.cluster.modify(detach_custom_instance_role)\n</code></pre>"},{"location":"integrating_bodo/platform_sdk/#workspace-resource","title":"Workspace resource","text":"<p>Module responsible for managing workspaces in an organization.</p>"},{"location":"integrating_bodo/platform_sdk/#workspace-getting-started","title":"Workspace getting started","text":"<p>In order to work with Workspace, users need to generate Personal Tokens, under Admin Console, from the Bodo Platform Dashboard. Then instantiate a PersonalKeys object with the generated client_id and secret_id. Then Pass in this personal key while instantiating a client object</p> <pre><code>from bodosdk.models import PersonalKeys\npersonal_keys = PersonalKeys(\n    client_id='&lt;CLIENT-ID&gt;',\n    secret_id='&lt;SECRET-ID&gt;',\n)\nclient = get_bodo_organization_client(personal_keys)\n</code></pre>"},{"location":"integrating_bodo/platform_sdk/#create-workspace","title":"Create Workspace","text":"<p><code>BodoClient.workspace.create(workspace_definition: WorkspaceDefinition)</code> Creates a workspace with the specifications passed in through a WorkspaceDefinition object under the user's organization</p> <pre><code>from bodosdk.models import PersonalKeys\nfrom bodosdk.models import WorkspaceDefinition\npersonal_keys = PersonalKeys(\n    client_id='&lt;CLIENT-ID&gt;',\n    secret_id='&lt;SECRET-ID&gt;',\n)\nclient = get_bodo_organization_client(personal_keys)\nwd = WorkspaceDefinition(\n    name=\"&lt;WORSPACE-NAME&gt;\",\n    cloud_config_uuid=\"&lt;CONFIG-UUID&gt;\",\n    region=\"&lt;WORKSPACE-REGION&gt;\"\n)\nresp = client.workspace.create(wd)\n</code></pre>"},{"location":"integrating_bodo/platform_sdk/#list-workspaces","title":"List Workspaces","text":"<p><code>BodoClient.workspace.list()</code> Returns a list of all workspaces defined under this organization. The with_task boolean controls printing out tasks running in the workspaces. The returned list is a list of GetWorkspaceResponse object</p> <pre><code>from bodosdk.models import PersonalKeys\npersonal_keys = PersonalKeys(\n    client_id='&lt;CLIENT-ID&gt;',\n    secret_id='&lt;SECRET-ID&gt;',\n)\nclient = get_bodo_organization_client(personal_keys)\nresp = client.workspace.list(with_tasks=False)\n</code></pre>"},{"location":"integrating_bodo/platform_sdk/#get-workspace","title":"Get Workspace","text":"<p><code>BodoClient.workspace.get(uuid: str)</code> Returns information about the workspace with the given uuid. Returns a GetWorkspaceResponse object with details about the workspace uuid mentioned.</p> <pre><code>from bodosdk.models import PersonalKeys\npersonal_keys = PersonalKeys(\n    client_id='&lt;CLIENT-ID&gt;',\n    secret_id='&lt;SECRET-ID&gt;',\n)\nclient = get_bodo_organization_client(personal_keys)\nresp = client.workspace.get(\"&lt;WORKSPACE-UUID&gt;\")\n</code></pre>"},{"location":"integrating_bodo/platform_sdk/#remove-workspace","title":"Remove Workspace","text":"<p><code>BodoClient.workspace.remove(uuid: str)</code> Removes the workspace with the passed in uuid. The operation is only successful if all resources within the workspaces( jobs, clusters, notebooks) are terminated. Otherwise, returns an error. Returns None if successful</p> <pre><code>from bodosdk.models import PersonalKeys\npersonal_keys = PersonalKeys(\n    client_id='&lt;CLIENT-ID&gt;',\n    secret_id='&lt;SECRET-ID&gt;',\n)\nclient = get_bodo_organization_client(personal_keys)\nresp = client.workspace.remove(\"&lt;WORKSPACE-UUID&gt;\")\n</code></pre>"},{"location":"integrating_bodo/platform_sdk/#assign-user","title":"Assign user","text":"<p><code>BodoClient.workspace.remove(uuid: str)</code> Assign user to workspace.</p> <pre><code>from bodosdk.models import PersonalKeys\npersonal_keys = PersonalKeys(\n    client_id='&lt;CLIENT-ID&gt;',\n    secret_id='&lt;SECRET-ID&gt;',\n)\nclient = get_bodo_organization_client(personal_keys)\nworkspace_uuid = \"&lt;some uuid&gt;\"\nusers: List[UserAssignment] = [\n    UserAssignment(\n        email=\"example@example.com\",\n        skip_email=True,\n        bodo_role=BodoRole.ADMIN\n    )\n]\nclient.workspace.assign_users(workspace_uuid, users):\n</code></pre>"},{"location":"integrating_bodo/platform_sdk/#cloud-config","title":"Cloud Config","text":"<p>Module responsible for creating cloud configurations for organization.</p> <p></p>"},{"location":"integrating_bodo/platform_sdk/#create-config","title":"Create config","text":"<p><code>BodoClient.cloud_config.create(config: Union[CreateAwsCloudConfig, CreateAzureCloudConfig])</code></p> <p>Create cloud configuration for cloud</p> <p>AWS example</p> <pre><code>from bodosdk.models import OrganizationKeys, CreateAwsProviderData, CreateAwsCloudConfig, AwsCloudConfig\nfrom bodosdk.client import get_bodo_client\nkeys = OrganizationKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\nconfig = CreateAwsCloudConfig(\nname='test',\naws_provider_data=CreateAwsProviderData(\ntf_backend_region='us-west-1',\naccess_key_id='xyz',\nsecret_access_key='xyz'\n)\n)\nconfig: AwsCloudConfig = client.cloud_config.create(config)\n</code></pre> <p>Azure example</p> <pre><code>from bodosdk.models import OrganizationKeys, CreateAzureProviderData, CreateAzureCloudConfig, AzureCloudConfig\nfrom bodosdk.client import get_bodo_client\nkeys = OrganizationKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\nconfig = CreateAzureCloudConfig(\nname='test',\nazure_provider_data=CreateAzureProviderData(\ntf_backend_region='eastus',\ntenant_id='xyz',\nsubscription_id='xyz',\nresource_group='MyResourceGroup'\n)\n)\nconfig: AzureCloudConfig = client.cloud_config.create(config)\n</code></pre> <p></p>"},{"location":"integrating_bodo/platform_sdk/#list-configs","title":"List configs","text":"<p><code>BodoClient.cloud_config.list()</code></p> <p>Get list of cloud configs.</p> <pre><code>from bodosdk.models import OrganizationKeys, AzureCloudConfig, AwsCloudConfig\nfrom bodosdk.client import get_bodo_client\nfrom typing import Union, List\nkeys = OrganizationKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\nconfigs: List[Union[AwsCloudConfig, AzureCloudConfig]] = client.cloud_config.list()\n</code></pre> <p></p>"},{"location":"integrating_bodo/platform_sdk/#get-config","title":"Get config","text":"<p><code>BodoClient.cloud_config.get(uuid: Union[str, UUID])</code></p> <p>Get cloud config by uuid.</p> <pre><code>from bodosdk.models import OrganizationKeys, AzureCloudConfig, AwsCloudConfig\nfrom bodosdk.client import get_bodo_client\nfrom typing import Union\nkeys = OrganizationKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\nconfig: Union[AwsCloudConfig, AzureCloudConfig] = client.cloud_config.get('8c32aec5-7181-45cc-9e17-8aff35fd269e')\n</code></pre>"},{"location":"integrating_bodo/platform_sdk/#instance-role","title":"Instance Role Manager","text":"<p>Module responsible for managing AWS roles in workspace.</p> <p></p>"},{"location":"integrating_bodo/platform_sdk/#create-role","title":"Create role","text":"<p><code>BodoClient.instance_role.create()</code></p> <p>Creates an AWS role with the specified role definition with a given AWS role arn.</p> <pre><code>from bodosdk.models import WorkspaceKeys, CreateRoleDefinition, CreateRoleResponse\nfrom bodosdk.client import get_bodo_client\nfrom typing import List\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\nrole_definition = CreateRoleDefinition(\nname=\"test-sdk-role-creation\",\ndescription=\"testing\",\ndata=InstanceRole(role_arn=\"arn:aws:iam::1234567890:role/testing\")\n)\nresult_create: CreateRoleResponse = client.instance_role.create(role_definition)\n</code></pre> <p></p>"},{"location":"integrating_bodo/platform_sdk/#list-roles","title":"List roles","text":"<p><code>BodoClient.instance_role.list()</code></p> <p>Returns list of all roles in workspace</p> <pre><code>from bodosdk.models import WorkspaceKeys, InstanceRoleItem\nfrom bodosdk.client import get_bodo_client\nfrom typing import List\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\nresult_list: List[InstanceRoleItem] = client.instance_role.list()\n</code></pre> <p></p>"},{"location":"integrating_bodo/platform_sdk/#get-role","title":"Get role","text":"<p><code>BodoClient.instance_role.get(cluster_uuid)</code></p> <p>Returns role by uuid</p> <pre><code>from bodosdk.models import WorkspaceKeys, InstanceRoleItem\nfrom bodosdk.client import get_bodo_client\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\nclusters: InstanceRoleItem = client.instance_role.get('&lt;CLUSTER-UUID&gt;')\n</code></pre> <p></p>"},{"location":"integrating_bodo/platform_sdk/#remove-role","title":"Remove role","text":"<p><code>BodoClient.instance_role.remove(cluster_uuid, mark_as_terminated=False)</code></p> <p>Method removing role from a workspace</p> <ul> <li>mark_as_terminated: mark role as removed without removing resources, may be useful if role creation failed and common   removing is failing</li> </ul> <pre><code>from bodosdk.models import WorkspaceKeys\nfrom bodosdk.client import get_bodo_client\nfrom typing import List\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\nclient.instance_role.remove('&lt;ROLE-UUID&gt;')\n</code></pre>"},{"location":"integrating_bodo/platform_sdk/#catalog","title":"Catalog","text":"<p>Module responsible for storing database catalogs</p>"},{"location":"integrating_bodo/platform_sdk/#create-catalog","title":"Create Catalog","text":"<p><code>BodoClient.catalog.create()</code></p> <p>Stores the Database Catalog</p> <pre><code>from bodosdk.models import WorkspaceKeys\nfrom bodosdk.client import get_bodo_client\nfrom bodosdk.models.catalog import CatalogDefinition, SnowflakeConnectionDefinition\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\n# Type Support for Snowflake \nsnowflake_definition = SnowflakeConnectionDefinition(\nhost=\"test.snowflake.com\",\nport=443,\nusername=\"test-username\",\npassword=\"password\",\ndatabase=\"test-db\",\nwarehouse=\"test-wh\",\nrole=\"test-role\"\n)\n# For other databases, need to defined as JSON\nconnection_data = {\n\"host\": \"test.db.com\",\n\"username\": \"test-username\",\n\"password\": \"*****\",\n\"database\": \"test-db\",\n}\ncatalog_definition = CatalogDefinition(\nname=\"catalog-1\",\ndescription=\"catalog description\",\ncatalogType=\"SNOWFLAKE\",  # Currently Support Snowflake \ndata=snowflake_definition\n)\nclient.catalog.create(catalog_definition)\n</code></pre>"},{"location":"integrating_bodo/platform_sdk/#get-catalog-uuid","title":"Get Catalog by UUID","text":"<p><code>BodoClient.catalog.get_catalog()</code></p> <p>Retrieves the Catalog details by UUID</p> <pre><code>from bodosdk.models import WorkspaceKeys\nfrom bodosdk.client import get_bodo_client\nfrom bodosdk.models.catalog import CatalogInfo\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\ncatalog_info: CatalogInfo = client.catalog.get(\"&lt;CATALOG-UUID&gt;\")\n</code></pre>"},{"location":"integrating_bodo/platform_sdk/#get-catalog-name","title":"Get Catalog by Name","text":"<p><code>BodoClient.catalog.get_by_name()</code></p> <p>Retrieves the Catalog details by UUID</p> <pre><code>from bodosdk.models import WorkspaceKeys\nfrom bodosdk.client import get_bodo_client\nfrom bodosdk.models.catalog import CatalogInfo\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\ncatalog_info: CatalogInfo = client.catalog.get_by_name(\"test-catalog\")\n</code></pre> <p></p>"},{"location":"integrating_bodo/platform_sdk/#list-catalogs","title":"List Catalogs","text":"<p><code>BodoClient.catalog.list()</code></p> <p>Retrieves all catalogs in a workspace.</p> <pre><code>from bodosdk.models import WorkspaceKeys\nfrom bodosdk.client import get_bodo_client\nfrom bodosdk.models.catalog import CatalogInfo\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\ncatalog_info: CatalogInfo = client.catalog.list()\n</code></pre>"},{"location":"integrating_bodo/platform_sdk/#update-catalog","title":"Update Catalog","text":"<p><code>BodoClient.catalog.update()</code></p> <p>Updates the Database Catalog</p> <pre><code>from bodosdk.models import WorkspaceKeys\nfrom bodosdk.client import get_bodo_client\nfrom bodosdk.models.catalog import CatalogDefinition, SnowflakeConnectionDefinition\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\n# Type Support for Snowflake \nsnowflake_definition = SnowflakeConnectionDefinition(\nhost=\"update.snowflake.com\",\nport=443,\nusername=\"test-username\",\npassword=\"password\",\ndatabase=\"test-db\",\nwarehouse=\"test-wh\",\nrole=\"test-role\"\n)\nnew_catalog_def = CatalogDefinition(\nname=\"catalog-1\",\ndescription=\"catalog description\",\ncatalogType=\"SNOWFLAKE\",  # Currently Support Snowflake \ndata=snowflake_definition\n)\nclient.catalog.update(\"&lt;CATALOG-UUID&gt;\", new_catalog_def)\n</code></pre>"},{"location":"integrating_bodo/platform_sdk/#remove-catalog-uuid","title":"Remove Catalog by UUID","text":"<p><code>BodoClient.catalog.remove()</code></p> <p>Deletes a Database Catalog by UUID</p> <pre><code>from bodosdk.models import WorkspaceKeys\nfrom bodosdk.client import get_bodo_client\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\nclient.catalog.remove(\"&lt;CATALOG-UUID&gt;\")\n</code></pre>"},{"location":"integrating_bodo/platform_sdk/#remove-all-catalogs","title":"Remove all Catalogs","text":"<p><code>BodoClient.catalog.remove()</code></p> <p>Deletes a Database Catalog by UUID</p> <pre><code>from bodosdk.models import WorkspaceKeys\nfrom bodosdk.client import get_bodo_client\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\nclient.catalog.remove_all()\n</code></pre>"},{"location":"integrating_bodo/platform_sdk/#secret-group","title":"Secret Groups","text":"<p>Module responsible for separating secrets into multiple groups.</p> <p>A default secret group will be created at the time of workspace creation. Users can define custom secret groups using the following functions.</p>"},{"location":"integrating_bodo/platform_sdk/#create-secret-group","title":"Create Secret Group","text":"<p><code>BodoClient.secret_group.create()</code></p> <p>Create a secret group</p> <pre><code>from bodosdk.models import WorkspaceKeys\nfrom bodosdk.client import get_bodo_client\nfrom bodosdk.models.secret_group import SecretGroupDefinition\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\nsecret_group_definition = SecretGroupDefinition(\nname=\"sg-1\",  # Name should be unique to that workspace\ndescription=\"secret group description\",\n)\nclient.secret_group.create(secret_group_definition)\n</code></pre>"},{"location":"integrating_bodo/platform_sdk/#list-secret-groups","title":"List Secret Groups","text":"<p><code>BodoClient.secret_group.list()</code></p> <p>List all the secret groups in a workspace.</p> <pre><code>from bodosdk.models import WorkspaceKeys\nfrom bodosdk.client import get_bodo_client\nfrom bodosdk.models.secret_group import SecretGroupInfo\nfrom typing import List\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\ngroups_list: List[SecretGroupInfo] = client.secret_group.list()\n</code></pre>"},{"location":"integrating_bodo/platform_sdk/#update-secret-group","title":"Update Secret Group","text":"<p><code>BodoClient.secret_group.update()</code></p> <p>Updates the secret group description</p> <pre><code>from bodosdk.models import WorkspaceKeys\nfrom bodosdk.client import get_bodo_client\nfrom bodosdk.models.secret_group import SecretGroupInfo, SecretGroupDefinition\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\nupdate_secret_group_def = SecretGroupDefinition(\nname=\"sg-1\",  # Cannot modify the name in the group\ndescription=\"secret group description\",\n)\ngroups_data: SecretGroupInfo = client.secret_group.update(update_secret_group_def)\n</code></pre>"},{"location":"integrating_bodo/platform_sdk/#delete-secret-group","title":"Delete Secret Group","text":"<p><code>BodoClient.secret_group.remove()</code></p> <p>Removes the secret group.</p> <p>Note: Can only remove if all the secrets in the group are deleted</p> <pre><code>from bodosdk.models import WorkspaceKeys\nfrom bodosdk.client import get_bodo_client\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\nclient.secret_group.remove(\"&lt;secret-group-uuid&gt;\")\n</code></pre>"},{"location":"integrating_bodo/platform_sdk/#secrets","title":"Secrets","text":"<p>Module responsible for creating secrets.</p>"},{"location":"integrating_bodo/platform_sdk/#create-secret","title":"Create Secret","text":"<p><code>BodoClient.secrets.create()</code></p> <p>Create the secret in a secret group.</p> <pre><code>from bodosdk.models import WorkspaceKeys\nfrom bodosdk.client import get_bodo_client\nfrom bodosdk.models.secrets import SecretDefinition\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\nsecret_definition = SecretDefinition(\nname=\"secret-1\",\ndata={\n\"key\": \"value\"\n},\nsecret_group=\"&lt;secret-group-name&gt;\"  # If not defined, defaults to default to secret group\n)\nclient.secrets.create(secret_definition)\n</code></pre>"},{"location":"integrating_bodo/platform_sdk/#get-secret","title":"Get Secrets by UUID","text":"<p><code>BodoClient.secrets.get()</code></p> <p>Retrieves the Secrets by UUID</p> <pre><code>from bodosdk.models import WorkspaceKeys\nfrom bodosdk.client import get_bodo_client\nfrom bodosdk.models.secrets import SecretInfo\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\nsecret_info: SecretInfo = client.secrets.get(\"&lt;secret-uuid&gt;\")\n</code></pre>"},{"location":"integrating_bodo/platform_sdk/#list-secrets","title":"List Secrets by Workspace","text":"<p><code>BodoClient.secrets.list()</code></p> <p>List the secrets in a workspace</p> <pre><code>from bodosdk.models import WorkspaceKeys\nfrom bodosdk.client import get_bodo_client\nfrom bodosdk.models.secrets import SecretInfo\nfrom typing import List\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\nsecrets_info: List[SecretInfo] = client.secrets.list()\n</code></pre>"},{"location":"integrating_bodo/platform_sdk/#list-secrets-by-secret-group","title":"List Secrets by Secret Group","text":"<p><code>BodoClient.secrets.list_by_group()</code></p> <p>List the Secrets by Secret Group</p> <pre><code>from bodosdk.models import WorkspaceKeys\nfrom bodosdk.client import get_bodo_client\nfrom bodosdk.models.secrets import SecretInfo\nfrom typing import List\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\nsecrets_info: List[SecretInfo] = client.secrets.list_by_group(\"&lt;secret-group-name&gt;\")\n</code></pre>"},{"location":"integrating_bodo/platform_sdk/#update-secret","title":"Update Secret","text":"<p><code>BodoClient.secrets.update()</code></p> <p>Updates the secret.</p> <pre><code>from bodosdk.models import WorkspaceKeys\nfrom bodosdk.client import get_bodo_client\nfrom bodosdk.models.secrets import SecretDefinition\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\nupdate_secret_def = SecretDefinition(\ndata={\n\"key\": \"value\"\n}\n)\nclient.secrets.update(\"&lt;secret-uuid&gt;\", update_secret_def)\n</code></pre>"},{"location":"integrating_bodo/platform_sdk/#delete-secret","title":"Delete Secrets by UUID","text":"<p><code>BodoClient.secrets.remove()</code></p> <p>Delete the Secret by UUID</p> <pre><code>from bodosdk.models import WorkspaceKeys\nfrom bodosdk.client import get_bodo_client\nfrom bodosdk.models.secrets import SecretInfo\nkeys = WorkspaceKeys(\nclient_id='XYZ',\nsecret_key='XYZ'\n)\nclient = get_bodo_client(keys)\nsecret_info: SecretInfo = client.secrets.remove(\"&lt;secret-uuid&gt;\")\n</code></pre>"},{"location":"integrating_bodo/spark/","title":"Spark Examples","text":"<p>Bodo offers simplicity and maintainability of Python codes while unlocking orders of magnitude performance improvement. Spark APIs are usually equivalent to simpler Python/Pandas APIs, which are automatically parallelized by Bodo. This page aims to assist spark users with their transition to Bodo. Here, we show the most common data wrangling methods in PySpark and Pandas through brief code examples. We used the COVID-19 World Vaccination Progress dataset that can be downloaded from Kaggle. If you want to execute the code as shown below, make sure that you have Bodo installed. Here is a list of examples. </p>"},{"location":"integrating_bodo/spark/#Environment","title":"Environment Setup","text":"<p>With Bodo: <pre><code>import bodo\nimport pandas as pd\nimport numpy as np \n</code></pre></p> <p>With PySpark: <pre><code>from pyspark.sql import SparkSession\nspark = SparkSession \\\n    .builder \\\n    .appName(\"Migration From Spark\") \\\n    .getOrCreate()\n</code></pre></p>"},{"location":"integrating_bodo/spark/#Load","title":"Load Data","text":"<p>With Bodo:</p> <pre><code>@bodo.jit(distributed = ['df'])\ndef load_data():\ndf = pd.read_csv('country_vaccinations_by_manufacturer.csv')\nreturn df\ndf = load_data()\n</code></pre> <p>With PySpark:</p> <pre><code>data = spark.read.csv('country_vaccinations_by_manufacturer.csv', header = True)\n</code></pre>"},{"location":"integrating_bodo/spark/#Display","title":"Display the Schema of the DataFrame","text":"<p>With Bodo:</p> <pre><code>@bodo.jit(distributed = ['df'])\ndef schema(df):\nprint(df.dtypes)\nschema(df)\n</code></pre> <p>With PySpark:</p> <pre><code>print(data.printSchema())\n</code></pre>"},{"location":"integrating_bodo/spark/#Change","title":"Change Data Types of the DataFrame","text":"<p>With Bodo:</p> <pre><code>    @bodo.jit(distributed = ['df'])\ndef load_data():\ndf = pd.read_csv('country_vaccinations_by_manufacturer.csv', \ndtype = {'location' : 'str', 'vaccine' : 'str',\n'total_vaccinations' : 'Int64'}, \nparse_dates=['date'])\nprint(df.info())\nreturn df\ndf = load_data()\n</code></pre> <p>With PySpark:</p> <pre><code>from pyspark.sql.types import StructField,IntegerType, StringType, DateType, StructType\nnew_schema = [StructField('location', StringType(), True),\nStructField('date', DateType(), True), \nStructField('vaccine', StringType(), True),\nStructField('total_vaccinations', IntegerType(), True)]\ndata = spark.read.csv('country_vaccinations_by_manufacturer.csv', header = True,\nschema = StructType(fields = new_schema))\ndata.printSchema()\n</code></pre>"},{"location":"integrating_bodo/spark/#Display","title":"Display the Head of the DataFrame","text":"<p>With Bodo:</p> <pre><code>@bodo.jit(distributed = ['df'])\ndef head_data(df):\nprint(df.head())\nhead_data(df)\n</code></pre> <p>With PySpark:</p> <pre><code>data.show(5)\ndata.take(5)\n</code></pre>"},{"location":"integrating_bodo/spark/#Select","title":"Select Columns from the DataFrame","text":"<p>With Bodo:</p> <pre><code>@bodo.jit(distributed = ['df', 'df_columns'])\ndef load_data(df):\ndf_columns = df[['location', 'vaccine']]\nreturn df_columns\ndf_columns = load_data(df)\n</code></pre> <p>With PySpark:</p> <pre><code>data_columns = data.select('location', 'vaccine').show()\n</code></pre>"},{"location":"integrating_bodo/spark/#Show","title":"Show the Statistics of the DataFrame","text":"<p>With Bodo:</p> <pre><code>@bodo.jit(distributed = ['df'])\ndef get_describe(df):\nprint(df.describe())\nget_describe(df)\n</code></pre> <p>With Pyspark:</p> <pre><code>data.describe().show()\n</code></pre>"},{"location":"integrating_bodo/spark/#Drop","title":"Drop Duplicate Values","text":"<p>With Bodo:</p> <pre><code>@bodo.jit(distributed = ['df', 'df_cleaned'])\ndef drop(df):\ndf_cleaned = df.drop_duplicates()\nreturn df_cleaned\ndf_cleaned = drop(df)\n</code></pre> <p>With Pyspark:</p> <pre><code>data.dropDuplicates().show()\n</code></pre>"},{"location":"integrating_bodo/spark/#Missing","title":"Missing Values","text":""},{"location":"integrating_bodo/spark/#count-na","title":"Count NA","text":"<p>With Bodo:</p> <pre><code>@bodo.jit(distributed = ['df'])\ndef count_na(df):\nprint(df.isnull().sum())\ncount_na(df)\n</code></pre> <p>With Pyspark:</p> <pre><code>from pyspark.sql.functions import isnan, when, count, col\ndata.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_s.columns]).show()\n</code></pre>"},{"location":"integrating_bodo/spark/#drop-na","title":"Drop NA","text":"<p>With Bodo:</p> <pre><code>@bodo.jit(distributed = ['df', 'df_valid'])\ndef drop_na(df):\ndf_valid = df.dropna(how ='any')\nreturn df_valid\ndf_valid = drop_na(df)\n</code></pre> <p>With Pyspark:</p> <pre><code>data_valid = data.dropna(how='any')\n</code></pre>"},{"location":"integrating_bodo/spark/#replace-na","title":"Replace NA","text":"<p>With Bodo:</p> <pre><code>@bodo.jit(distributed = ['df', 'df_filled'])\ndef replace_na(df):\ndf_filled = df.fillna(0)\nreturn df_filled\ndf_filled = replace_na(df)\n</code></pre> <p>With Pyspark:</p> <pre><code>data_replaced = data.na.fill(value = 0)\n</code></pre>"},{"location":"integrating_bodo/spark/#DateTime","title":"DateTime Manipulation","text":"<p>Convert String to Datetime :</p> <p>With Bodo:</p> <pre><code>@bodo.jit(distributed = ['df'])\ndef convert_date(df):\ndf['record_date'] = pd.to_datetime(df['date'])\nreturn df\ndf = convert_date(df)\n</code></pre> <p>With Pyspark:</p> <pre><code>from pyspark.sql.types import DateType\ndata = data.withColumn(\"record_date\", data[\"date\"].cast(DateType()))\n</code></pre> <p>Extract Day / Month / Year from Datetime :</p> <p>With Bodo:</p> <pre><code>@bodo.jit(distributed = ['df'])\ndef extract_date(df):\nprint(df['record_date'].dt.year)\nextract_date(df)\n</code></pre> <p>With Pyspark:</p> <pre><code>from pyspark.sql.functions import year\ndata.select(year(df_s.record_date)).show()\n</code></pre>"},{"location":"integrating_bodo/spark/#Filter","title":"Filter Data Based on Conditions","text":"<p>With Bodo:</p> <pre><code>@bodo.jit(distributed = ['df', 'df_filtered'])\ndef sort_data(df):\ndf_filtered = df[df.vaccine =='Pfizer/BioNTech']\nreturn df_filtered\ndf_filtered = sort_data(df)\n</code></pre> <p>With Pyspark:</p> <pre><code>data_filtered = data.where(data.vaccine =='Pfizer/BioNTech')\n</code></pre>"},{"location":"integrating_bodo/spark/#Aggregation","title":"Aggregation Functions: (sum, count, mean, max, min, etc)","text":"<p>With Bodo:</p> <pre><code>@bodo.jit(distributed = ['df'])\ndef group_by(df):\nprint(df.groupby('location').agg({'total_vaccinations' : 'sum'}))\ngroup_by(df)\n</code></pre> <p>With Pyspark:</p> <pre><code>data.groupBy('location').agg({'total_vaccinations' : 'sum'}).show()\n</code></pre>"},{"location":"integrating_bodo/spark/#Sort","title":"Sort Data","text":"<p>With Bodo:</p> <pre><code>@bodo.jit(distributed = ['df', 'df_sorted'])\ndef sort_data(df):\ndf_sorted = df.sort_values(by = ['total_vaccinations'], ascending=False)\nreturn df_sorted\ndf_sorted = sort_data(df)\n</code></pre> <p>With Pyspark:</p> <pre><code>from pyspark.sql.types import IntegerType\nfrom pyspark.sql.functions import col\nfrom pyspark.sql.functions import desc \ndata_sorted = data.withColumn(\"total_vaccinations\", col(\"total_vaccinations\") \n.cast(IntegerType())).select(\"total_vaccinations\") \n.sort(desc('total_vaccinations')).show()\n</code></pre>"},{"location":"integrating_bodo/spark/#Rename","title":"Rename Columns","text":"<p>With Bodo:</p> <pre><code>@bodo.jit(distributed = ['df', 'df_renamed'])\ndef rename_column(df):\ndf_renamed = df.rename(columns = {'location' : 'country'}, inplace = True)\nreturn data_renamed\ndf_renamed = rename_column(df)\n</code></pre> <p>With Pyspark:</p> <pre><code>data_renamed = data.withColumnRenamed(\"location\",\"country\").show()\n</code></pre>"},{"location":"integrating_bodo/spark/#Create","title":"Create New Columns","text":"<p>With Bodo:</p> <pre><code>@bodo.jit(distributed = ['df'])\ndef create_column(df):\ndf['doubled'] = 2 * df['total_vaccinations']\nreturn df\ndf = create_column(df)\n</code></pre> <p>With Pyspark:</p> <pre><code>from pyspark.sql.functions import col\ndata = data.withColumn(\"doubled\", 2*col(\"total_vaccinations\")).show()\n</code></pre>"},{"location":"integrating_bodo/spark/#User-Defined","title":"User-Defined Functions","text":"<p>With Bodo:</p> <pre><code>@bodo.jit(distributed = ['df'])\ndef udf(df):\ndf['new_column'] = df['location'].apply(lambda x: x.upper())\nreturn df\ndf = udf(df)\n</code></pre> <p>With Pyspark:</p> <pre><code>from pyspark.sql.functions import udf\nfrom pyspark.sql.types import StringType\npyspark_udf = udf(lambda x: x.upper(), StringType())\ndata = data.withColumn(\"new_column\", pyspark_udf(df_s.location)).show()\n</code></pre>"},{"location":"integrating_bodo/spark/#Create","title":"Create a DataFrame","text":"<p>With Bodo:</p> <pre><code>@bodo.jit()\ndef create():\ndf = pd.DataFrame({'id': [1, 2], 'label': [\"one\", \"two\"]})\nreturn df\ndf = create()\n</code></pre> <p>With Pyspark:</p> <pre><code>data = spark.createDataFrame([(1, \"one\"),(2, \"two\"),],[\"id\", \"label\"])\n</code></pre>"},{"location":"integrating_bodo/spark/#Export","title":"Export the Data","text":"<p>With Bodo:</p> <pre><code>@bodo.jit()\ndef export_data():\ndf = pd.DataFrame({'id': [1, 2], 'label': [\"one\", \"two\"]})\ndf_pandas = df.to_csv('pandas_data.csv')\nreturn df_pandas\nexport_data()\n</code></pre> <p>With Pyspark:</p> <pre><code>df = spark.createDataFrame([(1, \"one\"),(2, \"two\"),],[\"id\", \"label\"])\ndf_spark.write.csv(\"df_spark.csv\", header = True)\n</code></pre>"},{"location":"integrating_bodo/sparkcheatsheet/","title":"PySpark Bodo Cheatsheet","text":"<p>References of PySpark methods and their Python equivalents supported by Bodo.</p>"},{"location":"integrating_bodo/sparkcheatsheet/#pssession","title":"pyspark.sql.SparkSession","text":"<p>The table below is a reference of SparkSession methods and their equivalents in Python, which are supported by Bodo.</p> PySpark Method Python Equivalent <code>pyspark.sql.SparkSession.read.csv</code> - <code>pd.read_csv()</code> <code>pyspark.sql.SparkSession.read.text</code> <code>pd.read_csv(\"file.txt\", sep=\"\\n\", names=[\"value\"], dtype={\"value\": \"str\"})</code> <code>pyspark.sql.SparkSession.read.parquet</code> <code>pd.read_parquet()</code> <code>pyspark.sql.SparkSession.read.json</code> <code>pd.read_json()</code>"},{"location":"integrating_bodo/sparkcheatsheet/#psdataframe","title":"pyspark.sql.DataFrame","text":"<p>The table below is a reference of Spark DataFrame methods and their equivalents in Python, which are supported by Bodo.</p> PySpark Method Python Equivalent <code>pyspark.sql.DataFrame.alias</code> <code>alias = df</code> <code>pyspark.sql.DataFrame.approxQuantile</code> <code>df[['A', 'B', 'C']].quantile(q)</code> <code>pyspark.sql.DataFrame.columns</code> <code>df.columns</code> <code>pyspark.sql.DataFrame.corr</code> <code>df[['A', 'B']].corr()</code> <code>pyspark.sql.DataFrame.count</code> <code>df.count()</code> <code>pyspark.sql.DataFrame.cov</code> <code>df[['A', 'B']].cov()</code> <code>pyspark.sql.DataFrame.crossJoin</code> <code>df1.assign(key=1).merge(df2.assign(key=1), on=\"key\").drop(\"key\", axis=1)</code> <code>pyspark.sql.DataFrame.describe</code> <code>df.describe()</code> <code>pyspark.sql.DataFrame.distinct</code> <code>df.distinct()</code> <code>pyspark.sql.DataFrame.drop</code> <code>df.drop(col, axis=1)</code> <code>pyspark.sql.DataFrame.dropDuplicates</code> <code>df.drop_duplicates()</code> <code>pyspark.sql.DataFrame.drop_duplicates</code> <code>df.drop_duplicates()</code> <code>pyspark.sql.DataFrame.dropna</code> <code>df.dropna()</code> <code>pyspark.sql.DataFrame.fillna</code> <code>df.fillna(value)</code> <code>pyspark.sql.DataFrame.filter</code> <code>df[cond]</code> <code>pyspark.sql.DataFrame.first</code> <code>df.head(1)</code> <code>pyspark.sql.DataFrame.foreach</code> <code>df.apply(f, axis=1)</code> <code>pyspark.sql.DataFrame.groupBy</code> <code>df.groupby(\"col\")</code> <code>pyspark.sql.DataFrame.groupby</code> <code>df.groupby(\"col\")</code> <code>pyspark.sql.DataFrame.head</code> <code>df.head(n)</code> <code>pyspark.sql.DataFrame.intersect</code> <code>pd.merge(df1[['col1', 'col2']].drop_duplicates(), df2[['col1', 'col2']].drop_duplicates(), on =['col1', 'col2'])</code> <code>pyspark.sql.DataFrame.intersectAll</code> <code>pd.merge(df1[['col1', 'col2']], df2[['col1', 'col2']].drop_duplicates(), on =['col1', 'col2'])</code> <code>pyspark.sql.DataFrame.join</code> <code>df1.join(df2)</code> <code>pyspark.sql.DataFrame.orderBy</code> <code>df.sort_values('colname')</code> <code>pyspark.sql.DataFrame.show</code> <code>print(df.head(n))</code> <code>pyspark.sql.DataFrame.sort</code> <code>df.sort_values('colname')</code>"},{"location":"integrating_bodo/sparkcheatsheet/#psfunctions","title":"pyspark.sql.functions","text":"<p>The table below is a reference of Spark SQL functions and their equivalents in Python, which are supported by Bodo.</p> PySpark Function Python Equivalent <code>pyspark.sql.functions.abs</code> <code>df.col.abs()</code> <code>pyspark.sql.functions.acos</code> <code>np.arccos(df.col)</code> <code>pyspark.sql.functions.acosh</code> <code>np.arccosh(df.col)</code> <code>pyspark.sql.functions.add_months</code> <code>df.col + pd.DateOffset(months=num_months)</code> <code>pyspark.sql.functions.approx_count_distinct</code> <code>df.col.nunique()</code> <code>pyspark.sql.functions.array_contains</code> <code>df.col.apply(lambda a, value: value in a, value=value)</code> <code>pyspark.sql.functions.array_distinct</code> <code>df.col.map(lambda x: np.unique(x))</code> <code>pyspark.sql.functions.array_except</code> <code>df[['col1', 'col2']].apply(lambda x: np.setdiff1d(x[0], x[1]), axis=1)</code> <code>pyspark.sql.functions.array_join</code> <code>df.col.apply(lambda x, sep: sep.join(x), sep=sep)</code> <code>pyspark.sql.functions.array_max</code> <code>df.col.map(lambda x: np.nanmax(x))</code> <code>pyspark.sql.functions.array_min</code> <code>df.col.map(lambda x: np.nanmin(x))</code> <code>pyspark.sql.functions.array_position</code> <code>df.col.apply(lambda x, value: np.append(np.where(x == value)[0], -1)[0], value=value)</code> <code>pyspark.sql.functions.array_repeat</code> <code>df.col.apply(lambda x, count: np.repeat(x, count), count=count)</code> <code>pyspark.sql.functions.array_sort</code> <code>df.col.map(lambda x: np.sort(x))</code> <code>pyspark.sql.functions.array_union</code> <code>df[['col1', 'col2']].apply(lambda x: np.union1d(x[0], x[1]), axis=1)</code> <code>pyspark.sql.functions.array_overlap</code> <code>df[['A', 'B']].apply(lambda x: len(np.intersect1d(x[0], x[1])) &gt; 0, axis=1)</code> <code>pyspark.sql.functions.asc</code> <code>df.sort_values('col')</code> <code>pyspark.sql.functions.asc_nulls_first</code> <code>df.sort_values('col', na_position='first')</code> <code>pyspark.sql.functions.asc_nulls_last</code> <code>df.sort_values('col')</code> <code>pyspark.sql.functions.ascii</code> <code>df.col.map(lambda x: ord(x[0]))</code> <code>pyspark.sql.functions.asin</code> <code>np.arcsin(df.col)</code> <code>pyspark.sql.functions.asinh</code> <code>np.arcsinh(df.col)</code> <code>pyspark.sql.functions.atan</code> <code>np.arctan(df.col)</code> <code>pyspark.sql.functions.atanh</code> <code>np.arctanh(df.col)</code> <code>pyspark.sql.functions.atan2</code> <code>df[['col1', 'col2']].apply(lambda x: np.arctan2(x[0], x[1]), axis=1)</code> <code>pyspark.sql.functions.avg</code> <code>df.col.mean()</code> <code>pyspark.sql.functions.bin</code> <code>df.col.map(lambda x: \"{0:b}\".format(x))</code> <code>pyspark.sql.functions.bitwiseNOT</code> <code>np.invert(df.col)</code> <code>pyspark.sql.functions.bround</code> <code>df.col.apply(lambda x, scale: np.round(x, scale), scale=scale)</code> <code>pyspark.sql.functions.cbrt</code> <code>df.col.map(lambda x: np.cbrt(x))</code> <code>pyspark.sql.functions.ceil</code> <code>np.ceil(df.col)</code> <code>pyspark.sql.functions.col</code> <code>df.col</code> <code>pyspark.sql.functions.collect_list</code> <code>df.col.to_numpy()</code> <code>pyspark.sql.functions.collect_set</code> <code>np.unique(df.col.to_numpy())</code> <code>pyspark.sql.functions.column</code> <code>df.col</code> <code>pyspark.sql.functions.corr</code> <code>df[['col1', 'col2']].corr(method = 'pearson')</code> <code>pyspark.sql.functions.cos</code> <code>np.cos(df.col)</code> <code>pyspark.sql.functions.cosh</code> <code>np.cosh(df.col)</code> <code>pyspark.sql.functions.count</code> <code>df.col.count()</code> <code>pyspark.sql.functions.countDistinct</code> <code>df.col.drop_duplicates().count()</code> <code>pyspark.sql.functions.current_date</code> <code>datetime.datetime.now().date()</code> <code>pyspark.sql.functions.current_timestamp</code> <code>datetime.datetime.now()</code> <code>pyspark.sql.functions.date_add</code> <code>df.col + pd.tseries.offsets.DateOffset(num_days)</code> <code>pyspark.sql.functions.date_format</code> <code>df.col.dt.strftime(format_str)</code> <code>pyspark.sql.functions.date_sub</code> <code>df.col - pd.tseries.offsets.DateOffset(num_days)</code> <code>pyspark.sql.functions.datediff</code> <code>(df.col1 - df.col2).dt.days</code> <code>pyspark.sql.functions.dayofmonth</code> <code>df.col.dt.day</code> <code>pyspark.sql.functions.dayofweek</code> <code>df.col.dt.dayofweek</code> <code>pyspark.sql.functions.dayofyear</code> <code>df.col.dt.dayofyear</code> <code>pyspark.sql.functions.degrees</code> <code>np.degrees(df.col)</code> <code>pyspark.sql.functions.desc</code> <code>df.sort_values('col', ascending=False)</code> <code>pyspark.sql.functions.desc_nulls_first</code> <code>df.sort_values('col', ascending=False, na_position='first')</code> <code>pyspark.sql.functions.desc_nulls_last</code> <code>df.sort_values('col', ascending=False)</code> <code>pyspark.sql.functions.exp</code> <code>np.exp(df.col)</code> <code>pyspark.sql.functions.expm1</code> <code>np.exp(df.col) - 1</code> <code>pyspark.sql.functions.factorial</code> <code>df.col.map(lambda x: math.factorial(x))</code> <code>pyspark.sql.functions.filter</code> <code>df.filter()</code> <code>pyspark.sql.functions.floor</code> <code>np.floor(df.col)</code> <code>pyspark.sql.functions.format_number</code> <code>df.col.apply(lambda x,d : (\"{:,.\" + str(d) + \"f}\").format(np.round(x, d)), d=d)</code> <code>pyspark.sql.functions.format_string</code> <code>df.col.apply(lambda x, format_str : format_str.format(x), format_str=format_str)</code> <code>pyspark.sql.functions.from_unixtime</code> <code>df.col.map(lambda x: pd.Timestamp(x, 's')).dt.strftime(format_str)</code> <code>pyspark.sql.functions.greatest</code> <code>df[['col1', 'col2']].apply(lambda x: np.nanmax(x), axis=1)</code> <code>pyspark.sql.functions.hash</code> <code>df.col.map(lambda x: hash(x))</code> <code>pyspark.sql.functions.hour</code> <code>df.col.dt.hour</code> <code>pyspark.sql.functions.hypot</code> <code>df[['col1', 'col2']].apply(lambda x: np.hypot(x[0], x[1]), axis=1)</code> <code>pyspark.sql.functions.initcap</code> <code>df.col.str.title()</code> <code>pyspark.sql.functions.instr</code> <code>df.col.str.find(sub=substr)</code> <code>pyspark.sql.functions.isnan</code> <code>np.isnan(df.col)</code> <code>pyspark.sql.functions.isnull</code> <code>df.col.isna()</code> <code>pyspark.sql.functions.kurtosis</code> <code>df.col.kurtosis()</code> <code>pyspark.sql.functions.last_day</code> <code>df.col + pd.tseries.offsets.MonthEnd()</code> <code>pyspark.sql.functions.least</code> <code>df.min(axis=1)</code> <code>pyspark.sql.functions.locate</code> <code>df.col.str.find(sub=substr, start=start)</code> <code>pyspark.sql.functions.log</code> <code>np.log(df.col) / np.log(base)</code> <code>pyspark.sql.functions.log10</code> <code>np.log10(df.col)</code> <code>pyspark.sql.functions.log1p</code> <code>np.log(df.col) + 1</code> <code>pyspark.sql.functions.log2</code> <code>np.log2(df.col)</code> <code>pyspark.sql.functions.lower</code> <code>df.col.str.lower()</code> <code>pyspark.sql.functions.lpad</code> <code>df.col.str.pad(len, flllchar=char)</code> <code>pyspark.sql.functions.ltrim</code> <code>df.col.str.lstrip()</code> <code>pyspark.sql.functions.max</code> <code>df.col.max()</code> <code>pyspark.sql.functions.mean</code> <code>df.col.mean()</code> <code>pyspark.sql.functions.min</code> <code>df.col.min()</code> <code>pyspark.sql.functions.minute</code> <code>df.col.dt.minute</code> <code>pyspark.sql.functions.monotonically_increasing_id</code> <code>pd.Series(np.arange(len(df)))</code> <code>pyspark.sql.functions.month</code> <code>df.col.dt.month</code> <code>pyspark.sql.functions.nanvl</code> <code>df[['A', 'B']].apply(lambda x: x[0] if not pd.isna(x[0]) else x[1], axis=1)</code> <code>pyspark.sql.functions.overlay</code> <code>df.A.str.slice_replace(start=index, stop=index+len, repl=repl_str)</code> <code>pyspark.sql.functions.pandas_udf</code> <code>df.apply(f)</code> or <code>df.col.map(f)</code> <code>pyspark.sql.functions.pow</code> <code>np.power(df.col1, df.col2)</code> <code>pyspark.sql.functions.quarter</code> <code>df.col.dt.quarter</code> <code>pyspark.sql.functions.radians</code> <code>np.radians(df.col)</code> <code>pyspark.sql.functions.rand</code> <code>pd.Series(np.random.rand(1, num_cols))</code> <code>pyspark.sql.functions.randn</code> <code>pd.Series(np.random.randn(num_cols))</code> <code>pyspark.sql.functions.regexp_replace</code> <code>df.col.str.replace(pattern, repl_string)</code> <code>pyspark.sql.functions.repeat</code> <code>df.col.str.repeat(count)</code> <code>pyspark.sql.functions.reverse</code> <code>df.col.map(lambda x: x[::-1])</code> <code>pyspark.sql.functions.rint</code> <code>df.col.map(lambda x: int(np.round(x, 0)))</code> <code>pyspark.sql.functions.round</code> <code>df.col.apply(lambda x, decimal_places: np.round(x, decimal_places), decimal_places=decimal_places)</code> <code>pyspark.sql.functions.rpad</code> <code>df.col.str.pad(len, side='right', flllchar=char)</code> <code>pyspark.sql.functions.rtrim</code> <code>df.col.str.rstrip()</code> <code>pyspark.sql.functions.second</code> <code>df.col.dt.second</code> <code>pyspark.sql.functions.sequence</code> <code>df[['col1', 'col2', 'col3']].apply(lambda x: np.arange(x[0], x[1], x[2]), axis=1)</code> <code>pyspark.sql.functions.shuffle</code> <code>df.col.map(lambda x: np.random.permutation(x))</code> <code>pyspark.sql.functions.signum</code> <code>np.sign(df.col)</code> <code>pyspark.sql.functions.sin</code> <code>np.sin(df.col)</code> <code>pyspark.sql.functions.sinh</code> <code>np.sinh(df.col)</code> <code>pyspark.sql.functions.size</code> <code>df.col.map(lambda x: len(x))</code> <code>pyspark.sql.functions.skewness</code> <code>df.col.skew()</code> <code>pyspark.sql.functions.slice</code> <code>df.col.map(lambda x: x[start : end])</code> <code>pyspark.sql.functions.split</code> <code>df.col.str.split(pat, num_splits)</code> <code>pyspark.sql.functions.sqrt</code> <code>np.sqrt(df.col)</code> <code>pyspark.sql.functions.stddev</code> <code>df.col.std()</code> <code>pyspark.sql.functions.stddev_pop</code> <code>df.col.std(ddof=0)</code> <code>pyspark.sql.functions.stddev_samp</code> <code>df.col.std()</code> <code>pyspark.sql.functions.substring</code> <code>df.col.str.slice(start, start+len)</code> <code>pyspark.sql.functions.substring_index</code> <code>df.col.apply(lambda x, sep, count: sep.join(x.split(sep)[:count]), sep=sep, count=count)</code> <code>pyspark.sql.functions.sum</code> <code>df.col.sum()</code> <code>pyspark.sql.functions.sumDistinct</code> <code>df.col.drop_duplicates().sum()</code> <code>pyspark.sql.functions.tan</code> <code>np.tan(df.col)</code> <code>pyspark.sql.functions.tanh</code> <code>np.tanh(df.col)</code> <code>pyspark.sql.functions.timestamp_seconds</code> <code>pd.to_datetime(\"now\")</code> <code>pyspark.sql.functions.to_date</code> <code>df.col.apply(lambda x, format_str: pd.to_datetime(x, format=format_str).date(), format_str=format_str)</code> <code>pyspark.sql.functions.to_timestamp</code> <code>df.A.apply(lambda x, format_str: pd.to_datetime(x, format=format_str), format_str=format_str)</code> <code>pyspark.sql.functions.translate</code> <code>df.col.str.split(\"\").apply(lambda x: \"\".join(pd.Series(x).replace(to_replace, values).tolist()), to_replace=to_replace, values=values)</code> <code>pyspark.sql.functions.trim</code> <code>df.col.str.strip()</code> <code>pyspark.sql.functions.udf</code> <code>df.apply</code> or <code>df.col.map</code> <code>pyspark.sql.functions.unix_timestamp</code> <code>df.col.apply(lambda x, format_str: (pd.to_datetime(x, format=format_str) - pd.Timestamp(\"1970-01-01\")).total_seconds(), format_str=format_str)</code> <code>pyspark.sql.functions.upper</code> <code>df.col.str.upper()</code> <code>pyspark.sql.functions.var_pop</code> <code>df.col.var(ddof=0)</code> <code>pyspark.sql.functions.var_samp</code> <code>df.col.var()</code> <code>pyspark.sql.functions.variance</code> <code>df.col.var()</code> <code>pyspark.sql.functions.weekofyear</code> <code>df.col.dt.isocalendar().week</code> <code>pyspark.sql.functions.when</code> <code>df.A.apply(lambda a, cond, val, other: val if cond(a) else other, cond=cond, val=val, other=other)</code> <code>pyspark.sql.functions.year</code> <code>df.col.dt.year</code>"},{"location":"integrating_bodo/sparkcheatsheet/#special-cases","title":"Special Cases","text":""},{"location":"integrating_bodo/sparkcheatsheet/#pysparksqlfunctionsconcat","title":"<code>pyspark.sql.functions.concat</code>","text":"<ul> <li><code>pyspark.sql.functions.concat</code><ul> <li>for Arrays : <code>df[['col1', 'col2', 'col3']].apply(lambda x: np.hstack(x), axis=1)</code></li> <li>for Strings : <code>df[['col1', 'col2', 'col3']].apply(lambda x: \"\".join(x), axis=1)</code></li> </ul> </li> </ul>"},{"location":"integrating_bodo/sparkcheatsheet/#pysparksqlfunctionsconv","title":"<code>pyspark.sql.functions.conv</code>","text":"<ul> <li> <p><code>pyspark.sql.functions.conv</code></p> <p>pandas equivalent: </p> <pre><code>base_map = {2: \"{0:b}\", 8: \"{0:o}\", 10: \"{0:d}\", 16: \"{0:x}\"}\nnew_format = base_map[new_base]\ndf.col.apply(lambda x, old_base, new_format: new_format.format(int(x, old_base)), old_base=old_base, new_format=new_format)\n</code></pre> </li> </ul>"},{"location":"integrating_bodo/sparkcheatsheet/#pysparksqlfunctionsdate_trunc","title":"<code>pyspark.sql.functions.date_trunc</code>","text":"<ul> <li> <p><code>pyspark.sql.functions.date_trunc</code> </p> <ul> <li>For frequencies day and below: <code>df.col.dt.floor(freq=trunc_val)</code></li> <li>For month: <code>df.col.map(lambda x: pd.Timestamp(year=x.year, month=x.month, day=1))</code></li> <li>For year: <code>df.col.map(lambda x: pd.Timestamp(year=x.year, month=1, day=1))</code></li> </ul> </li> </ul>"},{"location":"integrating_bodo/sparkcheatsheet/#pysparksqlfunctionsregexp_extract","title":"<code>pyspark.sql.functions.regexp_extract</code>","text":"<ul> <li> <p><code>pyspark.sql.functions.regexp_extract</code></p> <p>Here's a small pandas function equivalent:</p> <pre><code>def f(x, pat):\nres = re.search(pat, x)\nreturn \"\" if res is None else res[0]\ndf.col.apply(f, pat=pat)  \n</code></pre> </li> </ul>"},{"location":"integrating_bodo/sparkcheatsheet/#pysparksqlfunctionsshiftleft","title":"<code>pyspark.sql.functions.shiftLeft</code>","text":"<ul> <li> <p><code>pyspark.sql.functions.shiftLeft</code></p> <ul> <li>If the type is uint64 <code>np.left_shift(df.col.astype(np.int64), numbits).astype(np.uint64))</code></li> <li>Other integer types: <code>np.left_shift(df.col, numbits)</code></li> </ul> </li> </ul>"},{"location":"integrating_bodo/sparkcheatsheet/#pysparksqlfunctionsshiftright","title":"<code>pyspark.sql.functions.shiftRight</code>","text":"<ul> <li> <p><code>pyspark.sql.functions.shiftRight</code></p> <ul> <li>If the type is uint64 use <code>shiftRightUnsigned</code></li> <li>Other integer types: <code>np.right_shift(df.col, numbits)</code></li> </ul> </li> </ul>"},{"location":"integrating_bodo/sparkcheatsheet/#pysparksqlfunctionsshiftrightunsigned","title":"<code>pyspark.sql.functions.shiftRightUnsigned</code>","text":"<ul> <li> <p><code>pyspark.sql.functions.shiftRightUnsigned</code></p> <p>Here's a small pandas function equivalent:</p> <pre><code>def shiftRightUnsigned(col, num_bits):\nbits_minus_1 = max((num_bits - 1), 0)\nmask_bits = (np.int64(1) &lt;&lt; bits_minus_1) - 1\nmask = ~(mask_bits &lt;&lt; (63 - bits_minus_1))\nreturn np.right_shift(col.astype(np.int64), num_bits) &amp; mask).astype(np.uint64)\nshiftRightUnsigned(df.col, numbits)  \n</code></pre> </li> </ul>"},{"location":"integrating_bodo/sparkcheatsheet/#pysparksqlfunctionssort_array","title":"<code>pyspark.sql.functions.sort_array</code>","text":"<ul> <li> <p><code>pyspark.sql.functions.sort_array</code></p> <ul> <li>Ascending:  <code>df.col.map(lambda x: np.sort(x))</code></li> <li>Descending: <code>df.col.map(lambda x: np.sort(x)[::-1])</code></li> </ul> </li> </ul>"},{"location":"integrating_bodo/sparkcheatsheet/#pysparksqlfunctionstrunc","title":"<code>pyspark.sql.functions.trunc</code>","text":"<ul> <li> <p><code>pyspark.sql.functions.trunc</code></p> <pre><code>def f(date, trunc_str):\nif trunc_str == 'year':\nreturn pd.Timestamp(year=date.year, month=1, day=1)\nif trunc_str == 'month':\nreturn pd.Timestamp(year=date.year, month=date.month, day=1)\ndf.A.apply(f, trunc_str=trunc_str)\n</code></pre> </li> </ul>"},{"location":"performance/caching/","title":"Caching","text":"<p>In many situations, Bodo can save the binary resulting from the compilation of a function to disk, to be reused in future runs. This avoids the need to recompile functions the next time that you run your application.</p> <p>Recompiling a function is only necessary when it is called with new input types, and the same applies to caching. In other words, an application can be run multiple times and process different data without having to recompile any code if the data types remain the same (which is the most common situation).</p> <p>Warning</p> <p>Caching works in most (but not all) situations, and is disabled by default. See caching limitations below for more information.</p>"},{"location":"performance/caching/#caching-example","title":"Caching Example","text":"<p>To cache a function, we only need to add the option <code>cache=True</code> to the JIT decorator:</p> <pre><code>import time\nimport pandas as pd\nimport bodo\n@bodo.jit(cache=True)\ndef mean_power_speed():\ndf = pd.read_parquet(\"data/cycling_dataset.pq\")\nreturn df[[\"power\", \"speed\"]].mean()\nt0 = time.time()\nresult = mean_power_speed()\nif bodo.get_rank() == 0:\nprint(result)\nprint(\"Total execution time:\", round(time.time() - t0, 3), \"secs\")\n</code></pre> <p>The first time that the above code runs, Bodo compiles the function and caches it to disk. The code times the whole function call, which includes compilation time the first time the function is run:</p> <p><pre><code>power    102.078421\nspeed      5.656851\ndtype: float64\nTotal execution time: 4.614 secs\n</code></pre> In subsequent runs, it will recover the function from cache and as a result, the execution time will be much faster:</p> <pre><code>power    102.078421\nspeed      5.656851\ndtype: float64\nTotal execution time: 0.518 secs\n</code></pre> <p>Note</p> <p><code>data/cycling_dataset.pq</code> is located in the Bodo tutorial repo.</p>"},{"location":"performance/caching/#cache-location-and-portability","title":"Cache Location and Portability","text":"<p>In most cases, the cache is saved in the <code>__pycache__</code> directory inside the directory where the source files are located. The variable <code>NUMBA_DEBUG_CACHE</code> can be set to <code>1</code> in order to see where exactly the cache is and whether it is being written to or read from.</p> <p>On Jupyter notebooks, the cache directory is called <code>numba_cache</code> and is located in <code>IPython.paths.get_ipython_cache_dir()</code>. See here for more information on these and other alternate cache locations. For example, when running in a notebook:</p> <pre><code>import os\nimport IPython\ncache_dir = IPython.paths.get_ipython_cache_dir() + \"/numba_cache\"\nprint(\"Cache files:\")\nos.listdir(cache_dir)\n</code></pre> <pre><code>Cache files:\n['ipython-input-bce41f829e09.mean_power_speed-4444615264.py38.nbi',\n'ipython-input-bce41f829e09.mean_power_speed-4444615264.py38.1.nbc']\n</code></pre> <p>Cached objects work across systems with the same CPU model and CPU features. Therefore, it is safe to share and reuse the contents in the cache directory on a different machine. See here for more information.</p>"},{"location":"performance/caching/#cache-invalidation","title":"Cache Invalidation","text":"<p>The cache is invalidated automatically when the corresponding source code is modified. One way to observe this behavior is to modify the above example after it has been cached a first time, by changing the name of the variable <code>df</code>. The next time that we run the code, Bodo will determine that the source code has been modified, invalidate the cache and recompile the function.</p> <p>Warning</p> <p>It is sometimes necessary to clear the cache manually (see caching limitations below). To clear the cache, the cache files can simply be removed.</p>"},{"location":"performance/caching/#tips-for-reusing-the-cache","title":"Tips for Reusing the Cache","text":"<p>As explained above, caching is invalidated for a function any time any of the source code in the file changes. If we define a function and call it in the same file, and modify the arguments passed to the function, the cache will be invalidated.</p>"},{"location":"performance/caching/#caching-file-io","title":"Caching File IO","text":"<p>For example: a typical use case is calling an IO function with a different file name.</p> <pre><code>@bodo.jit(cache=True)\ndef io_call(file_name):\n...\nio_call(\"mydata.parquet\")\n</code></pre> <p>The above function would need to be recompiled if the argument to <code>io_call</code> changes from <code>mydata.parquet</code>. By separating into separate files the function call from the function definition, the function definition does not need to be recompiled for each function call with new arguments. The cached IO function will work for a change in file name so long as the file schema is the same. For example, the below code snippet</p> <pre><code>import IO_function from IO_functions\nIO_function(file_name)\n</code></pre> <p>would not need to recompile <code>IO_function</code> each time <code>file_name</code> is modified since <code>IO_function</code> is isolated from that code change.</p>"},{"location":"performance/caching/#caching-notebook-cells","title":"Caching Notebook Cells","text":"<p>For IPython notebooks the function to be cached should be in a separate cell from the function call.</p> <pre><code>@bodo.jit(cache=True)\ndef io_call(file_name):\n...\n</code></pre> <pre><code>io_call(file_name)\nio_call(another_file_name)\n...\n</code></pre> <p>If a cell with a cached function is modified, then its cache is invalidated and the function must be compiled again.</p>"},{"location":"performance/caching/#current-caching-limitations","title":"Current Caching Limitations","text":"<ul> <li>Changes in compiled functions are not seen across files. For     example, if we have a cached Bodo function that calls a cached Bodo     function in a different file, and modify the latter, Bodo will not     update its cache (and therefore run with the old version of the     function).</li> <li>Global variables are treated as compile-time constants. When a     function is compiled, the value of any globals that the function     uses are embedded in the binary at compilation time and remain     constant. If the value of the global changes in the source code     after compilation, the compiled object (and cache) will not rebind     to the new value.</li> </ul>"},{"location":"performance/caching/#troubleshooting","title":"Troubleshooting","text":"<p>During execution, Bodo will print information on caching if the environment variable <code>NUMBA_DEBUG_CACHE</code> is set to <code>1</code>. For example, on first run it will show if the cache is being saved to and where, and on subsequent runs it will show if the compiler is successfully loading from cache.</p> <p>If the compiler reports that it is not able to cache a function, or load a function from cache, please report the issue on our feedback respository.</p>"},{"location":"performance/inlining/","title":"Inlining","text":"<p>Inlining allows the compiler to perform optimizations across functions, at the cost of increased compilation time. Use inlining when you have your code split into multiple Bodo functions and there are important optimizations that need to performed on some functions, that are dependent on the code of other functions. We will explain this with examples below.</p> <p>Danger</p> <p>Inlining should be used sparingly as it can cause increased compilation time. We strongly recommend against inlining functions with 10 or more lines of code.</p> <p>Bodo's compiler translates high-level code inside <code>bodo.jit</code> decorated functions to highly optimized lower level code. It can perform many optimizations on the generated code based on the structure of the code inside the function being compiled.</p> <p>Let's consider the following example where <code>data.pq</code> is a dataset with 1000 columns:</p> <pre><code>@bodo.jit\ndef example():\ndf = pd.read_parquet(\"data.pq\")\nreturn df.groupby(\"A\")[\"B\", \"C\"].sum()\n</code></pre> <p>To execute the query inside the <code>example</code> function, Bodo doesn't need to read all the columns from the file. It only needs three columns (<code>A</code>, <code>B</code> and <code>C</code>), and can save a lot of time and memory by just reading those. When compiling <code>example</code>, Bodo automatically optimizes the <code>read_parquet</code> call to only read the three required columns.</p> <p>Warning</p> <p>If you have separate Bodo functions and their code needs to be optimized jointly, you need to use inlining.</p> <p>Any code that needs to be optimized jointly needs to be compiled as part of the same JIT compilation. If we have the following:</p> <pre><code>@bodo.jit\ndef read_data(fname):\nreturn pd.read_parquet(fname)\n@bodo.jit\ndef query():\ndf = read_data(\"data.pq\")\nreturn df.groupby(\"A\")[\"B\", \"C\"].sum()\n</code></pre> <p>Bodo will compile the functions separately, and won't be able to optimize the <code>read_parquet</code> call because it doesn't know how the return value of <code>read_data</code> is used. To structure the code into different functions and still allow the compiler to do holistic optimizations, you can specify the <code>inline=\"always\"</code> option to the jit decorator to tell the compiler to include that function during compilation of another one.</p> <p>For example:</p> <pre><code>@bodo.jit(inline=\"always\")\ndef read_data(fname):\nreturn pd.read_parquet(fname)\n@bodo.jit\ndef query():\ndf = read_data(\"data.pq\")\nreturn df.groupby(\"A\")[\"B\", \"C\"].sum()\n</code></pre> <p>The option <code>inline=\"always\"</code> in this example tells the compiler to compile and include <code>read_data</code> when it is compiling <code>query</code>.</p>"},{"location":"performance/performance/","title":"Performance Measurement","text":"<p>This page provides tips on measuring performance of Bodo programs. It is important to keep the following in mind when measuring program run time:</p> <ol> <li>Every program has some overhead, so large data sets may be     necessary for useful measurements.</li> <li>Performance can vary from one run to another. Several measurements     are always needed.</li> <li>It is important to use a sequence of tests with increasing input     size, which helps understand the impact of problem size on program     performance.</li> <li>Testing with different data (in terms statistical distribution and     skew) can be useful to see the impact of data skew on performance     and scaling.</li> <li>Simple programs are useful to study performance factors. Complex     programs are impacted by multiple factors and their performance is     harder to understand.</li> <li>Longer computations typically provide more reliable run time     information.</li> </ol>"},{"location":"performance/performance/#measuring-execution-time-of-bodo-functions","title":"Measuring execution time of Bodo functions","text":"<p>Since Bodo-decorated functions are JIT-compiled, the compilation time is non-negligible but it only happens the first time a function is compiled. Compiled functions stay in memory and don't need to be re-compiled, and they can also be cached to disk (see caching) to be reused across different executions.</p> <p>To avoid measuring compilation time, place timers inside the functions. For example:</p> <pre><code>\"\"\"\ncalc_pi.py: computes the value of Pi using Monte-Carlo Integration\n\"\"\"\nimport numpy as np\nimport bodo\nimport time\nn = 2 * 10**8\ndef calc_pi(n):\nt1 = time.time()\nx = 2 * np.random.ranf(n) - 1\ny = 2 * np.random.ranf(n) - 1\npi = 4 * np.sum(x**2 + y**2 &lt; 1) / n\nprint(\"Execution time:\", time.time()-t1, \"\\nresult:\", pi)\nreturn pi\nbodo_calc_pi = bodo.jit(calc_pi)\nprint(\"python:\")\ncalc_pi(n)\nprint(\"\\nbodo:\")\nbodo_calc_pi(n)\n</code></pre> <p>The output of this code is as follows:</p> <pre><code>python:\nExecution time: 5.060443162918091\nresult: 3.14165914\nbodo:\nExecution time: 2.165610068012029\nresult: 3.14154512\n</code></pre> <p>Bodo's parallel speedup can be measured similarly:</p> <pre><code>\"\"\"\ncalc_pi.py: computes the value of Pi using Monte-Carlo Integration\n\"\"\"\nimport numpy as np\nimport bodo\nimport time\n@bodo.jit\ndef calc_pi(n):\nt1 = time.time()\nx = 2 * np.random.ranf(n) - 1\ny = 2 * np.random.ranf(n) - 1\npi = 4 * np.sum(x**2 + y**2 &lt; 1) / n\nprint(\"Execution time:\", time.time()-t1, \"\\nresult:\", pi)\nreturn pi\ncalc_pi(2 * 10**8)\n</code></pre> <p>Launched on eight parallel cores:</p> <pre><code>$ mpiexec -n 8 python calc_pi.py\nExecution time: 0.5736249439651147\nresult: 3.14161474\n</code></pre> <p>And the time it takes can be compared with Python performance. Here, we have a <code>5.06/0.57 ~= 9x</code> speedup (from parallelism and sequential optimizations).</p>"},{"location":"performance/performance/#measuring-sections-inside-bodo-functions","title":"Measuring sections inside Bodo functions","text":"<p>We can add multiple timers inside a function to see how much time each section takes:</p> <pre><code>\"\"\"\ncalc_pi.py: computes the value of Pi using Monte-Carlo Integration\n\"\"\"\nimport numpy as np\nimport bodo\nimport time\nn = 2 * 10**8\ndef calc_pi(n):\nt1 = time.time()\nx = 2 * np.random.ranf(n) - 1\ny = 2 * np.random.ranf(n) - 1\nt2 = time.time()\nprint(\"Initializing x,y takes: \", t2-t1)\npi = 4 * np.sum(x**2 + y**2 &lt; 1) / n\nprint(\"calculation takes:\", time.time()-t2, \"\\nresult:\", pi)\nreturn pi\nbodo_calc_pi = bodo.jit(calc_pi)\nprint(\"python: ------------------\")\ncalc_pi(n)\nprint(\"\\nbodo: ------------------\")\nbodo_calc_pi(n)\n</code></pre> <p>The output is as follows:</p> <pre><code>python: ------------------\nInitializing x,y takes:  3.9832258224487305\ncalculation takes: 1.1460411548614502\nresult: 3.14156454\nbodo: ------------------\nInitializing x,y takes:  3.0611653940286487\ncalculation takes: 0.35728363902308047\nresult: 3.14155538\n</code></pre> <p>Note</p> <p>Note that Bodo execution took longer in the last example than previous ones, since the presence of timers in the middle of computation can inhibit some code optimizations (e.g. code reordering and fusion). Therefore, one should be cautious about adding timers in the middle of computation.</p>"},{"location":"performance/performance/#disable-jit","title":"Disabling JIT Compilation","text":"<p>Sometimes it is convenient to disable JIT compilation without removing the <code>jit</code> decorators in the code, to enable easy performance comparison with regular Python or perform debugging. This can be done by setting the environment variable <code>NUMBA_DISABLE_JIT</code> to <code>1</code>, which makes the jit decorators act as if they perform no operation. In this case, the invocation of decorated functions calls the original Python functions instead of compiled versions.</p>"},{"location":"performance/performance/#load-imbalance","title":"Load Imbalance","text":"<p>Bodo distributes and processes equal amounts of data across cores as much as possible. There are certain cases, however, where depending on the statistical properties of the data and the operation being performed on it, some cores will need to process much more data than others at certain points in the application, which limits the scaling that can be achieved. How much this impacts performance depends on the degree of imbalance and the impact the affected operation has on overall execution time.</p> <p>For example, consider the following operation:</p> <pre><code>df.groupby(\"A\")[\"B\"].nunique()\n</code></pre> <p>Where <code>df</code> has one billion rows, <code>A</code> only has 3 unique values, and we are running this on a cluster with 1000 cores. Although the work can be distributed to a certain extent, the final result for each group of <code>A</code> has to be computed on a single core. Because there are only 3 groups, during computation of the final result there will only be at most three cores active.</p>"},{"location":"performance/performance/#expected-scaling","title":"Expected Scaling","text":"<p>Scaling can be measured as the speedup achieved with n cores compared to running on a single core, that is, the ratio of execution time with 1 core vs n cores.</p> <p>For a fixed input size, the speed up achieved by Bodo with increasing number of cores (also known as strong scaling) depends on a combination of various factors: size of the input data (problem size), properties of the data, compute operations used, and the hardware platform's attributes (such as effective network throughput).</p> <p>For example, the program above can scale almost linearly (e.g. 100x speed up on 100 cores) for large enough problem sizes, since the only communication overhead is parallel summation of the partial sums obtained by <code>np.sum</code> on each processor.</p> <p>On the other hand, some operations such as join and groupby may require communicating significant amounts of data across the network, depending on the characteristics of the data and the exact operation (e.g. <code>groupby.sum</code>, <code>groupby.nunique</code>, <code>groupy.apply</code>, inner vs outer <code>join</code>, etc.), requiring fast cluster interconnection networks to scale to large number of cores.</p> <p>Load imbalance, as described above, can also significantly impair scaling in certain situations.</p>"},{"location":"release_notes/Apr_2020/","title":"Bodo 2020.04 Release (Date: 04/08/2020)","text":""},{"location":"release_notes/Apr_2020/#new-features-and-improvements","title":"New Features and Improvements","text":"<ul> <li>Support for <code>scatterv</code> operation</li> <li>Improved memory management for DataFrame and Series data</li> <li>Initial support for <code>pandas.read_sql()</code></li> <li><code>pandas.read_csv()</code> reads a directory of csv files</li> <li><code>pandas.read_csv()</code> reads from S3, and Hadoop Distributed File     System (HDFS)</li> <li><code>pandas.read_parquet()</code> now reads all integer types (like int16) and     gets nullable information for integer columns from pandas metadata</li> <li><code>pandas.read_parquet()</code> now supports reading columns of list of     string elements</li> <li>avoid type error for unselected columns in Parquet files</li> <li>support <code>pandas.RangeIndex</code> when reading a non-partitioned parquet     dataset</li> <li><code>pandas.Dataframe.to_parquet()</code> to Hadoop Distributed File System     (HDFS)</li> <li><code>pandas.Dataframe.to_parquet()</code> always writes <code>pandas.RangeIndex</code> to     Parquet metadata</li> <li>support <code>pandas.Dataframe.to_parquet()</code> writing datetime64 (default     in Pandas) and <code>datatime.date</code> types to Parquet files</li> <li>support <code>decimal.Decimal</code> type in dataframes and Parquet I/O</li> <li>Support for <code>&amp;</code>, <code>|</code>, and <code>pandas.Series.dt</code> in     <code>pandas.Dataframe.query()</code></li> <li>Support added for groupby <code>last</code> operation</li> <li><code>min</code>, <code>max</code>, and <code>sum</code> support in <code>groupby()</code> for string columns</li> <li>non-constant list of column names as argument support for functions     like <code>groupby()</code></li> <li>MultiIndex support for <code>groupby(...).agg(as_index=False)</code></li> <li><code>pandas.Dataframe.merge()</code> one dataframe on index, and the other on     a column</li> <li>sorting compilation time improvement</li> <li>supports for integer, float, string, string list, <code>datetime.date</code>,     <code>datetime.datetime</code>, and <code>datetime.timedelta</code> types in     <code>pandas.Series.cummin()</code>, <code>pandas.DataFrame.cummin()</code>,     <code>pandas.Series.cummax()</code>, and <code>pandas.DataFrame.cummax()</code></li> <li><code>NA</code>s in <code>datetime.date</code> array</li> <li>better <code>datetime.timedelta</code> support</li> <li>Support for <code>min</code> and <code>max</code> in <code>pandas.Timestamp</code> and     <code>datetime.date</code></li> <li><code>pandas.DataFrame.all()</code> for boolean series</li> <li><code>pandas.Series.astype()</code> to float, int, str</li> <li>Convert string columns to float using <code>astype()</code></li> <li><code>NA</code> support for <code>Series.str.split()</code></li> <li>refactored and improved Dataframe indexing: <code>pandas.loc()</code>,     <code>pandas.Dataframe.iloc()</code>, and <code>pandas.Dataframe.iat()</code></li> <li>better support for <code>pandas.Series.shift()</code>,     <code>pandas.Series.pct_change()</code>, <code>pandas.Dataframe.drop()</code></li> <li>set dataframe column using a scalar</li> <li>support for <code>Index.values</code></li> <li>Addition support for String columns</li> </ul>"},{"location":"release_notes/Apr_2020/#bug-fix","title":"Bug Fix","text":"<ul> <li><code>pandas.join()</code> produce the correct index.</li> <li><code>pandas.groupby()</code> use the latest schema</li> <li><code>groupby(...).cumsum()</code> preserves index</li> <li><code>groupby(...).agg()</code> when passing a dictionary of functions: support     mix of multi-function lists and single functions</li> <li>Fixed Numpy slicing error in a corner case when the slice is     equivalent to array and array size is a constant</li> <li>proper construction of dataframe from slicing Numpy 2D array</li> <li><code>pandas.read_csv</code> reads a dataframe containing only datetime like     columns</li> <li>When using <code>pandas.merge()</code> and <code>pandas.join()</code> integer columns     which can have a missing value <code>NA</code> are returned as     nullable integer array (as opposed to <code>0</code> and     <code>-1</code> before)</li> <li>avoid errors in comparing Pandas and Numpy</li> </ul>"},{"location":"release_notes/April_2021/","title":"Bodo 2021.4 Release (Date: 4/19/2021)","text":"<p>This release includes many new features, bug fixes and usability improvements. Overall, 98 code patches were merged since the last release.</p>"},{"location":"release_notes/April_2021/#new-features-and-improvements","title":"New Features and Improvements","text":"<ul> <li> <p>Bodo is available for Windows as a Conda package (similar to Linux     and macOS)</p> </li> <li> <p>Removed boost library dependency</p> </li> <li> <p>Many improvements to error checking and reporting, including:</p> <ul> <li>Internal compiler errors and stack traces are now avoided more     effectively (clear errors are thrown)</li> <li>Ensure that an error is thrown if user specifies an argument     as distributed but it must be replicated</li> <li>Improvements in error checking for user-defined functions     (UDFs)</li> </ul> </li> <li> <p>Connectors:</p> <ul> <li>Support for writing partitioned Parquet datasets     (<code>df.to_parquet</code> with <code>partition_cols</code> parameter)</li> <li>Support for S3 anonymous access with     <code>storage_options={\"anon\": True}</code> in <code>pd.read_parquet()</code></li> <li>Parquet read: optimized metadata collection for nested parquet     directories (includes hive-partitioned dataset)</li> <li>To reduce Parquet read time, schema validation of multi-file     parquet datasets can be disabled with     <code>bodo.parquet_validate_schema=False</code></li> </ul> </li> <li> <p>Reduced compilation time for Pandas APIs</p> </li> <li> <p>Improved compilation time for <code>df.head/tail</code></p> </li> <li> <p>Support for format spec in f-strings, for example: <code>f\"{a:0.0%}\"</code></p> </li> <li> <p>Support for arrays in <code>bodo.rebalance()</code></p> </li> <li> <p>Pandas coverage:</p> <ul> <li>Support for <code>df.filter</code> for filtering columns</li> <li>Support for <code>indicator=True</code> in <code>pd.merge()</code></li> <li>Support for <code>DataFrame/Series/GroupBy.pipe()</code></li> <li>Support for setting dataframe columns using a 2D array</li> <li>Support for string and nullable arrays (e.g. pd.Int64Dtype) in     <code>DataFrame/Series.shift()</code></li> <li>Support for <code>pandas.tseries.offsets.MonthBegin</code></li> <li><code>Series.where</code> and <code>Series.mask</code>: support for nullable arrays     (e.g. pd.Int64Dtype)</li> </ul> </li> <li> <p>Scikit-learn:</p> <ul> <li>Support for <code>sklearn.ensemble.RandomForestRegressor</code></li> </ul> </li> </ul>"},{"location":"release_notes/April_2022/","title":"Bodo 2022.4 Release (Date: 4/29/2022)","text":"<p>This release includes many new features, usability and performance improvements, and bug fixes. Overall, 60 code patches were merged since the last release.</p>"},{"location":"release_notes/April_2022/#new-features-and-improvements","title":"New Features and Improvements","text":"<ul> <li> <p>Support for Python 3.10 (Conda/pip packages will be available soon)</p> </li> <li> <p>Support for Pandas 1.4 (along with continued support for v1.3)</p> </li> <li> <p>Connectors:</p> <ul> <li>When passing a list of paths to <code>pd.read_parquet</code>, the paths can be a combination     of paths to files and glob strings.</li> <li>Improved performance of <code>pd.read_parquet</code> on remote filesystems when passing     long lists of files.</li> <li><code>DataFrame.to_parquet</code> now supports <code>row_group_size</code> parameter, which can be used to specify the maximum number     of rows in generated row groups. Bodo now has a default row group size of 1M rows, to improve     performance when reading the generated parquet datasets in parallel.</li> <li><code>pd.read_parquet</code>: string columns can be forced to be read with dictionary encoding     by passing a list of column names with <code>_bodo_read_as_dict</code> parameter.</li> <li>Support for S3 anonymous access with <code>storage_options={\"anon\": True}</code>     in <code>pd.read_csv</code> and <code>pd.read_json</code></li> <li>Improved performance and memory utilization of <code>pd.read_csv</code> at compilation and     run time (especially when reading first n rows from remote filesystems such as S3)</li> </ul> </li> <li> <p>Parallel support for <code>pd.date_range</code>: Bodo automatically creates a date range     that is distributed across processes</p> </li> <li> <p>Improved performance of <code>Series.str.startswith/endswith/contains</code> for dictionary-encoded string arrays</p> </li> <li> <p>Reduced compilation time for <code>DataFrame.memory_usage()</code></p> </li> <li> <p>Reduced compilation time when using <code>pandas.read_sql()</code> with wide tables.</p> </li> <li> <p>Pandas:</p> <ul> <li>Support for <code>DataFrame.melt()</code> and <code>pd.melt()</code></li> </ul> </li> </ul>"},{"location":"release_notes/August_2020/","title":"Bodo 2020.08 Release (Date: 08/21/2020)","text":"<p>This release includes many new features, bug fixes and performance improvements. Overall, 112 code patches were merged since the last release.</p>"},{"location":"release_notes/August_2020/#new-features-and-improvements","title":"New Features and Improvements","text":"<ul> <li> <p>Bodo is updated to use the latest versions of Numba, pandas and     Arrow:</p> <ul> <li>Numba 0.51.0</li> <li>pandas 1.1.0</li> <li>Arrow 1.0</li> </ul> </li> <li> <p>Support reading and writing Parquet files with columns where values     are arrays or structs, which can contain other arrays/structs with     arbitrary nesting.</p> </li> <li> <p>S3 I/O: automatically determine the region of the S3 bucket when     reading and writing.</p> </li> <li> <p>Initial support for scikit-learn RandomForestClassifier (fit,     predict and score methods)</p> </li> <li> <p>Support <code>sklearn.metrics.precision_score</code>,     <code>sklearn.metrics.recall_score</code> and <code>sklearn.metrics.f1_score</code>.</p> </li> <li> <p>Improved caching support (caching <code>@bodo.jit</code> functions with     cache=True)</p> </li> <li> <p>Initial support for arrays of map data structures</p> </li> <li> <p>Support <code>count</code> and <code>offset</code> arguments of <code>np.fromfile</code></p> </li> <li> <p>New <code>bodo.rebalance()</code> function for load balancing dataframes     manually if desired</p> </li> <li> <p>Support setting dataframe column as attribute, for example:     <code>df.B = \"AA\"</code></p> </li> <li> <p>Support DataFrame min/max/sum/prod/mean/median functions with     <code>axis=1</code></p> </li> <li> <p>Support <code>df.loc[:,columns]</code> indexing</p> </li> <li> <p><code>pd.concat</code> support for mix of Numpy and nullable integer/bool     arrays</p> </li> <li> <p>Support parallel append to dataframes (concatenation reduction)</p> </li> <li> <p>Support <code>GroupBy.idxmin</code> and <code>GroupBy.idxmax</code></p> </li> <li> <p>Improvements and optimizations in user-defined function (UDF)     handling</p> </li> <li> <p>Basic support for <code>Series.where()</code></p> </li> <li> <p>Support calling bodo.jit functions inside prange loops</p> </li> <li> <p>Support <code>DataFrame.select_dtypes</code> with constant strings</p> </li> <li> <p>Support <code>DataFrame.sample</code></p> </li> <li> <p>Support <code>Series.replace()</code> and <code>df.replace()</code> (scalars and lists)</p> </li> <li> <p>Support for Series.dt methods: <code>total_seconds()</code> and     <code>to_pytimedelta()</code></p> </li> <li> <p>Improved support for Categorical data types</p> </li> <li> <p>Support for <code>pandas.Timestamp.isocalendar()</code></p> </li> <li> <p>Support <code>np.digitize()</code></p> </li> <li> <p>Improved error handling during I/O when input CSV or Parquet file     does not exist</p> </li> <li> <p>Support pd.concat(axis=1) for dataframes</p> </li> <li> <p>Significant improvements in compilation time for dataframes with     large number of columns</p> </li> <li> <p><code>bodo.is_jit_execution()</code> can be used to know if a function is     running with Bodo.</p> </li> </ul>"},{"location":"release_notes/August_2021/","title":"Bodo 2021.8 Release (Date: 8/30/2021)","text":"<p>This release includes many new features, optimizations, bug fixes and usability improvements. Overall, 74 code patches were merged since the last release.</p>"},{"location":"release_notes/August_2021/#new-features-and-improvements","title":"New Features and Improvements","text":"<ul> <li> <p>Bodo is updated to use pandas 1.3 and Arrow 5.0 (latest)</p> </li> <li> <p>Updated <code>bodo.jit</code> flag handling to remove the need for the     <code>distributed</code> flag in most cases. Arguments and return types are now     automatically inferred as distributed in many cases. Automatic     inference can be disabled using the new <code>returns_maybe_distributed</code>     and <code>args_maybe_distributed</code> flags if necessary.</p> </li> <li> <p>Connectors:</p> <ul> <li>Improved <code>pd.read_sql</code> performance on Snowflake by using the     Snowflake connector APIs directly.</li> <li>Improved performance of <code>pd.read_parquet</code> when reading large     partitioned datasets</li> </ul> </li> <li> <p>Performance improvements:</p> <ul> <li>Reduced compilation time for some DataFrame operations</li> <li>General performance improvements in Bodo's execution engine     resulting in better speed and memory efficiency for a wide     range of operations</li> <li>Improved performance of <code>merge</code> and <code>join</code> operations</li> <li>Improved performance and scalability of <code>groupby</code> operations</li> <li>Improved performance of <code>groupby.apply</code></li> <li>Improved performance of <code>groupby.transform</code></li> <li>Significantly optimized <code>Series.str.contains(..., regex=True)</code></li> <li>Improved performance of filtering operations involving string     arrays</li> </ul> </li> <li> <p>Pandas:</p> <ul> <li>Support for passing string function names to <code>Series.apply</code>.     The string can refer to a Series method or a Numpy ufunc.</li> <li>Support for passing string function names to     <code>DataFrame.apply</code>. The string can refer to a DataFrame method.     <code>axis</code> can be provided if the method takes an <code>axis</code> argument.</li> <li>Enhanced support for binary arrays, including within     series/dataframes</li> <li><code>astype()</code> support for casting strings to nullable integers</li> <li>Support for <code>operator.mul</code> between a <code>Timedelta</code> scalar and     integers Series</li> <li>Support for <code>std</code> in <code>groupby.transform</code>.</li> </ul> </li> <li> <p>Scikit-learn:</p> <ul> <li>Support for <code>sklearn.feature_extraction.text.CountVectorizer</code></li> <li>Support for <code>coef_</code> attribute for <code>Ridge</code></li> </ul> </li> </ul> <p>BodoSQL 2021.8beta Release (Date: 8/30/2021)</p> <p>This release adds more SQL coverage, introduces new BodoSQL specific features, and fixes bugs. Overall, 53 code patches were merged since the last release.</p>"},{"location":"release_notes/August_2021/#new-features-and-improvements_1","title":"New Features and Improvements","text":"<ul> <li> <p>Parameterized Queries:</p> <p>Parameterized queries allow replacing scalars with Python variables during runtime execution. This enables caching more complex BodoSQL queries When paired with Bodo jit: a query parameter can change without the need to recompile the query. More information and example usage can be found in our documentation.</p> </li> <li> <p>SQL Coverage:</p> <p>This release added the following additional SQL coverage to BodoSQL. Please refer to our documentation for more details regarding usage.</p> <ul> <li>Support for != and &lt;=operators </li> <li>Support for CAST </li> <li>Support for LEAST </li> <li>Support for [NOT] IN with lists of literals </li> <li>Support for the offset optional argument in queries with LIMIT     (i.e. SELECT A from table LIMIT 1, 4) </li> <li>Initial support for YEAR/MONTH interval literals/scalars.     Currently these are only supported with addition and     subtraction operators and cannot be used as a column type. </li> <li>Support the following string functions: <ul> <li>CHAR (to convert a value to a string)</li> <li>LENGTH </li> </ul> </li> <li>Support for the following Timestamp functions: <ul> <li>ADDDATE</li> <li>SUBDATE</li> <li>TIMESTAMPDIFF</li> <li>WEEKDAY</li> <li>YEARWEEK</li> <li>LAST_DAY</li> </ul> </li> </ul> </li> </ul>"},{"location":"release_notes/August_2022/","title":"Bodo 2022.8 Release (Date: 08/31/2022)","text":""},{"location":"release_notes/August_2022/#new-features-and-improvements","title":"New Features and Improvements","text":"<p>Compilation / Performance improvements:</p> <ul> <li>BodoSQL generated plans are now more optimized to reduce runtime, compile time, and memory usage.</li> <li>Performance improvements to pivot_table by reducing the amount of data being shuffled.</li> <li>BodoSQL <code>CASE</code> statements are now faster to compile.</li> </ul> <p>I/O:</p> <ul> <li>Bodo now uses a new optimized connector to write to Snowflake efficiently in parallel (with standard <code>DataFrame.to_sql()</code> syntax).</li> <li>Support for reading strings columns with dictionary encoding when fetching data from Snowflake.</li> <li>Bodo is now upgraded to use Arrow 8.</li> <li>Bodo can avoid loading any columns with parquet if only the length needs to be computed.</li> </ul> <p>Iceberg:</p> <ul> <li>Support for limit pushdown with data read from Iceberg.</li> </ul> <p>Pandas coverage:</p> <ul> <li>Added support for dictionary-encoded string arrays (that have reduced memory usage and execution time) with <code>pandas.concat</code></li> <li>Support for <code>groupby.sum()</code> with boolean columns.</li> <li>Support for <code>MultiIndex.nbytes</code></li> <li>Support for <code>Series.str.index</code></li> <li>Support for <code>Series.str.rindex</code></li> </ul> <p>BodoSQL:</p> <ul> <li> <p>Update the default null ordering with <code>ORDER BY</code> (nulls first with ASC, nulls last with DESC).</p> </li> <li> <p>Updates aggregation without a <code>GROUP BY</code> to return a replicated result.</p> </li> <li> <p>Improved runtime performance when computing a <code>SUM</code> inside a window function.</p> </li> <li> <p>Added support for the following column functions</p> <ul> <li><code>ACOSH</code></li> <li><code>ASINH</code></li> <li><code>ATANH</code></li> <li><code>BITAND</code></li> <li><code>BITOR</code></li> <li><code>BITXOR</code></li> <li><code>BITNOT</code></li> <li><code>BITSHIFTLEFT</code></li> <li><code>BITSHIFTRIGHT</code></li> <li><code>BOOLAND</code></li> <li><code>BOOLNOT</code></li> <li><code>BOOLOR</code></li> <li><code>BOOLXOR</code></li> <li><code>CBRT</code></li> <li><code>COSH</code></li> <li><code>DATEADD</code></li> <li><code>DECODE</code></li> <li><code>DIV0</code></li> <li><code>EDITDISTANCE</code></li> <li><code>EQUAL_NULL</code></li> <li><code>FACTORIAL</code></li> <li><code>GETBIT</code></li> <li><code>HAVERSINE</code></li> <li><code>INITCAP</code></li> <li><code>REGEXP</code></li> <li><code>REGEXP_COUNT</code></li> <li><code>REGEXP_INSTR</code></li> <li><code>REGEXP_LIKE</code></li> <li><code>REGEXP_REPLACE</code></li> <li><code>REGEXP_SUBSTR</code></li> <li><code>REGR_VALX</code></li> <li><code>REGR_VALY</code></li> <li><code>RLIKE</code></li> <li><code>SINH</code></li> <li><code>SPLIT_PART</code></li> <li><code>SQUARE</code></li> <li><code>STRTOK</code></li> <li><code>TANH</code></li> <li><code>TRANSLATE</code></li> <li><code>WIDTH_BUCKET</code></li> </ul> </li> <li> <p>Added support for binary data with the following functions:</p> <ul> <li><code>LEFT</code></li> <li><code>LEN</code></li> <li><code>LENGTH</code></li> <li><code>LPAD</code></li> <li><code>REVERSE</code></li> <li><code>RIGHT</code></li> <li><code>RPAD</code></li> <li><code>SUBSTR</code></li> <li><code>SUBSTRING</code></li> </ul> </li> <li> <p>Added support for the following window/aggregation functions</p> <ul> <li><code>ANY_VALUE</code></li> <li><code>COUNT_IF</code></li> <li><code>CONDITIONAL_CHANGE_EVENT</code></li> <li><code>CONDITIONAL_TRUE_EVEN</code></li> </ul> </li> </ul>"},{"location":"release_notes/December_2020/","title":"Bodo 2020.12 Release (Date: 12/30/2020)","text":"<p>This release includes many new features, bug fixes and performance improvements. Overall, 60 code patches were merged since the last release.</p>"},{"location":"release_notes/December_2020/#new-features-and-improvements","title":"New Features and Improvements","text":"<ul> <li> <p>Bodo is updated to use Numba 0.52 (latest)</p> </li> <li> <p>Support for reading CSV and Parquet from Azure Data Lake Storage     (ADLS)</p> </li> <li> Improved support for UDFs <ul> <li>More robust user function handling</li> <li>Improved support for date/time data types in UDFs</li> </ul> </li> <li> Improved support for rolling window functions <ul> <li>Support <code>raw</code> argument of <code>apply()</code></li> <li>Support column selection from rolling objects</li> <li>Support for nullable int values</li> </ul> </li> <li> Pandas coverage: <ul> <li>Support for <code>groupby.apply</code></li> <li>Support for groupby rolling functions</li> <li>Improved support for dataframe indexing using df.loc/iloc</li> <li>Improve dtype handling in <code>read_csv</code></li> <li>Support for <code>Series.mask</code></li> <li>Improved robustness for highly skewed string data (e.g. most     of string data is on a few processes due to uneven data     distribution)</li> <li>Support for dataframes with repeated column names</li> <li>Support for <code>datetime.date</code> arrays as Index in <code>pivot_table</code>     and as argument to <code>pd.DatetimeIndex</code></li> <li>Improved error checking in Pandas implementations</li> <li>Unroll constant loops for type stability in more cases</li> </ul> </li> <li> Numpy coverage: <ul> <li>Support for <code>np.hstack</code></li> </ul> </li> <li> Scikit-learn: <ul> <li>Support for <code>sklearn.preprocessing.StandardScaler</code> inside     jit functions.</li> </ul> </li> </ul>"},{"location":"release_notes/December_2021/","title":"Bodo 2021.12 Release (Date: 12/29/2021)","text":"<p>This release includes many new features and usability improvements. Overall, 67 code patches were merged since the last release.</p>"},{"location":"release_notes/December_2021/#new-features-and-improvements","title":"New Features and Improvements","text":"<ul> <li> <p>Significantly upgrades to the Bodo documentation to improve the     developer experience</p> </li> <li> <p>Improvements to documentation and unsupported attribute handling for     Pandas APIs</p> </li> <li> <p>Significant enhancements to objmode user experience and robustness,     such as automatic output data type checking and automatic conversion     if possible</p> </li> <li> <p>Improved support for <code>re</code> package, such as support for <code>re</code> flags,     better support for returning <code>None</code> when necessary, and better     catching of unsupported corner cases</p> </li> <li> <p>Support caching functions that take a string as input and create a     file path using concatenation. For example:</p> <pre><code>@bodo.jit(cache=True)\ndef f(folder):\n  return pd.read_parquet(folder + \"/example.pq\")\n</code></pre> </li> <li> <p>Connectors:</p> <ul> <li>Improved <code>read_parquet</code> runtime performance when reading from S3</li> <li>Decreased compilation time for <code>read_csv</code> on DataFrames with     large number of columns (100)</li> </ul> </li> <li> <p>Improved compilation time for dataframes with large number of     columns (&gt;10,000)</p> </li> <li> <p>Improved NA handling in User Defined Functions with df.apply when     functions are not inlined</p> </li> <li> <p>Support for using <code>logging.RootLogger.info</code> when passing the logger     as an argument to a JIT function</p> </li> <li> <p>Support for <code>datetime.datetime.today</code></p> </li> <li> <p>Simpler <code>bodo.scatterv</code> usage from regular Python. Other ranks are     ignored but not required to have <code>None</code> as their data</p> </li> <li> <p>Improved support for map arrays in various operations</p> </li> <li> <p>Support <code>feature_importances_</code> of XGBoost</p> </li> <li> <p>Support <code>predict_proba</code> and <code>predict_log_proba</code> in Scikit-learn     classifier algorithms</p> </li> <li> <p>Pandas:</p> <ul> <li>Support for Bodo specific argument <code>_bodo_upcast_to_float64</code> in     pd.read_csv. This can be used when all data is numeric but     schema inference cannot accurate predict data types.</li> <li>Support for using <code>DataFrame.to_parquet</code> with \"wide\"     DataFrames with large number of columns</li> <li>Support for storing a <code>DateTimeIndex</code> with     <code>DataFrame.to_parquet</code></li> <li>Support for the 'method' argument in <code>DataFrame.fillna</code> and     <code>Series.fillna</code></li> <li>Support for <code>Series.bfill</code>, <code>Series.ffill</code>, <code>Series.pad</code>, and     <code>Series.backfill</code></li> <li>Support for <code>Series.keys</code></li> <li>Support for <code>Series.infer_objects</code> and <code>DataFrame.infer_objects</code></li> <li>Decreased runtime when calling <code>.astype(\"categorical\")</code> on     Series with large numbers of categories</li> </ul> </li> </ul>"},{"location":"release_notes/Feb_2020/","title":"Bodo 2020.02 Release (Date: 02/14/2020)","text":""},{"location":"release_notes/Feb_2020/#new-features-and-improvements","title":"New Features and Improvements","text":"<ul> <li> <p>Bodo now utilizes the following packages:</p> <pre><code>-   pandas &gt;= 1.0.0\n-   numba 0.48.0\n-   Apache Arrow 0.16.0\n</code></pre> </li> <li> <p>Custom S3 endpoint is supported as well as S3-like object storage     systems such as MinIO</p> </li> <li> <p>Reading and writing of parquet files with S3 is more robust</p> </li> <li> <p>Parquet read now supports reading columns where elements are list of     strings</p> </li> <li> <p>pandas.read_csv() now also accepts a list of column names for the     parse_date parameter</p> </li> <li> <p>pandas groupby.agg() supports list of functions for a column:</p> <pre><code>df = pd.DataFrame(\n    {\"A\": [2, 1, 1, 1, 2, 2, 1], \"B\": [\"a\", \"b\", \"c\", \"c\", \"b\", \"c\", \"a\"]}\n)\ngb = df.groupby(\"B\").agg({\"A\": [\"sum\", \"mean\"]})\n</code></pre> </li> <li> <p>pandas groupby.agg() now supports a tuple of built-in functions:</p> <pre><code>gb = df.groupby(\"B\")[\"A\"].agg((\"sum\", \"median\"))\n</code></pre> </li> <li> <p>User-defined functions can now be used with groupby.agg() and     constant dict:</p> <pre><code>gb = df.groupby(\"B\").agg({\"A\": my_function})\n</code></pre> </li> <li> <p>The compilation time and run time have been improved for pandas     groupby with <code>median</code>, <code>cumsum</code>, and     <code>cumprod</code>.</p> </li> <li> <p>pandas groupby now supports <code>cumsum</code>, <code>max</code>,     <code>min</code>, <code>prod</code>, <code>sum</code> functions     for string columns.</p> </li> <li> <p>pandas groupby.agg() now supports mixing median and nunique with     other functions, and use of multiple \"cumulative\" operations in     the same groupby (example: cumsum, cumprod, etc).</p> </li> <li> <p>Selecting groupby columns using attribute is now possible:</p> <pre><code>df = pd.DataFrame(\n    {\"A\": [2, 1, 1, 1, 2, 2, 1], \"B\": [3, 5, 6, 5, 4, 4, 3]}\n)\ndf.groupby('A').B.sum()\n</code></pre> </li> <li> <p>pandas <code>Series.str.extractall</code>,     <code>Series.all()</code> and <code>Series.any()</code> are     supported</p> </li> <li> <p>Support for returning MultiIndex in groupby operations</p> </li> <li> <p>Various forms of UDFs in df.apply and Series.map are supported</p> </li> <li> <p>Comparison of datetime fields with datetime constants is now     possible</p> </li> <li> <p>Converting <code>date</code> and <code>datetime</code> of Python     <code>datetime</code> module to pandas Timestamp is now supported</p> </li> <li> <p>Conversion to float using float class as dtype for pandas     Series.astype() is now supported:</p> <pre><code>S = pd.Series(['1', '2', '3'])\nS.astype(float)\n</code></pre> </li> </ul>"},{"location":"release_notes/Feb_2020/#bug-fix","title":"Bug Fix","text":"<ul> <li>Fixed a memory leak issue when returning a dataframe from a Bodo     function</li> <li>pandas DataFrame.sort_values() now returns correct output for input     cases that contain NA</li> <li>Groupby.agg: explicit column selection when using constant     dictionary is no longer required</li> <li>Fixed an issue that Bodo always dropped the index in reset_index()</li> </ul>"},{"location":"release_notes/February_2021/","title":"Bodo 2021.2 Release (Date: 2/16/2021)","text":"<p>This release includes many new features, bug fixes and usability improvements. Overall, 70 code patches were merged since the last release.</p>"},{"location":"release_notes/February_2021/#new-features-and-improvements","title":"New Features and Improvements","text":"<ul> <li> <p>Bodo is updated to use pandas 1.2 and Arrow 3.0 (latest)</p> </li> <li> <p>Many improvements to error checking and reporting</p> </li> <li> <p>Several documentation improvements</p> </li> <li> <p>Support tuple return from Bodo functions where elements of the tuple     have a mix of distributed and replicated distributions</p> </li> <li> <p>Improvements in automatic loop unrolling to support column names     generated in loops, e.g.     <code>pd.DataFrame(X, columns=[\"y\"] + [\"x{}\".format(i) for i in range(m)])</code></p> </li> <li> <p>Improvements in caching to cover missing cases</p> </li> <li> <p>Pandas coverage:</p> <ul> <li>Support column indices in <code>read_csv()</code> <code>dtype</code> argument. For     example: <code>df = pd.read_csv(fname, dtype={3: str})</code></li> <li>Support for <code>df.to_string()</code></li> <li>Initial support for <code>pd.Categorical()</code></li> <li>Support <code>Series.min</code> and <code>Series.max</code> for categorical data</li> <li>Support <code>pd.to_datetime()</code> with categorical string input</li> <li>Support <code>pd.Series()</code> constructor without <code>data</code> argument     specified</li> <li>Support <code>dtype=\"str\"</code> in Series constructor</li> <li>Support for <code>Series.to_dict()</code></li> <li>Support for <code>Series.between()</code></li> <li>Support <code>Series.loc[]</code> setitem with boolean array index, such     as <code>S.loc[idx] = val</code> where <code>idx</code> is a boolean array or Series</li> <li>Support dictionary input in <code>Series.map()</code>, such as     <code>S.map({1.0: \"A\", 4.0: \"DD\"})</code></li> <li>Support for <code>pd.TimedeltaIndex</code> min and max</li> <li>Support for <code>pd.tseries.offsets.Week</code></li> </ul> </li> <li> <p>Numpy coverage:</p> <ul> <li>Support <code>axis=1</code> in distributed <code>np.concatenate</code></li> <li>Initial support for <code>np.random.multivariate_normal</code></li> </ul> </li> <li> <p>Scikit-learn:</p> <ul> <li>Add <code>coef_</code> attribute to SGDClassifier model.</li> <li>Add <code>coef_</code> attribute to LinearRegression model.</li> <li>Support for <code>sklearn.preprocessing.LabelEncoder</code> inside jit     functions.</li> <li>Support for <code>sklearn.metrics.r2_score</code> inside jit functions.</li> </ul> </li> </ul>"},{"location":"release_notes/February_2022/","title":"Bodo 2022.2 Release (Date: 2/28/2022)","text":"<p>This release includes many new features and usability improvements. Overall, 82 code patches were merged since the last release.</p>"},{"location":"release_notes/February_2022/#new-features-and-improvements","title":"New Features and Improvements","text":"<ul> <li> <p>Reduced the import time of the Bodo package substantially</p> </li> <li> <p>Bodo is now available with <code>pip</code> on x86 Mac</p> </li> <li> <p>Bodo is upgraded to use Numba 0.55.1 (the latest release)</p> </li> <li> <p>Bodo is upgraded to use scikit-learn v1</p> </li> <li> <p>Bodo now supports MPICH version 3.4</p> </li> <li> <p>Connectors:</p> <ul> <li><code>pd.read_sql</code>: Support and getting start documentation for for Oracle DB     and PostgreSQL.</li> <li><code>pd.read_parquet</code> now supports glob patterns</li> <li>Support for <code>escapechar</code> argument in <code>pd.read_csv</code></li> <li>Decreased compilation time when reading wide schemas with 1000s     of columns usings <code>pd.read_parquet</code>.</li> <li>Optimized runtime of <code>pd.read_parquet</code> with <code>head(0)</code> to skip     any unnecessary schema collection for each parquet file and just     look at the metadata. This optimization is helpful when loading     a DataFrame schema.</li> <li>Support using filter pushdown with a single filter consisting of     <code>Series.isna</code>, <code>Series.isnull</code>, <code>Series.notna</code>, or <code>Series.notnull</code>.</li> <li>Full filter pushdown support with <code>hdfs</code> and <code>gcs</code> using <code>pd.read_parquet</code></li> <li>Improved performance and error handling when using <code>DataFrame.to_sql</code>     with Snowflake.</li> <li>Bodo now prints a warning if the number of Parquet row groups is too small for effective parallel I/O.</li> </ul> </li> <li> <p>Support for using lists and sets as constant global values.</p> </li> <li> <p>Support for distributed global dataframe values</p> </li> <li> <p>Added a compiler optimizations for forcing the columns in a DataFrame     to match a DataFrame with an existing schema via <code>DataFrame.dtypes</code>.     In particular when Bodo encounters code like:</p> <pre><code>@bodo.jit\ndef f(df1, df2):\n    return df1.astype(df2.dtypes)\n</code></pre> <p>Bodo will automatically use the internal Bodo types for all columns in <code>df2</code>. This enables using astypes for conversions that are typically not possible in Pandas because the column has an <code>object</code> dtype. For example, this can be used to convert a column from <code>datetime64[ns]</code> to <code>datetime.date</code> with <code>astype</code>.</p> </li> <li> <p>Improved runtime performance when copying a string data from one array to     another or when computing an array of string lengths.</p> </li> <li> <p>Pandas:</p> <ul> <li>Support for passing multiple columns to <code>values</code> and <code>index</code> with     <code>DataFrame.pivot()</code> and <code>DataFrame.pivot_table()</code></li> <li>Support for using <code>pd.pivot()</code> and <code>pd.pivot_table()</code>. Functionality     is equivalent to <code>DataFrame.pivot()</code> and <code>DataFrame.pivot_table()</code></li> <li>Support for <code>DataFrame.explode()</code></li> <li>Support for <code>DataFrame.where()</code> and <code>DataFrame.mask()</code></li> <li>Support for <code>Series.duplicated()</code> and <code>Index.duplicated()</code>.</li> <li>Support for <code>Series.rename_axis()</code></li> <li>Support for using <code>object</code> in <code>DataFrame.astype</code>. Bodo doesn't     have a generic \"object\" type, so the type of the column remains     the same.</li> </ul> </li> </ul>"},{"location":"release_notes/January_2021/","title":"Bodo 2021.1 Release (Date: 1/26/2021)","text":"<p>This release includes many new features, bug fixes and performance improvements. Overall, 61 code patches were merged since the last release.</p>"},{"location":"release_notes/January_2021/#new-features-and-improvements","title":"New Features and Improvements","text":"<ul> <li> <p>Connectors:</p> <ul> <li>Support filter pushdown when reading partitioned parquet     datasets: at compile time, Bodo detects if filters are applied     to a dataframe after <code>read_parquet</code>, and generates code that     applies those filters at read time so that only the required     parquet files are read.</li> <li>Support for <code>Series.to_csv()</code></li> <li>Supports passing <code>file</code> and <code>dtype</code> arguments of <code>np.fromfile</code>     as kwargs.</li> </ul> </li> <li> <p>Support for f-strings in Bodo jitted functions</p> </li> <li> <p>Support passing Bodo distributed JIT functions to other Bodo JIT     functions</p> </li> <li> <p>Pandas coverage:</p> <ul> <li>Support groupby with <code>pd.NamedAgg()</code></li> <li>Support for <code>groupby.size</code></li> <li>Support for <code>groupby.shift</code></li> <li>Match input row order of pandas in <code>groupby.apply</code> when     applicable</li> <li>Support <code>min_periods</code> in rolling calls</li> <li>Support passing a dictionary of data types to <code>df.astype()</code></li> <li>Support dataframe setitem of multiple columns. For example:     <code>df[[\"A\", \"B\"]] = 1.3</code></li> <li>Support for <code>Index.get_loc()</code></li> <li>Support <code>ddof</code> argument (delta degrees of freedom) of     <code>Series.cov</code></li> <li>Support <code>Series.is_monotonic</code> property</li> <li>Initial support for dictionaries in <code>Series.replace</code></li> <li>Support <code>Series.reset_index(drop=True)</code></li> <li>Support level argument with all levels in <code>reset_index()</code></li> <li>Several documentation improvements</li> </ul> </li> <li> <p>Scikit-learn:</p> <ul> <li>Support for <code>sklearn.model_selection.train_test_split</code> inside     jit functions.</li> <li>Support for <code>sklearn.preprocessing.MinMaxScaler</code> inside jit     functions.</li> </ul> </li> </ul>"},{"location":"release_notes/January_2022/","title":"Bodo 2022.1 Release (Date: 1/31/2022)","text":"<p>This release includes many new features and usability improvements. Overall, 71 code patches were merged since the last release.</p>"},{"location":"release_notes/January_2022/#new-features-and-improvements","title":"New Features and Improvements","text":"<ul> <li> <p>Bodo is now available with <code>pip</code> on both Linux and Windows</p> </li> <li> <p>Bodo is upgraded to use Numba 0.55.0 (the latest release)</p> </li> <li> <p>Bodo can now evaluate JIT functions at compilation time if possible     to extract constant values. This improves user experience by     simplifying type stability requirements. For example, the function     below can be refactored to be type stable easily:</p> <pre><code>@bodo.jit\ndef f(df):\n    df.columns = [f\"m_{c}\" if c not in [\"B\", \"C\"] else c for c in df.columns]\n    return df\n</code></pre> <pre><code>@bodo.jit\ndef g(df_cols):\n    return [f\"m_{c}\" if c not in [\"B\", \"C\"] else c for c in df_cols]\n&gt;\n@bodo.jit\ndef f(df):\n    df.columns = g(df.columns)\n    return df\n</code></pre> </li> <li> <p>Connectors:</p> <ul> <li><code>read_csv</code> now skips hidden files when reading from a directory.</li> <li><code>read_parquet</code> now supports reading a list of files.</li> <li>Improved error handling for both <code>read_csv</code> and <code>read_sql</code></li> </ul> </li> <li> <p>Improved null value handling in user-defined-functions that aren't     inlined.</p> </li> <li> <p>Truncated error messages with DataFrames with large numbers of     columns to improve readability.</p> </li> <li> <p>Improved support for the <code>logging</code> standard library:</p> <ul> <li>Support regular <code>logging.Logger</code> in addition to the     <code>logging.RootLogger</code>.</li> <li>Supports passing a logger as a constant global.</li> <li>Supports the attributes: <code>level</code>, <code>name</code>, <code>propagate</code>,     <code>disabled</code>, and <code>parent</code>.</li> <li>Supports the methods: <code>debug</code>, <code>warning</code>, <code>warn</code>, <code>error</code>,     <code>exception</code>, <code>critical</code>, <code>log</code>, and <code>setLevel</code>.</li> </ul> </li> <li> <p>Improvments to global value handling of the compiler to avoid memory     leaks in corner cases.</p> </li> <li> <p>Pandas:</p> <ul> <li>Support for <code>DataFrame.pivot()</code> and <code>DataFrame.pivot_table()</code>     without requiring a constant list of output columns. Bodo     currently only supports limited operations on output DataFrames     of pivot, so users are recommended to immediately return these     DataFrames to Python before doing any further processing in     Bodo.</li> <li>Support for <code>Index.rename</code></li> <li>Support for <code>Index.is_monotonic</code>,     <code>Index.is_montonic_increasing</code>, and     <code>Index.is_monotonic_decreasing</code></li> <li>Support for <code>Index.notna</code> and <code>Index.notnull</code></li> <li>Support for <code>Index.drop_duplicates</code></li> <li>Support for <code>groupby.min</code>, <code>groupby.max</code>, <code>groupby.first</code>, and     <code>groupby.last</code> on DataFrames with Categorical columns</li> <li>Support for column slice assignment with <code>df.iloc</code> (e.g.     <code>df.iloc[0,:] = 0</code>)</li> <li>Support for <code>Series.first</code>, <code>Series.last</code>, <code>DataFrame.first</code>,     and <code>DataFrame.last</code></li> </ul> </li> </ul>"},{"location":"release_notes/January_2023/","title":"Bodo 2023.1 Release (Date: 01/06/2023)","text":""},{"location":"release_notes/January_2023/#new-features-and-improvements","title":"New Features and Improvements","text":"<p>Bodo:</p> <ul> <li>Added support for returning timezone aware timestamp scalars with DataFrame attributes iat and iloc.</li> <li>Support for comparison operators between timezone aware Timestamp values in Series, array, and scalars.</li> <li>Improved the performance of coalesce for string columns.</li> <li>Improved performance on dictionary encoded columns for coalesce and support for dictionary encoded output.</li> <li>Support for tz-aware data in pd.concat.</li> <li>pd.merge now supports cross join type (how=\u201dcross\u201d). Cross joins in BodoSQL are now significantly faster and more scalable.</li> <li>Supported passing timezone to pd.Timestamp.now().</li> <li>Support for comparison operators between Timestamps (both timezone aware and timezone naive) and datetime.date values in Series, array, and scalars.</li> </ul> <p>BodoSQL:</p> <p>Added support for the following functions:</p> <ul> <li>CURRENT_TIMESTAMP</li> <li>DATE_PART</li> <li>GETDATE</li> <li>DATEADD (in the form DATEADD(unit_string_literal, integer_amount, starting_datetime))</li> <li>TIMEADD</li> <li>TO_BOOLEAN / TRY_TO_BOOLEAN</li> <li>TO_CHAR / TO_VARCHAR</li> <li>CHARINDEX (not supported for binary data)</li> <li>POSITION (only in the form POSITION(X IN Y), not supported for binary data)</li> <li>INSERT (behavior when numerical arguments are negative is currently not well defined)</li> <li>STARTSWITH / ENDSWITH</li> <li>RTRIMMED_LENGTH</li> <li>MODE (only as a window function, not as a generic aggregation)</li> <li>RATIO_TO_REPORT</li> <li>BOOLOR_AGG</li> </ul> <p>Parity Improvements:</p> <ul> <li>Added support for timezone aware data in all BodoSQL datetime functions.</li> <li>Adjusted TIMESTAMPDIFF to obey Snowflake SQL rounding rules (i.e. ignoring all units smaller than the selected unit).</li> <li>Support for loading views and other non-standard tables with the SnowflakeCatalog.</li> <li>Support for all join types offered by Snowflake.</li> <li>Support for tz-aware data outputs in Case statements.</li> </ul> <p>Other Improvements:</p> <ul> <li>Multiple top-level calls to window functions will now compile faster in BodoSQL if they use the same partition and order.</li> <li>Snowflake writes with df.to_sql can now use the more performant direct upload strategy for Azure based Snowflake accounts.</li> <li>Snowflake I/O (read and write) no longer requires the snowflake-sqlalchemy package.</li> <li>Improved performance for reading string data in compressed format from Snowflake.</li> <li>Performance Warning if running Bodo and Snowflake in different cloud regions.</li> <li>Added support for returning timezone aware timestamp scalars with Series attributes iat, iloc, loc and regular getitem.</li> </ul>"},{"location":"release_notes/July_2020/","title":"Bodo 2020.07 Release (Date: 07/16/2020)","text":"<p>This release includes many new features and bug fixes. Overall, 59 code patches were merged since the last release, including the major addition of support for columns of array and struct values with arbitrary nesting.</p>"},{"location":"release_notes/July_2020/#new-features-and-improvements","title":"New Features and Improvements","text":"<ul> <li> <p>Bodo is updated to use the latest version of Numba (Numba 0.50.1)</p> </li> <li> <p>Series and dataframe columns can have values that are arrays. For     example:</p> <pre><code>A          B\n0  0  [1, 2, 3]\n1  1     [4, 5]\n2  2        [6]\n3  3  [7, 8, 9]\n</code></pre> </li> <li> <p>Series and dataframe columns can have values that are structs. For     example:</p> <pre><code>A                   B\n0  0  {'A': 1, 'B': 2.1}\n1  1  {'A': 3, 'B': 4.3}\n2  2  {'A': 5, 'B': 6.5}\n3  3  {'A': 7, 'B': 8.4}\n</code></pre> </li> <li> <p>Array and Struct values can contain other arrays/structs with     arbitrary nesting. For example:</p> <pre><code>A                                     B\n0  0               {'A': [1, 2], 'B': [3]}\n1  1            {'A': [4, 5, 6], 'B': [7]}\n2  2  {'A': [8, 9, 10, 11], 'B': [12, 13]}\n3  3                {'A': [14], 'B': [15]}\n</code></pre> </li> <li> <p><code>df.drop_duplicates()</code> and <code>df.merge()</code> is supported for nested     array/struct columns.</p> </li> <li> <p>Added support for categorical array data type without explicit     categories. Added support for <code>Series.astype(cat_dtype)</code> and     <code>Series.astype(\"category\")</code>.</p> </li> <li> <p>Generalized <code>df.dropna()</code> to all arrays, and added support for     'how' and 'subset' options.</p> </li> <li> <p>Support for <code>Series.explode()</code></p> </li> <li> <p><code>series.median()</code>: support 'skipna' option and Decimal type, and     bug fixes.</p> </li> <li> <p>Added Series.radd/rsub/rmul/rdiv/rpow/rmod</p> </li> <li> <p>Support for Series.dot/kurt/kurtosis/skew/sem</p> </li> <li> <p>Added Series.mad (mean absolute deviation)</p> </li> <li> <p><code>Series.var()</code> and <code>Series.std()</code>: Added support for 'skipna' and     'ddof' options</p> </li> <li> <p>Support Series.equals</p> </li> <li> <p>Series product/sum: added support for 'min_count' and 'skipna'     options</p> </li> <li> <p>Support Index.map() for all Index type</p> </li> <li> <p>Support all Bodo array types as output of Series.map/apply, df.apply</p> </li> <li> <p>Support df.values with nullable int columns</p> </li> <li> <p>Bodo release builds now enforce licensing (expiration date and     maximum core count) via license keys provided as a file or an     environment variable called \"BODO_LICENSE\".</p> </li> </ul>"},{"location":"release_notes/July_2021/","title":"Bodo 2021.7 Release (Date: 7/23/2021)","text":"<p>This release includes many new features, optimizations, bug fixes and usability improvements. Overall, 109 code patches were merged since the last release.</p>"},{"location":"release_notes/July_2021/#new-features-and-improvements","title":"New Features and Improvements","text":"<ul> <li> <p>Documentation has been reorganized and updated, with improved     navigation and a detailed walkthrough of Pandas equivalents of     PySpark functions.</p> </li> <li> <p>Improvements to enable BodoSQL features</p> </li> <li> Connectors: <ul> <li>Improved performance of <code>pd.read_parquet</code> when reading from     remote storage systems like S3</li> <li>Support reading categorical columns of Parquet</li> </ul> </li> <li> Performance improvements: <ul> <li>Improved performance and scalability of <code>sort_values</code></li> <li>Optimized <code>pd.Series.isin(values)</code> performance for long list     of <code>values</code>.</li> </ul> </li> <li> <p>UDFs in Series.apply and Dataframe.apply: the Bodo compiler     transforms the code to pass main function values referenced in the     UDF (\"free variables\") as arguments to <code>apply()</code> automatically if     possible (to simplify UDF usage).</p> </li> <li> <p>Support passing Bodo data types to objmode directly (in addition to     string representation of the data types). For example, the following     code sets the return type an int64 type:</p> <pre><code>@bodo.jit\ndef f(a, b):\n    with bodo.objmode(res=bodo.int64):\n        res = random.randint(a, b)\n    return res\n</code></pre> </li> <li> <p>Compilation time improvements for some dataframe operations</p> </li> <li> <p>Distributed support for <code>pd.RangeIndex</code> calls</p> </li> <li> Pandas coverage: <ul> <li>Initial support for binary arrays, including within     series/dataframes</li> </ul> <pre><code>-   Support for `groupby.transform`\n\n-   Groupby: support repeated input columns. For example:\n\n        df.groupby(\"A\").agg(\n                D=pd.NamedAgg(column=\"B\", aggfunc=lambda A: A.sum()),\n                F=pd.NamedAgg(column=\"C\", aggfunc=\"max\"),\n                E=pd.NamedAgg(column=\"B\", aggfunc=\"min\"),\n        )\n\n-   Support Groupby with `dropna=False`\n\n-   Support for `dropna` in `Series.nunique`,\n    `DataFrame.nunique`, and `groupby.nunique`\n\n-   Support for `DataFrame.insert()`\n\n-   Support `tolist()` for string and numpy arrays\n\n-\n\n    Expanded `astype` support:\n\n    :   -   str to timedelta64/datetime64\n        -   timedelta64/datetime64 to int64\n        -   date arrays\n        -   Numeric-like inputs to datetime/timedelta\n        -   Support for `pd.StringDtype()` in `astype`\n        -   numeric-like to nullable integer types\n\n-   Support for `pd.Timestamp.now()`\n\n-   Support Timestamp in `pd.to_datetime`\n\n-   Support for Timestamp/Timedelta as the scalar value for a\n    Series\n\n-   Support for `Series.dt.month_name`, `Timestamp.month_name`\n\n-   Support for min/max on timedelta64 series/arrays\n</code></pre> </li> <li> Python coverage: <ul> <li>Support for <code>bytes.fromhex()</code></li> <li>Support for <code>bytes.__hash__</code></li> <li>Support for <code>min</code> and <code>max</code> for string values</li> </ul> </li> </ul>"},{"location":"release_notes/July_2022/","title":"Bodo 2022.7 Release (Date: 07/31/2022)","text":""},{"location":"release_notes/July_2022/#new-features-and-improvements","title":"New Features and Improvements","text":"<p>Compilation / Performance improvements:</p> <ul> <li><code>Groupby</code> operations are now faster to compile and support super-wide DataFrames</li> <li><code>Groupby.apply()</code> operations have improved compilation time, runtime memory usage and performance.</li> <li>Most <code>BodoSQL</code> select statements are now faster to compile.</li> <li>Cache is now automatically invalidated when upgrading Bodo.</li> </ul> <p>Iceberg:</p> <ul> <li>Added support for writing Iceberg tables via <code>to_sql</code></li> </ul> <p>I/O:</p> <ul> <li><code>to_csv</code>, <code>to_json</code>, and <code>to_parquet</code> now support a custom argument <code>_bodo_file_prefix</code> to specify the prefix of files written in distributed cases.</li> <li>Snowflake data load now supports filter pushdown with <code>Series.str.startswith</code> and <code>Series.str.endswith</code>.</li> </ul> <p>Pandas coverage:</p> <ul> <li><code>read_csv</code> and <code>read_json</code> now support argument <code>sample_nrows</code> to set the number of rows that are sampled to infer column dtypes (by default <code>sample_nrows=100</code>).</li> <li>Support for <code>DataFrame.rank</code></li> <li>Support for <code>Groupby.ngroup</code></li> <li>Added support for dictionary-encoded string arrays (that have reduced memory usage and execution time) in the following functions:<ul> <li><code>Groupby.min</code></li> <li><code>Groupby.max</code></li> <li><code>Groupby.first</code></li> <li><code>Groupby.last</code></li> <li><code>Groupby.shift</code></li> <li><code>Groupby.head</code></li> <li><code>Groupby.nunique</code></li> <li><code>Groupby.sum</code></li> <li><code>Groupby.cumsum</code></li> <li><code>Groupby.transform</code></li> </ul> </li> </ul> <p>BodoSQL:</p> <ul> <li> <p>Added support for the following query syntax</p> <ul> <li><code>QUALIFY</code></li> <li><code>GROUP BY GROUPING SETS</code></li> <li><code>GROUP BY CUBE</code></li> <li><code>GROUP BY ROLLING</code></li> </ul> </li> <li> <p>Added support for the following functions:</p> <ul> <li><code>IFF</code></li> <li><code>NULLIFZERO</code></li> <li><code>NVL2</code></li> <li><code>ZEROIFNULL</code></li> </ul> </li> <li> <p>Added support for the following windowed aggregation functions:</p> <ul> <li><code>RANK</code></li> <li><code>DENSE_RANK</code></li> <li><code>PERCENT_RANK</code></li> <li><code>CUME_DIST</code></li> </ul> </li> <li> <p>The following functions are much faster to compile:</p> <ul> <li><code>ADDDATE/DATE_ADD/SUBDATE/DATE_SUB</code> if the second argument is an integer column</li> <li><code>ASCII</code></li> <li><code>CHAR</code></li> <li><code>COALESCE</code></li> <li><code>CONV</code></li> <li><code>DAYNAME</code></li> <li><code>FORMAT</code></li> <li><code>FROM_DAYS</code></li> <li><code>FROM_UNIXTIME</code></li> <li><code>IF</code></li> <li><code>IFNULL</code></li> <li><code>INSTR</code></li> <li><code>LAST_DAY</code></li> <li><code>LEFT</code></li> <li><code>LOG</code></li> <li><code>LPAD</code></li> <li><code>MAKEDATE</code></li> <li><code>MONTHNAME</code></li> <li><code>NULLIF</code></li> <li><code>NVL</code></li> <li><code>ORD</code></li> <li><code>REPEAT</code></li> <li><code>REPLACE</code></li> <li><code>REVERSE</code></li> <li><code>RIGHT</code></li> <li><code>RPAD</code></li> <li><code>SPACE</code></li> <li><code>STRCMP</code></li> <li><code>SUBSTRING</code></li> <li><code>SUBSTRING_INDEX</code></li> <li><code>TIMESTAMPDIFF</code> (if the unit is Month, Quarter, or Year)</li> <li><code>Unary -</code></li> <li><code>WEEKDAY</code></li> <li><code>YEAROFWEEKISO</code></li> </ul> </li> <li> <p>Support for binary data in complex join operations</p> </li> <li>Support for UTF-8 string literals in queries (previously just ASCII).</li> </ul>"},{"location":"release_notes/July_2023/","title":"Bodo 2023.7 Release (Date: 07/31/2023)","text":""},{"location":"release_notes/July_2023/#new-features-and-improvements","title":"New Features and Improvements","text":"<p>BodoSQL:</p> <ul> <li>Fixed a rare bug where final column names lost assigned aliases.</li> <li>Reduced compilation time for some queries.</li> <li>INTERVAL_QUARTER support</li> <li>Optional argument support in REPLACE</li> <li>Remove interval related words from restricted keywords.</li> <li>Support optional arguments in CEIL and FLOOR</li> <li>Support unquoted units for DATE_PART</li> <li>Support TO_CHAR with format string for time and timestamp</li> </ul>"},{"location":"release_notes/June_2020/","title":"Bodo 2020.06 Release (Date: 06/12/2020)","text":""},{"location":"release_notes/June_2020/#new-features-and-improvements","title":"New Features and Improvements","text":"<ul> <li> <p>Bodo is updated to use the latest minor releases of Numba and Apache     Arrow packages:</p> <ul> <li>numba 0.49.1</li> <li>Apache Arrow 0.17.1</li> </ul> </li> <li> <p>Significant optimizations in read CSV/JSON/Parquet to reduce number     of requests, files opened and overall load on the filesystem (for     local filesystems, S3 and HDFS).</p> </li> <li> <p>Improvements in <code>pandas.read_csv()</code> and <code>pandas.read_json()</code>:</p> <ul> <li>Support reading compressed JSON and CSV files (gzip and bz2)</li> <li>Can read directories containing files with any extension</li> <li>Correctly handle CSV files with headers when reading a     directory of CSV files</li> <li>Support automatic data type inference of JSON files when     <code>orient='records'</code> and <code>lines=True</code></li> </ul> </li> <li> <p>Bodo can now automatically infer the required constant values (e.g.     list of key names for groupby) from the program in many cases. In     addition, Bodo raises informative errors for cases that are not     possible to infer automatically.</p> </li> <li> <p>Various improvements to support caching of Bodo functions, including     adding support for caching inside Jupyter Notebook (see     here     for more information)</p> </li> <li> <p>Support NA value check with <code>pandas.isna(A[i])</code></p> </li> <li> <p>Support creating empty dataframes and setting columns on empty     dataframes</p> </li> <li> <p>More balanced workload distribution across processor cores</p> </li> <li> <p>Support for user-defined functions calling other JIT functions, and     improved error messages for invalid cases</p> </li> <li> <p><code>pandas.read_parquet()</code>: support reading columns of list of     integers/floats</p> </li> <li> <p>Support <code>bodo.scatterv()</code> for arrays of list of     strings/integers/floats.</p> </li> <li> <p>Improved support for <code>pd.to_datetime()</code> to handle optional arguments     and cases such as string and integer array/Series inputs</p> </li> <li> <p>Improved <code>pd.concat</code> support to handle arrays of list,     <code>Decimal</code> and <code>datetime.date</code> values</p> </li> <li> <p>Improved array indexing (getitem/setitem) support for various data     types such as date/time cases and Decimals</p> </li> <li> <p>Support sorting of Decimal series</p> </li> <li> <p>Support Dataframe <code>merge</code> and <code>groupby</code> with Decimal columns</p> </li> <li> <p>Groupby: ignore non-numeric columns for numeric-only operations like     sum (same behavior as pandas).</p> </li> <li> <p>Support for comparison of Timedelta data types (<code>datetime.timedelta</code>     and <code>timedelta64</code>)</p> </li> <li> <p>Parallelization of <code>numpy.full()</code></p> </li> <li> <p>Support <code>glob.glob(...)</code> inside Bodo functions</p> </li> <li> <p>Error messages and warnings:</p> <ul> <li>Improvements to clarity and conciseness of error messages</li> <li>Can use numba syntax highlighting for Bodo errors (enable with     NUMBA_COLOR_SCHEME     environment variable)</li> </ul> </li> <li> <p>Documentation:</p> <ul> <li>New theme and style</li> <li>Revamped introductory material and guide</li> <li>Improved documentation for <code>pd.read_csv()</code> and     <code>pd.read_json()</code></li> <li>Documented Bodo's coverage of data types</li> </ul> </li> </ul> <p>Overall, 82 code patches are merged since the last release.</p>"},{"location":"release_notes/June_2022/","title":"Bodo 2022.6 Release (Date: 06/30/2022)","text":""},{"location":"release_notes/June_2022/#new-features-and-improvements","title":"New Features and Improvements","text":"<ul> <li>Bodo is upgraded to use Numba 0.55.2 (the latest release)</li> </ul> <p>Dataframe compilation improvements:</p> <ul> <li> <p><code>pandas.merge</code> is now much faster to compile and supports super wide dataframes (e.g. 100,000 columns).</p> </li> <li> <p><code>DataFrame.sort_values</code> is now much faster to compile and supports super wide dataframes.</p> </li> <li> <p><code>DataFrame.astype</code> is now much faster to compile and supports super wide dataframes.</p> </li> <li> <p><code>DataFrame.loc</code>, <code>DataFrame.iloc</code> and <code>DataFrame[col_list]</code> are now faster to compile and support super wide dataframes when returning a DataFrame.</p> </li> <li> <p>Bodo can now automatically optimize out unused output keys of join and sort operations (e.g. pd.merge, df.sort_values). This should result in significant runtime and memory usage improvements.</p> </li> </ul> <p>Iceberg connector (alpha):</p> <ul> <li> <p>Now supports reading from Nessie, Arctic, and Glue catalogs.</p> </li> <li> <p>Iceberg connector now uses py4j. This should remove any conflicts with other packages that use jpype.</p> </li> </ul> <p>Parquet I/O:</p> <ul> <li> <p>Improved performance and robustness when reading Parquet files.</p> </li> <li> <p>Several improvements to Dead Column Elimination and Filter Pushdown that enable faster Parquet read in many scenarios.</p> </li> </ul> <p>Pandas coverage:</p> <ul> <li> <p>Several Series operation are optimized to support dictionary-encoded string arrays, which reduces memory usage and execution time:</p> <ul> <li><code>pd.Series.str.get</code></li> <li><code>pd.Series.str.repeat</code></li> <li><code>pd.Series.str.slice</code></li> <li><code>pd.Series.str.pad</code></li> <li><code>pd.Series.str.rjust</code></li> <li><code>pd.Series.str.ljust</code></li> <li><code>pd.Series.str.zfill</code></li> <li><code>pd.Series.str.center</code></li> <li><code>pd.Series.str.count</code></li> <li><code>pd.Series.str.len</code></li> <li><code>pd.Series.str.find</code></li> <li><code>pd.Series.str.rfind</code></li> <li><code>pd.Series.str.strip</code></li> <li><code>pd.Series.str.lstrip</code></li> <li><code>pd.Series.str.rstrip</code></li> <li><code>pd.Series.str.extract</code></li> <li><code>pd.Series.str.extractall</code></li> <li><code>pd.Series.str.isalnum</code></li> <li><code>pd.Series.str.isalpha</code></li> <li><code>pd.Series.str.isdigit</code></li> <li><code>pd.Series.str.isspace</code></li> <li><code>pd.Series.str.islower</code></li> <li><code>pd.Series.str.isupper</code></li> <li><code>pd.Series.str.istitle</code></li> <li><code>pd.Series.str.isnumeric</code></li> <li><code>pd.Series.str.isdecimal</code></li> </ul> </li> <li> <p>Support for dictionary-encoded string arrays as the key values to <code>DataFrame.groupby</code>, which reduces memory usage and execution time.</p> </li> <li> <p>Bodo now supports <code>Index.is_integer()</code>, <code>Index.is_floating()</code>, <code>Index.is_boolean()</code>, <code>Index.is_numeric()</code>, <code>Index.is_interval()</code>, <code>Index.is_categorical()</code>, <code>Index.is_object()</code>, <code>Index.T, Index.size</code>, <code>Index.ndim</code>, <code>Index.nlevels</code>, <code>Index.is_all_dates</code>, <code>Index.inferred_type</code>, <code>Index.empty</code>, <code>Index.names</code>, <code>Index.shape</code> for all Index types.</p> </li> <li> <p>Bodo now supports <code>Index.argmax()</code>, <code>Index.argmin()</code>, <code>Index.argsort()</code>, and <code>Index.nunique()</code> for the follwing Index types:</p> <ul> <li>NumericIndex</li> <li>RangeIndex</li> <li>StringIndex</li> <li>BinaryIndex</li> <li>DatetimeIndex</li> <li>TimedeltaIndex</li> <li>CategoricalIndex</li> <li>PeriodIndex</li> </ul> </li> <li> <p>Bodo now supports <code>Index.all()</code> and <code>Index.any()</code> for the following index types:</p> <ul> <li>NumericIndex</li> <li>RangeIndex</li> <li>StringIndex</li> <li>BinaryIndex</li> </ul> </li> <li> <p>Bodo now supports <code>Index.isin()</code>, <code>Index.union()</code>, <code>Index.intersection()</code>, <code>Index.difference()</code>, <code>Index.symmetric_difference()</code>, <code>Index.to_list()</code>, and <code>Index.tolist()</code> for the following index types:</p> <ul> <li>NumericIndex</li> <li>RangeIndex</li> <li>StringIndex</li> <li>BinaryIndex</li> <li>DatetimeIndex</li> <li>TimedeltaIndex</li> </ul> </li> <li> <p>Bodo now supports <code>Index.dtype</code> and <code>Index.to_frame()</code> for the following index types</p> <ul> <li>NumericIndex</li> <li>RangeIndex</li> <li>StringIndex</li> <li>BinaryIndex</li> <li>DatetimeIndex</li> <li>TimedeltaIndex</li> <li>CategoricalIndex</li> <li>MultiIndex</li> </ul> </li> <li> <p>Bodo now supports <code>Index.to_series()</code>, <code>Index.where()</code>, <code>Index.putmask()</code>, and <code>Index.sort_values()</code> for the following index types:</p> <ul> <li>NumericIndex</li> <li>RangeIndex</li> <li>StringIndex</li> <li>BinaryIndex</li> <li>DatetimeIndex</li> <li>TimedeltaIndex</li> <li>CategoricalIndex</li> </ul> </li> <li> <p>Bodo now supports <code>Index.unique()</code>, and <code>Index.to_numpy()</code> for the following index types:</p> <ul> <li>NumericIndex</li> <li>RangeIndex</li> <li>StringIndex</li> <li>BinaryIndex</li> <li>DatetimeIndex</li> <li>TimedeltaIndex</li> <li>CategoricalIndex</li> <li>IntervalIndex</li> </ul> </li> <li> <p>Added support for <code>Categorical Index iterator</code></p> </li> <li> <p>Added support for <code>Series.rank()</code> with replicated data</p> </li> </ul> <p>Scikit-Learn Coverage:</p> <ul> <li>Added support for the following functions:<ul> <li><code>sklearn.metrics.log_loss</code></li> <li><code>sklearn.metrics.pairwise.cosine_similarity</code></li> <li><code>sklearn.model_selection.KFold</code></li> <li><code>sklearn.model_selection.LeavePOut</code></li> <li><code>sklearn.preprocessing.OneHotEncoder</code></li> <li><code>sklearn.preprocessing.MaxAbsScaler</code></li> <li><code>sklearn.utils.shuffle</code></li> </ul> </li> </ul> <p>BodoSQL:</p> <ul> <li> <p>BodoSQL is available on pypi</p> </li> <li> <p>BodoSQL now uses py4j. This should remove any conflicts with other packages that use jpype.</p> </li> <li> <p>Significantly reduced compilation time when compiling queries with large numbers of columns for common operations (join, where, order by, limit)</p> </li> <li> <p>Optimized <code>first_value</code> and <code>last_value</code> window functions when a single value is repeated for the entire column.</p> </li> <li> <p>Reduced compilation with <code>LPAD</code> and <code>RPAD</code></p> </li> <li> <p>Increased filter pushdown coverage when loading data from Parquet.</p> </li> </ul>"},{"location":"release_notes/June_2023/","title":"Bodo 2023.6 Release (Date: 06/23/2023)","text":""},{"location":"release_notes/June_2023/#new-features-and-improvements","title":"New Features and Improvements","text":"<p>Bodo:</p> <ul> <li>Added original date type support for all datetime functions.</li> <li>Support filter pushdown for various functions.</li> <li>Upgrade to Arrow 11.</li> <li>Improved performance on join operations by using streaming loop.</li> <li>Support nullable timestamp, float and boolean array.</li> <li>Zero-Copy support for most Arrow Arrays.</li> <li>Supported passing timezone to pd.Timestamp.now().</li> <li>Support for comparison operators between date and tz-aware/naive timestamps.</li> </ul> <p>BodoSQL:</p> <p>Added support for the following functions:</p> <ul> <li>CURRENT_DATE</li> <li>DATEDIFF/TIMEDIFF/TIMESTAMPDIFF</li> <li>TRY_CAST</li> <li>LEAD/LAG</li> <li>[TRY_]TO_BINARY</li> <li>[TRY_]TO_DECIMAL, [TRY_]TO_NUMBER, [TRY_]TO_NUMERIC, [TRY_]TO_DOUBLE</li> <li>[TRY_]TO_DOUBLE</li> <li>[TRY_]TO_TIME</li> <li>SAMPLE</li> <li>ILIKE/ANY/ALL</li> <li>LEAST/GREATEST</li> <li>ADD_MONTH/MONTH_BETWEEN</li> <li>HASH</li> <li>RANDOM</li> <li>UNIFORM</li> <li>TO_ARRAY</li> <li>ARRAY_TO_STRING</li> <li>SPLIT</li> </ul> <p>Parity Improvements:</p> <ul> <li>Added support for reading nested arrays.</li> <li>Support <code>repeats</code> for tz-aware data in join optimization.</li> <li>Support logical and comparison operators between Boolean and Numeric Types.</li> <li>Support for date outputs in Case statements.</li> <li>Added support for the window functions LEAD/LAG using the <code>IGNORE NULLS</code> keyword.</li> </ul> <p>Other Improvements:</p> <ul> <li>More efficient fill templating for Join.</li> <li>Improved Snowflake sampling for dict-encoding detection.</li> <li>Revamped C++ array representation to be more robust.</li> <li>Support batching / streaming Snowflake Read Implementation.</li> </ul>"},{"location":"release_notes/March_2021/","title":"Bodo 2021.3 Release (Date: 3/25/2021)","text":"<p>This release includes many new features, bug fixes and usability improvements. Overall, 148 code patches were merged since the last release.</p>"},{"location":"release_notes/March_2021/#new-features-and-improvements","title":"New Features and Improvements","text":"<ul> <li> <p>Bodo is updated to use Numba 0.53 (latest) and support Python 3.9</p> </li> <li> <p>Many improvements to error checking and reporting</p> </li> <li> <p>Compilation time is reduced, especially for user-defined functions     (UDFs)</p> </li> <li> <p>Reduced initialization time when importing Bodo</p> </li> <li> <p>Distributed diagnostics improvements:</p> <ul> <li>Show distributed diagnostics when raising errors for     distributed flag</li> <li>Only show user defined variables in diagnostics level one</li> </ul> </li> <li> <p>Performance optimizations:</p> <ul> <li>Faster groupby <code>nunique</code> with improved scaling</li> <li>Faster <code>setitem</code> for categorical arrays</li> </ul> </li> <li> <p>Connectors:</p> <ul> <li>Google Cloud Storage (GCS) support with Parquet</li> <li>Support reading Delta Lake tables</li> <li>Improved Snowflake support</li> <li>Removed s3fs dependency (Bodo now fully relies on Apache Arrow     for S3 connectivity)</li> </ul> </li> <li> <p>Change default parallelism semantics of <code>unique()</code> to replicated     output to match user expectations better</p> </li> <li> <p>Support <code>objmode</code> in groupby apply UDFs</p> </li> <li> <p>Pandas coverage:</p> <ul> <li>Support <code>pd.DataFrame.duplicated()</code> with categorical data </li> <li>Groupby support for min/max on categorical data </li> <li>Support for categorical in <code>pd.Series.dropna</code> </li> <li>Support nullable int array in <code>pd.Categorical</code> constructor </li> <li>Support for <code>pd.Series.where</code> and <code>pd.Series.mask</code> with     categorical data and a scalar value. </li> <li>Support for <code>pd.Series.diff()</code> </li> <li>Support for <code>pd.DataFrame.diff()</code> </li> <li>Support for <code>pd.Series.repeat()</code> </li> <li>Support list of functions in <code>groupby.agg()</code> </li> <li>Support tuple of UDFs inside <code>groupby.agg()</code> dictionary case </li> <li>Support single row and scalar UDF output in <code>groupby.apply()</code> </li> <li>Support Categorical values in <code>Groupby.shift</code> </li> <li>Support <code>case=False</code> in <code>Series.str.contains</code> </li> <li>Support <code>mapper</code> with <code>axis=1</code> for <code>pd.DataFrame.rename</code>. </li> <li>Support <code>Timedelta64</code> data in <code>pd.Groupby</code> </li> <li>Support for <code>datetime.date</code> arrays in <code>Series.max</code> and     <code>Series.min</code> </li> <li>Support for <code>pd.timedelta_range</code> </li> <li>Support equality between <code>datetime64</code>/<code>pd.Timestamp</code> and     <code>timedelta64</code>/<code>pd.Timedelta</code> </li> <li>Support for iterating across most index types </li> <li>Support getting the <code>name</code> attribute of data inside <code>df.apply</code> </li> <li>Support <code>Series.reset_index(drop=False)</code> for common cases </li> <li>Support <code>==</code> and <code>!=</code> on Dataframe and a scalar with a     different type </li> <li> <pre><code>Sequential support for `pd.Series.idxmax`, `pd.Series.idxmin`,\n\n:   `pd.DataFrame.idxmax`, and `pd.DataFrame.idxmin` with\n    Nullable and Categorical arrays.\n</code></pre> </li> </ul> </li> <li> <p>Python coverage:</p> <ul> <li>Support <code>datetime.date.replace()</code></li> <li>Improved support for <code>datetime.date.strftime()</code></li> <li>Support for <code>calendar.month_abbr</code></li> </ul> </li> <li> <p>SciPy:</p> <ul> <li>Initial support for <code>scipy.sparse.csr_matrix</code></li> </ul> </li> <li> <p>Scikit-learn:</p> <ul> <li>Support for     <code>sklearn.feature_extraction.text.HashingVectorizer</code></li> </ul> </li> </ul>"},{"location":"release_notes/March_2022/","title":"Bodo 2022.3 Release (Date: 3/31/2022)","text":"<p>This release includes many new features, usability and performance improvements, and bug fixes. Overall, 74 code patches were merged since the last release.</p>"},{"location":"release_notes/March_2022/#new-features-and-improvements","title":"New Features and Improvements","text":"<ul> <li> <p>Bodo is updated to use Arrow 7.0 (latest)</p> </li> <li> <p>Initial support for dictionary-encoded string arrays.     Dictionary encoding can improve performance and reduce memory usage significantly     when data has many repeated values which is common in practice (see here).     Bodo now uses dictionary encoding automatically in <code>pd.read_parquet</code> when a string column can benefit from it.     Join, sort and parquet write operations support dictionary-encoded string arrays as well, and     the support will expand to others in the future.     Bodo will fall back to regular string arrays automatically if an     operation does not support dictionary encoding.</p> </li> <li> <p>Connectors:</p> <ul> <li><code>pd.read_parquet</code> performance improvements when multiple processes read     from the same file.</li> <li>Support for filter pushdown in Parquet and Snowflake when using <code>Series.isin</code></li> <li>Support for SparkSQL's <code>input_file_name</code> functionality for <code>read_parquet</code> using a new <code>_bodo_input_file_name_col</code> argument.</li> <li>Support for <code>chunksize</code> in <code>pd.to_sql</code></li> <li>Optimized <code>df.to_parquet</code> memory usage when writing string columns</li> <li>Support for passing list of columns as <code>columns</code> parameter of <code>df.to_csv</code></li> <li>Support in <code>pd.read_sql</code> for returning an empty DataFrame from Snowflake, either     due to an empty query or the result of filter pushdown.</li> <li>Changed default value of <code>orient</code> and <code>lines</code> in <code>DataFrame.to_json</code> to <code>records</code> and <code>True</code> respectively to enable parallel write (Pandas uses <code>columns</code> and <code>False</code> as default).</li> </ul> </li> <li> <p>Bodo now provides compiler optimization logging through <code>bodo.set_verbose_level()</code>.     This can be used to display certain optimizations performed at compile time,     such as filter pushdown, column pruning, and which columns are read with dictionary     encoding when reading from Parquet. See Verbose Mode for more details. </p> </li> <li> <p>Improvements in error checking and quality of error messages.</p> </li> <li> <p>Avoid hang when encountering unhandled exceptions on a single process.</p> </li> <li> <p>Introduced <code>replicated</code> JIT decorator flag (opposite of <code>distributed</code>).</p> </li> <li> <p>If the user provided <code>distributed</code> JIT flag for some input and return values but not all, bodo can now infer distribution of the rest.</p> </li> <li> <p>Performance optimizations:</p> <ul> <li>Improved memory usage during parallel <code>groupby.apply</code></li> <li>Improved <code>df.sample</code> performance when <code>frac=1</code> and <code>replace=False</code></li> </ul> </li> <li> <p>Pandas:</p> <ul> <li>Initial support for Timezone-Aware arrays and timestamps<ul> <li>Added support for <code>array.tz_convert</code>, <code>Series.dt.tz_convert</code>, <code>Timestamp.tz_convert</code>, <code>DatetimeIndex.tz_convert</code>, <code>Timestamp.tz_localize</code></li> </ul> </li> <li>Support for <code>Series.str.cat</code></li> <li>Support for <code>pd.unique</code> on Series and 1-D arrays</li> <li>Support for comparison operators between <code>DatetimeIndex</code> and <code>pd.Timestamp</code>     and <code>TimedeltaIndex</code> and <code>pd.Timedelta</code></li> <li>Support for <code>DataFrame.set_index</code> on single-column DataFrames</li> <li>Support for <code>Series.first_valid_index</code> and <code>Series.last_valid_index</code></li> <li>Support for conversion between <code>pd.timestamp</code> and <code>np.datetime64</code></li> </ul> </li> </ul>"},{"location":"release_notes/May_2020/","title":"Bodo 2020.05 Release (Date: 05/06/2020)","text":""},{"location":"release_notes/May_2020/#new-features-and-improvements","title":"New Features and Improvements","text":"<ul> <li> Bodo is updated to use the latest versions of Numba and Apache Arrow packages: <ul> <li>numba 0.49.0</li> <li>Apache Arrow 0.17.0</li> </ul> </li> <li> <p>Various improvements to clarity and conciseness of error messages</p> </li> <li> <p>Initial support for <code>pandas.DataFrame.to_sql()</code></p> </li> <li> <p><code>pandas.read_sql()</code> support <code>sql</code> and <code>con</code> passed to Bodo-decorated     functions</p> </li> <li> <p>Added support for <code>pandas.read_json()</code> and     <code>pandas.DataFrame.to_json()</code> from &amp; to POSIX, S3, and Hadoop File     Systems.</p> </li> <li> <p>Initial support for <code>pandas.read_excel()</code></p> </li> <li> <p><code>numpy.fromfile()</code> and <code>numpy.tofile()</code> from and to S3, and Hadoop     File Systems.</p> </li> <li> <p>Reduction in number of requests in I/O read calls</p> </li> <li> <p>Initial support for array of lists of fixed sized values</p> </li> <li> <p>List of strings data type support for <code>pandas.DataFrame.join()</code>,     <code>pandas.DataFrame.drop_duplicates()</code>, and     <code>pandas.DataFrame.groupby()</code></p> </li> <li> <p><code>pandas.Timestamp</code> subtraction, min and max</p> </li> <li> <p>Improved support for null values in datetime and timedelta     operations</p> </li> <li> <p>Support <code>copy()</code> function for Series of <code>decimal.Decimal</code> and     <code>datetime.date</code> data types and most Index types</p> </li> <li> <p>Improved support for Series <code>decimal.Decimal</code> dtype</p> </li> <li> <p>String Series and Dataframe Column are now mutable and support     inplace <code>fillna()</code></p> </li> <li> <p><code>pandas.Series.round()</code></p> </li> <li> <p><code>pandas.Dataframe.assign()</code></p> </li> <li> <p>Support <code>groupby(...).first()</code> operation</p> </li> <li> <p><code>pandas.Dataframe.iloc</code> support for extracting a subset of columns</p> </li> <li> <p><code>numpy.array.sum(axis=0)</code></p> </li> <li> <p><code>numpy.reshape()</code> multi-dimensional distributed arrays</p> </li> <li> <p>Initial implementation of experimental legacy mode</p> </li> <li> <p>Proper error when using unsupported <code>pandas.(...)</code> &amp;     <code>pandas.Series.(...)</code> functions</p> </li> <li> <p>Improved robustness of <code>pandas.DataFrame</code> inplace operations</p> </li> <li> <p>Memory usage improvements</p> </li> <li> <p>Type safety improvements</p> </li> <li> <p>Compilation time improvements</p> </li> </ul>"},{"location":"release_notes/May_2020/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Fixed an issue in <code>pandas.read_csv()</code> reading a large CSV file in     specific distributed cases</li> <li><code>numpy.dot()</code> with empty vector/matrix input</li> </ul>"},{"location":"release_notes/May_2021/","title":"Bodo 2021.5 Release (Date: 5/19/2021)","text":"<p>This release includes many new features, optimizations, bug fixes and usability improvements. Overall, 70 code patches were merged since the last release.</p>"},{"location":"release_notes/May_2021/#new-features-and-improvements","title":"New Features and Improvements","text":"<ul> <li> <p>Bodo is updated to use Arrow 4.0 (latest)</p> </li> <li> <p>Connectors:</p> <ul> <li>Improved performance of <code>pd.read_parquet</code> significantly for     large multi-file datasets by optimizing Parquet metadata     collection</li> <li>Bodo nows reads only the first few rows from a Parquet dataset     if the program only requires <code>df.head(n)</code> and/or <code>df.shape</code>.     This helps with exploring large datasets without the need for     a large cluster to load the full data in memory.</li> </ul> </li> <li> <p>Visualization: Bodo now supports calling many Matplotlib plotting     functions directly from JIT code. See the \"Data Visualization\"     section of our documentation for more details. The current support     gathers the data into one process but this will be avoided in future     releases.</p> </li> <li> <p>Improved compilation time for dataframe functions</p> </li> <li> <p>Improved the performance and scalability of <code>groupby.nunique</code></p> </li> <li> <p>Many improvements to error checking and reporting</p> </li> <li> <p>Bodo now avoids printing empty slices of distributed data to make     print output easier to read.</p> </li> <li> <p>Pandas coverage:</p> <ul> <li>Support for <code>DataFrame.info()</code></li> <li>Support for <code>memory_usage()</code> for DataFrame and Series</li> <li>Support for <code>nbytes</code> for array and Index types</li> <li>Support for <code>df.describe()</code> with datetime data (assumes     <code>datetime_is_numeric=True</code>)</li> <li>Support for <code>groupby.value_counts()</code></li> <li>Support for <code>pd.NamedAgg</code> with <code>nunique</code> in groupby</li> <li>Initial support for CategoricalIndex type and categorical keys     in groupby</li> <li>Support for groupby <code>idxmin</code> and <code>idxmax</code> with nullable     Integer and Boolean arrays</li> <li>Support for timedelta64 in <code>Groupby.agg</code></li> <li>Support for <code>bins</code> and other optional arguments in     <code>Series.value_counts()</code></li> <li>Support for <code>df.dtypes</code></li> <li>Support passing <code>df.dtypes</code> to <code>df.astype()</code>, for example:     <code>df1.astype(df2.dtypes)</code></li> <li>Support for boolean <code>pd.Index</code></li> <li>Support for <code>Series.sort_index()</code></li> <li>Support for <code>Timestamp.day_name()</code> and <code>Series.dt.day_name()</code></li> <li>Support for <code>Series.quantile()</code> with datetime</li> <li>Support for passing list of quantile values to     <code>Series.quantile()</code></li> <li>Support for <code>Series.to_frame()</code></li> <li>Support for <code>sum()</code> method of Boolean Arrays</li> <li>Initial support for <code>MultiIndex.from_product</code></li> <li>String array comparison returns a Pandas nullable boolean     array instead of a Numpy boolean array</li> </ul> </li> </ul>"},{"location":"release_notes/May_2022/","title":"Bodo 2022.5 Release (Date: 5/31/2022)","text":"<p>This release includes many new features, usability and performance improvements, and bug fixes.</p>"},{"location":"release_notes/May_2022/#new-features-and-improvements","title":"New Features and Improvements","text":"<ul> <li> <p>Iceberg connector (alpha):</p> <ul> <li>Initial support for reading Iceberg tables using the <code>read_sql_table</code> API.   It supports automatic filter pushdown, and tables can be stored on local file system   or Hive Metastore.</li> </ul> </li> <li> <p>Improved write performance of dataframe <code>to_sql</code> to OracleDB.</p> </li> <li> <p>Better error messages linked to user documentation.</p> </li> <li> <p>Pandas:</p> <ul> <li> <p>Bodo now matches Pandas 1.4 date/time offset behavior for nansecond fragments.</p> </li> <li> <p>Support for <code>var_name</code> and <code>value_name</code> arguments in <code>pd.melt</code>.</p> </li> <li> <p>Super wide dataframe support for <code>copy</code> and <code>rename</code>.</p> </li> <li> <p>Support for Index <code>unique</code>, <code>isin</code>, and <code>contains</code>.</p> </li> <li> <p>Improved memory-efficiency and performance of <code>Series.str</code> <code>center</code>, <code>capitalize</code>, <code>lower</code>, <code>swapcase</code>, <code>title</code>, and <code>upper</code> with dictionary-encoded string arrays.</p> </li> </ul> </li> <li> <p>BodoSQL:</p> <ul> <li> <p>Support for Python 3.10</p> </li> <li> <p>Upgraded to Calcite 1.30 (latest release)</p> </li> </ul> </li> </ul>"},{"location":"release_notes/November_2020/","title":"Bodo 2020.11 Release (Date: 11/19/2020)","text":"<p>This release includes many new features, bug fixes and performance improvements. Overall, 126 code patches were merged since the last release.</p>"},{"location":"release_notes/November_2020/#new-features-and-improvements","title":"New Features and Improvements","text":"<ul> <li> <p>Bodo is updated to use Apache Arrow 2.0 (latest)</p> </li> <li> <p>Performance and memory optimizations</p> <ul> <li>Significant memory usage optimizations for several operations     involving string arrays</li> <li>Up to 2x speedup for many string operations such as     <code>Series.str.replace/get/contains</code> and <code>groupby.sum()</code></li> </ul> </li> <li> <p>User-defined functions (UDFs)</p> <ul> <li>Support for returning datafarames from <code>DataFrame.apply()</code> and     <code>Series.apply()</code></li> <li>Support for returning nested arrays</li> </ul> </li> <li> <p>Caching: for Bodo functions that receive CSV and JSON file names as     string arguments, the cache will now be reused when file name     arguments differ but have the same dataset type (schema).</p> </li> <li> <p>Support for distributed deep learning with Tensorflow and PyTorch:     https://docs.bodo.ai/latest/source/dl.html</p> </li> <li> <p>Pandas coverage:</p> <ul> <li>Support for tuple values in Series and DataFrame columns</li> <li>Improvements to error checking and handling</li> <li>Automatic unrolling of loops over dataframe columns when     necessary for type stability</li> <li>Support integer column names for Dataframes</li> <li>Support for <code>pd.Timedelta</code> values</li> <li>Support for <code>pd.tseries.offsets.DateOffset</code> and     <code>pd.tseries.offsets.Monthend</code></li> <li>Support for Series.dt, Timestamp, and DateTimeIndex attributes     (<code>is_month_start</code>, <code>is_month_end</code>, <code>is_quarter_start</code>,     <code>is_quarter_end</code>, <code>is_year_start</code>, <code>is_year_end</code>, <code>week</code>,     <code>weekofyear</code>, <code>weekday</code>)</li> <li>Support for Series.dt and Timestamp <code>normalize</code> method</li> <li>Support for <code>Timestamp.components</code> and <code>Timestamp.strftime</code></li> <li>Support for <code>Series.dt.ceil</code> and <code>Series.dt.round</code></li> <li>Support for <code>pd.to_timedelta</code></li> <li>Support <code>Series.replace</code> for categorical arrays where     <code>value</code> and <code>to_replace</code> are scalars or lists</li> <li>Support for comparison operators on Decimal types</li> <li>Support for Series.add() with String, datetime, and timedelta</li> <li>Support for Series.mul() with string and int literal</li> <li>Support for setting values in categorical arrays</li> <li>Initial support for <code>pd.get_dummies()</code></li> <li>Support for <code>Series.groupby()</code></li> </ul> </li> <li> <p>Scikit-learn: the following classes and functions are supported     inside jit functions:</p> <ul> <li><code>sklearn.linear_model.LinearRegression</code></li> <li><code>sklearn.linear_model.LogisticRegression</code></li> <li><code>sklearn.linear_model.Ridge</code></li> <li><code>sklearn.linear_model.Lasso</code></li> <li><code>sklearn.svm.LinearSVC</code></li> <li><code>sklearn.naive_bayes.MultinomialNB</code></li> <li><code>sklearn.metrics.accuracy_score</code></li> <li><code>sklearn.metrics.mean_squared_error</code></li> <li><code>sklearn.metrics.mean_absolute_error</code></li> </ul> </li> <li> <p>XGBoost: Training XGBoost model (with Scitkit-learn like API) is now     supported inside jit functions:</p> <ul> <li><code>xgboost.XGBClassifier</code></li> <li><code>xgboost.XGBRegressor</code></li> </ul> <p>Visit &lt;https://docs.bodo.ai/latest/source/ml.htmlfor more information about supported ML functions.</p> </li> <li> <p>NumPy coverage:</p> <ul> <li>Support for <code>numpy.any</code> and <code>numpy.all</code> for all array types</li> <li>Support for <code>numpy.cbrt</code></li> <li>Support for <code>numpy.linspace</code> arguments <code>endpoint</code>, <code>retstep</code>,     and <code>dtype</code></li> <li><code>np.argmin</code> with axis=1</li> <li>Support for <code>np.float32(str)</code></li> </ul> </li> <li> <p>Support for <code>str.format</code>, <code>math.factorial</code>, <code>zlib.crc32</code></p> </li> </ul>"},{"location":"release_notes/November_2021/","title":"Bodo 2021.11 Release (Date: 11/30/2021)","text":"<p>This release includes many new features, optimizations, bug fixes and usability improvements. Overall, 107 code patches were merged since the last release.</p>"},{"location":"release_notes/November_2021/#new-features-and-improvements","title":"New Features and Improvements","text":"<ul> <li> <p>Support for \"wide\" DataFrames with large number of columns:</p> <ul> <li> <p>Bodo compiler is transitioning to a new internal dataframe     compilation format that substantially decreases compliation time     for dataframes with thousands of columns.</p> <p>All DataFrame APIs will transition to this new format over time.</p> </li> <li> <p><code>read_csv</code>, <code>read_parquet</code>, <code>bodo.gatherv</code> and dataframe     filtering are upgraded to support this new format in this     release.</p> </li> <li>Connectors:</li> <li>Significantly improved performance when reading Parquet from S3     (up to 10x faster read depending on the dataset).</li> <li>General support for predicate pushdown when reading from Parquet     (filtering rows at the storage level).</li> <li>Improvements to BodoSQL's filter pushdown, such as higher     compiler accuracy in detecting possible filters.</li> <li>Faster <code>read_parquet</code> compilation time by validating the schema     only at runtime.</li> <li>Faster <code>pd.read_csv()</code> execution time with large numbers of     columns.</li> <li>Bodo automatically maintains type information when passing DataFrames and Series between Bodo and regular Python. This avoids potential typing issues when parallel data chunks do not have enough non-null data for automatic type inference.</li> <li>Improved error messages and documentation.</li> <li>Pandas:</li> <li>Support for Array of dictionary outputs of <code>DataFrame.apply()</code>     and <code>Series.apply()</code></li> <li>Support for Array of dictionary inputs to <code>pd.concat()</code></li> <li>Support for <code>Series.astype(str)</code> with Categorical type for     non-string categories.</li> <li>Support for callable arguments to <code>DataFrame.assign()</code></li> <li>Support for passing a list as <code>skiprows</code> of <code>pd.read_csv()</code></li> <li>Support for <code>low_memory</code> argument in <code>pd.read_csv()</code></li> <li>Support for using a string label for indexing Series with string     Index (for non-parallel Series)</li> <li>Support for initializing a Series with a constant dictionary</li> <li>Support for <code>subset</code> argument to <code>DataFrame.drop_duplicates</code></li> <li>Support for <code>DataFrame.plot</code> with arguments <code>x</code>, <code>y</code>, <code>kind</code>,     <code>figsize</code>, <code>xlabel</code>, <code>ylabel</code>, <code>title</code>, <code>legend</code>, <code>fontsize</code>,     <code>xticks</code>, <code>yticks</code>, and <code>ax</code>. <code>DataFrame.plot</code> behaves the same     as Bodo's Matplotlib support.</li> <li>Support for <code>DataFrame.groupby.head</code></li> <li>Numpy:</li> <li>Support for <code>np.select</code></li> <li>ML:</li> <li>Support <code>predict_proba</code> and <code>predict_log_proba</code> for     <code>RandomForestClassifier</code>, <code>SGD Classifier</code> and     <code>LogisticRegression</code></li> <li>Support <code>predict_proba</code> for XGBoostClassifier</li> <li>Support for <code>sklearn.metrics.confusion_matrix</code></li> </ul> </li> </ul> <p>BodoSQL 2021.11beta Release (Date: 11/30/2021)</p> <p>This release includes SQL bug fixes and support for Bodo's filter pushdown from BodoSQL. Most of the improvements to BodoSQL are integrating enhancements made to Bodo. Overall, 10 code patches were merged since the last release.</p>"},{"location":"release_notes/November_2021/#new-features-and-improvements_1","title":"New Features and Improvements","text":"<ul> <li> <p>Support for a new filepath API <code>bodosql.TablePath</code>. This API takes     the path and file type and uses this to load/remove the data within     the query.</p> <p>For example:</p> <pre><code>bc = bodosql.BodoSQLContext(\"table1\": bodosql.TablePath(\"myfile.pq\", \"parquet\"))\nreturn bc.query(\"Select A from table1\")\n</code></pre> <p>This is functionally equivalent to using the Pandas <code>read_</code> functions inside a Bodo function, but it may have some additional performance optimizations.</p> <p>Currently only Parquet files are supported.</p> </li> <li> <p>Support for Bodo's filter pushdown when using the     <code>bodosql.TablePath</code> API.</p> </li> <li> <p>Reduced compliation and execution time when using the <code>FIRST_VALUE</code>     function repeatedly on the same exact window.</p> </li> <li> <p>SQL Coverage</p> <p>This release added the following additional SQL coverage to BodoSQL. Please refer to our documentation for more details regarding usage.</p> <ul> <li>Support for omitting the second argument from the <code>ROUND</code>     function (defaults to 0).</li> <li>Support for providing an integer as the second argument     <code>DATE_ADD</code> and <code>DATE_SUB</code>. If you pass     an integer, it is assigned <code>days</code> as its unit.</li> </ul> </li> </ul>"},{"location":"release_notes/October_2020/","title":"Bodo 2020.10 Release (Date: 10/20/2020)","text":"<p>This release includes many new features, bug fixes and performance improvements. Overall, 117 code patches were merged since the last release.</p>"},{"location":"release_notes/October_2020/#new-features-and-improvements","title":"New Features and Improvements","text":"<ul> <li> <p>Initial support for Python classes using <code>bodo.jitclass</code> decorator.</p> </li> <li> Scikit-learn: <ul> <li></li> </ul> <pre><code>    Initial support for these scikit-learn classes:\n\n    :   -   `sklearn.linear_model.SGDClassifier`\n        -   `sklearn.linear_model.SGDRegressor`\n        -   `sklearn.cluster.KMeans`\n\n        For more information please refer to the documentation\n        [here](https://docs.bodo.ai/latest/source/sklearn.html)\n\n-   Improved scaling of `RandomForestClassifier` training\n</code></pre> </li> <li> <p>Memory management and memory consumption improvements</p> </li> <li> Improvements for User-defined functions (UDFs): <ul> <li>Compilation errors are now clearly shown for UDFs</li> <li>Support more complex UDFs (by running a full compiler     pipeline)</li> <li>Support passing keyword arguments to UDF in     <code>DataFrame.apply()</code> and <code>Series.apply()</code></li> <li>Support much wider range of UDF types in <code>groupby.agg</code></li> </ul> </li> <li> Connectors: <ul> <li>Improved connector error handling</li> <li>Improved performance of <code>pd.read_csv</code> (further improvements     in next release)</li> <li><code>pd.read_parquet</code> supports column containing all NA (null)     values</li> </ul> </li> <li> <p>Caching: for Bodo functions that receive parquet file names as     string arguments, the cache will now be reused when file name     arguments differ but have the same parquet dataset type (schema).</p> </li> <li> <p>Significantly improved the performance of merge/join operations in     some cases</p> </li> <li> <p>Support for loops over dataframe columns by automatic loop     unrolling</p> </li> <li> <p>Support using global dataframe/array values inside jit functions</p> </li> <li> <p>Performance optimization for the <code>series.str.split().explode()</code>     pattern</p> </li> <li> Pandas coverage: <ul> <li>Support setting <code>df.columns</code> and <code>df.index</code></li> <li>Support setting values in Categorical arrays</li> <li><code>series.str.split</code>: added support for regular expression and     <code>n</code> parameter</li> <li><code>Series.replace</code> support for more array types</li> <li>Support <code>pd.series.dt.quarter</code></li> <li>Support <code>series.str.slice_replace</code></li> <li>Support <code>series.str.repeat</code></li> <li>Improved support for <code>df.pivot_table</code> and <code>pd.crosstab</code></li> <li>Support for <code>Series.notnull</code></li> <li>Support integer label indexing for Dataframes and Series     with RangeIndex</li> <li>Support setting <code>None</code> and <code>Optional</code> values for most arrays</li> </ul> </li> <li> NumPy coverage: <ul> <li>Support for <code>np.union1d</code></li> <li><code>np.where</code>, <code>np.unique</code>, <code>np.sort</code>, <code>np.repeat</code>: support for     Series and most array types</li> <li>Support <code>np.argmax</code> with <code>axis=1</code></li> <li>Support for <code>np.min</code>, <code>np.max</code>, <code>min</code>, <code>max</code>, <code>np.sum</code>,     <code>sum</code>, <code>np.prod</code> on nullable arrays</li> </ul> </li> </ul>"},{"location":"release_notes/October_2021/","title":"Bodo 2021.10 Release (Date: 10/28/2021)","text":"<p>This release includes many new features, optimizations, bug fixes and usability improvements. Overall, 71 code patches were merged since the last release.</p>"},{"location":"release_notes/October_2021/#new-features-and-improvements","title":"New Features and Improvements","text":"<ul> <li> <p>The Bodo Community Edition can now run on up to 8 cores.</p> </li> <li> <p>Bodo is updated to use Numba 0.54.1 (latest).</p> </li> <li> <p>Improved error messages and documentation.</p> </li> <li> <p>Connectors:</p> <ul> <li><code>pandas.read_csv</code>: support for <code>chunksize</code> and <code>nrows</code>     parameters </li> <li>Snowflake: <ul> <li>Improved performance and scalability using the new     parallel fetch functionality of Snowflake's Python     connector, which retrieves data as batches of Arrow     tables</li> <li>Support for removing unused columns from the SQL query.</li> <li>Support for filter pushdown of Pandas comparison     operations into the SQL query.</li> </ul> </li> </ul> </li> <li> <p>Reduced compilation time for <code>DataFrame.describe</code></p> </li> <li> <p>Pandas:</p> <ul> <li><code>DataFrame.sort_values</code>: supports passing <code>na_position</code> as a     list with one value per column.</li> </ul> </li> </ul> <p>BodoSQL 2021.10beta Release (Date: 10/28/2021)</p> <p>This release includes SQL bug fixes, increased SQL coverage and various usability improvements. Overall, 27 code patches were merged since the last release.</p>"},{"location":"release_notes/October_2021/#new-features-and-improvements_1","title":"New Features and Improvements","text":"<ul> <li> <p>Improved error messages with expanded documentation.</p> </li> <li> <p>Support for passing <code>CategoricalArray</code> and     <code>DateArray</code> to BodoSQL. BodoSQL will automatically     convert these arrays to supported types.</p> </li> <li> <p>SQL Coverage</p> <p>This release added the following additional SQL coverage to BodoSQL. Please refer to our documentation for more details regarding usage.</p> <ul> <li>Support for <code>TO_DATE</code> function</li> <li>Support for string column casting inside     <code>DATE_ADD</code> and <code>DATE_SUB</code></li> <li>Support for <code>nulls first</code> and <code>nulls last</code> inside <code>order by</code>.</li> <li>Support for String columns in Window Aggregation Functions.</li> <li>Provided more efficient implementations for <code>NVL</code> and <code>IFNULL</code>     when there is a column and a scalar.</li> </ul> </li> </ul>"},{"location":"release_notes/September_2020/","title":"Bodo 2020.09 Release (Date: 09/17/2020)","text":"<p>This release includes many new features, bug fixes and performance improvements. Overall, 88 code patches were merged since the last release.</p>"},{"location":"release_notes/September_2020/#new-features-and-improvements","title":"New Features and Improvements","text":"<ul> <li> <p>Bodo is updated to use the latest versions of Numba, pandas and     Arrow:</p> <ul> <li>Numba 0.51.2</li> <li>pandas 1.1.2</li> <li>Arrow 1.0.1</li> </ul> </li> <li> <p>Major improvements in memory management. Bodo's memory consumption     is reduced significantly by releasing memory as soon as possible in     various operations such as Join, GroupBy, and Sort.</p> </li> <li> <p>Significant improvements in checking and handling various errors in     I/O, providing clear error messages and graceful exits.</p> </li> <li> <p>Improvements in speed and scalability of <code>read_parquet</code>     when reading from directories with large number of files.</p> </li> <li> <p>Distributed diagnostics is improved to provide clear messages on why     a variable was assigned REP distribution.</p> </li> <li> <p>Improvements in caching support for I/O calls and groupby     user-defined functions (UDFs).</p> </li> <li> <p>Support for more distributed getitem/setitem cases on arrays.</p> </li> <li> <p>Improvements on checking for unsupported functions and optional     arguments.</p> </li> <li> <p>Significant performance improvements in groupby transformations     (e.g. <code>GroupBy.cumsum</code>).</p> </li> <li> <p>Enhanced support for <code>DataFrame.select_dtypes</code>.</p> </li> <li> <p>Support for <code>axis=1</code> in <code>DataFrame.var/std</code>.</p> </li> <li> <p>Support for <code>Series.autocorr</code>.</p> </li> <li> <p>Support for <code>Series.is_monotonic_increasing/is_monotonic_decreasing</code>.</p> </li> <li> <p>Support <code>pd.Series()</code> constructor with a scalar data     value.</p> </li> <li> <p>Support for <code>dayofweek</code>, <code>is_leap_year</code> and     <code>days_in_month</code> in <code>Timestamp</code> and     `Series.dt]{.title-ref}.</p> </li> <li> <p>Support for <code>isocalendar</code> in <code>Series.dt</code> and     <code>DatetimeIndex</code>.</p> </li> <li> <p>Support for <code>Series.cumsum/cummin/cummax</code>.</p> </li> <li> <p>Support for <code>Decimal</code> values in nested data structures.</p> </li> <li> <p>Improvements in table join performance.</p> </li> <li> <p>Support for <code>Series.drop_duplicates</code>.</p> </li> <li> <p>Support for <code>np.dot</code> and <code>@</code> operator on     <code>Series</code>.</p> </li> <li> <p>Improvements in <code>pd.concat</code> support.</p> </li> <li> <p>Optimized <code>Series.astype(str)</code> for <code>int64</code>     values.</p> </li> <li> <p>Support for <code>pd.Index</code> constructor.</p> </li> </ul>"},{"location":"release_notes/September_2021/","title":"Bodo 2021.9 Release (Date: 9/29/2021)","text":"<p>This release includes many new features, optimizations, bug fixes and usability improvements. Overall, 98 code patches were merged since the last release.</p>"},{"location":"release_notes/September_2021/#new-features-and-improvements","title":"New Features and Improvements","text":"<ul> <li> <p>Bodo is updated to use Numba 0.54 (latest)</p> </li> <li> <p>Performance improvements:</p> <ul> <li>Significantly improved the performance and scalability of     parallel <code>merge</code> and <code>join</code> operations</li> <li>Improved the performance and scalability of <code>groupby.nunique</code></li> <li>General performance improvements for operations involving data     shuffling</li> <li>Optimized many compilation paths, especially those involving     DataFrames. This will lead to shorter compilation times for     many use cases.</li> <li>Optimizations in <code>pd.read_sql</code> to limit the data read when     <code>LIMIT</code> is provided.</li> </ul> </li> <li> <p>Pandas:</p> <ul> <li>Support for <code>Series.shift</code> on timedelta64 data</li> <li>Support for <code>pd.cut()</code> and <code>pd.qcut()</code></li> <li>Support for <code>first</code>, <code>last</code>, <code>median</code>, <code>nunique</code>, <code>prod</code>, and     <code>var</code> in <code>groupby.transform</code></li> <li>Support for multiplication with DateOffset</li> <li>Support for <code>Series.round()</code> on nullable integers</li> <li>Support for <code>to_strip</code> argument in     <code>series.str.strip/lstrip/rstrip</code></li> <li>Increased Binary Array/Series/DataFrame support. In particular:<ul> <li>Support for <code>first</code>, <code>last</code>, <code>shift</code>, <code>count</code>, <code>nunique</code>,     <code>size</code>, <code>value_counts</code> for Binary Series and DataFrames.</li> <li>Groupby support with binary keys/values.</li> <li>Support for <code>sort_values</code> with binary columns.</li> <li>Join with binary keys</li> <li>Most generic Series/DataFrame operations.</li> </ul> </li> <li>Support for equi-join with additional non-equi-join conditions     through our general merge condition syntax. Please refer to the     documentation for more information.</li> </ul> </li> </ul> <p>BodoSQL 2021.9beta Release (Date: 9/29/2021)</p> <p>This release adds SQL bug fixes and various usability improvements, including a reduced package size. BodoSQL users should also benefit from compilation time improvements due to improvements in the engine. Overall, 25 code patches were merged since the last release.</p>"},{"location":"release_notes/September_2021/#new-features-and-improvements_1","title":"New Features and Improvements","text":"<ul> <li> <p>Decreased package size and removed external dependencies.</p> </li> <li> <p>Improved error messages with shortened stack traces.</p> </li> <li> <p>SQL Coverage</p> <p>This release added the following additional SQL coverage to BodoSQL. Please refer to our documentation for more details regarding usage.</p> <ul> <li>Support for <code>UTC_TIMESTAMP</code> function </li> <li>Support for <code>UTC_DATE</code> function </li> <li>Support for <code>PIVOT</code> </li> <li>Support for the following Window Functions: <ul> <li><code>MAX</code></li> <li><code>MIN</code></li> <li><code>COUNT/COUNT(*)</code></li> <li><code>SUM</code></li> <li><code>AVG</code></li> <li><code>STDDEV</code></li> <li><code>STDDEV_POP</code></li> <li><code>VARIANCE</code></li> <li><code>VAR_POP</code></li> <li><code>LEAD</code></li> <li><code>LAG</code></li> <li><code>FIRST_VALUE</code></li> <li><code>LAST_VALUE</code></li> <li><code>NTH_VALUE</code></li> <li><code>NTILE</code></li> <li><code>ROW_NUMBER</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"release_notes/September_2022/","title":"Bodo 2022.9 Release (Date: 09/31/2022)","text":""},{"location":"release_notes/September_2022/#new-features-and-improvements","title":"New Features and Improvements","text":"<p>Compilation / Performance improvements:</p> <ul> <li>Passing string data from Bodo JIT to Python and back (boxing/unboxing) is now much faster using the new Arrow support in Pandas. Dictionary-encoded (compressed) string arrays stay dictionary-encoded between calls.</li> <li>Optimized <code>pd.to_numeric()</code> for compressed string data.</li> <li>Support for compressed strings in <code>read_csv()</code> using user-specified argument (<code>\u201c_bodo_read_as_dict\u201c</code>).</li> </ul> <p>I/O:</p> <ul> <li>Support for loading no data columns from Iceberg and Snowflake when just returning the length of a table.</li> <li>Support for limit pushdown with Snowflake.</li> <li>Update the verbose logging API to track limit pushdown with verbose level 1.</li> </ul> <p>Iceberg:</p> <ul> <li>Support for appending to Iceberg tables with pre-defined partition spec and/or sort-order.</li> <li>Support for compressed string read from Iceberg tables.</li> </ul> <p>BodoSQL:</p> <ul> <li>Introduced the <code>SnowflakeCatalog</code> object so users can connect their Snowflake account to BodoSQL easily. When added to a <code>BodoSQLContext</code>, BodoSQL will directly search and load tables from inside Snowflake. For more information please refer to the documentation.</li> <li>Added <code>BodoSQLContext</code> methods <code>add_or_replace_view</code>, <code>remove_view</code>, <code>add_catalog</code>, and <code>remove_catalog</code> for creating an updated <code>BodoSQLContext</code>.</li> <li>BodoSQL now pushes limits in front of projections/element-wise functions to enable limit pushdown in most queries.</li> <li>If passing unsupported types to BodoSQL, BodoSQL will now attempt to process the query without using those columns. This enables compilation when using only the columns in the table with supported types.</li> <li><code>LEAD</code> and <code>LAG</code> now support an optional fill value argument, and the explicit <code>RESPECT_NULLS</code> syntax.</li> <li>Support for explicitly passing <code>NULL</code> for the fill value.</li> <li>Support for issuing a delete query in Snowflake using <code>SnowflakeCatalog</code>. This works by pushing the entire query directly into Snowflake.</li> <li>Support for <code>ILIKE</code> operator</li> <li>Support for <code>CONTAINS</code> operator</li> <li>Support for <code>MEDIAN</code> aggregate function</li> <li>Support for <code>SQUARE</code>, <code>CBRT</code>, <code>FACTORIAL</code> functions</li> <li>Support for aliases <code>VARIANCE_POP</code> and <code>VARIANCE_SAMP</code>.</li> <li>Support for <code>NEXT_DAY</code> and <code>PREVIOUS_DAY</code>.</li> </ul>"}]}