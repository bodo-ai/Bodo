{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sophisticated-philadelphia",
   "metadata": {},
   "source": [
    "# Predicting Flight Delays\n",
    "\n",
    "This example shows use of classification models to predict flight delays. \n",
    "Original example can be found [here](https://github.com/frenchlam/dask_CDSW/blob/master/03_Dask_ML-LargeDS.ipynb) (dataset is [here](https://github.com/frenchlam/dask_CDSW/blob/master/data/1988.csv.bz2))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "narrative-landing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bodo\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-mortgage",
   "metadata": {},
   "source": [
    "## Pre-processing in Pandas\n",
    "\n",
    "### Read flights dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "relative-advertising",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Month  DayofMonth  DayOfWeek  CRSDepTime  ...  FlightNum Origin  Dest Cancelled\n",
      "0      1           9          6        1331  ...        942    SYR   BWI         0\n",
      "1      1          10          7        1331  ...        942    SYR   BWI         0\n",
      "2      1          11          1        1331  ...        942    SYR   BWI         0\n",
      "3      1          12          2        1331  ...        942    SYR   BWI         0\n",
      "4      1          13          3        1331  ...        942    SYR   BWI         0\n",
      "\n",
      "[5 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "@bodo.jit(cache=True)\n",
    "def read_flights(input_file):\n",
    "    flight_df = pd.read_csv(input_file, sep=',', header=0,\n",
    "        usecols=['Month', 'DayofMonth', 'DayOfWeek', 'CRSDepTime', 'CRSArrTime', 'UniqueCarrier', 'FlightNum', 'Origin', 'Dest','Cancelled'])    \n",
    "    print(flight_df.head())    \n",
    "    return flight_df\n",
    "\n",
    "input_file = \"s3://bodo-example-data/flights/1988.csv.bz2\"\n",
    "flight_df = read_flights(input_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-anatomy",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "Create routes from origin and destination:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stainless-ceiling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "route\n",
      "LAX_SFO    20750\n",
      "SFO_LAX    20658\n",
      "LAX_PHX    13461\n",
      "PHX_LAX    13273\n",
      "LAX_LAS    12175\n",
      "LGA_BOS    12027\n",
      "LAS_LAX    11801\n",
      "SJC_LAX    11535\n",
      "LAX_SJC    11292\n",
      "BOS_LGA    11141\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "@bodo.jit(cache=True)\n",
    "def create_routes(flight_df):\n",
    "    flight_df['route'] = flight_df['Origin'] + \"_\" + flight_df['Dest']\n",
    "    # show top 20 routes - As defined by nb of flights\n",
    "    top_routes = flight_df['route'].value_counts(ascending=False)\n",
    "    print(top_routes.head(10))\n",
    "    # focus on 50 biggest routes - As defined by nb of flights \n",
    "    route_lst = top_routes.head(50)\n",
    "    flight_df = flight_df[flight_df['route'].isin(route_lst.index)]\n",
    "    return flight_df\n",
    "\n",
    "flight_df = create_routes(flight_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-draft",
   "metadata": {},
   "source": [
    "Look at their cancellations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "thousand-vinyl",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      route  count  nb_cancelled\n",
      "0   LAX_SFO  20750           228\n",
      "32  SFO_LAX  20658           206\n",
      "43  LAX_PHX  13461            78\n",
      "29  PHX_LAX  13273            71\n",
      "35  LAX_LAS  12175            58\n",
      "41  LGA_BOS  12027           287\n",
      "      route  count  nb_cancelled\n",
      "19  LAS_LAX  11801            47\n",
      "10  SJC_LAX  11535            71\n",
      "42  LAX_SJC  11292            71\n",
      "24  BOS_LGA  11141           243\n"
     ]
    }
   ],
   "source": [
    "@bodo.jit(cache=True)\n",
    "def check_cancelations(flight_df):\n",
    "    res = flight_df[['route', 'Cancelled', 'Month']].groupby(by='route')\\\n",
    "         .agg({'Month':'size', 'Cancelled':'sum'})\\\n",
    "        .rename(columns={'Month':'count','Cancelled':'nb_cancelled'}) \\\n",
    "        .reset_index()\\\n",
    "        .sort_values(['count'], ascending=False)\n",
    "    print(res.head(10))\n",
    "\n",
    "check_cancelations(flight_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0718a9d",
   "metadata": {},
   "source": [
    "Bodo automatically distributes the data on the worker processes. You can view this distribution by running the simple JIT'd function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "wrong-scoop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63970, 11)\n",
      "(64152, 11)\n",
      "(60700, 11)\n",
      "(58127, 11)\n",
      "(55781, 11)\n",
      "(66801, 11)\n",
      "(59454, 11)\n",
      "(58268, 11)\n"
     ]
    }
   ],
   "source": [
    "@bodo.wrap_python(bodo.types.none)\n",
    "def print_info(flight_df):\n",
    "    print(flight_df.shape)\n",
    "\n",
    "@bodo.jit\n",
    "def print_info_jit(flight_df):\n",
    "    print_info(flight_df)\n",
    "\n",
    "print_info_jit(flight_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-verse",
   "metadata": {},
   "source": [
    "Quick sanity check - count number of null values():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "charming-township",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month            0\n",
      "DayofMonth       0\n",
      "DayOfWeek        0\n",
      "CRSDepTime       0\n",
      "CRSArrTime       0\n",
      "UniqueCarrier    0\n",
      "FlightNum        0\n",
      "Origin           0\n",
      "Dest             0\n",
      "Cancelled        0\n",
      "route            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "@bodo.jit\n",
    "def check_count(flight_df):\n",
    "    print(flight_df.isnull().sum())\n",
    "    \n",
    "check_count(flight_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-anderson",
   "metadata": {},
   "source": [
    "### Feature and label encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-demographic",
   "metadata": {},
   "source": [
    "#### Encode Labels using Cancelled column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "designed-seafood",
   "metadata": {},
   "outputs": [],
   "source": [
    "@bodo.jit(cache=True)\n",
    "def encode_labels(flight_df):\n",
    "    flight_df['Cancelled'] = pd.Categorical(flight_df[\"Cancelled\"])\n",
    "    flight_df['Label'] = flight_df['Cancelled'].cat.codes\n",
    "    return flight_df.drop(['Cancelled'], axis=1)\n",
    "\n",
    "flight_df = encode_labels(flight_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fancy-basics",
   "metadata": {},
   "source": [
    "#### Feature Encoding\n",
    "\n",
    "This is needed because Scikit-learn only supports numerical values. Get airport unique values and encode origin, destination, and route features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "postal-williams",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "@bodo.jit(cache=True)\n",
    "def get_airport_list(flight_df):\n",
    "    airport_list = np.sort((pd.concat((flight_df['Origin'], flight_df['Dest']))).unique())\n",
    "    return airport_list\n",
    "\n",
    "airport_list = get_airport_list(flight_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "extra-macintosh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding time:  0.17063599999983126  sec\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "@bodo.jit(cache=True)\n",
    "def encode_features(flight_df, airport_list):\n",
    "    t1 = time.time()    \n",
    "    # encode airlines \n",
    "    le_carrier = LabelEncoder()\n",
    "    flight_df['Carrier_encoded'] = pd.Series(le_carrier.fit_transform(flight_df['UniqueCarrier'].values))\n",
    "    # Encode airports : Using same encoder for both origin and dest ( consistent encoding of airports )\n",
    "    le_airport = LabelEncoder()\n",
    "    le_airport.fit(airport_list)\n",
    "    flight_df['Origin_encoded'] = pd.Series(le_airport.transform(flight_df['Origin']))\n",
    "    flight_df['Dest_encoded'] = pd.Series(le_airport.transform(flight_df['Dest']))\n",
    "    # Encode routes \n",
    "    le_route = LabelEncoder()\n",
    "    flight_df['route_encoded'] = pd.Series(le_route.fit_transform(flight_df['route'].values))\n",
    "    print(\"Encoding time: \", (time.time()-t1), \" sec\")\n",
    "    return flight_df\n",
    "\n",
    "flight_df = encode_features(flight_df, airport_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "stupid-retrieval",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       UniqueCarrier  Carrier_encoded  ...    route  route_encoded\n",
      "207963            PI                8  ...  MCO_MIA             25\n",
      "450866            PS                9  ...  SFO_SEA             47\n",
      "\n",
      "[2 rows x 8 columns]\n",
      "        UniqueCarrier  Carrier_encoded  ...    route  route_encoded\n",
      "3704375            CO                2  ...  ORD_EWR             30\n",
      "3510950            TW               10  ...  SFO_LAX             45\n",
      "3889736            US               12  ...  SFO_LAX             45\n",
      "\n",
      "[3 rows x 8 columns]\n",
      "        UniqueCarrier  Carrier_encoded  ...    route  route_encoded\n",
      "2574835            US               12  ...  LAX_SEA             19\n",
      "2310854            NW                6  ...  ORD_DTW             29\n",
      "2094889            AA                0  ...  LAX_SFO             20\n",
      "\n",
      "[3 rows x 8 columns]\n",
      "        UniqueCarrier  Carrier_encoded  ...    route  route_encoded\n",
      "2614541            TW               10  ...  LAX_SFO             20\n",
      "3077243            UA               11  ...  DEN_ORD              8\n",
      "\n",
      "[2 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "@bodo.jit(cache=True)\n",
    "def sample(flight_df):\n",
    "    print(flight_df[['UniqueCarrier','Carrier_encoded','Origin','Origin_encoded',\n",
    "           'Dest', 'Dest_encoded', 'route', 'route_encoded' ]].sample(10))\n",
    "    \n",
    "sample(flight_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "saved-barcelona",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splitting time:  0.7646199999999226  sec\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "@bodo.jit(cache=True)\n",
    "def split_data(flight_df):\n",
    "    t1 = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(flight_df.drop(['UniqueCarrier','Origin','Dest','route'],axis=1),\n",
    "                                                    flight_df['Label'], \n",
    "                                                    test_size=0.3, train_size=0.7,\n",
    "                                                    random_state=100)\n",
    "    print(\"Data splitting time: \", (time.time()-t1), \" sec\")    \n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(flight_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-berkeley",
   "metadata": {},
   "source": [
    "## Model Training Using Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-cleaner",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fifth-greene",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier fit and predict time:  1.9505760000001828\n",
      "Accuracy score 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ehsan/dev/Bodo/.pixi/envs/default/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/ehsan/dev/Bodo/.pixi/envs/default/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/ehsan/dev/Bodo/.pixi/envs/default/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/ehsan/dev/Bodo/.pixi/envs/default/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/ehsan/dev/Bodo/.pixi/envs/default/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/ehsan/dev/Bodo/.pixi/envs/default/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/ehsan/dev/Bodo/.pixi/envs/default/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/ehsan/dev/Bodo/.pixi/envs/default/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score # evaluation metric\n",
    "\n",
    "@bodo.jit(cache=True)\n",
    "def rf_model(X_train, X_test, y_train, y_test):\n",
    "    start = time.time()\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X_train.to_numpy(), y_train.values)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    print(\"RandomForestClassifier fit and predict time: \", time.time()-start)    \n",
    "    print('Accuracy score {}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "rf_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-museum",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ready-allen",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ehsan/dev/Bodo/bodo/submit/worker.py:409: BodoWarning: Data is distributed so Bodo will fit model with SGD solver optimization (SGDClassifier)\n",
      "  res = func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression fit and predict time:  0.6519339999999829\n",
      "Accuracy score 0.9815770030647986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ehsan/dev/Bodo/.pixi/envs/default/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/ehsan/dev/Bodo/.pixi/envs/default/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/ehsan/dev/Bodo/.pixi/envs/default/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/ehsan/dev/Bodo/.pixi/envs/default/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/ehsan/dev/Bodo/.pixi/envs/default/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/ehsan/dev/Bodo/.pixi/envs/default/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/ehsan/dev/Bodo/.pixi/envs/default/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/ehsan/dev/Bodo/.pixi/envs/default/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score  # evaluation metric\n",
    "@bodo.jit(cache=True)\n",
    "def lr_model(X_train, X_test, y_train, y_test):\n",
    "    start = time.time()\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train, y_train.values)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    print(\"Logistic Regression fit and predict time: \", time.time()-start)    \n",
    "    print('Accuracy score {}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "lr_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cb7d20-22d8-4d13-aece-c528418c67dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16c8ad1c156570dbb9b8c59e261dba05f4270231d6ef51b3fb205099379bfe9f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
