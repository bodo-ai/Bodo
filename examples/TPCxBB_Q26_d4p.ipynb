{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "Connecting to backend execution cores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "c = ipp.Client(profile='mpi')\n",
    "view = c[:]\n",
    "view.activate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TPCxBB_Q26 Example Code\n",
    "Retail analytics example from [TPCxBB](http://www.tpc.org/tpcx-bb/default.asp): cluster customers into book buddies/club groups based on their in store book purchasing histories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import daal4py\n",
    "daal4py.daalinit(1); daal4py.my_procid()\n",
    "import bodo\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "@bodo.jit(distributed={'A'})\n",
    "def q26(ss_file, i_file, category, item_count):\n",
    "    t1 = time.time()\n",
    "    ss_dtype = {'ss_item_sk': np.int64, 'ss_customer_sk': np.int64}\n",
    "    store_sales = pd.read_csv(ss_file, sep='|', usecols=[2,3],\n",
    "        names=ss_dtype.keys(), dtype=ss_dtype)\n",
    "\n",
    "    i_dtype = {\n",
    "        'i_item_sk': np.int64, 'i_class_id': np.int32, 'i_category': str}\n",
    "    item = pd.read_csv(i_file, sep='|', usecols=[0, 9, 12],\n",
    "        names=i_dtype.keys(), dtype=i_dtype)\n",
    "\n",
    "    item2 = item[item['i_category']==category]\n",
    "    sale_items = pd.merge(\n",
    "        store_sales, item2, left_on='ss_item_sk', right_on='i_item_sk')\n",
    "\n",
    "    count1 = sale_items.groupby('ss_customer_sk')['ss_item_sk'].count()\n",
    "    gp1 = sale_items.groupby('ss_customer_sk')['i_class_id']\n",
    "\n",
    "    def id1(x): return (x==1).sum()\n",
    "    def id2(x): return (x==2).sum()\n",
    "    def id3(x): return (x==3).sum()\n",
    "    def id4(x): return (x==4).sum()\n",
    "    def id5(x): return (x==5).sum()\n",
    "    def id6(x): return (x==6).sum()\n",
    "    def id7(x): return (x==7).sum()\n",
    "    def id8(x): return (x==8).sum()\n",
    "    def id9(x): return (x==9).sum()\n",
    "    def id10(x): return (x==10).sum()\n",
    "    def id11(x): return (x==11).sum()\n",
    "    def id12(x): return (x==12).sum()\n",
    "    def id13(x): return (x==13).sum()\n",
    "    def id14(x): return (x==14).sum()\n",
    "    def id15(x): return (x==15).sum()\n",
    "\n",
    "    customer_i_class = gp1.agg((id1, id2, id3, id4, id5, id6, id7, id8, id9,\n",
    "        id10, id11, id12, id13, id14, id15))\n",
    "\n",
    "    customer_i_class['ss_item_count'] = count1\n",
    "\n",
    "    customer_i_class = customer_i_class[\n",
    "        customer_i_class.ss_item_count > item_count]\n",
    "    A = customer_i_class.values.astype(np.float64)\n",
    "#     print(\"checksum\", res)\n",
    "    print(\"exec time\", time.time()-t1)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] exec time 8.02197103598155\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "ss_file = \"/Users/ehsan/dev/sw/data/store_sales_10.dat\"\n",
    "i_file =  \"/Users/ehsan/dev/sw/data/item_10.dat\"\n",
    "q26_i_category_IN = 'Books'\n",
    "q26_count_ss_item_sk = 5\n",
    "A = q26(ss_file, i_file, q26_i_category_IN, q26_count_ss_item_sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-33b5bcd979bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'px'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'--block'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"num_centroids = 5\\ncentroids = daal4py.kmeans_init(\\n    num_centroids, method='plusPlusDense', distributed=True).compute(\\n        A).centroids\\nmodel = daal4py.kmeans(num_centroids, 30, distributed=True).compute(\\n    A, centroids).centroids\\ndaal4py.daalfini()\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda3/envs/DEV/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2357\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2358\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2359\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2360\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/DEV/lib/python3.7/site-packages/ipyparallel/client/magics.py\u001b[0m in \u001b[0;36mcell_px\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    319\u001b[0m             ar = self.parallel_execute(cell, block=block,\n\u001b[1;32m    320\u001b[0m                                 \u001b[0mgroupby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m                                 \u001b[0msave_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             )\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/DEV/lib/python3.7/site-packages/ipyparallel/client/magics.py\u001b[0m in \u001b[0;36mparallel_execute\u001b[0;34m(self, cell, block, groupby, save_name)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/DEV/lib/python3.7/site-packages/ipyparallel/client/asyncresult.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \"\"\"\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/DEV/lib/python3.7/site-packages/ipyparallel/client/asyncresult.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/DEV/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/DEV/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "num_centroids = 5\n",
    "centroids = daal4py.kmeans_init(\n",
    "    num_centroids, method='plusPlusDense', distributed=True).compute(\n",
    "        A).centroids\n",
    "model = daal4py.kmeans(num_centroids, 30, distributed=True).compute(\n",
    "    A, centroids).centroids\n",
    "daal4py.daalfini()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Version\n",
    "The same computation in regular Python takes a long time, especially since user-defined aggregate functions are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bodo\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "def q26(ss_file, i_file, category, item_count):\n",
    "    t1 = time.time()\n",
    "    ss_dtype = {'ss_item_sk': np.int64, 'ss_customer_sk': np.int64}\n",
    "    store_sales = pd.read_csv(ss_file, sep='|', usecols=[2,3],\n",
    "        names=ss_dtype.keys(), dtype=ss_dtype)\n",
    "\n",
    "    i_dtype = {\n",
    "        'i_item_sk': np.int64, 'i_class_id': np.int32, 'i_category': str}\n",
    "    item = pd.read_csv(i_file, sep='|', usecols=[0, 9, 12],\n",
    "        names=i_dtype.keys(), dtype=i_dtype)\n",
    "\n",
    "    item2 = item[item['i_category']==category]\n",
    "    sale_items = pd.merge(\n",
    "        store_sales, item2, left_on='ss_item_sk', right_on='i_item_sk')\n",
    "\n",
    "    count1 = sale_items.groupby('ss_customer_sk')['ss_item_sk'].count()\n",
    "    gp1 = sale_items.groupby('ss_customer_sk')['i_class_id']\n",
    "\n",
    "    def id1(x): return (x==1).sum()\n",
    "    def id2(x): return (x==2).sum()\n",
    "    def id3(x): return (x==3).sum()\n",
    "    def id4(x): return (x==4).sum()\n",
    "    def id5(x): return (x==5).sum()\n",
    "    def id6(x): return (x==6).sum()\n",
    "    def id7(x): return (x==7).sum()\n",
    "    def id8(x): return (x==8).sum()\n",
    "    def id9(x): return (x==9).sum()\n",
    "    def id10(x): return (x==10).sum()\n",
    "    def id11(x): return (x==11).sum()\n",
    "    def id12(x): return (x==12).sum()\n",
    "    def id13(x): return (x==13).sum()\n",
    "    def id14(x): return (x==14).sum()\n",
    "    def id15(x): return (x==15).sum()\n",
    "\n",
    "    customer_i_class = gp1.agg((id1, id2, id3, id4, id5, id6, id7, id8, id9,\n",
    "        id10, id11, id12, id13, id14, id15))\n",
    "\n",
    "    customer_i_class['ss_item_count'] = count1\n",
    "\n",
    "    customer_i_class = customer_i_class[\n",
    "        customer_i_class.ss_item_count > item_count]\n",
    "    res = customer_i_class.values.astype(np.float64).sum()\n",
    "    print(\"checksum\", res)\n",
    "    print(\"exec time\", time.time()-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checksum 3380326.0\n",
      "exec time 715.5162229537964\n"
     ]
    }
   ],
   "source": [
    "ss_file = \"/Users/ehsan/dev/sw/data/store_sales_10.dat\"\n",
    "i_file =  \"/Users/ehsan/dev/sw/data/item_10.dat\"\n",
    "q26_i_category_IN = 'Books'\n",
    "q26_count_ss_item_sk = 5\n",
    "q26(ss_file, i_file, q26_i_category_IN, q26_count_ss_item_sk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This computation takes 715.5 seconds on Python but only 3.27 seconds on Bodo (220x speedup on 8 cores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark/Scala/SQL Version\n",
    "The Spark/Scala/SQL version of the same code is much more complicated, and is also much slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.{SparkConf, SparkContext}\n",
    "import org.apache.spark.SparkContext._\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.DataFrame\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.SQLContext\n",
    "import org.apache.spark.sql.functions._\n",
    "import scala.language.existentials\n",
    "\n",
    "import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n",
    "import org.apache.spark.sql.catalyst.TableIdentifier\n",
    "import org.apache.spark.sql.execution.joins._\n",
    "\n",
    "import org.apache.spark.ml.clustering.{KMeansModel, KMeans}\n",
    "import org.apache.spark.ml.linalg.{Vector, Vectors}\n",
    "import org.apache.spark.ml.feature.VectorAssembler\n",
    "import org.apache.spark.rdd.RDD\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n",
    "import scala.language.reflectiveCalls\n",
    "import java.lang.management.ManagementFactory\n",
    "import scala.collection.JavaConversions._\n",
    "\n",
    "object Query26 {\n",
    "  def main(args: Array[String]) {\n",
    "    // Starting time\n",
    "    val t0 = System.currentTimeMillis\n",
    "    val spark = SparkSession\n",
    "      .builder()\n",
    "      .appName(\"Q26\")\n",
    "      .config(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\")\n",
    "      .getOrCreate()\n",
    "\n",
    "    import spark.implicits._\n",
    "    val table_store_sales_path = args(0)\n",
    "    val table_item_path = args(1)\n",
    "\n",
    "    val schema_store_sales = StructType(Array(\n",
    "      StructField(\"ss_sold_date_sk\", LongType, true),\n",
    "      StructField(\"ss_sold_time_sk\", LongType, true),\n",
    "      StructField(\"ss_item_sk\", LongType, true),\n",
    "      StructField(\"ss_customer_sk\", LongType, true),\n",
    "      StructField(\"ss_cdemo_sk\", LongType, true),\n",
    "      StructField(\"ss_hdemo_sk\", LongType, true),\n",
    "      StructField(\"ss_addr_sk\", LongType, true),\n",
    "      StructField(\"ss_store_sk\", LongType, true),\n",
    "      StructField(\"ss_promo_sk\", LongType, true),\n",
    "      StructField(\"ss_ticket_number\", LongType, true),\n",
    "      StructField(\"ss_quantity\", IntegerType, true),\n",
    "      StructField(\"ss_wholesale_cost\", FloatType, true),\n",
    "      StructField(\"ss_list_price\", FloatType, true),\n",
    "      StructField(\"ss_sales_price\", FloatType, true),\n",
    "      StructField(\"ss_ext_discount_amt\", FloatType, true),\n",
    "      StructField(\"ss_ext_sales_price\", FloatType, true),\n",
    "      StructField(\"ss_ext_wholesale_cost\", FloatType, true),\n",
    "      StructField(\"ss_ext_list_price\", FloatType, true),\n",
    "      StructField(\"ss_ext_tax\", FloatType, true),\n",
    "      StructField(\"ss_coupon_amt\", FloatType, true),\n",
    "      StructField(\"ss_net_paid\", FloatType, true),\n",
    "      StructField(\"ss_net_paid_inc_tax\", FloatType, true),\n",
    "      StructField(\"ss_net_profit\", FloatType, true)\n",
    "      ))\n",
    "    val df_store_sales = spark.read.schema(schema_store_sales).format(\"csv\").option(\"sep\", \"|\").load(table_store_sales_path)\n",
    "\n",
    "    val schema_item = StructType(Array(\n",
    "      StructField(\"i_item_sk\", LongType, true),\n",
    "      StructField(\"i_item_id\", StringType, true),\n",
    "      StructField(\"i_rec_start_date\", StringType, true),\n",
    "      StructField(\"i_rec_end_date\", StringType, true),\n",
    "      StructField(\"i_item_desc\", StringType, true),\n",
    "      StructField(\"i_current_price\", FloatType, true),\n",
    "      StructField(\"i_wholesale_cost\", FloatType, true),\n",
    "      StructField(\"i_brand_id\", IntegerType, true),\n",
    "      StructField(\"i_brand\", StringType, true),\n",
    "      StructField(\"i_class_id\", IntegerType, true),\n",
    "      StructField(\"i_class\", StringType, true),\n",
    "      StructField(\"i_category_id\", IntegerType, true),\n",
    "      StructField(\"i_category\", StringType, true),\n",
    "      StructField(\"i_manufact_id\", IntegerType, true),\n",
    "      StructField(\"i_manufact\", StringType, true),\n",
    "      StructField(\"i_size\", StringType, true),\n",
    "      StructField(\"i_formulation\", StringType, true),\n",
    "      StructField(\"i_color\", StringType, true),\n",
    "      StructField(\"i_units\", StringType, true),\n",
    "      StructField(\"i_container\", StringType, true),\n",
    "      StructField(\"i_manager_id\", IntegerType, true),\n",
    "      StructField(\"i_product_name\", StringType, true)\n",
    "      ))\n",
    "\n",
    "    val df_item = spark.read.schema(schema_item).format(\"csv\").option(\"sep\", \"|\").load(table_item_path)\n",
    "    // val df_item = spark.read.parquet(table_item_path)\n",
    "\n",
    "    df_store_sales.registerTempTable(\"store_sales_table\")\n",
    "    df_item.registerTempTable(\"item_table\")\n",
    "    // collect() fails so using first()\n",
    "    // df_store_sales.cache().first()\n",
    "    // df_item.cache().first()\n",
    "\n",
    "    val fin  = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "  ss.ss_customer_sk AS cid,\n",
    "  count(CASE WHEN i.i_class_id=1  THEN 1 ELSE NULL END) AS id1,\n",
    "  count(CASE WHEN i.i_class_id=2  THEN 1 ELSE NULL END) AS id2,\n",
    "  count(CASE WHEN i.i_class_id=3  THEN 1 ELSE NULL END) AS id3,\n",
    "  count(CASE WHEN i.i_class_id=4  THEN 1 ELSE NULL END) AS id4,\n",
    "  count(CASE WHEN i.i_class_id=5  THEN 1 ELSE NULL END) AS id5,\n",
    "  count(CASE WHEN i.i_class_id=6  THEN 1 ELSE NULL END) AS id6,\n",
    "  count(CASE WHEN i.i_class_id=7  THEN 1 ELSE NULL END) AS id7,\n",
    "  count(CASE WHEN i.i_class_id=8  THEN 1 ELSE NULL END) AS id8,\n",
    "  count(CASE WHEN i.i_class_id=9  THEN 1 ELSE NULL END) AS id9,\n",
    "  count(CASE WHEN i.i_class_id=10 THEN 1 ELSE NULL END) AS id10,\n",
    "  count(CASE WHEN i.i_class_id=11 THEN 1 ELSE NULL END) AS id11,\n",
    "  count(CASE WHEN i.i_class_id=12 THEN 1 ELSE NULL END) AS id12,\n",
    "  count(CASE WHEN i.i_class_id=13 THEN 1 ELSE NULL END) AS id13,\n",
    "  count(CASE WHEN i.i_class_id=14 THEN 1 ELSE NULL END) AS id14,\n",
    "  count(CASE WHEN i.i_class_id=15 THEN 1 ELSE NULL END) AS id15\n",
    "FROM store_sales_table ss\n",
    "INNER JOIN item_table i\n",
    "  ON (ss.ss_item_sk = i.i_item_sk AND i.i_category = \"Books\"\n",
    "  AND ss.ss_customer_sk IS NOT NULL\n",
    ")\n",
    "GROUP BY ss.ss_customer_sk\n",
    "HAVING count(ss.ss_item_sk) > 5\n",
    "    \"\"\")\n",
    "    val assembler = new VectorAssembler().setInputCols(\n",
    "      Array(\"id1\", \"id2\", \"id3\",\"id4\",\"id5\",\"id6\",\"id7\",\n",
    "      \"id8\",\"id9\",\"id10\",\"id11\",\"id12\",\"id13\",\"id14\",\"id15\")).setOutputCol(\"features\")\n",
    "    val ds = assembler.transform(fin)\n",
    "    ds.cache.first\n",
    "    val t1 = System.currentTimeMillis\n",
    "\n",
    "    // Measure time\n",
    "    println(\"Query 26 time(s) took: \" + (t1 - t0).toFloat / 1000)\n",
    "  }\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
