{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bodo Getting Started Tutorial\n",
    "\n",
    "In a nutshell, Bodo provides a just-in-time (JIT) compilation workflow using the `@bodo.jit` decorator.\n",
    "It replaces decorated Python functions with an optimized and parallelized binary version under the hood.\n",
    "\n",
    "In this tutorial, we will cover the basics of using Bodo and explain its important concepts. We strongly recommend reading this page before using Bodo.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parallel Pandas with Bodo\n",
    "First, we demonstrate how Bodo automatically parallelizes and optimizes standard Python programs that make use of pandas and NumPy, without the need to rewrite your code. Bodo can scale your analytics code to thousands of cores, providing orders of magnitude speed up depending on program characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_rows = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data\n",
    "To begin, let's generate a simple dataset and write to a [Parquet](http://parquet.apache.org/) file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 A        B\n",
      "0              NaT        0\n",
      "...            ...      ...\n",
      "9999999 2015-09-29  9999999\n",
      "\n",
      "[10000000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 10m data points\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"A\": np.repeat(pd.date_range(\"2013-01-03\", periods=1000), 10_000),\n",
    "        \"B\": np.arange(10_000_000),\n",
    "    }\n",
    ")\n",
    "# set some values to NA\n",
    "df.iloc[np.arange(1000) * 3, 0] = pd.NA\n",
    "# using row_group_size helps with efficient parallel read of data later\n",
    "df.to_parquet(\"pd_example.pq\", row_group_size=100000)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Code in Pandas\n",
    "Here is a simple data transformation code in Pandas that processes a column of datetime values and creates two new columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 61.33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999999</th>\n",
       "      <td>2015-09-29</td>\n",
       "      <td>P2</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 A   B    C\n",
       "0              NaT  NA  NaN\n",
       "...            ...  ..  ...\n",
       "9999999 2015-09-29  P2  9.0\n",
       "\n",
       "[10000000 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def data_transform():\n",
    "    t0 = time.time()\n",
    "    df = pd.read_parquet(\"pd_example.pq\")\n",
    "    df[\"B\"] = df.apply(lambda r: \"NA\" if pd.isna(r.A) else \"P1\" if r.A.month < 5 else \"P2\", axis=1)\n",
    "    df[\"C\"] = df.A.dt.month\n",
    "    print(\"Total time: {:.2f}\".format(time.time()-t0))\n",
    "    return df\n",
    "\n",
    "data_transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard Python is quite slow for these data transforms since\n",
    "1. The use of custom code inside apply() does not let Pandas run an optimized prebuilt C library in its backend. Therefore, the Python interpreter overheads dominate.\n",
    "2. Python uses just a single CPU core and does not parallelize computation.\n",
    "\n",
    "Bodo solves both of these problems as we demonstrate below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Bodo JIT Decorator\n",
    "Bodo optimizes and parallelizes data workloads by providing just-in-time (JIT) compilation. To run the code with Bodo, all that we have to do is add the `bodo.jit` decorator to the function (`distributed=False` for now to use a single core)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 1.04\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NA</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999999</th>\n",
       "      <td>2015-09-29</td>\n",
       "      <td>P2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 A   B     C\n",
       "0              NaT  NA  <NA>\n",
       "...            ...  ..   ...\n",
       "9999999 2015-09-29  P2     9\n",
       "\n",
       "[10000000 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import bodo\n",
    "import time\n",
    "\n",
    "@bodo.jit(distributed=False)\n",
    "def data_transform():\n",
    "    t0 = time.time()\n",
    "    df = pd.read_parquet(\"pd_example.pq\")\n",
    "    df[\"B\"] = df.apply(lambda r: \"NA\" if pd.isna(r.A) else \"P1\" if r.A.month < 5 else \"P2\", axis=1)\n",
    "    df[\"C\"] = df.A.dt.month\n",
    "    print(\"Total time: {:.2f}\".format(time.time()-t0))\n",
    "    return df\n",
    "\n",
    "data_transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the code is still running on a single core, it is ~60x faster because Bodo compiles the function into a native binary, eliminating the interpreter overheads in apply.\n",
    "\n",
    "Now let’s run the code on all available cores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 0.32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NA</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999999</th>\n",
       "      <td>2015-09-29</td>\n",
       "      <td>P2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 A   B     C\n",
       "0              NaT  NA  <NA>\n",
       "...            ...  ..   ...\n",
       "9999999 2015-09-29  P2     9\n",
       "\n",
       "[10000000 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@bodo.jit\n",
    "def data_transform():\n",
    "    t0 = time.time()\n",
    "    df = pd.read_parquet(\"pd_example.pq\")\n",
    "    df[\"B\"] = df.apply(lambda r: \"NA\" if pd.isna(r.A) else \"P1\" if r.A.month < 5 else \"P2\", axis=1)\n",
    "    df[\"C\"] = df.A.dt.month\n",
    "    print(\"Total time: {:.2f}\".format(time.time()-t0))\n",
    "    return df\n",
    "\n",
    "data_transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the program appears to be a regular sequential Python program, Bodo compiles and *transforms* the decorated code (the `data_transform` function in this example) under the hood, so that it can run in parallel on many cores. Each core operates on a different chunk of the data and communicates with other cores when necessary. The speedup depends on the data and program characteristics, as well as the number of cores used. Usually, we can continue scaling to many more cores as long as the data is large enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilation Time and Caching\n",
    "Bodo’s JIT workflow compiles the function the first time it is called, but reuses the compiled version for subsequent calls. In the previous example, we added timers inside the function to avoid measuring compilation time. Let’s move the timers outside and call the function twice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time first call: 2.73\n",
      "Total time second call: 1.42\n"
     ]
    }
   ],
   "source": [
    "@bodo.jit\n",
    "def data_transform():\n",
    "    df = pd.read_parquet(\"pd_example.pq\")\n",
    "    df[\"B\"] = df.apply(lambda r: \"NA\" if pd.isna(r.A) else \"P1\" if r.A.month < 5 else \"P2\", axis=1)\n",
    "    df[\"C\"] = df.A.dt.month\n",
    "    df.to_parquet(\"bodo_output.pq\")\n",
    "\n",
    "\n",
    "t0 = time.time()\n",
    "data_transform()\n",
    "print(\"Total time first call: {:.2f}\".format(time.time()-t0))\n",
    "t0 = time.time()\n",
    "data_transform()\n",
    "print(\"Total time second call: {:.2f}\".format(time.time()-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first call is slower due to compilation of the function, but the second call reuses the compiled version and runs faster. See [Caching](https://docs.bodo.ai/performance/caching/?h=caching) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Python Processes\n",
    "![Groupby shuffle communication pattern](img/groupby.jpg)\n",
    "\n",
    "Bodo uses the MPI parallelism model, which allows cores to communicate efficiently without the overheads of driver-executor libraries.\n",
    "When a Bodo JIT function is invoked for the first time, Bodo spawns parallel Python processes in the background using MPI, with each process managing a distinct portion of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas dataframe: \n",
      "                  A        B\n",
      "0              NaT        0\n",
      "...            ...      ...\n",
      "9999999 2015-09-29  9999999\n",
      "\n",
      "[10000000 rows x 2 columns]\n",
      "Bodo dataframe: \n",
      " Bodo dataframe: \n",
      " Bodo dataframe: \n",
      " Bodo dataframe: \n",
      " Bodo dataframe: \n",
      " Bodo dataframe: \n",
      " Bodo dataframe: \n",
      " Bodo dataframe: \n",
      "                  A        B\n",
      "7500000 2015-01-23  7500000\n",
      "7500001 2015-01-23  7500001\n",
      "7500002 2015-01-23  7500002\n",
      "7500003 2015-01-23  7500003\n",
      "7500004 2015-01-23  7500004\n",
      "...            ...      ...\n",
      "8749995 2015-05-27  8749995\n",
      "8749996 2015-05-27  8749996\n",
      "8749997 2015-05-27  8749997\n",
      "8749998 2015-05-27  8749998\n",
      "8749999 2015-05-27  8749999\n",
      "\n",
      "[1250000 rows x 2 columns]\n",
      "                 A        B\n",
      "3750000 2014-01-13  3750000\n",
      "3750001 2014-01-13  3750001\n",
      "3750002 2014-01-13  3750002\n",
      "3750003 2014-01-13  3750003\n",
      "3750004 2014-01-13  3750004\n",
      "...            ...      ...\n",
      "4999995 2014-05-17  4999995\n",
      "4999996 2014-05-17  4999996\n",
      "4999997 2014-05-17  4999997\n",
      "4999998 2014-05-17  4999998\n",
      "4999999 2014-05-17  4999999\n",
      "\n",
      "[1250000 rows x 2 columns]\n",
      "                 A        B\n",
      "5000000 2014-05-18  5000000\n",
      "5000001 2014-05-18  5000001\n",
      "5000002 2014-05-18  5000002\n",
      "5000003 2014-05-18  5000003\n",
      "5000004 2014-05-18  5000004\n",
      "...            ...      ...\n",
      "6249995 2014-09-19  6249995\n",
      "6249996 2014-09-19  6249996\n",
      "6249997 2014-09-19  6249997\n",
      "6249998 2014-09-19  6249998\n",
      "6249999 2014-09-19  6249999\n",
      "\n",
      "[1250000 rows x 2 columns]\n",
      "                 A        B\n",
      "8750000 2015-05-28  8750000\n",
      "8750001 2015-05-28  8750001\n",
      "8750002 2015-05-28  8750002\n",
      "8750003 2015-05-28  8750003\n",
      "8750004 2015-05-28  8750004\n",
      "...            ...      ...\n",
      "9999995 2015-09-29  9999995\n",
      "9999996 2015-09-29  9999996\n",
      "9999997 2015-09-29  9999997\n",
      "9999998 2015-09-29  9999998\n",
      "9999999 2015-09-29  9999999\n",
      "\n",
      "[1250000 rows x 2 columns]\n",
      "                 A        B\n",
      "0              NaT        0\n",
      "1       2013-01-03        1\n",
      "2       2013-01-03        2\n",
      "3              NaT        3\n",
      "4       2013-01-03        4\n",
      "...            ...      ...\n",
      "1249995 2013-05-07  1249995\n",
      "1249996 2013-05-07  1249996\n",
      "1249997 2013-05-07  1249997\n",
      "1249998 2013-05-07  1249998\n",
      "1249999 2013-05-07  1249999\n",
      "\n",
      "[1250000 rows x 2 columns]\n",
      "                 A        B\n",
      "6250000 2014-09-20  6250000\n",
      "6250001 2014-09-20  6250001\n",
      "6250002 2014-09-20  6250002\n",
      "6250003 2014-09-20  6250003\n",
      "6250004 2014-09-20  6250004\n",
      "...            ...      ...\n",
      "7499995 2015-01-22  7499995\n",
      "7499996 2015-01-22  7499996\n",
      "7499997 2015-01-22  7499997\n",
      "7499998 2015-01-22  7499998\n",
      "7499999 2015-01-22  7499999\n",
      "\n",
      "[1250000 rows x 2 columns]\n",
      "                 A        B\n",
      "1250000 2013-05-08  1250000\n",
      "1250001 2013-05-08  1250001\n",
      "1250002 2013-05-08  1250002\n",
      "1250003 2013-05-08  1250003\n",
      "1250004 2013-05-08  1250004\n",
      "...            ...      ...\n",
      "2499995 2013-09-09  2499995\n",
      "2499996 2013-09-09  2499996\n",
      "2499997 2013-09-09  2499997\n",
      "2499998 2013-09-09  2499998\n",
      "2499999 2013-09-09  2499999\n",
      "\n",
      "[1250000 rows x 2 columns]                 A        B\n",
      "2500000 2013-09-10  2500000\n",
      "2500001 2013-09-10  2500001\n",
      "2500002 2013-09-10  2500002\n",
      "2500003 2013-09-10  2500003\n",
      "2500004 2013-09-10  2500004\n",
      "...            ...      ...\n",
      "3749995 2014-01-12  3749995\n",
      "3749996 2014-01-12  3749996\n",
      "3749997 2014-01-12  3749997\n",
      "3749998 2014-01-12  3749998\n",
      "3749999 2014-01-12  3749999\n",
      "\n",
      "[1250000 rows x 2 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_data_pandas():\n",
    "    df = pd.read_parquet(\"pd_example.pq\")\n",
    "    print(\"pandas dataframe: \\n\", df)\n",
    "\n",
    "@bodo.jit\n",
    "def load_data_bodo():\n",
    "    df = pd.read_parquet(\"pd_example.pq\")\n",
    "    print(\"Bodo dataframe: \\n\", df)\n",
    "\n",
    "load_data_pandas()\n",
    "load_data_bodo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first dataframe printed is a regular Pandas dataframe and has all the 10 million rows.\n",
    "However, the other dataframes printed are Bodo parallelized Pandas dataframes, each containing a portion of the data.\n",
    "In this case, Bodo parallelizes read_parquet automatically and loads different chunks of data into different cores.\n",
    "Therefore, the non-JIT parts of the Python program run sequentially whereas Bodo JIT functions are parallelized.\n",
    "For more information on handling distributed data in python/JIT code, see [Handling distributed data](https://docs.bodo.ai/file_io/?h=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Computation\n",
    "Bodo automatically divides computation and manages communication across cores as this example demonstrates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@bodo.jit\n",
    "def data_groupby():\n",
    "    df = pd.read_parquet(\"pd_example.pq\")\n",
    "    df2 = df.groupby(\"A\", as_index=False).sum()\n",
    "    print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This program uses groupby which requires rows with the same key to be aggregated together. Therefore, Bodo shuffles the data automatically under the hoods using MPI, and the user doesn’t need to worry about parallelism challenges like communication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bodo JIT Requirements\n",
    "Bodo JIT supports specific APIs in Pandas currently, and other APIs cannot be used inside JIT functions. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "BodoError",
     "evalue": "\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1mDataFrame.transpose() not supported yet.\u001b[0m\n\u001b[1m\nFile \"../../../../../../var/folders/nb/s_7bnf052hg0lfqvbrw10bsw0000gn/T/ipykernel_27138/2559399185.py\", line 4:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBodoError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m     df2 \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mtranspose()\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df2\n\u001b[0;32m----> 7\u001b[0m \u001b[43mdf_unsupported\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/Bodo/bodo/submit/spawner.py:599\u001b[0m, in \u001b[0;36mSubmitDispatcher.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 599\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msubmit_func_to_workers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecorator_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpropagate_env\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/Bodo/bodo/submit/spawner.py:584\u001b[0m, in \u001b[0;36msubmit_func_to_workers\u001b[0;34m(dispatcher, propagate_env, *args, **kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get the global spawner and submit `func` for execution\"\"\"\u001b[39;00m\n\u001b[1;32m    583\u001b[0m spawner \u001b[38;5;241m=\u001b[39m get_spawner()\n\u001b[0;32m--> 584\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mspawner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit_func_to_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdispatcher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpropagate_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/Bodo/bodo/submit/spawner.py:295\u001b[0m, in \u001b[0;36mSpawner.submit_func_to_workers\u001b[0;34m(self, dispatcher, propagate_env, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m all_ranks_failed \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(types) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(msgs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    294\u001b[0m     excep \u001b[38;5;241m=\u001b[39m caught_exceptions[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 295\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m excep\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;66;03m# Annotate exceptions with their rank\u001b[39;00m\n\u001b[1;32m    298\u001b[0m     exceptions \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mBodoError\u001b[0m: \u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1mDataFrame.transpose() not supported yet.\u001b[0m\n\u001b[1m\nFile \"../../../../../../var/folders/nb/s_7bnf052hg0lfqvbrw10bsw0000gn/T/ipykernel_27138/2559399185.py\", line 4:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "@bodo.jit\n",
    "def df_unsupported():\n",
    "    df = pd.DataFrame({\"A\": [1, 2, 3]})\n",
    "    df2 = df.transpose()\n",
    "    return df2\n",
    "\n",
    "df_unsupported()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the error indicates, Bodo doesn’t currently support the transpose call in JIT functions. In these cases, an alternative API should be used or this portion of the code should be done in regular Python. See [Pandas Operations](https://docs.bodo.ai/api_docs/pandas/general/#pdcrosstab) for the complete list of supported Pandas operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type Stability\n",
    "The key requirement of JIT compilation is being able to infer data types for all variables and values. In Bodo, column names are part of dataframe data types, so Bodo tries to infer column name related inputs in all operations. For example, key names in groupby are used to determine the output data type and need to be known to Bodo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "BodoError",
     "evalue": "\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1mgroupby(): argument 'by' requires a constant value but variable 'keys' is updated inplace using 'append'\n\u001b[1m\nFile \"../../../../../../var/folders/nb/s_7bnf052hg0lfqvbrw10bsw0000gn/T/ipykernel_27138/4278964147.py\", line 7:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBodoError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     df2 \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(keys)\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(df2)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mgroupby_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/Bodo/bodo/submit/spawner.py:599\u001b[0m, in \u001b[0;36mSubmitDispatcher.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 599\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msubmit_func_to_workers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecorator_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpropagate_env\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/Bodo/bodo/submit/spawner.py:584\u001b[0m, in \u001b[0;36msubmit_func_to_workers\u001b[0;34m(dispatcher, propagate_env, *args, **kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get the global spawner and submit `func` for execution\"\"\"\u001b[39;00m\n\u001b[1;32m    583\u001b[0m spawner \u001b[38;5;241m=\u001b[39m get_spawner()\n\u001b[0;32m--> 584\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mspawner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit_func_to_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdispatcher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpropagate_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/Bodo/bodo/submit/spawner.py:295\u001b[0m, in \u001b[0;36mSpawner.submit_func_to_workers\u001b[0;34m(self, dispatcher, propagate_env, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m all_ranks_failed \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(types) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(msgs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    294\u001b[0m     excep \u001b[38;5;241m=\u001b[39m caught_exceptions[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 295\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m excep\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;66;03m# Annotate exceptions with their rank\u001b[39;00m\n\u001b[1;32m    298\u001b[0m     exceptions \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mBodoError\u001b[0m: \u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1mgroupby(): argument 'by' requires a constant value but variable 'keys' is updated inplace using 'append'\n\u001b[1m\nFile \"../../../../../../var/folders/nb/s_7bnf052hg0lfqvbrw10bsw0000gn/T/ipykernel_27138/4278964147.py\", line 7:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "@bodo.jit\n",
    "def groupby_keys(extra_keys):\n",
    "    df = pd.read_parquet(\"pd_example.pq\")\n",
    "    keys = [c for c in df.columns if c not in [\"B\", \"C\"]]\n",
    "    if extra_keys:\n",
    "        keys.append(\"B\")\n",
    "    df2 = df.groupby(keys).sum()\n",
    "    print(df2)\n",
    "    \n",
    "groupby_keys(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the list of groupby keys is determined by a dynamic flag, and Bodo is not able to infer it from the program during compilation time. The alternative is to pass the keys as an argument to the JIT function to make the values known to Bodo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      B\n",
      "A                      \n",
      "2013-01-03     48496500\n",
      "2013-01-12    949995000\n",
      "2013-01-19   1649995000\n",
      "2013-01-30   2749995000\n",
      "2013-02-24   5249995000\n",
      "...                 ...\n",
      "2015-08-27  96649995000\n",
      "2015-09-04  97449995000\n",
      "2015-09-20  99049995000\n",
      "2015-09-23  99349995000\n",
      "2015-09-28  99849995000\n",
      "\n",
      "[108 rows x 1 columns]\n",
      "                      B\n",
      "A                      \n",
      "2013-01-04    149995000\n",
      "2013-01-07    449995000\n",
      "2013-03-09   6549995000\n",
      "2013-03-14   7049995000\n",
      "2013-03-17   7349995000\n",
      "...                 ...\n",
      "2015-09-07  97749995000\n",
      "2015-09-11  98149995000\n",
      "2015-09-14  98449995000\n",
      "2015-09-16  98649995000\n",
      "2015-09-29  99949995000\n",
      "\n",
      "[125 rows x 1 columns]\n",
      "                      B\n",
      "A                      \n",
      "2013-01-11    849995000\n",
      "2013-01-15   1249995000\n",
      "2013-01-21   1849995000\n",
      "2013-01-22   1949995000\n",
      "2013-01-24   2149995000\n",
      "...                 ...\n",
      "2015-08-24  96349995000\n",
      "2015-08-28  96749995000\n",
      "2015-09-10  98049995000\n",
      "2015-09-18  98849995000\n",
      "2015-09-24  99449995000\n",
      "\n",
      "[119 rows x 1 columns]\n",
      "                      B\n",
      "A                      \n",
      "2013-01-09    649995000\n",
      "2013-01-10    749995000\n",
      "2013-01-18   1549995000\n",
      "2013-02-08   3649995000\n",
      "2013-02-22   5049995000\n",
      "...                 ...\n",
      "2015-08-17  95649995000\n",
      "2015-08-21  96049995000\n",
      "2015-08-25  96449995000\n",
      "2015-09-09  97949995000\n",
      "2015-09-22  99249995000\n",
      "\n",
      "[123 rows x 1 columns]\n",
      "                      B\n",
      "A                      \n",
      "2013-01-05    249995000\n",
      "2013-01-06    349995000\n",
      "2013-01-08    549995000\n",
      "2013-01-14   1149995000\n",
      "2013-01-25   2249995000\n",
      "...                 ...\n",
      "2015-08-08  94749995000\n",
      "2015-08-26  96549995000\n",
      "2015-08-31  97049995000\n",
      "2015-09-08  97849995000\n",
      "2015-09-26  99649995000\n",
      "\n",
      "[113 rows x 1 columns]\n",
      "                      B\n",
      "A                      \n",
      "2013-01-23   2049995000\n",
      "2013-01-26   2349995000\n",
      "2013-02-05   3349995000\n",
      "2013-02-07   3549995000\n",
      "2013-02-12   4049995000\n",
      "...                 ...\n",
      "2015-07-24  93249995000\n",
      "2015-08-15  95449995000\n",
      "2015-08-23  96249995000\n",
      "2015-08-30  96949995000\n",
      "2015-09-17  98749995000\n",
      "\n",
      "[132 rows x 1 columns]\n",
      "                      B\n",
      "A                      \n",
      "2013-01-13   1049995000\n",
      "2013-01-16   1349995000\n",
      "2013-01-20   1749995000\n",
      "2013-02-02   3049995000\n",
      "2013-02-03   3149995000\n",
      "...                 ...\n",
      "2015-09-02  97249995000\n",
      "2015-09-05  97549995000\n",
      "2015-09-13  98349995000\n",
      "2015-09-21  99149995000\n",
      "2015-09-25  99549995000\n",
      "\n",
      "[145 rows x 1 columns]\n",
      "                      B\n",
      "A                      \n",
      "2013-01-17   1449995000\n",
      "2013-01-27   2449995000\n",
      "2013-02-01   2949995000\n",
      "2013-02-17   4549995000\n",
      "2013-02-18   4649995000\n",
      "...                 ...\n",
      "2015-09-06  97649995000\n",
      "2015-09-12  98249995000\n",
      "2015-09-15  98549995000\n",
      "2015-09-19  98949995000\n",
      "2015-09-27  99749995000\n",
      "\n",
      "[135 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "@bodo.jit\n",
    "def groupby_keys(keys):\n",
    "    df = pd.read_parquet(\"pd_example.pq\")\n",
    "    df2 = df.groupby(keys).sum()\n",
    "    print(df2)\n",
    "    \n",
    "groupby_keys([\"A\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This program works since `keys` is passed from regular Python to the JIT function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on out type stability requirement, see our [Documentation on compile time constants](https://docs.bodo.ai/bodo_parallelism/compile_time_constants/?h=compile+time+constan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Python Features\n",
    "\n",
    "Bodo uses [Numba](https://numba.pydata.org/) for compiling regular Python features and some of Numba’s requirements apply to Bodo as well.\n",
    "For example, values in data structures like lists should have the same data type. This example fails since list values are either integers or strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypingError",
     "evalue": "\u001b[1mFailed in bodo mode pipeline (step: <class 'bodo.transforms.typing_pass.BodoTypeInference'>)\n\u001b[1m\u001b[1m\u001b[1mInvalid use of BoundFunction(list.append for list(int64)<iv=None>) with parameters (Literal[str](A))\n\u001b[0m\u001b[0m\u001b[1mDuring: resolving callee type: BoundFunction(list.append for list(int64)<iv=None>)\u001b[0m\u001b[0m\u001b[1mDuring: typing of call at /var/folders/nb/s_7bnf052hg0lfqvbrw10bsw0000gn/T/ipykernel_27138/3649282494.py (5)\n\u001b[0m\n\u001b[1m\nFile \"../../../../../../var/folders/nb/s_7bnf052hg0lfqvbrw10bsw0000gn/T/ipykernel_27138/3649282494.py\", line 5:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n\u001b[0m",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     out\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m---> 10\u001b[0m \u001b[43mcreate_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/Bodo/bodo/submit/spawner.py:599\u001b[0m, in \u001b[0;36mSubmitDispatcher.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 599\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msubmit_func_to_workers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecorator_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpropagate_env\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/Bodo/bodo/submit/spawner.py:584\u001b[0m, in \u001b[0;36msubmit_func_to_workers\u001b[0;34m(dispatcher, propagate_env, *args, **kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get the global spawner and submit `func` for execution\"\"\"\u001b[39;00m\n\u001b[1;32m    583\u001b[0m spawner \u001b[38;5;241m=\u001b[39m get_spawner()\n\u001b[0;32m--> 584\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mspawner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit_func_to_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdispatcher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpropagate_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/Bodo/bodo/submit/spawner.py:295\u001b[0m, in \u001b[0;36mSpawner.submit_func_to_workers\u001b[0;34m(self, dispatcher, propagate_env, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m all_ranks_failed \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(types) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(msgs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    294\u001b[0m     excep \u001b[38;5;241m=\u001b[39m caught_exceptions[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 295\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m excep\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;66;03m# Annotate exceptions with their rank\u001b[39;00m\n\u001b[1;32m    298\u001b[0m     exceptions \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mTypingError\u001b[0m: \u001b[1mFailed in bodo mode pipeline (step: <class 'bodo.transforms.typing_pass.BodoTypeInference'>)\n\u001b[1m\u001b[1m\u001b[1mInvalid use of BoundFunction(list.append for list(int64)<iv=None>) with parameters (Literal[str](A))\n\u001b[0m\u001b[0m\u001b[1mDuring: resolving callee type: BoundFunction(list.append for list(int64)<iv=None>)\u001b[0m\u001b[0m\u001b[1mDuring: typing of call at /var/folders/nb/s_7bnf052hg0lfqvbrw10bsw0000gn/T/ipykernel_27138/3649282494.py (5)\n\u001b[0m\n\u001b[1m\nFile \"../../../../../../var/folders/nb/s_7bnf052hg0lfqvbrw10bsw0000gn/T/ipykernel_27138/3649282494.py\", line 5:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n\u001b[0m"
     ]
    }
   ],
   "source": [
    "@bodo.jit\n",
    "def create_list():\n",
    "    out = []\n",
    "    out.append(0)\n",
    "    out.append(\"A\")\n",
    "    out.append(1)\n",
    "    out.append(\"B\")\n",
    "    return out\n",
    "\n",
    "create_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using tuples can often solve these problems since tuples can hold values of different types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'A'), (1, 'B')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@bodo.jit\n",
    "def create_list():\n",
    "    out = []\n",
    "    out.append((0, \"A\"))\n",
    "    out.append((1, \"B\"))\n",
    "    return out\n",
    "create_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [Unsupported Python Programs](https://docs.bodo.ai/2022.6/bodo_parallelism/not_supported/?h=bodo+pr) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c055ab4e8dcaec5bc09e1db7dc9ba0af7856e6dca0079f8d0a35c557fbc4193a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
