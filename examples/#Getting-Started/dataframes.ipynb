{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bodo DataFrames\n",
    "\n",
    "This notebook demonstrates some of the core functionality of Bodo.DataFrames for data engineering, data science, AI and ML applications. \n",
    "It has three main sections: \n",
    "1. Simple AI inference workflows\n",
    "2. Scalable dataset management with Iceberg\n",
    "3. Accelerating Pandas code with a one-line-change. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Environment Setup\n",
    "\n",
    "Download the dataset used in section 2 and 3.\n",
    "The data is a from the New York City Taxi and Limosuine commission and contains trips from taxi and rideshare apps from 2019-2023. \n",
    "The data is ~1 GiB, Parquet format. In addition to the Taxi dataset, \n",
    "section 3 also uses a small dataset of weather observations from Central Park stored in a ~0.5 MiB CSV file. \n",
    "The data is hosted in a public S3 bucket, downloading the data first eliminates variability due to internet speeds throughout the demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "\n",
    "bucket_name = \"bodo-example-data\"\n",
    "\n",
    "def download_data_s3(path_to_s3: str, local_data_dir: str = \"data\") -> str:\n",
    "    \"\"\"Download the dataset from S3 if already exists, skip download.\"\"\"\n",
    "    file_name = path_to_s3.split(\"/\", -1)[-1]\n",
    "    local_path = os.path.join(local_data_dir, file_name)\n",
    "\n",
    "    if os.path.exists(local_path):\n",
    "        return local_path\n",
    "\n",
    "    print(\"Downloading dataset from S3...\")\n",
    "\n",
    "    s3 = boto3.client(\"s3\", config=Config(signature_version=UNSIGNED))\n",
    "\n",
    "    if not os.path.exists(local_data_dir):\n",
    "        os.mkdir(local_data_dir)\n",
    "\n",
    "    s3.download_file(bucket_name, path_to_s3, local_path)\n",
    "    return local_path\n",
    "\n",
    "# Download the weather data (CSV)\n",
    "download_data_s3(\"nyc-taxi/central_park_weather.csv\", )\n",
    "\n",
    "# Download Taxi data (parquet files)\n",
    "pq_files = [\n",
    "    \"nyc-taxi/fhvhv_tripdata/fhvhv_tripdata_2019-02.parquet\",\n",
    "    \"nyc-taxi/fhvhv_tripdata/fhvhv_tripdata_2019-03.parquet\",\n",
    "]\n",
    "\n",
    "for file in pq_files:\n",
    "    download_data_s3(file, local_data_dir=\"data/fhvhv_tripdata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter warnings on workers\n",
    "# These are performance warnings due to the small number of data files.\n",
    "# Skip this cell to see the raw output.\n",
    "\n",
    "import warnings\n",
    "import bodo.spawn.spawner as spawner\n",
    "\n",
    "spawner.submit_func_to_workers(lambda: warnings.filterwarnings(\"ignore\"), [])\n",
    "\n",
    "# Filter Frontend warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple AI inference workflows\n",
    "\n",
    "Bodo DataFrames uses an extended version of the Pandas API for simplifying and scaling common AI workflows, \n",
    "such as making multiple inference calls to an LLM service in parallel. \n",
    "In this example, we show how you can rapidly develop AI pipelines using Bodo DataFrames and S3 vectors, \n",
    "a new vector database built directly into S3, making it great for cost effective Retrieval Augmented Generation (RAG) applications. \n",
    "\n",
    "Bodo DataFrames parallelizes calls to S3 vectors APIs when putting vectors into the database, \n",
    "making it ideal for loading large chunks of data at a time.\n",
    "\n",
    "Before running the cells below, create an S3 vector bucket and vector index \n",
    "(follow the first two steps of [this tutorial](https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-vectors-getting-started.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import bodo.pandas as bd\n",
    "\n",
    "openai_api_key = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [-0.052156    0.07325729 -0.00435186 ...  0.00...\n",
       "1    [-0.00483433  0.06850652  0.00449129 ... -0.00...\n",
       "2    [ 0.01458554  0.04918431 -0.01516628 ...  0.00...\n",
       "Name: data, dtype: list<item: double>[pyarrow]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create embeddings using OpenAI API\n",
    "\n",
    "texts = [\n",
    "   \"Star Wars: A farm boy joins rebels to fight an evil empire in space\",\n",
    "   \"Jurassic Park: Scientists create dinosaurs in a theme park that goes wrong\",\n",
    "   \"Finding Nemo: A father fish searches the ocean to find his lost son\"\n",
    "]\n",
    "keys = [\"Star Wars\", \"Jurassic Park\", \"Finding Nemo\"]\n",
    "genres = [\"scifi\", \"scifi\", \"family\"]\n",
    "\n",
    "\n",
    "df = bd.DataFrame({\"key\": keys, \"text\": texts, \"genre\": genres})\n",
    "df[\"data\"] = df.text.ai.embed(model=\"text-embedding-3-small\", api_key=openai_api_key)\n",
    "\n",
    "df[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write embeddings into vector index with metadata.\n",
    "\n",
    "df[\"metadata\"] = df.apply(lambda row: {\"source_text\": row.text, \"genre\": row.genre}, axis=1)\n",
    "df.to_s3_vectors(\n",
    "   vector_bucket_name=\"scott-s3-vectors-test-123\",\n",
    "   index_name=\"movie-summaries\",\n",
    "   region=\"us-east-2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            keys                distances  \\\n",
      "0  ['Star Wars' 'Jurassic Park']  [0.62165797 0.7365789 ]   \n",
      "\n",
      "                                            metadata  \n",
      "0  [\"{'genre': 'scifi', 'source_text': 'Star Wars...  \n"
     ]
    }
   ],
   "source": [
    "# Query the vector index (with filtering)\n",
    "\n",
    "input_text = \"adventures in space\"\n",
    "df = bd.DataFrame({\"text\": [input_text]})\n",
    "df[\"data\"] = df.text.ai.embed(model=\"text-embedding-3-small\", api_key=openai_api_key)\n",
    "out = df.data.ai.query_s3_vectors(\n",
    "   vector_bucket_name=\"scott-s3-vectors-test-123\",\n",
    "   index_name=\"movie-summaries\",\n",
    "   region=\"us-east-2\",\n",
    "   topk=3,\n",
    "   filter={\"genre\": \"scifi\"},\n",
    "   return_distance=True,\n",
    "   return_metadata=True,\n",
    ")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Scalable dataset management with Iceberg\n",
    "\n",
    "Bodo DataFrames provides simple APIs for reading and writing to Iceberg Tables. \n",
    "Iceberg is an open source table format which provides an extra layer of scalable dataset management ontop of raw files like Parquet. \n",
    "One benefit of using Iceberg is the Time Travel feature, which let's you inspect the state of a table at a previous point in time, so you can track your data as it changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bodo.pandas as pd\n",
    "import pyiceberg\n",
    "from bodo.io.iceberg.catalog.dir import DirCatalog\n",
    "\n",
    "warehouse_loc = \"./iceberg_warehouse\"\n",
    "table_name = \"fhvhv_tripdata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hvfhs_license_num</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>pickup_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>245</td>\n",
       "      <td>251</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2019-02-01 00:14:57</td>\n",
       "      <td>2019-02-01 00:05:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>216</td>\n",
       "      <td>197</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2019-02-01 00:49:39</td>\n",
       "      <td>2019-02-01 00:41:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>261</td>\n",
       "      <td>234</td>\n",
       "      <td>5.01</td>\n",
       "      <td>2019-02-01 01:28:29</td>\n",
       "      <td>2019-02-01 00:51:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2019-02-01 00:07:16</td>\n",
       "      <td>2019-02-01 00:03:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>87</td>\n",
       "      <td>198</td>\n",
       "      <td>6.84</td>\n",
       "      <td>2019-02-01 00:39:56</td>\n",
       "      <td>2019-02-01 00:09:44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hvfhs_license_num  PULocationID  DOLocationID  trip_miles  \\\n",
       "0            HV0003           245           251        2.45   \n",
       "1            HV0003           216           197        1.71   \n",
       "2            HV0005           261           234        5.01   \n",
       "3            HV0005            87            87        0.34   \n",
       "4            HV0005            87           198        6.84   \n",
       "\n",
       "      dropoff_datetime      pickup_datetime  \n",
       "0  2019-02-01 00:14:57  2019-02-01 00:05:18  \n",
       "1  2019-02-01 00:49:39  2019-02-01 00:41:29  \n",
       "2  2019-02-01 01:28:29  2019-02-01 00:51:34  \n",
       "3  2019-02-01 00:07:16  2019-02-01 00:03:51  \n",
       "4  2019-02-01 00:39:56  2019-02-01 00:09:44  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a portion of the NYC Taxi Data into Iceberg\n",
    "\n",
    "df = pd.read_parquet(\"data/fhvhv_tripdata/fhvhv_tripdata_2019-02.parquet\")\n",
    "df = df[['hvfhs_license_num', 'PULocationID', 'DOLocationID', 'trip_miles', 'dropoff_datetime', 'pickup_datetime']].head(5)\n",
    "\n",
    "df.to_iceberg(table_name, location=warehouse_loc)\n",
    "\n",
    "out_df = pd.read_iceberg(table_name, location=warehouse_loc)\n",
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hvfhs_license_num</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>pickup_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>245</td>\n",
       "      <td>251</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2019-02-01 00:14:57</td>\n",
       "      <td>2019-02-01 00:05:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>216</td>\n",
       "      <td>197</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2019-02-01 00:49:39</td>\n",
       "      <td>2019-02-01 00:41:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>261</td>\n",
       "      <td>234</td>\n",
       "      <td>5.01</td>\n",
       "      <td>2019-02-01 01:28:29</td>\n",
       "      <td>2019-02-01 00:51:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2019-02-01 00:07:16</td>\n",
       "      <td>2019-02-01 00:03:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>87</td>\n",
       "      <td>198</td>\n",
       "      <td>6.84</td>\n",
       "      <td>2019-02-01 00:39:56</td>\n",
       "      <td>2019-02-01 00:09:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HV0004</td>\n",
       "      <td>36</td>\n",
       "      <td>80</td>\n",
       "      <td>2.18</td>\n",
       "      <td>2019-03-01 00:28:51</td>\n",
       "      <td>2019-03-01 00:13:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HV0004</td>\n",
       "      <td>37</td>\n",
       "      <td>232</td>\n",
       "      <td>3.66</td>\n",
       "      <td>2019-03-01 00:43:03</td>\n",
       "      <td>2019-03-01 00:23:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>25</td>\n",
       "      <td>62</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2019-03-01 00:15:09</td>\n",
       "      <td>2019-03-01 00:03:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>65</td>\n",
       "      <td>262</td>\n",
       "      <td>9.34</td>\n",
       "      <td>2019-03-01 00:50:43</td>\n",
       "      <td>2019-03-01 00:29:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>140</td>\n",
       "      <td>196</td>\n",
       "      <td>7.88</td>\n",
       "      <td>2019-03-01 01:20:47</td>\n",
       "      <td>2019-03-01 00:58:56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hvfhs_license_num  PULocationID  DOLocationID  trip_miles  \\\n",
       "0            HV0003           245           251        2.45   \n",
       "1            HV0003           216           197        1.71   \n",
       "2            HV0005           261           234        5.01   \n",
       "3            HV0005            87            87        0.34   \n",
       "4            HV0005            87           198        6.84   \n",
       "5            HV0004            36            80        2.18   \n",
       "6            HV0004            37           232        3.66   \n",
       "7            HV0005            25            62        2.53   \n",
       "8            HV0003            65           262        9.34   \n",
       "9            HV0003           140           196        7.88   \n",
       "\n",
       "      dropoff_datetime      pickup_datetime  \n",
       "0  2019-02-01 00:14:57  2019-02-01 00:05:18  \n",
       "1  2019-02-01 00:49:39  2019-02-01 00:41:29  \n",
       "2  2019-02-01 01:28:29  2019-02-01 00:51:34  \n",
       "3  2019-02-01 00:07:16  2019-02-01 00:03:51  \n",
       "4  2019-02-01 00:39:56  2019-02-01 00:09:44  \n",
       "5  2019-03-01 00:28:51  2019-03-01 00:13:55  \n",
       "6  2019-03-01 00:43:03  2019-03-01 00:23:58  \n",
       "7  2019-03-01 00:15:09  2019-03-01 00:03:37  \n",
       "8  2019-03-01 00:50:43  2019-03-01 00:29:46  \n",
       "9  2019-03-01 01:20:47  2019-03-01 00:58:56  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add more rows to the table\n",
    "\n",
    "df = pd.read_parquet(\"data/fhvhv_tripdata/fhvhv_tripdata_2019-03.parquet\")\n",
    "df = df[['hvfhs_license_num', 'PULocationID', 'DOLocationID', 'trip_miles', 'dropoff_datetime', 'pickup_datetime']].head(5)\n",
    "\n",
    "df.to_iceberg(table_name, location=\"./iceberg_warehouse\", append=True)\n",
    "\n",
    "out_df = pd.read_iceberg(table_name, location=\"./iceberg_warehouse\")\n",
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SnapshotLogEntry(snapshot_id=6178841661585853159, timestamp_ms=1755289799351),\n",
       " SnapshotLogEntry(snapshot_id=2169839336463401993, timestamp_ms=1755289802465)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With Iceberg, you can see a history of changes to your data\n",
    "\n",
    "catalog = DirCatalog(\n",
    "    None,\n",
    "    **{\n",
    "        pyiceberg.catalog.WAREHOUSE_LOCATION: warehouse_loc,\n",
    "    },\n",
    ")\n",
    "\n",
    "table = catalog.load_table(f\".{table_name}\")\n",
    "history = table.history()\n",
    "prev_snapshot = history[0].snapshot_id\n",
    "\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hvfhs_license_num</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>pickup_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>245</td>\n",
       "      <td>251</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2019-02-01 00:14:57</td>\n",
       "      <td>2019-02-01 00:05:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>216</td>\n",
       "      <td>197</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2019-02-01 00:49:39</td>\n",
       "      <td>2019-02-01 00:41:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>261</td>\n",
       "      <td>234</td>\n",
       "      <td>5.01</td>\n",
       "      <td>2019-02-01 01:28:29</td>\n",
       "      <td>2019-02-01 00:51:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2019-02-01 00:07:16</td>\n",
       "      <td>2019-02-01 00:03:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>87</td>\n",
       "      <td>198</td>\n",
       "      <td>6.84</td>\n",
       "      <td>2019-02-01 00:39:56</td>\n",
       "      <td>2019-02-01 00:09:44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hvfhs_license_num  PULocationID  DOLocationID  trip_miles  \\\n",
       "0            HV0003           245           251        2.45   \n",
       "1            HV0003           216           197        1.71   \n",
       "2            HV0005           261           234        5.01   \n",
       "3            HV0005            87            87        0.34   \n",
       "4            HV0005            87           198        6.84   \n",
       "\n",
       "      dropoff_datetime      pickup_datetime  \n",
       "0  2019-02-01 00:14:57  2019-02-01 00:05:18  \n",
       "1  2019-02-01 00:49:39  2019-02-01 00:41:29  \n",
       "2  2019-02-01 01:28:29  2019-02-01 00:51:34  \n",
       "3  2019-02-01 00:07:16  2019-02-01 00:03:51  \n",
       "4  2019-02-01 00:39:56  2019-02-01 00:09:44  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hvfhs_license_num</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>pickup_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>245</td>\n",
       "      <td>251</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2019-02-01 00:14:57</td>\n",
       "      <td>2019-02-01 00:05:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>216</td>\n",
       "      <td>197</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2019-02-01 00:49:39</td>\n",
       "      <td>2019-02-01 00:41:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>261</td>\n",
       "      <td>234</td>\n",
       "      <td>5.01</td>\n",
       "      <td>2019-02-01 01:28:29</td>\n",
       "      <td>2019-02-01 00:51:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2019-02-01 00:07:16</td>\n",
       "      <td>2019-02-01 00:03:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>87</td>\n",
       "      <td>198</td>\n",
       "      <td>6.84</td>\n",
       "      <td>2019-02-01 00:39:56</td>\n",
       "      <td>2019-02-01 00:09:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HV0004</td>\n",
       "      <td>36</td>\n",
       "      <td>80</td>\n",
       "      <td>2.18</td>\n",
       "      <td>2019-03-01 00:28:51</td>\n",
       "      <td>2019-03-01 00:13:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HV0004</td>\n",
       "      <td>37</td>\n",
       "      <td>232</td>\n",
       "      <td>3.66</td>\n",
       "      <td>2019-03-01 00:43:03</td>\n",
       "      <td>2019-03-01 00:23:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>25</td>\n",
       "      <td>62</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2019-03-01 00:15:09</td>\n",
       "      <td>2019-03-01 00:03:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>65</td>\n",
       "      <td>262</td>\n",
       "      <td>9.34</td>\n",
       "      <td>2019-03-01 00:50:43</td>\n",
       "      <td>2019-03-01 00:29:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>140</td>\n",
       "      <td>196</td>\n",
       "      <td>7.88</td>\n",
       "      <td>2019-03-01 01:20:47</td>\n",
       "      <td>2019-03-01 00:58:56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hvfhs_license_num  PULocationID  DOLocationID  trip_miles  \\\n",
       "0            HV0003           245           251        2.45   \n",
       "1            HV0003           216           197        1.71   \n",
       "2            HV0005           261           234        5.01   \n",
       "3            HV0005            87            87        0.34   \n",
       "4            HV0005            87           198        6.84   \n",
       "5            HV0004            36            80        2.18   \n",
       "6            HV0004            37           232        3.66   \n",
       "7            HV0005            25            62        2.53   \n",
       "8            HV0003            65           262        9.34   \n",
       "9            HV0003           140           196        7.88   \n",
       "\n",
       "      dropoff_datetime      pickup_datetime  \n",
       "0  2019-02-01 00:14:57  2019-02-01 00:05:18  \n",
       "1  2019-02-01 00:49:39  2019-02-01 00:41:29  \n",
       "2  2019-02-01 01:28:29  2019-02-01 00:51:34  \n",
       "3  2019-02-01 00:07:16  2019-02-01 00:03:51  \n",
       "4  2019-02-01 00:39:56  2019-02-01 00:09:44  \n",
       "5  2019-03-01 00:28:51  2019-03-01 00:13:55  \n",
       "6  2019-03-01 00:43:03  2019-03-01 00:23:58  \n",
       "7  2019-03-01 00:15:09  2019-03-01 00:03:37  \n",
       "8  2019-03-01 00:50:43  2019-03-01 00:29:46  \n",
       "9  2019-03-01 01:20:47  2019-03-01 00:58:56  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use Time Travel to query both versions of the dataset\n",
    "\n",
    "df = pd.read_iceberg(table_name, location=\"./iceberg_warehouse\", snapshot_id=prev_snapshot)\n",
    "display(df)\n",
    "\n",
    "current_shapshot = history[1].snapshot_id\n",
    "\n",
    "df = pd.read_iceberg(table_name, location=\"./iceberg_warehouse\", snapshot_id=current_shapshot)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional cleanup\n",
    "\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree(\"./iceberg_warehouse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Accelerating Pandas code with a one-line-change\n",
    "\n",
    "Bodo DataFrames automatically parallelizes and optimizes workload written in Pandas.\n",
    "This example uses a representative data engineering workload for creating trip summaries using weather observations from Central Park (CSV) and NYC Taxi/Rideshare data (parquet),\n",
    "highlighting Bodo DataFrames performance on key transformations such as read parquet, datetime manipulation, merge, groupby and sort. \n",
    "We first measure the performance both Bodo DataFrames and Pandas to see an improvement. \n",
    "This gap becomes larger as we scale to more data and add more compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "\n",
    "\n",
    "def get_monthly_travels_weather(weather_dataset : str, hvfhv_dataset : str, out_file : str, pd=pd):\n",
    "    \"\"\" Run the full workload and write results to Parquet. \"\"\"\n",
    "    start = perf_counter()\n",
    "    central_park_weather_observations = pd.read_csv(\n",
    "        weather_dataset,\n",
    "        parse_dates=[\"DATE\"],\n",
    "    )\n",
    "    central_park_weather_observations = central_park_weather_observations.rename(\n",
    "        columns={\"DATE\": \"date\", \"PRCP\": \"precipitation\"}, copy=False\n",
    "    )\n",
    "    fhvhv_tripdata = pd.read_parquet(hvfhv_dataset)\n",
    "\n",
    "    central_park_weather_observations[\"date\"] = central_park_weather_observations[\n",
    "        \"date\"\n",
    "    ].dt.date\n",
    "    fhvhv_tripdata[\"date\"] = fhvhv_tripdata[\"pickup_datetime\"].dt.date\n",
    "    fhvhv_tripdata[\"month\"] = fhvhv_tripdata[\"pickup_datetime\"].dt.month\n",
    "    fhvhv_tripdata[\"hour\"] = fhvhv_tripdata[\"pickup_datetime\"].dt.hour\n",
    "    fhvhv_tripdata[\"weekday\"] = fhvhv_tripdata[\"pickup_datetime\"].dt.dayofweek.isin(\n",
    "        [0, 1, 2, 3, 4]\n",
    "    )\n",
    "\n",
    "    monthly_trips_weather = fhvhv_tripdata.merge(\n",
    "        central_park_weather_observations, on=\"date\", how=\"inner\"\n",
    "    )\n",
    "    monthly_trips_weather[\"date_with_precipitation\"] = (\n",
    "        monthly_trips_weather[\"precipitation\"] > 0.1\n",
    "    )\n",
    "\n",
    "    def get_time_bucket(t):\n",
    "        bucket = \"other\"\n",
    "        if t in (8, 9, 10):\n",
    "            bucket = \"morning\"\n",
    "        elif t in (11, 12, 13, 14, 15):\n",
    "            bucket = \"midday\"\n",
    "        elif t in (16, 17, 18):\n",
    "            bucket = \"afternoon\"\n",
    "        elif t in (19, 20, 21):\n",
    "            bucket = \"evening\"\n",
    "        return bucket\n",
    "\n",
    "    monthly_trips_weather[\"time_bucket\"] = monthly_trips_weather.hour.map(\n",
    "        get_time_bucket\n",
    "    )\n",
    "    monthly_trips_weather = monthly_trips_weather.groupby(\n",
    "        [\n",
    "            \"PULocationID\",\n",
    "            \"DOLocationID\",\n",
    "            \"month\",\n",
    "            \"weekday\",\n",
    "            \"date_with_precipitation\",\n",
    "            \"time_bucket\",\n",
    "        ],\n",
    "        as_index=False,\n",
    "    ).agg({\"hvfhs_license_num\": \"count\", \"trip_miles\": \"mean\"})\n",
    "    monthly_trips_weather = monthly_trips_weather.sort_values(\n",
    "        by=[\n",
    "            \"PULocationID\",\n",
    "            \"DOLocationID\",\n",
    "            \"month\",\n",
    "            \"weekday\",\n",
    "            \"date_with_precipitation\",\n",
    "            \"time_bucket\",\n",
    "        ]\n",
    "    )\n",
    "    monthly_trips_weather = monthly_trips_weather.rename(\n",
    "        columns={\n",
    "            \"hvfhs_license_num\": \"trips\",\n",
    "            \"trip_miles\": \"avg_distance\",\n",
    "        },\n",
    "        copy=False,\n",
    "    )\n",
    "\n",
    "    monthly_trips_weather.to_parquet(out_file)\n",
    "    end = perf_counter()\n",
    "    print(\"Total E2E time:\", (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total E2E time: 10.817763417000151\n"
     ]
    }
   ],
   "source": [
    "weather_dataset = \"data/central_park_weather.csv\"\n",
    "hvfhv_dataset = \"data/fhvhv_tripdata/\"\n",
    "get_monthly_travels_weather(weather_dataset, hvfhv_dataset, out_file=\"bodo_monthly_trips_weather_pandas.pq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing to Pandas\n",
    "\n",
    "Run the cell below to see the comparison to Pandas. \n",
    "Without any code changed, Bodo accelerates the workflow by ~6-10x (on a 2023 10-core Macbook Pro)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total E2E time: 92.34436408300007\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "weather_dataset = \"data/central_park_weather.csv\"\n",
    "hvfhv_dataset = \"data/fhvhv_tripdata/\"\n",
    "get_monthly_travels_weather(weather_dataset, hvfhv_dataset, out_file=\"pandas_monthly_trips_weather.pq\", pd=pandas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
