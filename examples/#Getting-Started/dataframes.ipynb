{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bodo DataFrames\n",
    "\n",
    "This notebook demonstrates some of the core functionality of Bodo.DataFrames for data engineering, data science, AI and ML applications. \n",
    "It has three main sections: \n",
    "1. Simple AI inference workflows\n",
    "2. Scalable dataset management with Iceberg\n",
    "3. Accelerating Pandas with a one-line-change. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Environment Setup\n",
    "\n",
    "The dataset used in sections 2 and 3 is from the [New York City Taxi and Limousine Commission](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page) and contains trips from taxi and rideshare apps from 2019-2023. \n",
    "This notebook uses a subset of the 2019 data (~1 GiB, Parquet format). In addition to the Taxi dataset, \n",
    "section 3 also uses a small dataset of [weather observations from Central Park](https://github.com/toddwschneider/nyc-taxi-data/blob/c65ad8332a44f49770644b11576c0529b40bbc76/data/central_park_weather.csv) (~0.5 MiB CSV file). \n",
    "The data is hosted in a public S3 bucket and downloading the data first eliminates variability due to internet speeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "\n",
    "bucket_name = \"bodo-example-data\"\n",
    "\n",
    "def download_data_s3(path_to_s3: str, local_data_dir: str = \"data\") -> str:\n",
    "    \"\"\"Download the dataset from S3 if already exists, skip download.\"\"\"\n",
    "    file_name = os.path.basename(path_to_s3)\n",
    "    local_path = os.path.join(local_data_dir, file_name)\n",
    "\n",
    "    if os.path.exists(local_path):\n",
    "        return local_path\n",
    "\n",
    "    print(\"Downloading dataset from S3...\")\n",
    "\n",
    "    s3 = boto3.client(\"s3\", config=Config(signature_version=UNSIGNED))\n",
    "\n",
    "    if not os.path.exists(local_data_dir):\n",
    "        os.mkdir(local_data_dir)\n",
    "\n",
    "    s3.download_file(bucket_name, path_to_s3, local_path)\n",
    "    return local_path\n",
    "\n",
    "# Download the weather data (CSV)\n",
    "download_data_s3(\"nyc-taxi/central_park_weather.csv\", )\n",
    "\n",
    "# Download Taxi data (parquet files)\n",
    "pq_files = [\n",
    "    \"nyc-taxi/fhvhv_tripdata/fhvhv_tripdata_2019-02.parquet\",\n",
    "    \"nyc-taxi/fhvhv_tripdata/fhvhv_tripdata_2019-03.parquet\",\n",
    "]\n",
    "\n",
    "for file in pq_files:\n",
    "    download_data_s3(file, local_data_dir=\"data/fhvhv_tripdata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter warnings on workers\n",
    "# These are performance warnings due to the small number of data files.\n",
    "# Skip this cell to see the raw output.\n",
    "\n",
    "import warnings\n",
    "import bodo.spawn.spawner as spawner\n",
    "\n",
    "spawner.submit_func_to_workers(lambda: warnings.filterwarnings(\"ignore\"), [])\n",
    "\n",
    "# Filter Frontend warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simple AI inference workflows\n",
    "\n",
    "Bodo DataFrames provides an extended version of the Pandas API for simplifying and scaling common AI workflows.\n",
    "In this example, we show how you can create and query vector embeddings using Bodo DataFrames and S3 Vectors.\n",
    "Bodo DataFrames parallelizes calls to S3 Vectors APIs when putting vectors, \n",
    "making it ideal for loading large chunks of data at a time.\n",
    "Before running the cells below, create an S3 vector bucket and vector index \n",
    "(follow the first two steps of [this tutorial](https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-vectors-getting-started.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import bodo.pandas as bd\n",
    "\n",
    "openai_api_key = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [-0.05209277  0.07324854 -0.00430418 ...  0.00...\n",
       "1    [-0.00482084  0.06854609  0.00452549 ... -0.00...\n",
       "2    [ 0.01458554  0.04918431 -0.01516628 ...  0.00...\n",
       "Name: data, dtype: list<item: double>[pyarrow]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create embeddings using OpenAI API\n",
    "\n",
    "texts = [\n",
    "   \"Star Wars: A farm boy joins rebels to fight an evil empire in space\",\n",
    "   \"Jurassic Park: Scientists create dinosaurs in a theme park that goes wrong\",\n",
    "   \"Finding Nemo: A father fish searches the ocean to find his lost son\"\n",
    "]\n",
    "keys = [\"Star Wars\", \"Jurassic Park\", \"Finding Nemo\"]\n",
    "genres = [\"scifi\", \"scifi\", \"family\"]\n",
    "\n",
    "\n",
    "df = bd.DataFrame({\"key\": keys, \"text\": texts, \"genre\": genres})\n",
    "df[\"data\"] = df.text.ai.embed(model=\"text-embedding-3-small\", api_key=openai_api_key)\n",
    "\n",
    "df[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write embeddings into vector index with metadata.\n",
    "\n",
    "# TODO: fill in with your vector bucket/index and region\n",
    "vector_bucket_name = \"your-vector-bucket\"\n",
    "index_name = \"your-vector-index\"\n",
    "region = \"your-region\"\n",
    "\n",
    "df[\"metadata\"] = df.apply(lambda row: {\"source_text\": row.text, \"genre\": row.genre}, axis=1)\n",
    "df.to_s3_vectors(\n",
    "   vector_bucket_name=vector_bucket_name,\n",
    "   index_name=index_name,\n",
    "   region=region\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keys</th>\n",
       "      <th>distances</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Star Wars' 'Jurassic Park']</td>\n",
       "      <td>[0.62180173 0.73625743]</td>\n",
       "      <td>[\"{'source_text': 'Star Wars: A farm boy joins...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            keys                distances  \\\n",
       "0  ['Star Wars' 'Jurassic Park']  [0.62180173 0.73625743]   \n",
       "\n",
       "                                            metadata  \n",
       "0  [\"{'source_text': 'Star Wars: A farm boy joins...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query the vector index (with filtering)\n",
    "\n",
    "input_text = \"adventures in space\"\n",
    "df = bd.DataFrame({\"text\": [input_text]})\n",
    "df[\"data\"] = df.text.ai.embed(model=\"text-embedding-3-small\", api_key=openai_api_key)\n",
    "out = df.data.ai.query_s3_vectors(\n",
    "   vector_bucket_name=vector_bucket_name,\n",
    "   index_name=index_name,\n",
    "   region=region,\n",
    "   topk=3,\n",
    "   filter={\"genre\": \"scifi\"},\n",
    "   return_distance=True,\n",
    "   return_metadata=True,\n",
    ")\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Scalable dataset management with Iceberg\n",
    "\n",
    "Bodo DataFrames provides simple and scalable APIs for reading and writing data to Iceberg tables, an open source table format which provides an extra layer of scalable dataset management on top of raw files. \n",
    "One benefit of using Iceberg is the Time Travel feature, which let's you inspect the state of a table at a previous point in time, so you can track your data as it changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bodo.pandas as pd\n",
    "import pyiceberg\n",
    "from bodo.io.iceberg.catalog.dir import DirCatalog\n",
    "\n",
    "warehouse_loc = \"./iceberg_warehouse\"\n",
    "table_name = \"fhvhv_tripdata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hvfhs_license_num</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>pickup_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>245</td>\n",
       "      <td>251</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2019-02-01 00:14:57</td>\n",
       "      <td>2019-02-01 00:05:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>216</td>\n",
       "      <td>197</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2019-02-01 00:49:39</td>\n",
       "      <td>2019-02-01 00:41:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>261</td>\n",
       "      <td>234</td>\n",
       "      <td>5.01</td>\n",
       "      <td>2019-02-01 01:28:29</td>\n",
       "      <td>2019-02-01 00:51:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2019-02-01 00:07:16</td>\n",
       "      <td>2019-02-01 00:03:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>87</td>\n",
       "      <td>198</td>\n",
       "      <td>6.84</td>\n",
       "      <td>2019-02-01 00:39:56</td>\n",
       "      <td>2019-02-01 00:09:44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hvfhs_license_num  PULocationID  DOLocationID  trip_miles  \\\n",
       "0            HV0003           245           251        2.45   \n",
       "1            HV0003           216           197        1.71   \n",
       "2            HV0005           261           234        5.01   \n",
       "3            HV0005            87            87        0.34   \n",
       "4            HV0005            87           198        6.84   \n",
       "\n",
       "      dropoff_datetime      pickup_datetime  \n",
       "0  2019-02-01 00:14:57  2019-02-01 00:05:18  \n",
       "1  2019-02-01 00:49:39  2019-02-01 00:41:29  \n",
       "2  2019-02-01 01:28:29  2019-02-01 00:51:34  \n",
       "3  2019-02-01 00:07:16  2019-02-01 00:03:51  \n",
       "4  2019-02-01 00:39:56  2019-02-01 00:09:44  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a portion of the NYC Taxi Data into Iceberg\n",
    "\n",
    "df = pd.read_parquet(\"data/fhvhv_tripdata/fhvhv_tripdata_2019-02.parquet\")\n",
    "df = df[['hvfhs_license_num', 'PULocationID', 'DOLocationID', 'trip_miles', 'dropoff_datetime', 'pickup_datetime']].head(5)\n",
    "\n",
    "df.to_iceberg(table_name, location=warehouse_loc)\n",
    "\n",
    "out_df = pd.read_iceberg(table_name, location=warehouse_loc)\n",
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hvfhs_license_num</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>pickup_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>245</td>\n",
       "      <td>251</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2019-02-01 00:14:57</td>\n",
       "      <td>2019-02-01 00:05:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>216</td>\n",
       "      <td>197</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2019-02-01 00:49:39</td>\n",
       "      <td>2019-02-01 00:41:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>261</td>\n",
       "      <td>234</td>\n",
       "      <td>5.01</td>\n",
       "      <td>2019-02-01 01:28:29</td>\n",
       "      <td>2019-02-01 00:51:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2019-02-01 00:07:16</td>\n",
       "      <td>2019-02-01 00:03:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>87</td>\n",
       "      <td>198</td>\n",
       "      <td>6.84</td>\n",
       "      <td>2019-02-01 00:39:56</td>\n",
       "      <td>2019-02-01 00:09:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HV0004</td>\n",
       "      <td>36</td>\n",
       "      <td>80</td>\n",
       "      <td>2.18</td>\n",
       "      <td>2019-03-01 00:28:51</td>\n",
       "      <td>2019-03-01 00:13:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HV0004</td>\n",
       "      <td>37</td>\n",
       "      <td>232</td>\n",
       "      <td>3.66</td>\n",
       "      <td>2019-03-01 00:43:03</td>\n",
       "      <td>2019-03-01 00:23:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>25</td>\n",
       "      <td>62</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2019-03-01 00:15:09</td>\n",
       "      <td>2019-03-01 00:03:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>65</td>\n",
       "      <td>262</td>\n",
       "      <td>9.34</td>\n",
       "      <td>2019-03-01 00:50:43</td>\n",
       "      <td>2019-03-01 00:29:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>140</td>\n",
       "      <td>196</td>\n",
       "      <td>7.88</td>\n",
       "      <td>2019-03-01 01:20:47</td>\n",
       "      <td>2019-03-01 00:58:56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hvfhs_license_num  PULocationID  DOLocationID  trip_miles  \\\n",
       "0            HV0003           245           251        2.45   \n",
       "1            HV0003           216           197        1.71   \n",
       "2            HV0005           261           234        5.01   \n",
       "3            HV0005            87            87        0.34   \n",
       "4            HV0005            87           198        6.84   \n",
       "5            HV0004            36            80        2.18   \n",
       "6            HV0004            37           232        3.66   \n",
       "7            HV0005            25            62        2.53   \n",
       "8            HV0003            65           262        9.34   \n",
       "9            HV0003           140           196        7.88   \n",
       "\n",
       "      dropoff_datetime      pickup_datetime  \n",
       "0  2019-02-01 00:14:57  2019-02-01 00:05:18  \n",
       "1  2019-02-01 00:49:39  2019-02-01 00:41:29  \n",
       "2  2019-02-01 01:28:29  2019-02-01 00:51:34  \n",
       "3  2019-02-01 00:07:16  2019-02-01 00:03:51  \n",
       "4  2019-02-01 00:39:56  2019-02-01 00:09:44  \n",
       "5  2019-03-01 00:28:51  2019-03-01 00:13:55  \n",
       "6  2019-03-01 00:43:03  2019-03-01 00:23:58  \n",
       "7  2019-03-01 00:15:09  2019-03-01 00:03:37  \n",
       "8  2019-03-01 00:50:43  2019-03-01 00:29:46  \n",
       "9  2019-03-01 01:20:47  2019-03-01 00:58:56  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add more rows to the table\n",
    "\n",
    "df = pd.read_parquet(\"data/fhvhv_tripdata/fhvhv_tripdata_2019-03.parquet\")\n",
    "df = df[['hvfhs_license_num', 'PULocationID', 'DOLocationID', 'trip_miles', 'dropoff_datetime', 'pickup_datetime']].head(5)\n",
    "\n",
    "df.to_iceberg(table_name, location=\"./iceberg_warehouse\", append=True)\n",
    "\n",
    "out_df = pd.read_iceberg(table_name, location=\"./iceberg_warehouse\")\n",
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SnapshotLogEntry(snapshot_id=4162266328373461502, timestamp_ms=1755540265399),\n",
       " SnapshotLogEntry(snapshot_id=6911853098964568922, timestamp_ms=1755540267586)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use PyIceberg to get a history of the dataset over time.\n",
    "\n",
    "catalog = DirCatalog(\n",
    "    None,\n",
    "    **{\n",
    "        pyiceberg.catalog.WAREHOUSE_LOCATION: warehouse_loc,\n",
    "    },\n",
    ")\n",
    "\n",
    "table = catalog.load_table(f\".{table_name}\")\n",
    "history = table.history()\n",
    "prev_snapshot = history[0].snapshot_id\n",
    "\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hvfhs_license_num</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>pickup_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>245</td>\n",
       "      <td>251</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2019-02-01 00:14:57</td>\n",
       "      <td>2019-02-01 00:05:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>216</td>\n",
       "      <td>197</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2019-02-01 00:49:39</td>\n",
       "      <td>2019-02-01 00:41:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>261</td>\n",
       "      <td>234</td>\n",
       "      <td>5.01</td>\n",
       "      <td>2019-02-01 01:28:29</td>\n",
       "      <td>2019-02-01 00:51:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2019-02-01 00:07:16</td>\n",
       "      <td>2019-02-01 00:03:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>87</td>\n",
       "      <td>198</td>\n",
       "      <td>6.84</td>\n",
       "      <td>2019-02-01 00:39:56</td>\n",
       "      <td>2019-02-01 00:09:44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hvfhs_license_num  PULocationID  DOLocationID  trip_miles  \\\n",
       "0            HV0003           245           251        2.45   \n",
       "1            HV0003           216           197        1.71   \n",
       "2            HV0005           261           234        5.01   \n",
       "3            HV0005            87            87        0.34   \n",
       "4            HV0005            87           198        6.84   \n",
       "\n",
       "      dropoff_datetime      pickup_datetime  \n",
       "0  2019-02-01 00:14:57  2019-02-01 00:05:18  \n",
       "1  2019-02-01 00:49:39  2019-02-01 00:41:29  \n",
       "2  2019-02-01 01:28:29  2019-02-01 00:51:34  \n",
       "3  2019-02-01 00:07:16  2019-02-01 00:03:51  \n",
       "4  2019-02-01 00:39:56  2019-02-01 00:09:44  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hvfhs_license_num</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>pickup_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>245</td>\n",
       "      <td>251</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2019-02-01 00:14:57</td>\n",
       "      <td>2019-02-01 00:05:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>216</td>\n",
       "      <td>197</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2019-02-01 00:49:39</td>\n",
       "      <td>2019-02-01 00:41:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>261</td>\n",
       "      <td>234</td>\n",
       "      <td>5.01</td>\n",
       "      <td>2019-02-01 01:28:29</td>\n",
       "      <td>2019-02-01 00:51:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2019-02-01 00:07:16</td>\n",
       "      <td>2019-02-01 00:03:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>87</td>\n",
       "      <td>198</td>\n",
       "      <td>6.84</td>\n",
       "      <td>2019-02-01 00:39:56</td>\n",
       "      <td>2019-02-01 00:09:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HV0004</td>\n",
       "      <td>36</td>\n",
       "      <td>80</td>\n",
       "      <td>2.18</td>\n",
       "      <td>2019-03-01 00:28:51</td>\n",
       "      <td>2019-03-01 00:13:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HV0004</td>\n",
       "      <td>37</td>\n",
       "      <td>232</td>\n",
       "      <td>3.66</td>\n",
       "      <td>2019-03-01 00:43:03</td>\n",
       "      <td>2019-03-01 00:23:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>25</td>\n",
       "      <td>62</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2019-03-01 00:15:09</td>\n",
       "      <td>2019-03-01 00:03:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>65</td>\n",
       "      <td>262</td>\n",
       "      <td>9.34</td>\n",
       "      <td>2019-03-01 00:50:43</td>\n",
       "      <td>2019-03-01 00:29:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>140</td>\n",
       "      <td>196</td>\n",
       "      <td>7.88</td>\n",
       "      <td>2019-03-01 01:20:47</td>\n",
       "      <td>2019-03-01 00:58:56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hvfhs_license_num  PULocationID  DOLocationID  trip_miles  \\\n",
       "0            HV0003           245           251        2.45   \n",
       "1            HV0003           216           197        1.71   \n",
       "2            HV0005           261           234        5.01   \n",
       "3            HV0005            87            87        0.34   \n",
       "4            HV0005            87           198        6.84   \n",
       "5            HV0004            36            80        2.18   \n",
       "6            HV0004            37           232        3.66   \n",
       "7            HV0005            25            62        2.53   \n",
       "8            HV0003            65           262        9.34   \n",
       "9            HV0003           140           196        7.88   \n",
       "\n",
       "      dropoff_datetime      pickup_datetime  \n",
       "0  2019-02-01 00:14:57  2019-02-01 00:05:18  \n",
       "1  2019-02-01 00:49:39  2019-02-01 00:41:29  \n",
       "2  2019-02-01 01:28:29  2019-02-01 00:51:34  \n",
       "3  2019-02-01 00:07:16  2019-02-01 00:03:51  \n",
       "4  2019-02-01 00:39:56  2019-02-01 00:09:44  \n",
       "5  2019-03-01 00:28:51  2019-03-01 00:13:55  \n",
       "6  2019-03-01 00:43:03  2019-03-01 00:23:58  \n",
       "7  2019-03-01 00:15:09  2019-03-01 00:03:37  \n",
       "8  2019-03-01 00:50:43  2019-03-01 00:29:46  \n",
       "9  2019-03-01 01:20:47  2019-03-01 00:58:56  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use Time Travel to query both versions of the dataset\n",
    "\n",
    "df = pd.read_iceberg(table_name, location=\"./iceberg_warehouse\", snapshot_id=prev_snapshot)\n",
    "display(df)\n",
    "\n",
    "current_snapshot = history[1].snapshot_id\n",
    "\n",
    "df = pd.read_iceberg(table_name, location=\"./iceberg_warehouse\", snapshot_id=current_snapshot)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional cleanup\n",
    "\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree(\"./iceberg_warehouse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Accelerating Pandas code with a one-line-change\n",
    "\n",
    "Bodo DataFrames automatically parallelizes and optimizes workloads written in Pandas.\n",
    "This example uses a representative data engineering workload for creating trip summaries using Central Park weather observations (CSV) and NYC Taxi/Rideshare data (Parquet),\n",
    "highlighting Bodo DataFrames performance on key transformations such as read parquet, datetime manipulation, merge, groupby and sort. \n",
    "We first measure the performance of both Bodo DataFrames, then run in Pandas to see an improvement. \n",
    "This gap becomes larger as we scale to more data and add more cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "\n",
    "weather_dataset = \"data/central_park_weather.csv\"\n",
    "hvfhv_dataset = \"data/fhvhv_tripdata/\"\n",
    "\n",
    "def get_monthly_travels_weather(weather_dataset : str, hvfhv_dataset : str, out_file : str, pd):\n",
    "    \"\"\" Run the full workload and write results to Parquet. \"\"\"\n",
    "    start = perf_counter()\n",
    "    central_park_weather_observations = pd.read_csv(\n",
    "        weather_dataset,\n",
    "        parse_dates=[\"DATE\"],\n",
    "    )\n",
    "    central_park_weather_observations = central_park_weather_observations.rename(\n",
    "        columns={\"DATE\": \"date\", \"PRCP\": \"precipitation\"}, copy=False\n",
    "    )\n",
    "    fhvhv_tripdata = pd.read_parquet(hvfhv_dataset)\n",
    "\n",
    "    central_park_weather_observations[\"date\"] = central_park_weather_observations[\n",
    "        \"date\"\n",
    "    ].dt.date\n",
    "    fhvhv_tripdata[\"date\"] = fhvhv_tripdata[\"pickup_datetime\"].dt.date\n",
    "    fhvhv_tripdata[\"month\"] = fhvhv_tripdata[\"pickup_datetime\"].dt.month\n",
    "    fhvhv_tripdata[\"hour\"] = fhvhv_tripdata[\"pickup_datetime\"].dt.hour\n",
    "    fhvhv_tripdata[\"weekday\"] = fhvhv_tripdata[\"pickup_datetime\"].dt.dayofweek.isin(\n",
    "        [0, 1, 2, 3, 4]\n",
    "    )\n",
    "\n",
    "    monthly_trips_weather = fhvhv_tripdata.merge(\n",
    "        central_park_weather_observations, on=\"date\", how=\"inner\"\n",
    "    )\n",
    "    monthly_trips_weather[\"date_with_precipitation\"] = (\n",
    "        monthly_trips_weather[\"precipitation\"] > 0.1\n",
    "    )\n",
    "\n",
    "    def get_time_bucket(t):\n",
    "        bucket = \"other\"\n",
    "        if t in (8, 9, 10):\n",
    "            bucket = \"morning\"\n",
    "        elif t in (11, 12, 13, 14, 15):\n",
    "            bucket = \"midday\"\n",
    "        elif t in (16, 17, 18):\n",
    "            bucket = \"afternoon\"\n",
    "        elif t in (19, 20, 21):\n",
    "            bucket = \"evening\"\n",
    "        return bucket\n",
    "\n",
    "    monthly_trips_weather[\"time_bucket\"] = monthly_trips_weather.hour.map(\n",
    "        get_time_bucket\n",
    "    )\n",
    "    monthly_trips_weather = monthly_trips_weather.groupby(\n",
    "        [\n",
    "            \"PULocationID\",\n",
    "            \"DOLocationID\",\n",
    "            \"month\",\n",
    "            \"weekday\",\n",
    "            \"date_with_precipitation\",\n",
    "            \"time_bucket\",\n",
    "        ],\n",
    "        as_index=False,\n",
    "    ).agg({\"hvfhs_license_num\": \"count\", \"trip_miles\": \"mean\"})\n",
    "    monthly_trips_weather = monthly_trips_weather.sort_values(\n",
    "        by=[\n",
    "            \"PULocationID\",\n",
    "            \"DOLocationID\",\n",
    "            \"month\",\n",
    "            \"weekday\",\n",
    "            \"date_with_precipitation\",\n",
    "            \"time_bucket\",\n",
    "        ]\n",
    "    )\n",
    "    monthly_trips_weather = monthly_trips_weather.rename(\n",
    "        columns={\n",
    "            \"hvfhs_license_num\": \"trips\",\n",
    "            \"trip_miles\": \"avg_distance\",\n",
    "        },\n",
    "        copy=False,\n",
    "    )\n",
    "\n",
    "    monthly_trips_weather.to_parquet(out_file)\n",
    "    end = perf_counter()\n",
    "    print(\"Total E2E time:\", (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total E2E time: 10.84962783300216\n"
     ]
    }
   ],
   "source": [
    "import bodo.pandas\n",
    "\n",
    "get_monthly_travels_weather(weather_dataset, hvfhv_dataset, out_file=\"bodo_monthly_trips_weather_pandas.pq\", pd=bodo.pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing to Pandas\n",
    "\n",
    "Run the cell below to see the comparison to Pandas. \n",
    "Without any code changed, Bodo accelerates the workflow by ~6-10x on a 2023, 10-core Macbook Pro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total E2E time: 75.9208817079998\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "get_monthly_travels_weather(weather_dataset, hvfhv_dataset, out_file=\"pandas_monthly_trips_weather.pq\", pd=pandas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
