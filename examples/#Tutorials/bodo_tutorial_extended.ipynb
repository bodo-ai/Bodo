{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bodo Extended Tutorial\n",
    "\n",
    "This is a continuation of the getting started tutorial. You are encouraged to visit that tutorial first if you have not done so already. In this tutorial, we will explain core Bodo concepts in more detail, introduce additional Bodo features, and discuss more advanced topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Execution Model\n",
    "\n",
    "As we saw in the getting started tutorial, Bodo transforms functions for parallel execution. \n",
    "Parallel processes are spawned on the fly the first time a JIT function is invoked,\n",
    "with each process managing a distinct portion of the data (this is called the Single Program Multiple Data ([SPMD](https://en.wikipedia.org/wiki/SPMD)) paradigm).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A\n",
      "4  5\n",
      "5  6\n",
      "   A\n",
      "6  7\n",
      "7  8\n",
      "     A\n",
      "10  11\n",
      "11  12\n",
      "   A\n",
      "2  3\n",
      "3  4\n",
      "    A\n",
      "8   9\n",
      "9  10\n",
      "   A\n",
      "0  1\n",
      "1  2\n",
      "     A\n",
      "14  15\n",
      "15  16\n",
      "     A\n",
      "12  13\n",
      "13  14\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# limit the number of rows printed to standard out to reduce clutter\n",
    "pd.options.display.max_rows = 3\n",
    "import bodo\n",
    "\n",
    "@bodo.jit\n",
    "def f(n, a):\n",
    "    df = pd.DataFrame({\"A\": np.arange(n) + a})\n",
    "    print(df)\n",
    "\n",
    "f(16, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel APIs\n",
    "\n",
    "Bodo provides a limited number of parallel APIs to support advanced cases that may need them. The example below demonstrates getting the process number from Bodo (called `rank` in MPI terminology) and the total number of processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank 4 here\n",
      "rank 6 here\n",
      "rank 3 here\n",
      "rank 2 here\n",
      "rank 0 done\n",
      "rank 0 here\n",
      "total ranks: 8\n",
      "rank 1 here\n",
      "rank 5 here\n",
      "rank 7 here\n"
     ]
    }
   ],
   "source": [
    "@bodo.jit\n",
    "def f():\n",
    "    # some work only on rank 0\n",
    "    if bodo.get_rank() == 0:\n",
    "        print(\"rank 0 done\")\n",
    "    \n",
    "    # some work on every process\n",
    "    print(\"rank\", bodo.get_rank(), \"here\")\n",
    "    print(\"total ranks:\", bodo.get_size())\n",
    "f()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common pattern is using barriers to make sure all processes see side-effects at the same time. For example, a process can delete files from storage while others wait before writing to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, os\n",
    "import numpy as np\n",
    "\n",
    "@bodo.wrap_python(bodo.types.none)\n",
    "def delete_files():\n",
    "    if os.path.exists(\"data/data.pq\"):\n",
    "        shutil.rmtree(\"data/data.pq\")\n",
    "\n",
    "@bodo.jit\n",
    "def f(n):\n",
    "    # remove file if exists\n",
    "    if bodo.get_rank() == 0:\n",
    "        delete_files()\n",
    "    \n",
    "    # make sure all processes are synchronized\n",
    "    # (e.g. all processes need to see effect of rank 0's work)\n",
    "    bodo.barrier()\n",
    "    df = pd.DataFrame({\"A\": np.arange(n)})\n",
    "    df.to_parquet(\"data/data.pq\")\n",
    "\n",
    "f(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figure illustrates what happens when processes call `bodo.barrier()`. When barrier is called, a process pauses and waits until all other processes have reached the barrier:\n",
    "\n",
    "![Process synchronization with Barrier](img/barrier.svg)\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\"\n",
    "<b>Important:</b> The examples above show that it is possible to have each process follow a different control flow, but all processes must always call the same Bodo functions in the same order.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Distribution\n",
    "\n",
    "Bodo parallelizes computation by dividing data into separate chunks across processes. However, some data handled by a Bodo function may not be divided into chunks. There are are two main data distribution schemes:\n",
    "\n",
    "- Replicated (*REP*): the data associated with the variable is the same on every process.\n",
    "- One-dimensional (*1D*): the data is divided into chunks, split along one dimension (rows of a dataframe or first dimension of an array).\n",
    "\n",
    "Bodo determines distribution of variables automatically, using the nature of the computation that produces them. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "power    102.078421\n",
      "speed      5.656851\n",
      "dtype: float64\n",
      "power    102.078421\n",
      "speed      5.656851\n",
      "dtype: float64\n",
      "power    102.078421\n",
      "speed      5.656851\n",
      "dtype: float64\n",
      "power    102.078421\n",
      "speed      5.656851\n",
      "dtype: float64\n",
      "power    102.078421\n",
      "speed      5.656851\n",
      "dtype: float64\n",
      "power    102.078421\n",
      "speed      5.656851\n",
      "dtype: float64\n",
      "power    102.078421\n",
      "speed      5.656851\n",
      "dtype: float64\n",
      "power    102.078421\n",
      "speed      5.656851\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "@bodo.jit\n",
    "def mean_power_speed():\n",
    "    df = pd.read_parquet(\"data/cycling_dataset.pq\")\n",
    "    m = df[[\"power\", \"speed\"]].mean()\n",
    "    bodo.parallel_print(m)\n",
    "\n",
    "mean_power_speed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, `df` is parallelized (each process reads a different chunk) but `m` is replicated, even though it is a Series. Semantically, it makes sense for the output of `mean` operation to be replicated on all processors, since it is a reduction and produces \"small\" data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed Diagnostics\n",
    "\n",
    "The distributions found by Bodo can be printed either by setting the `distributed_diagnostics` JIT flag or the\n",
    "environment variable `BODO_DISTRIBUTED_DIAGNOSTICS=1`.\n",
    "Let's examine the previous example's distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributed diagnostics for function mean_power_speed, /var/folders/nb/s_7bnf052hg0lfqvbrw10bsw0000gn/T/ipykernel_62584/1953254433.py (1)\n",
      "\n",
      "Data distributions:\n",
      "   pq_table.823              1D_Block\n",
      "   pq_index.824              1D_Block\n",
      "   _v236call_19_985          1D_Block\n",
      "   _v178call_15_862          1D_Block\n",
      "   _v338call_29_874          1D_Block\n",
      "   data_878                  REP\n",
      "   _v76call_6_1160           REP\n",
      "   _v156call_13_908          REP\n",
      "   _v478call_44_890          REP\n",
      "   table.1323                1D_Block\n",
      "\n",
      "Parfor distributions:\n",
      "   2                    1D_Block\n",
      "   3                    1D_Block\n",
      "\n",
      "Distributed listing for function mean_power_speed, /var/folders/nb/s_7bnf052hg0lfqvbrw10bsw0000gn/T/ipykernel_62584/1953254433.py (1)\n",
      "--------------------------------------------------------| parfor_id/variable: distribution\n",
      "@bodo.jit(distributed_diagnostics=True, spawn=False)    | \n",
      "def mean_power_speed():                                 | \n",
      "    df = pd.read_parquet(\"data/cycling_dataset.pq\")-----| pq_table.823: 1D_Block, pq_index.824: 1D_Block\n",
      "    m = df[[\"power\", \"speed\"]].mean()-------------------| #2: 1D_Block, #3: 1D_Block, _v236call_19_985: 1D_Block, _v178call_15_862: 1D_Block, _v338call_29_874: 1D_Block, data_878: REP, _v478call_44_890: REP\n",
      "    bodo.parallel_print(m)                              | \n",
      "\n",
      "Setting distribution of variable 'data_878' to REP: output of np.asarray() call on non-array is REP\n",
      "\u001b[1m\n",
      "File \"../../../../../../var/folders/nb/s_7bnf052hg0lfqvbrw10bsw0000gn/T/ipykernel_62584/1953254433.py\", line 4:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "Setting distribution of variable '_v76call_6_1160' to REP: output of str_arr_from_sequence is REP\n",
      "\u001b[1m\n",
      "File \"../../bodo/hiframes/pd_index_ext.py\", line 869:\u001b[0m\n",
      "\u001b[1m            def impl(\n",
      "                <source elided>\n",
      "                return bodo.hiframes.pd_index_ext.init_binary_str_index(\n",
      "\u001b[1m                    bodo.utils.conversion.coerce_to_array(data), name\n",
      "\u001b[0m                    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\n",
      "power    102.078421\n",
      "speed      5.656851\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "@bodo.jit(distributed_diagnostics=True, spawn=False)\n",
    "def mean_power_speed():\n",
    "    df = pd.read_parquet(\"data/cycling_dataset.pq\")\n",
    "    m = df[[\"power\", \"speed\"]].mean()\n",
    "    bodo.parallel_print(m)\n",
    "\n",
    "mean_power_speed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables are renamed due to optimization. The output shows that `power` and `speed` columns of `df` are distributed (`1D_Block`) but `m` is replicated (`REP`). This is because `df` is output of `read_parquet` and input of `mean`, both of which can be distributed by Bodo. `m` is output of `mean`, which is always replicated (available on every process)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Arguments and Return Values\n",
    "\n",
    "Now let's see what happens if we pass the data into the Bodo function as a function parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "power    102.078421\n",
      "speed      5.656851\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "@bodo.jit\n",
    "def mean_power_speed(df):\n",
    "    m = df[[\"power\", \"speed\"]].mean()\n",
    "    return m\n",
    "\n",
    "df = pd.read_parquet(\"data/cycling_dataset.pq\")\n",
    "df.time = df.time.astype(\"datetime64[ns]\")\n",
    "res = mean_power_speed(df)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program runs and returns the same correct value as before. However, the input DataFrame is sent from the main Python process\n",
    "to the parallel MPI processes which can introduce significant overheads. In addition,\n",
    "parallel I/O and other I/O related optimizations such as filter pushdown and column pruning cannot be performed.\n",
    "Therefore, reading data inside JIT functions is very important for best performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bodo will attempt to return distributed data in most cases. However, the data is gathered in the\n",
    "main process lazily only when necessary. `BodoDataFrame` is a DataFrame wrapper class that manages this lazy data gather."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bodo.pandas.frame.BodoDataFrame'>\n",
      "      Unnamed: 0    altitude  cadence  ...  power  speed                time\n",
      "0              0  185.800003       51  ...     45  3.459 2016-10-20 22:01:26\n",
      "...          ...         ...      ...  ...    ...    ...                 ...\n",
      "3901        1131  178.399994        0  ...      0  2.853 2016-10-20 23:14:35\n",
      "\n",
      "[3902 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "import bodo\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_columns = 7\n",
    "\n",
    "@bodo.jit\n",
    "def mean_power_speed():\n",
    "    df = pd.read_parquet(\"data/cycling_dataset.pq\")\n",
    "    return df\n",
    "\n",
    "df = mean_power_speed()\n",
    "print(type(df))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing Distributed Data to Bodo\n",
    "\n",
    "Bodo returned parallel dataframes can be passed across Bodo functions without the need for gathering data in the main process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total size 3902\n",
      "total size 3902\n"
     ]
    }
   ],
   "source": [
    "@bodo.jit\n",
    "def read_data():\n",
    "    df = pd.read_parquet(\"data/cycling_dataset.pq\")\n",
    "    print(\"total size\", len(df))\n",
    "    return df\n",
    "\n",
    "@bodo.jit\n",
    "def write_data(df):\n",
    "    print(\"total size\", len(df))\n",
    "    df.to_parquet(\"data/cycling_dataset2.pq\")\n",
    "\n",
    "df = read_data()\n",
    "write_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel I/O\n",
    "\n",
    "![Bodo reads file chunks in parallel](img/file-read.jpg)\n",
    "\n",
    "Efficient parallel data processing requires data I/O to be parallelized effectively as well.\n",
    "Bodo provides parallel file I/O for many different formats such as [Parquet](http://parquet.apache.org),\n",
    "[Iceberg](https://iceberg.apache.org/), Snowflake,\n",
    "CSV, JSON, Numpy binaries, [HDF5](http://www.h5py.org) and SQL databases.\n",
    "This diagram demonstrates how chunks of data are partitioned among parallel execution engines by Bodo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parquet\n",
    "\n",
    "Parquet is a commonly used file format in analytics due to its efficient columnar storage. Bodo supports the standard pandas API for reading Parquet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0    altitude  cadence  ...  power  speed                time\n",
      "1464          69  125.599998       82  ...      9  6.890 2016-10-20 22:32:07\n",
      "1465          70  125.800003      144  ...      9  6.890 2016-10-20 22:32:08\n",
      "1466          71  126.000000        0  ...      4  6.590 2016-10-20 22:32:09\n",
      "1467          72  125.800003        0  ...      2  6.334 2016-10-20 22:32:10\n",
      "1468          73  125.800003        0  ...     11  6.306 2016-10-20 22:32:11\n",
      "...          ...         ...      ...  ...    ...    ...                 ...\n",
      "1947         552  147.000000       72  ...    135  6.356 2016-10-20 22:41:29\n",
      "1948         553  147.399994       99  ...    153  6.452 2016-10-20 22:41:30\n",
      "1949         554  147.600006       85  ...    117  6.550 2016-10-20 22:41:31\n",
      "1950         555  147.600006       78  ...    129  6.581 2016-10-20 22:41:32\n",
      "1951         556  147.600006       78  ...    121  6.621 2016-10-20 22:41:33\n",
      "\n",
      "[488 rows x 10 columns]\n",
      "      Unnamed: 0    altitude  cadence  ...  power  speed                time\n",
      "1952         557  147.399994       78  ...    161  6.714 2016-10-20 22:41:34\n",
      "1953         558  147.000000       85  ...    146  6.854 2016-10-20 22:41:35\n",
      "1954         559  146.600006      110  ...    178  7.022 2016-10-20 22:41:36\n",
      "1955         560  146.600006       78  ...    188  7.139 2016-10-20 22:41:37\n",
      "1956         561  146.399994       75  ...     63  7.260 2016-10-20 22:41:38\n",
      "...          ...         ...      ...  ...    ...    ...                 ...\n",
      "2435        1040  151.800003       82  ...      0  5.193 2016-10-20 22:49:37\n",
      "2436        1041  152.399994       64  ...      0  4.953 2016-10-20 22:49:38\n",
      "2437        1042  152.800003        0  ...      0  4.953 2016-10-20 22:49:39\n",
      "2438        1043  153.000000        0  ...    123  4.754 2016-10-20 22:49:40\n",
      "2439        1044  153.000000       56  ...    146  4.890 2016-10-20 22:49:41\n",
      "\n",
      "[488 rows x 10 columns]\n",
      "      Unnamed: 0    altitude  cadence  ...  power   speed                time\n",
      "3415         645  180.800003        0  ...      0   9.272 2016-10-20 23:06:11\n",
      "3416         646  180.600006        0  ...      0   9.630 2016-10-20 23:06:12\n",
      "3417         647  180.399994        0  ...      0   9.970 2016-10-20 23:06:13\n",
      "3418         648  180.000000        0  ...      0  10.285 2016-10-20 23:06:14\n",
      "3419         649  179.600006        0  ...      0  10.411 2016-10-20 23:06:15\n",
      "...          ...         ...      ...  ...    ...     ...                 ...\n",
      "3897        1127  178.199997        0  ...      0   3.497 2016-10-20 23:14:31\n",
      "3898        1128  178.199997        0  ...      0   3.289 2016-10-20 23:14:32\n",
      "3899        1129  178.199997        0  ...      0   2.969 2016-10-20 23:14:33\n",
      "3900        1130  178.399994        0  ...      0   2.969 2016-10-20 23:14:34\n",
      "3901        1131  178.399994        0  ...      0   2.853 2016-10-20 23:14:35\n",
      "\n",
      "[487 rows x 10 columns]\n",
      "     Unnamed: 0    altitude  cadence  ...  power  speed                time\n",
      "0             0  185.800003       51  ...     45  3.459 2016-10-20 22:01:26\n",
      "1             1  185.800003       68  ...      0  3.710 2016-10-20 22:01:27\n",
      "2             2  186.399994       38  ...     42  3.874 2016-10-20 22:01:28\n",
      "3             3  186.800003       38  ...      5  4.135 2016-10-20 22:01:29\n",
      "4             4  186.600006       38  ...      1  4.250 2016-10-20 22:01:30\n",
      "..          ...         ...      ...  ...    ...    ...                 ...\n",
      "483         483  162.600006       50  ...    124  4.030 2016-10-20 22:12:06\n",
      "484         484  162.399994       51  ...    105  4.776 2016-10-20 22:12:07\n",
      "485         485  162.399994       55  ...     93  5.182 2016-10-20 22:12:08\n",
      "486         486  162.399994       63  ...     45  5.560 2016-10-20 22:12:09\n",
      "487         487  162.399994       81  ...      0  5.810 2016-10-20 22:12:10\n",
      "\n",
      "[488 rows x 10 columns]\n",
      "     Unnamed: 0    altitude  cadence  ...  power  speed                time\n",
      "488         488  162.199997      100  ...      0  6.057 2016-10-20 22:12:11\n",
      "489         489  162.000000        0  ...      0  6.326 2016-10-20 22:12:12\n",
      "490         490  161.800003        0  ...      0  6.509 2016-10-20 22:12:13\n",
      "491         491  161.600006        0  ...      0  6.810 2016-10-20 22:12:14\n",
      "492         492  161.399994        0  ...      0  6.989 2016-10-20 22:12:15\n",
      "..          ...         ...      ...  ...    ...    ...                 ...\n",
      "971         971  132.399994        0  ...      1  4.385 2016-10-20 22:20:32\n",
      "972         972  132.199997        0  ...      1  4.122 2016-10-20 22:20:33\n",
      "973         973  132.199997        0  ...    283  4.715 2016-10-20 22:20:34\n",
      "974         974  132.399994       70  ...     98  5.161 2016-10-20 22:20:35\n",
      "975         975  132.399994      115  ...      1  5.155 2016-10-20 22:20:36\n",
      "\n",
      "[488 rows x 10 columns]\n",
      "      Unnamed: 0    altitude  cadence  ...  power  speed                time\n",
      "2928         158  191.800003       82  ...    169  5.656 2016-10-20 22:58:04\n",
      "2929         159  191.800003       78  ...    210  5.518 2016-10-20 22:58:05\n",
      "2930         160  192.000000       76  ...    223  5.518 2016-10-20 22:58:06\n",
      "2931         161  192.199997       76  ...    193  5.468 2016-10-20 22:58:07\n",
      "2932         162  192.600006       75  ...    154  5.406 2016-10-20 22:58:08\n",
      "...          ...         ...      ...  ...    ...    ...                 ...\n",
      "3410         640  181.000000       90  ...    155  8.268 2016-10-20 23:06:06\n",
      "3411         641  181.000000      108  ...      0  8.415 2016-10-20 23:06:07\n",
      "3412         642  180.600006       28  ...      0  8.550 2016-10-20 23:06:08\n",
      "3413         643  181.000000        0  ...      0  8.648 2016-10-20 23:06:09\n",
      "3414         644  181.000000        0  ...      0  8.902 2016-10-20 23:06:10\n",
      "\n",
      "[487 rows x 10 columns]\n",
      "      Unnamed: 0    altitude  cadence  ...  power  speed                time\n",
      "976          976  132.199997        0  ...      0  5.263 2016-10-20 22:20:37\n",
      "977          977  132.199997        0  ...      0  4.757 2016-10-20 22:20:38\n",
      "978          978  132.000000        0  ...      0  4.040 2016-10-20 22:20:39\n",
      "979          979  131.800003        0  ...    121  3.671 2016-10-20 22:20:40\n",
      "980          980  131.399994       24  ...     12  3.664 2016-10-20 22:20:41\n",
      "...          ...         ...      ...  ...    ...    ...                 ...\n",
      "1459          64  125.599998        0  ...    264  3.707 2016-10-20 22:32:02\n",
      "1460          65  125.599998       26  ...    353  3.945 2016-10-20 22:32:03\n",
      "1461          66  125.599998       47  ...    500  5.186 2016-10-20 22:32:04\n",
      "1462          67  125.800003       50  ...    593  6.213 2016-10-20 22:32:05\n",
      "1463          68  125.599998       59  ...    142  7.004 2016-10-20 22:32:06\n",
      "\n",
      "[488 rows x 10 columns]\n",
      "      Unnamed: 0    altitude  cadence  ...  power  speed                time\n",
      "2440        1045  152.800003       68  ...    151  5.005 2016-10-20 22:49:42\n",
      "2441        1046  152.399994       68  ...    140  5.100 2016-10-20 22:49:43\n",
      "2442        1047  152.000000       69  ...    154  5.162 2016-10-20 22:49:44\n",
      "2443        1048  152.199997       72  ...    154  5.162 2016-10-20 22:49:45\n",
      "2444        1049  152.399994       72  ...    135  5.219 2016-10-20 22:49:46\n",
      "...          ...         ...      ...  ...    ...    ...                 ...\n",
      "2923         153  189.800003        0  ...     21  7.963 2016-10-20 22:57:59\n",
      "2924         154  190.399994        0  ...    122  7.033 2016-10-20 22:58:00\n",
      "2925         155  190.800003       85  ...    229  6.539 2016-10-20 22:58:01\n",
      "2926         156  190.800003       96  ...    185  6.188 2016-10-20 22:58:02\n",
      "2927         157  191.399994       87  ...    181  5.794 2016-10-20 22:58:03\n",
      "\n",
      "[488 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "@bodo.jit\n",
    "def pq_read():\n",
    "    df = pd.read_parquet(\"data/cycling_dataset.pq\")\n",
    "    print(df)\n",
    "\n",
    "pq_read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bodo also supports the pandas API for writing Parquet files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@bodo.jit\n",
    "def generate_data_and_write():\n",
    "    df = pd.DataFrame({\"A\": np.arange(80)})\n",
    "    df.to_parquet(\"data/pq_output.pq\")\n",
    "\n",
    "generate_data_and_write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"\n",
    "<b>Note:</b> Bodo writes a directory of parquet files (one file per process) when writing distributed data. Bodo writes a single file when the data is replicated.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, `df` is distributed data so it is written to a directory a parquet files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bodo supports parallel read of single Parquet files, as well as directory of files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A\n",
      "40  40\n",
      "41  41\n",
      "42  42\n",
      "43  43\n",
      "44  44\n",
      "45  45\n",
      "46  46\n",
      "47  47\n",
      "48  48\n",
      "49  49\n",
      "     A\n",
      "50  50\n",
      "51  51\n",
      "52  52\n",
      "53  53\n",
      "54  54\n",
      "55  55\n",
      "56  56\n",
      "57  57\n",
      "58  58\n",
      "59  59\n",
      "     A\n",
      "70  70\n",
      "71  71\n",
      "72  72\n",
      "73  73\n",
      "74  74\n",
      "75  75\n",
      "76  76\n",
      "77  77\n",
      "78  78\n",
      "79  79\n",
      "     A\n",
      "10  10\n",
      "11  11\n",
      "12  12\n",
      "13  13\n",
      "14  14\n",
      "15  15\n",
      "16  16\n",
      "17  17\n",
      "18  18\n",
      "19  19\n",
      "     A\n",
      "20  20\n",
      "21  21\n",
      "22  22\n",
      "23  23\n",
      "24  24\n",
      "25  25\n",
      "26  26\n",
      "27  27\n",
      "28  28\n",
      "29  29\n",
      "     A\n",
      "30  30\n",
      "31  31\n",
      "32  32\n",
      "33  33\n",
      "34  34\n",
      "35  35\n",
      "36  36\n",
      "37  37\n",
      "38  38\n",
      "39  39\n",
      "     A\n",
      "60  60\n",
      "61  61\n",
      "62  62\n",
      "63  63\n",
      "64  64\n",
      "65  65\n",
      "66  66\n",
      "67  67\n",
      "68  68\n",
      "69  69\n",
      "   A\n",
      "0  0\n",
      "1  1\n",
      "2  2\n",
      "3  3\n",
      "4  4\n",
      "5  5\n",
      "6  6\n",
      "7  7\n",
      "8  8\n",
      "9  9\n"
     ]
    }
   ],
   "source": [
    "@bodo.jit\n",
    "def read_parquet_dir():\n",
    "    df = pd.read_parquet(\"data/pq_output.pq\")\n",
    "    print(df)\n",
    "\n",
    "read_parquet_dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV\n",
    "CSV is a common text format for data exchange. Bodo supports the standard pandas API to read CSV files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0    1           2    3  ...          7    8      9                   10\n",
      "1464  1464   69  125.599998   82  ... -97.764937    9   6.89  2016-10-20 22:32:07\n",
      "1465  1465   70  125.800003  144  ... -97.764988    9   6.89  2016-10-20 22:32:08\n",
      "1466  1466   71       126.0    0  ... -97.765038    4   6.59  2016-10-20 22:32:09\n",
      "1467  1467   72  125.800003    0  ... -97.765083    2  6.334  2016-10-20 22:32:10\n",
      "1468  1468   73  125.800003    0  ... -97.765132   11  6.306  2016-10-20 22:32:11\n",
      "...    ...  ...         ...  ...  ...        ...  ...    ...                  ...\n",
      "1947  1947  552       147.0   72  ... -97.782195  135  6.356  2016-10-20 22:41:29\n",
      "1948  1948  553  147.399994   99  ... -97.782233  153  6.452  2016-10-20 22:41:30\n",
      "1949  1949  554  147.600006   85  ...  -97.78227  117   6.55  2016-10-20 22:41:31\n",
      "1950  1950  555  147.600006   78  ... -97.782309  129  6.581  2016-10-20 22:41:32\n",
      "1951  1951  556  147.600006   78  ... -97.782343  121  6.621  2016-10-20 22:41:33\n",
      "\n",
      "[488 rows x 11 columns]\n",
      "         0     1           2   3  ...          7    8      9                   10\n",
      "2440  2440  1045  152.800003  68  ... -97.773363  151  5.005  2016-10-20 22:49:42\n",
      "2441  2441  1046  152.399994  68  ...  -97.77332  140    5.1  2016-10-20 22:49:43\n",
      "2442  2442  1047       152.0  69  ... -97.773273  154  5.162  2016-10-20 22:49:44\n",
      "2443  2443  1048  152.199997  72  ...  -97.77323  154  5.162  2016-10-20 22:49:45\n",
      "2444  2444  1049  152.399994  72  ... -97.773189  135  5.219  2016-10-20 22:49:46\n",
      "...    ...   ...         ...  ..  ...        ...  ...    ...                  ...\n",
      "2923  2923   153  189.800003   0  ... -97.767708   21  7.963  2016-10-20 22:57:59\n",
      "2924  2924   154  190.399994   0  ... -97.767669  122  7.033  2016-10-20 22:58:00\n",
      "2925  2925   155  190.800003  85  ... -97.767626  229  6.539  2016-10-20 22:58:01\n",
      "2926  2926   156  190.800003  96  ... -97.767593  185  6.188  2016-10-20 22:58:02\n",
      "2927  2927   157  191.399994  87  ... -97.767551  181  5.794  2016-10-20 22:58:03\n",
      "\n",
      "[488 rows x 11 columns]\n",
      "       0    1           2   3  ...          7    8      9                   10\n",
      "0      0    0  185.800003  51  ... -97.732711   45  3.459  2016-10-20 22:01:26\n",
      "1      1    1  185.800003  68  ... -97.732715    0   3.71  2016-10-20 22:01:27\n",
      "2      2    2  186.399994  38  ... -97.732717   42  3.874  2016-10-20 22:01:28\n",
      "3      3    3  186.800003  38  ...  -97.73272    5  4.135  2016-10-20 22:01:29\n",
      "4      4    4  186.600006  38  ... -97.732723    1   4.25  2016-10-20 22:01:30\n",
      "..   ...  ...         ...  ..  ...        ...  ...    ...                  ...\n",
      "483  483  483  162.600006  50  ... -97.748722  124   4.03  2016-10-20 22:12:06\n",
      "484  484  484  162.399994  51  ... -97.748739  105  4.776  2016-10-20 22:12:07\n",
      "485  485  485  162.399994  55  ...  -97.74876   93  5.182  2016-10-20 22:12:08\n",
      "486  486  486  162.399994  63  ... -97.748788   45   5.56  2016-10-20 22:12:09\n",
      "487  487  487  162.399994  81  ... -97.748813    0   5.81  2016-10-20 22:12:10\n",
      "\n",
      "[488 rows x 11 columns]\n",
      "       0    1           2    3  ...          7    8      9                   10\n",
      "488  488  488  162.199997  100  ...  -97.74884    0  6.057  2016-10-20 22:12:11\n",
      "489  489  489       162.0    0  ... -97.748867    0  6.326  2016-10-20 22:12:12\n",
      "490  490  490  161.800003    0  ...  -97.74889    0  6.509  2016-10-20 22:12:13\n",
      "491  491  491  161.600006    0  ... -97.748912    0   6.81  2016-10-20 22:12:14\n",
      "492  492  492  161.399994    0  ... -97.748936    0  6.989  2016-10-20 22:12:15\n",
      "..   ...  ...         ...  ...  ...        ...  ...    ...                  ...\n",
      "971  971  971  132.399994    0  ... -97.751541    1  4.385  2016-10-20 22:20:32\n",
      "972  972  972  132.199997    0  ... -97.751539    1  4.122  2016-10-20 22:20:33\n",
      "973  973  973  132.199997    0  ... -97.751541  283  4.715  2016-10-20 22:20:34\n",
      "974  974  974  132.399994   70  ... -97.751543   98  5.161  2016-10-20 22:20:35\n",
      "975  975  975  132.399994  115  ...        0.0    1  5.155  2016-10-20 22:20:36\n",
      "\n",
      "[488 rows x 11 columns]\n",
      "         0    1           2   3  ...          7    8      9                   10\n",
      "976    976  976  132.199997   0  ... -97.751543    0  5.263  2016-10-20 22:20:37\n",
      "977    977  977  132.199997   0  ... -97.751548    0  4.757  2016-10-20 22:20:38\n",
      "978    978  978       132.0   0  ... -97.751555    0   4.04  2016-10-20 22:20:39\n",
      "979    979  979  131.800003   0  ... -97.751561  121  3.671  2016-10-20 22:20:40\n",
      "980    980  980  131.399994  24  ... -97.751574   12  3.664  2016-10-20 22:20:41\n",
      "...    ...  ...         ...  ..  ...        ...  ...    ...                  ...\n",
      "1459  1459   64  125.599998   0  ... -97.764702  264  3.707  2016-10-20 22:32:02\n",
      "1460  1460   65  125.599998  26  ... -97.764731  353  3.945  2016-10-20 22:32:03\n",
      "1461  1461   66  125.599998  47  ... -97.764772  500  5.186  2016-10-20 22:32:04\n",
      "1462  1462   67  125.800003  50  ... -97.764822  593  6.213  2016-10-20 22:32:05\n",
      "1463  1463   68  125.599998  59  ... -97.764884  142  7.004  2016-10-20 22:32:06\n",
      "\n",
      "[488 rows x 11 columns]\n",
      "         0     1           2    3  ...          7    8      9                   10\n",
      "1952  1952   557  147.399994   78  ... -97.782387  161  6.714  2016-10-20 22:41:34\n",
      "1953  1953   558       147.0   85  ... -97.782426  146  6.854  2016-10-20 22:41:35\n",
      "1954  1954   559  146.600006  110  ... -97.782466  178  7.022  2016-10-20 22:41:36\n",
      "1955  1955   560  146.600006   78  ... -97.782496  188  7.139  2016-10-20 22:41:37\n",
      "1956  1956   561  146.399994   75  ... -97.782545   63   7.26  2016-10-20 22:41:38\n",
      "...    ...   ...         ...  ...  ...        ...  ...    ...                  ...\n",
      "2435  2435  1040  151.800003   82  ... -97.773593    0  5.193  2016-10-20 22:49:37\n",
      "2436  2436  1041  152.399994   64  ... -97.773548    0  4.953  2016-10-20 22:49:38\n",
      "2437  2437  1042  152.800003    0  ...   -97.7735    0  4.953  2016-10-20 22:49:39\n",
      "2438  2438  1043       153.0    0  ... -97.773454  123  4.754  2016-10-20 22:49:40\n",
      "2439  2439  1044       153.0   56  ...  -97.77341  146   4.89  2016-10-20 22:49:41\n",
      "\n",
      "[488 rows x 11 columns]\n",
      "         0    1           2    3  ...          7    8      9                   10\n",
      "2928  2928  158  191.800003   82  ... -97.767516  169  5.656  2016-10-20 22:58:04\n",
      "2929  2929  159  191.800003   78  ... -97.767484  210  5.518  2016-10-20 22:58:05\n",
      "2930  2930  160       192.0   76  ... -97.767454  223  5.518  2016-10-20 22:58:06\n",
      "2931  2931  161  192.199997   76  ... -97.767425  193  5.468  2016-10-20 22:58:07\n",
      "2932  2932  162  192.600006   75  ... -97.767394  154  5.406  2016-10-20 22:58:08\n",
      "...    ...  ...         ...  ...  ...        ...  ...    ...                  ...\n",
      "3410  3410  640       181.0   90  ... -97.747154  155  8.268  2016-10-20 23:06:06\n",
      "3411  3411  641       181.0  108  ... -97.747082    0  8.415  2016-10-20 23:06:07\n",
      "3412  3412  642  180.600006   28  ... -97.747004    0   8.55  2016-10-20 23:06:08\n",
      "3413  3413  643       181.0    0  ... -97.746918    0  8.648  2016-10-20 23:06:09\n",
      "3414  3414  644       181.0    0  ... -97.746833    0  8.902  2016-10-20 23:06:10\n",
      "\n",
      "[487 rows x 11 columns]\n",
      "         0     1           2  3  ...          7  8       9                   10\n",
      "3415  3415   645  180.800003  0  ... -97.746745  0   9.272  2016-10-20 23:06:11\n",
      "3416  3416   646  180.600006  0  ... -97.746663  0    9.63  2016-10-20 23:06:12\n",
      "3417  3417   647  180.399994  0  ...  -97.74657  0    9.97  2016-10-20 23:06:13\n",
      "3418  3418   648       180.0  0  ... -97.746476  0  10.285  2016-10-20 23:06:14\n",
      "3419  3419   649  179.600006  0  ... -97.746395  0  10.411  2016-10-20 23:06:15\n",
      "...    ...   ...         ... ..  ...        ... ..     ...                  ...\n",
      "3897  3897  1127  178.199997  0  ... -97.733165  0   3.497  2016-10-20 23:14:31\n",
      "3898  3898  1128  178.199997  0  ... -97.733141  0   3.289  2016-10-20 23:14:32\n",
      "3899  3899  1129  178.199997  0  ... -97.733114  0   2.969  2016-10-20 23:14:33\n",
      "3900  3900  1130  178.399994  0  ... -97.733087  0   2.969  2016-10-20 23:14:34\n",
      "3901  3901  1131  178.399994  0  ... -97.733063  0   2.853  2016-10-20 23:14:35\n",
      "\n",
      "[487 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "@bodo.jit()\n",
    "def csv_example():\n",
    "    df = pd.read_csv(\"data/cycling_dataset.csv\", header=None)\n",
    "    print(df)\n",
    "\n",
    "csv_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the pandas `read_csv()` functionality, Bodo can also read a directory containing multiple CSV files (all part of the same dataframe)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"\n",
    "<b>Note:</b>\n",
    "\n",
    "When writing distributed data to CSV:\n",
    "\n",
    "- To S3 or HDFS: Bodo writes to a directory of CSV files (one file per process)\n",
    "- To POSIX filesystem (e.g. local filesystem on Linux): Bodo writes the distributed data in parallel to a single file.\n",
    "\n",
    "If the data is replicated, Bodo always writes to a single file.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5\n",
    "HDF5 is a common format in scientific computing and AI, especially for multi-dimensional numerical data. HDF5 can be very efficient at scale, since it has native parallel I/O support. Bodo supports the standard h5py APIs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "@bodo.jit\n",
    "def example_h5():\n",
    "    f = h5py.File(\"data/data.h5\", \"r\")\n",
    "    return f[\"A\"][:].sum()\n",
    "\n",
    "res = example_h5()\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy Binary Files\n",
    "Bodo supports reading and writing binary files using Numpy APIs as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "@bodo.jit\n",
    "def example_np_io():\n",
    "    A = np.fromfile(\"data/data.dat\", np.int64)\n",
    "    return A.sum()\n",
    "\n",
    "res = example_np_io()\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type Annotation (when file name is unknown at compile time)\n",
    "\n",
    "Bodo needs to know or infer the types for all data, but this is not always possible for input from files if file name is not known at compilation time.\n",
    "\n",
    "For example, suppose we have the following files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def generate_files(n):\n",
    "    for i in range(n):\n",
    "        df = pd.DataFrame({\"A\": np.arange(5, dtype=np.int64)})\n",
    "        df.to_parquet(\"data/test\" + str(i) + \".pq\")\n",
    "\n",
    "generate_files(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we want to read them like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "BodoError",
     "evalue": "\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1mParquet schema not available. Either path argument should be constant for Bodo to look at the file at compile time or schema should be provided. For more information, see: https://docs.bodo.ai/latest/file_io/#parquet-section.\u001b[0m\n\u001b[1m\nFile \"../../../../../../var/folders/nb/s_7bnf052hg0lfqvbrw10bsw0000gn/T/ipykernel_67841/4178619562.py\", line 9:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBodoError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m         x \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m---> 15\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mread_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# BodoError: Parquet schema not available. Either path argument should be\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# constant for Bodo to look at the file at compile time or schema should be provided.\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/Bodo/bodo/submit/spawner.py:599\u001b[0m, in \u001b[0;36mSubmitDispatcher.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 599\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msubmit_func_to_workers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecorator_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpropagate_env\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/Bodo/bodo/submit/spawner.py:584\u001b[0m, in \u001b[0;36msubmit_func_to_workers\u001b[0;34m(dispatcher, propagate_env, *args, **kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get the global spawner and submit `func` for execution\"\"\"\u001b[39;00m\n\u001b[1;32m    583\u001b[0m spawner \u001b[38;5;241m=\u001b[39m get_spawner()\n\u001b[0;32m--> 584\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mspawner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit_func_to_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdispatcher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpropagate_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/Bodo/bodo/submit/spawner.py:295\u001b[0m, in \u001b[0;36mSpawner.submit_func_to_workers\u001b[0;34m(self, dispatcher, propagate_env, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m all_ranks_failed \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(types) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(msgs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    294\u001b[0m     excep \u001b[38;5;241m=\u001b[39m caught_exceptions[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 295\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m excep\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;66;03m# Annotate exceptions with their rank\u001b[39;00m\n\u001b[1;32m    298\u001b[0m     exceptions \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mBodoError\u001b[0m: \u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1mParquet schema not available. Either path argument should be constant for Bodo to look at the file at compile time or schema should be provided. For more information, see: https://docs.bodo.ai/latest/file_io/#parquet-section.\u001b[0m\n\u001b[1m\nFile \"../../../../../../var/folders/nb/s_7bnf052hg0lfqvbrw10bsw0000gn/T/ipykernel_67841/4178619562.py\", line 9:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bodo\n",
    "\n",
    "@bodo.jit\n",
    "def read_data(n):\n",
    "    x = 0\n",
    "    for i in range(n):\n",
    "        file_name = \"data/test\" + str(i) + \".pq\"\n",
    "        df = pd.read_parquet(file_name)\n",
    "        print(df)\n",
    "        x += df[\"A\"].sum()\n",
    "    return x\n",
    "\n",
    "result = read_data(5)\n",
    "# BodoError: Parquet schema not available. Either path argument should be\n",
    "# constant for Bodo to look at the file at compile time or schema should be provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file names are computed at runtime, which doesn't allow the compiler to find the files and extract the schemas. As shown below, the solution is to use *type annotation* to provide data types to the compiler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type annotation for Parquet files\n",
    "\n",
    "Example below uses the `locals` option of the decorator to provide the compiler with the schema of the local variable `df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ehsan/dev/Bodo/bodo/io/parquet_pio.py:994: BodoWarning: Total number of row groups in parquet dataset data/test0.pq (1) is too small for effective IO parallelization.For best performance the number of row groups should be greater than the number of workers (8). For more details, refer to https://docs.bodo.ai/latest/file_io/#parquet-section.\n",
      "  warnings.warn(\n",
      "/Users/ehsan/dev/Bodo/bodo/io/parquet_pio.py:994: BodoWarning: Total number of row groups in parquet dataset data/test1.pq (1) is too small for effective IO parallelization.For best performance the number of row groups should be greater than the number of workers (8). For more details, refer to https://docs.bodo.ai/latest/file_io/#parquet-section.\n",
      "  warnings.warn(\n",
      "/Users/ehsan/dev/Bodo/bodo/io/parquet_pio.py:994: BodoWarning: Total number of row groups in parquet dataset data/test2.pq (1) is too small for effective IO parallelization.For best performance the number of row groups should be greater than the number of workers (8). For more details, refer to https://docs.bodo.ai/latest/file_io/#parquet-section.\n",
      "  warnings.warn(\n",
      "/Users/ehsan/dev/Bodo/bodo/io/parquet_pio.py:994: BodoWarning: Total number of row groups in parquet dataset data/test3.pq (1) is too small for effective IO parallelization.For best performance the number of row groups should be greater than the number of workers (8). For more details, refer to https://docs.bodo.ai/latest/file_io/#parquet-section.\n",
      "  warnings.warn(\n",
      "/Users/ehsan/dev/Bodo/bodo/io/parquet_pio.py:994: BodoWarning: Total number of row groups in parquet dataset data/test4.pq (1) is too small for effective IO parallelization.For best performance the number of row groups should be greater than the number of workers (8). For more details, refer to https://docs.bodo.ai/latest/file_io/#parquet-section.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "@bodo.jit(locals={\"df\": {\"A\": bodo.types.int64[:]}})\n",
    "def read_data(n):\n",
    "    x = 0\n",
    "    for i in range(n):\n",
    "        file_name = \"data/test\" + str(i) + \".pq\"\n",
    "        df = pd.read_parquet(file_name)\n",
    "        x += df[\"A\"].sum()\n",
    "    return x\n",
    "\n",
    "result = read_data(5)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type annotation for CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For CSV files, we can annotate types in the same way as pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "def generate_files(n):\n",
    "    for i in range(n):\n",
    "        df = pd.DataFrame({\"A\": np.arange(5, dtype=np.int64)})\n",
    "        df.to_csv(\"data/test\" + str(i) + \".csv\", index=False)\n",
    "\n",
    "@bodo.jit\n",
    "def read_data(n):\n",
    "    coltypes = {\"A\": np.int64}\n",
    "    x = 0\n",
    "    for i in range(n):\n",
    "        file_name = \"data/test\" + str(i) + \".csv\"\n",
    "        df = pd.read_csv(file_name, names=coltypes.keys(), dtype=coltypes, header=0)\n",
    "        x += df[\"A\"].sum()\n",
    "    return x\n",
    "\n",
    "n = 5\n",
    "generate_files(n)\n",
    "result = read_data(n)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bodo Caching\n",
    "\n",
    "In many situations, Bodo can save the binary resulting from the compilation of a function to disk, to be reused in future runs. This avoids the need to recompile functions the next time that you run your application.\n",
    "\n",
    "As we explained earlier, recompiling a function is only necessary when it is called with new input types, and the same applies to caching. In other words, an application can be run multiple times and process different data without having to recompile any code if the data types remain the same (which is the most common situation).\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"\n",
    "<b>Warning:</b> Caching works in many (but not all) situations, and is disabled by default. See caching limitations below for more information.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caching Example\n",
    "\n",
    "To cache a function, we only need to add the option `cache=True` to the JIT decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "power    102.078421\n",
      "speed      5.656851\n",
      "dtype: float64\n",
      "Total execution time: 1.35 secs\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "@bodo.jit(cache=True)\n",
    "def mean_power_speed():\n",
    "    df = pd.read_parquet(\"data/cycling_dataset.pq\")\n",
    "    return df[[\"power\", \"speed\"]].mean()\n",
    "\n",
    "t0 = time.time()\n",
    "result = mean_power_speed()\n",
    "print(result)\n",
    "print(\"Total execution time:\", round(time.time() - t0, 3), \"secs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first time that the above code runs, Bodo compiles the function and caches it to disk. In subsequent runs, it will recover the function from cache and the execution time will be much faster as a result. You can try this out by running the above code multiple times, and changing between `cache=True` and `cache=False`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cache Location and Portability\n",
    "\n",
    "In most cases, the cache is saved in the `__pycache__` directory inside the directory where the source files are located.\n",
    "\n",
    "On Jupyter notebooks, the cache directory is called ``numba_cache`` and is located in ``IPython.paths.get_ipython_cache_dir()``. See [here](http://numba.pydata.org/numba-doc/latest/reference/envvars.html?#envvar-NUMBA_CACHE_DIR) for more information on these and other alternate cache locations. For example, when running in a notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache files:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['575913040.mean_power_speed-b2cd27ff54.py312bodo2024.11.2.dev18+ge776d57a2c.d20241201-af6917c9bc5148f3345e1483e0d8d05e.nbi',\n",
       " '575913040.mean_power_speed-b2cd27ff54.py312bodo2024.11.2.dev18+ge776d57a2c.d20241201-af6917c9bc5148f3345e1483e0d8d05e.1.nbc']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import IPython\n",
    "\n",
    "cache_dir = IPython.paths.get_ipython_cache_dir() + \"/numba_cache\"\n",
    "print(\"Cache files:\")\n",
    "os.listdir(cache_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cached objects work across systems with the same CPU model and CPU features. Therefore, it is safe to share and reuse the contents in the cache directory on a different machine. See [here](http://numba.pydata.org/numba-doc/latest/developer/caching.html#cache-sharing) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cache Invalidation\n",
    "\n",
    "The cache is invalidated automatically when the corresponding source code is modified. One way to observe this behavior is to modify the above example after it has been cached a first time, by changing the name of the variable `df`. The next time that we run the code, Bodo will determine that the source code has been modified, invalidate the cache and recompile the function.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"\n",
    "<b>Warning:</b> It is sometimes necessary to clear the cache manually (see caching limitations below). To clear the cache, the cache files can simply be removed.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current Caching Limitations\n",
    "\n",
    "- Changes in compiled functions are not seen across files. For example, if we have a cached Bodo function that calls a cached Bodo function in a different file, and modify the latter, Bodo will not update its cache (and therefore run with the old version of the function).\n",
    "- Global variables are treated as compile-time constants. When a function is compiled, the value of any globals that the function uses are embedded in the binary at compilation time and remain constant. If the value of the global changes in the source code after compilation, the compiled object (and cache) will not rebind to the new value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Features\n",
    "\n",
    "### Explicit Parallel Loops\n",
    "Sometimes explicit parallel loops are required since a program cannot be written in terms of data-parallel operators easily. In this case, one can use Bodo’s `prange` in place of `range` to specify that a loop can be parallelized. The user is required to make sure the loop does not have cross iteration dependencies except for supported reductions.\n",
    "\n",
    "The example below demonstrates a parallel loop with a reduction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank 7\n",
      "rank 6\n",
      "rank 3\n",
      "rank 5\n",
      "rank 2\n",
      "rank 1\n",
      "rank 1\n",
      "rank 0\n",
      "rank 0\n",
      "rank 4\n",
      "15.960590511716582\n"
     ]
    }
   ],
   "source": [
    "import bodo\n",
    "from bodo import prange\n",
    "import numpy as np\n",
    "\n",
    "@bodo.jit\n",
    "def prange_test(n):\n",
    "    A = np.random.ranf(n)\n",
    "    s = 0\n",
    "    B = np.empty(n)\n",
    "    for i in prange(len(A)):\n",
    "        bodo.parallel_print(\"rank\", bodo.get_rank())\n",
    "        # A[i]: distributed data access with loop index\n",
    "        # s: a supported sum reduction\n",
    "        s += A[i]\n",
    "        # write array with loop index\n",
    "        B[i] = 2 * A[i]\n",
    "    return s + B.sum()\n",
    "\n",
    "res = prange_test(10)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, reductions using +=, *=, min, and max operators are supported. Iterations are simply divided between processes and executed in parallel, but reductions are handled using data exchange."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collections of Distributed Data\n",
    "List and dictionary collections can be used to hold distributed data structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.119124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>0.713300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     A         B\n",
       "0    0  0.119124\n",
       "..  ..       ...\n",
       "99  99  0.713300\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@bodo.jit()\n",
    "def f():\n",
    "    to_concat = []\n",
    "    for i in range(10):\n",
    "        to_concat.append(pd.DataFrame({'A': np.arange(100), 'B': np.random.random(100)}))\n",
    "    df = pd.concat(to_concat)\n",
    "    return df\n",
    "\n",
    "f()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "### Compilation Tips\n",
    "\n",
    "The general recommendation is to **compile the code that is performance critical and/or requires scaling**.\n",
    "\n",
    "1. Don’t use Bodo for scripts that set up infrastucture or do initializations.\n",
    "2. Only use Bodo for data processing and analytics code.\n",
    "\n",
    "This reduces the risk of hitting unsupported features and reduces compilation time. To do so, simply factor out the code that needs to be compiled by Bodo and pass data into Bodo compiled functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilation Errors\n",
    "\n",
    "The most common reason is that the code relies on features that Bodo currently does not support, so it’s important to understand the limitations of Bodo. There are 4 main limitations:\n",
    "\n",
    "1. Not supported Pandas API (see [here](https://docs.bodo.ai/2022.6/api_docs/pandas/))\n",
    "2. Not supported NumPy API (see [here](https://docs.bodo.ai/2022.6/api_docs/numpy/))\n",
    "3. Not supported Python features or datatypes (see [here](https://docs.bodo.ai/2022.6/bodo_parallelism/not_supported/))\n",
    "4. Not supported Python programs due to type instability\n",
    "\n",
    "Solutions:\n",
    "\n",
    "1. Make sure your code works in Python (using a small sample dataset): a lot of the times a Bodo decorated function doesn’t compile, but it does not work in Python either.\n",
    "2. Replace unsupported operations with supported operations if possible.\n",
    "3. Refactor the code to partially use regular Python, explained in \"Integration with non-Bodo APIs\" section.\n",
    "\n",
    "For example, the code below uses heterogenous list values inside `a` which cannot be typed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "BodoError",
     "evalue": "\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBodoError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m         a\u001b[38;5;241m.\u001b[39mappend([i, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m a\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/dev/Bodo/bodo/submit/spawner.py:599\u001b[0m, in \u001b[0;36mSubmitDispatcher.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 599\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msubmit_func_to_workers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecorator_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpropagate_env\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/Bodo/bodo/submit/spawner.py:584\u001b[0m, in \u001b[0;36msubmit_func_to_workers\u001b[0;34m(dispatcher, propagate_env, *args, **kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get the global spawner and submit `func` for execution\"\"\"\u001b[39;00m\n\u001b[1;32m    583\u001b[0m spawner \u001b[38;5;241m=\u001b[39m get_spawner()\n\u001b[0;32m--> 584\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mspawner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit_func_to_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdispatcher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpropagate_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/Bodo/bodo/submit/spawner.py:295\u001b[0m, in \u001b[0;36mSpawner.submit_func_to_workers\u001b[0;34m(self, dispatcher, propagate_env, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m all_ranks_failed \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(types) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(msgs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    294\u001b[0m     excep \u001b[38;5;241m=\u001b[39m caught_exceptions[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 295\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m excep\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;66;03m# Annotate exceptions with their rank\u001b[39;00m\n\u001b[1;32m    298\u001b[0m     exceptions \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mBodoError\u001b[0m: \u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "@bodo.jit\n",
    "def f(n):\n",
    "    a = [[-1, \"a\"]]\n",
    "    for i in range(n):\n",
    "        a.append([i, \"a\"])\n",
    "    return a\n",
    "\n",
    "print(f(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this use case can be rewritten to use tuple values instead of lists since values don't change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-1, 'a'), (0, 'a'), (1, 'a'), (2, 'a')]\n"
     ]
    }
   ],
   "source": [
    "@bodo.jit\n",
    "def f(n):\n",
    "    a = [(-1, \"a\")]\n",
    "    for i in range(n):\n",
    "        a.append((i, \"a\"))\n",
    "    return a\n",
    "\n",
    "print(f(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Schema Stability\n",
    "\n",
    "Deterministic dataframe schemas (column names and types), which are required in most data systems, are key for type stability. For example, variable `df` in example below could be either a single column dataframe or a two column one – Bodo cannot determine it at compilation time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypingError",
     "evalue": "\u001b[1m\u001b[1m\u001b[1mCannot unify dataframe((Array(int64, 1, 'C', False, aligned=True),), RangeIndexType(none), ('A',), 1D_Block_Var, False, False) and dataframe((Array(int64, 1, 'C', False, aligned=True), Array(float64, 1, 'C', False, aligned=True)), RangeIndexType(none), ('A', 'C'), 1D_Block_Var, True, False) for 'df.2', defined at /var/folders/nb/s_7bnf052hg0lfqvbrw10bsw0000gn/T/ipykernel_67841/1453791955.py (8)\n\u001b[1m\nFile \"../../../../../../var/folders/nb/s_7bnf052hg0lfqvbrw10bsw0000gn/T/ipykernel_67841/1453791955.py\", line 8:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n\u001b[0m\u001b[0m\n\u001b[1m\nFile \"../../../../../../var/folders/nb/s_7bnf052hg0lfqvbrw10bsw0000gn/T/ipykernel_67841/1453791955.py\", line 8:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n\n\u001b[1m\nFile \"../../../../../../var/folders/nb/s_7bnf052hg0lfqvbrw10bsw0000gn/T/ipykernel_67841/1453791955.py\", line 8:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n\u001b[0m",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m         df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mmerge(df2)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# TypeError: Cannot unify dataframe((array(int64, 1d, C),), RangeIndexType(none), ('A',), False)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# and dataframe((array(int64, 1d, C), array(int64, 1d, C)), RangeIndexType(none), ('A', 'C'), False) for 'df'\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/Bodo/bodo/submit/spawner.py:599\u001b[0m, in \u001b[0;36mSubmitDispatcher.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 599\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msubmit_func_to_workers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecorator_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpropagate_env\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/Bodo/bodo/submit/spawner.py:584\u001b[0m, in \u001b[0;36msubmit_func_to_workers\u001b[0;34m(dispatcher, propagate_env, *args, **kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get the global spawner and submit `func` for execution\"\"\"\u001b[39;00m\n\u001b[1;32m    583\u001b[0m spawner \u001b[38;5;241m=\u001b[39m get_spawner()\n\u001b[0;32m--> 584\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mspawner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit_func_to_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdispatcher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpropagate_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/Bodo/bodo/submit/spawner.py:295\u001b[0m, in \u001b[0;36mSpawner.submit_func_to_workers\u001b[0;34m(self, dispatcher, propagate_env, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m all_ranks_failed \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(types) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(msgs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    294\u001b[0m     excep \u001b[38;5;241m=\u001b[39m caught_exceptions[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 295\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m excep\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;66;03m# Annotate exceptions with their rank\u001b[39;00m\n\u001b[1;32m    298\u001b[0m     exceptions \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mTypingError\u001b[0m: \u001b[1m\u001b[1m\u001b[1mCannot unify dataframe((Array(int64, 1, 'C', False, aligned=True),), RangeIndexType(none), ('A',), 1D_Block_Var, False, False) and dataframe((Array(int64, 1, 'C', False, aligned=True), Array(float64, 1, 'C', False, aligned=True)), RangeIndexType(none), ('A', 'C'), 1D_Block_Var, True, False) for 'df.2', defined at /var/folders/nb/s_7bnf052hg0lfqvbrw10bsw0000gn/T/ipykernel_67841/1453791955.py (8)\n\u001b[1m\nFile \"../../../../../../var/folders/nb/s_7bnf052hg0lfqvbrw10bsw0000gn/T/ipykernel_67841/1453791955.py\", line 8:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n\u001b[0m\u001b[0m\n\u001b[1m\nFile \"../../../../../../var/folders/nb/s_7bnf052hg0lfqvbrw10bsw0000gn/T/ipykernel_67841/1453791955.py\", line 8:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n\n\u001b[1m\nFile \"../../../../../../var/folders/nb/s_7bnf052hg0lfqvbrw10bsw0000gn/T/ipykernel_67841/1453791955.py\", line 8:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n\u001b[0m"
     ]
    }
   ],
   "source": [
    "@bodo.jit\n",
    "def f(a, n):\n",
    "    df = pd.DataFrame({\"A\": np.arange(n)})\n",
    "    df2 = pd.DataFrame({\"A\": np.arange(n) ** 2, \"C\": np.ones(n)})\n",
    "    if len(a) > 3:\n",
    "        df = df.merge(df2)\n",
    "\n",
    "    return df.mean()\n",
    "\n",
    "print(f([2, 3], 10))\n",
    "# TypeError: Cannot unify dataframe((array(int64, 1d, C),), RangeIndexType(none), ('A',), False)\n",
    "# and dataframe((array(int64, 1d, C), array(int64, 1d, C)), RangeIndexType(none), ('A', 'C'), False) for 'df'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error message means that Bodo cannot find a type that can unify the two types into a single type. This code can be refactored so that the if control flow is executed in regular Python context, but the rest of computation is in Bodo functions. For example, one could use two versions of the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    3.5\n",
      "C    1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "@bodo.jit\n",
    "def f1(n):\n",
    "    df = pd.DataFrame({\"A\": np.arange(n)})\n",
    "    return df.mean()\n",
    "\n",
    "@bodo.jit\n",
    "def f2(n):\n",
    "    df = pd.DataFrame({\"A\": np.arange(n)})\n",
    "    df2 = pd.DataFrame({\"A\": np.arange(n) ** 2, \"C\": np.ones(n)})\n",
    "    df = df.merge(df2)\n",
    "    return df.mean()\n",
    "\n",
    "a = [2, 3]\n",
    "if len(a) > 3:\n",
    "    print(f1(10))\n",
    "else:\n",
    "    print(f2(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common place where schema stability may be compromised is in passing non-constant list of key column names to dataframe operations such as `groupby`, `merge` and `sort_values`. In these operations, Bodo should be able to deduce the list of key column names at compile time in order to determine the output dataframe schema. For example, the program below is potentially type unstable since Bodo may not be able to infer `column_list` during compilation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "BodoError",
     "evalue": "\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1mgroupby(): 'by' parameter only supports a constant column label or column labels, not reflected list(unicode_type)<iv=None>.\u001b[0m\n\u001b[1m\nFile \"../../../../../../var/folders/nb/s_7bnf052hg0lfqvbrw10bsw0000gn/T/ipykernel_67841/3424421760.py\", line 8:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBodoError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\u001b[38;5;241m.\u001b[39mgroupby(column_list)\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     10\u001b[0m a \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 11\u001b[0m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# BodoError: groupby(): 'by' parameter only supports a constant column label or column labels.\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/Bodo/bodo/submit/spawner.py:599\u001b[0m, in \u001b[0;36mSubmitDispatcher.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 599\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msubmit_func_to_workers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecorator_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpropagate_env\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/Bodo/bodo/submit/spawner.py:584\u001b[0m, in \u001b[0;36msubmit_func_to_workers\u001b[0;34m(dispatcher, propagate_env, *args, **kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get the global spawner and submit `func` for execution\"\"\"\u001b[39;00m\n\u001b[1;32m    583\u001b[0m spawner \u001b[38;5;241m=\u001b[39m get_spawner()\n\u001b[0;32m--> 584\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mspawner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit_func_to_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdispatcher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpropagate_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/Bodo/bodo/submit/spawner.py:295\u001b[0m, in \u001b[0;36mSpawner.submit_func_to_workers\u001b[0;34m(self, dispatcher, propagate_env, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m all_ranks_failed \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(types) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(msgs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    294\u001b[0m     excep \u001b[38;5;241m=\u001b[39m caught_exceptions[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 295\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m excep\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;66;03m# Annotate exceptions with their rank\u001b[39;00m\n\u001b[1;32m    298\u001b[0m     exceptions \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mBodoError\u001b[0m: \u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1mgroupby(): 'by' parameter only supports a constant column label or column labels, not reflected list(unicode_type)<iv=None>.\u001b[0m\n\u001b[1m\nFile \"../../../../../../var/folders/nb/s_7bnf052hg0lfqvbrw10bsw0000gn/T/ipykernel_67841/3424421760.py\", line 8:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "@bodo.jit\n",
    "def f(a, n, flag):\n",
    "    # some computation that cannot be inferred statically\n",
    "    column_list = a\n",
    "    if flag:\n",
    "        column_list = [\"A\"]\n",
    "    df = pd.DataFrame({\"A\": np.arange(n), \"B\": np.ones(n)})\n",
    "    return df.groupby(column_list).sum()\n",
    "\n",
    "a = [\"A\", \"B\"]\n",
    "f(a, 10, True)\n",
    "# BodoError: groupby(): 'by' parameter only supports a constant column label or column labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code can most often be refactored to compute the key list in regular Python and pass as argument to Bodo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      B\n",
       "A      \n",
       "9   1.0\n",
       "..  ...\n",
       "6   1.0\n",
       "\n",
       "[10 rows x 1 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@bodo.jit\n",
    "def f(column_list, n):\n",
    "    df = pd.DataFrame({\"A\": np.arange(n), \"B\": np.ones(n)})\n",
    "    return df.groupby(column_list).sum()\n",
    "\n",
    "flag = True\n",
    "column_list = [\"A\", \"B\"]\n",
    "if flag:\n",
    "    column_list = [\"A\"]\n",
    "f(column_list, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nullable Integers in Pandas\n",
    "\n",
    "DataFrame and Series objects with integer data need special care due to [integer NA issues in Pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/gotchas.html#nan-integer-na-values-and-na-type-promotions). By default, Pandas dynamically converts integer columns to floating point when missing values (NAs) are needed, which can result in loss of precision as well as type instability.\n",
    "\n",
    "Pandas introduced [a new nullable integer data type](https://pandas.pydata.org/pandas-docs/stable/user_guide/integer_na.html#integer-na) that can solve this issue, which is also supported by Bodo. For example, this code reads column A into a nullable integer array (the capital “I” denotes nullable integer type):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B\n",
       "0   11  1.2\n",
       "..  ..  ...\n",
       "3    4 -0.1\n",
       "\n",
       "[4 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = (\n",
    "    \"11,1.2\\n\"\n",
    "    \"-2,\\n\"\n",
    "    \",3.1\\n\"\n",
    "    \"4,-0.1\\n\"\n",
    ")\n",
    "\n",
    "with open(\"data/data.csv\", \"w\") as f:\n",
    "    f.write(data)\n",
    "\n",
    "\n",
    "@bodo.jit()\n",
    "def f():\n",
    "    dtype = {\"A\": \"Int64\", \"B\": \"float64\"}\n",
    "    df = pd.read_csv(\"data/data.csv\", dtype = dtype, names = dtype.keys())\n",
    "    return df\n",
    "\n",
    "f()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking NA Values\n",
    "\n",
    "When an operation iterates over the values in a Series or Array, type stablity requires special handling for NAs using `pd.isna()`. For example, `Series.map()` applies an operation to each element in the series and failing to check for NAs can result in garbage values propagating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "    ..\n",
      "4    1\n",
      "Length: 5, dtype: int8[pyarrow]\n"
     ]
    }
   ],
   "source": [
    "S = pd.Series(pd.array([1, None, None, 3, 10], dtype=\"Int8\"))\n",
    "\n",
    "@bodo.jit\n",
    "def map_copy(S):\n",
    "    return S.map(lambda a: a if not pd.isna(a) else None)\n",
    "\n",
    "print(map_copy(S))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxing/Unboxing Overheads\n",
    "\n",
    "Bodo uses efficient native data structures which can be different than Python. When Python values are passed to Bodo, they are *unboxed* to native representation. On the other hand, returning Bodo values requires *boxing* to Python objects. Boxing and unboxing can have significant overhead depending on size and type of data. For example, passing `date` columns between Python/Bodo repeatedly can be expensive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       2016-10-20\n",
      "           ...    \n",
      "3901    2016-10-20\n",
      "Name: time, Length: 3902, dtype: object\n",
      "0       20\n",
      "        ..\n",
      "3901    20\n",
      "Name: time, Length: 3902, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "@bodo.jit()\n",
    "def get_data():\n",
    "    df = pd.read_parquet(\"data/cycling_dataset.pq\")\n",
    "    return df[\"time\"].dt.date\n",
    "\n",
    "@bodo.jit()\n",
    "def get_day(S):\n",
    "    return S.map(lambda d: d.day)\n",
    "\n",
    "S = get_data()\n",
    "print(S)\n",
    "res = get_day(S)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can try to keep data in Bodo functions as much as possible to avoid boxing/unboxing overheads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      2016-10-20\n",
      "1      2016-10-20\n",
      "2      2016-10-20\n",
      "3      2016-10-20\n",
      "4      2016-10-20\n",
      "          ...    \n",
      "483    2016-10-20\n",
      "484    2016-10-20\n",
      "485    2016-10-20\n",
      "486    2016-10-20\n",
      "487    2016-10-20\n",
      "Name: time, Length: 488, dtype: object\n",
      "1464    2016-10-20\n",
      "1465    2016-10-20\n",
      "1466    2016-10-20\n",
      "1467    2016-10-20\n",
      "1468    2016-10-20\n",
      "           ...    \n",
      "1947    2016-10-20\n",
      "1948    2016-10-20\n",
      "1949    2016-10-20\n",
      "1950    2016-10-20\n",
      "1951    2016-10-20\n",
      "Name: time, Length: 488, dtype: object\n",
      "2928    2016-10-20\n",
      "2929    2016-10-20\n",
      "2930    2016-10-20\n",
      "2931    2016-10-20\n",
      "2932    2016-10-20\n",
      "           ...    \n",
      "3410    2016-10-20\n",
      "3411    2016-10-20\n",
      "3412    2016-10-20\n",
      "3413    2016-10-20\n",
      "3414    2016-10-20\n",
      "Name: time, Length: 487, dtype: object\n",
      "3415    2016-10-20\n",
      "3416    2016-10-20\n",
      "3417    2016-10-20\n",
      "3418    2016-10-20\n",
      "3419    2016-10-20\n",
      "           ...    \n",
      "3897    2016-10-20\n",
      "3898    2016-10-20\n",
      "3899    2016-10-20\n",
      "3900    2016-10-20\n",
      "3901    2016-10-20\n",
      "Name: time, Length: 487, dtype: object\n",
      "2440    2016-10-20\n",
      "2441    2016-10-20\n",
      "2442    2016-10-20\n",
      "2443    2016-10-20\n",
      "2444    2016-10-20\n",
      "           ...    \n",
      "2923    2016-10-20\n",
      "2924    2016-10-20\n",
      "2925    2016-10-20\n",
      "2926    2016-10-20\n",
      "2927    2016-10-20\n",
      "Name: time, Length: 488, dtype: object\n",
      "488    2016-10-20\n",
      "489    2016-10-20\n",
      "490    2016-10-20\n",
      "491    2016-10-20\n",
      "492    2016-10-20\n",
      "          ...    \n",
      "971    2016-10-20\n",
      "972    2016-10-20\n",
      "973    2016-10-20\n",
      "974    2016-10-20\n",
      "975    2016-10-20\n",
      "Name: time, Length: 488, dtype: object\n",
      "976     2016-10-20\n",
      "977     2016-10-20\n",
      "978     2016-10-20\n",
      "979     2016-10-20\n",
      "980     2016-10-20\n",
      "           ...    \n",
      "1459    2016-10-20\n",
      "1460    2016-10-20\n",
      "1461    2016-10-20\n",
      "1462    2016-10-20\n",
      "1463    2016-10-20\n",
      "Name: time, Length: 488, dtype: object\n",
      "976     20\n",
      "977     20\n",
      "978     20\n",
      "979     20\n",
      "980     20\n",
      "        ..\n",
      "1459    20\n",
      "1460    20\n",
      "1461    20\n",
      "1462    20\n",
      "1463    20\n",
      "Name: time, Length: 488, dtype: int64\n",
      "0      20\n",
      "1      20\n",
      "2      20\n",
      "3      20\n",
      "4      20\n",
      "       ..\n",
      "483    20\n",
      "484    20\n",
      "485    20\n",
      "486    20\n",
      "487    20\n",
      "Name: time, Length: 488, dtype: int64\n",
      "488    20\n",
      "489    20\n",
      "490    20\n",
      "491    20\n",
      "492    20\n",
      "       ..\n",
      "971    20\n",
      "972    20\n",
      "973    20\n",
      "974    20\n",
      "975    20\n",
      "Name: time, Length: 488, dtype: int64\n",
      "1464    20\n",
      "1465    20\n",
      "1466    20\n",
      "1467    20\n",
      "1468    20\n",
      "        ..\n",
      "1947    20\n",
      "1948    20\n",
      "1949    20\n",
      "1950    20\n",
      "1951    20\n",
      "Name: time, Length: 488, dtype: int64\n",
      "1952    2016-10-20\n",
      "1953    2016-10-20\n",
      "1954    2016-10-20\n",
      "1955    2016-10-20\n",
      "1956    2016-10-20\n",
      "           ...    \n",
      "2435    2016-10-20\n",
      "2436    2016-10-20\n",
      "2437    2016-10-20\n",
      "2438    2016-10-20\n",
      "2439    2016-10-20\n",
      "Name: time, Length: 488, dtype: object\n",
      "1952    20\n",
      "1953    20\n",
      "1954    20\n",
      "1955    20\n",
      "1956    20\n",
      "        ..\n",
      "2435    20\n",
      "2436    20\n",
      "2437    20\n",
      "2438    20\n",
      "2439    20\n",
      "Name: time, Length: 488, dtype: int64\n",
      "2440    20\n",
      "2441    20\n",
      "2442    20\n",
      "2443    20\n",
      "2444    20\n",
      "        ..\n",
      "2923    20\n",
      "2924    20\n",
      "2925    20\n",
      "2926    20\n",
      "2927    20\n",
      "Name: time, Length: 488, dtype: int64\n",
      "2928    20\n",
      "2929    20\n",
      "2930    20\n",
      "2931    20\n",
      "2932    20\n",
      "        ..\n",
      "3410    20\n",
      "3411    20\n",
      "3412    20\n",
      "3413    20\n",
      "3414    20\n",
      "Name: time, Length: 487, dtype: int64\n",
      "3415    20\n",
      "3416    20\n",
      "3417    20\n",
      "3418    20\n",
      "3419    20\n",
      "        ..\n",
      "3897    20\n",
      "3898    20\n",
      "3899    20\n",
      "3900    20\n",
      "3901    20\n",
      "Name: time, Length: 487, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "@bodo.jit()\n",
    "def get_data():\n",
    "    df = pd.read_parquet(\"data/cycling_dataset.pq\")\n",
    "    return df[\"time\"].dt.date\n",
    "\n",
    "@bodo.jit()\n",
    "def get_day(S):\n",
    "    return S.map(lambda d: d.day)\n",
    "\n",
    "@bodo.jit\n",
    "def f():\n",
    "    S = get_data()\n",
    "    print(S)\n",
    "    res = get_day(S)\n",
    "    print(res)\n",
    "\n",
    "f()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating Over Columns\n",
    "\n",
    "Iterating over columns in a dataframe can cause type stability issues, since column types in each iteration can be different. Bodo supports this usage for many practical cases by automatically unrolling loops over dataframe columns when possible. For example, the example below computes the sum of all data frame columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2680.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@bodo.jit\n",
    "def f():\n",
    "    n = 20\n",
    "    df = pd.DataFrame({\"A\": np.arange(n), \"B\": np.arange(n) ** 2, \"C\": np.ones(n)})\n",
    "    s = 0\n",
    "    for c in df.columns:\n",
    "     s += df[c].sum()\n",
    "    return s\n",
    "\n",
    "f()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For automatic unrolling, the loop needs to be a `for` loop over column names that can be determined by Bodo at compile time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Expressions using `re`\n",
    "\n",
    "Bodo supports string processing using Pandas and the `re` standard package, offering significant flexibility for string processing applications. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    3\n",
       "2    5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "@bodo.jit\n",
    "def f(S):\n",
    "    def g(a):\n",
    "        res = 0\n",
    "        if re.search(\".*AB.*\", a):\n",
    "            res = 3\n",
    "        if re.search(\".*23.*\", a):\n",
    "            res = 5\n",
    "        return res\n",
    "\n",
    "    return S.map(g)\n",
    "\n",
    "S = pd.Series([\"AABCDE\", \"BBABCE\", \"1234\"])\n",
    "f(S)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c055ab4e8dcaec5bc09e1db7dc9ba0af7856e6dca0079f8d0a35c557fbc4193a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
