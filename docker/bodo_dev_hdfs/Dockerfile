FROM ubuntu:latest AS env_setup
#
# The docker is compiled for example with the command
# docker build -t bodo_dev_hdfs .
#

ENV DEBIAN_FRONTEND=noninteractive

WORKDIR /root
#
# Ubuntu installs and Mambaforge
#
RUN apt-get update && apt-get install -y wget bzip2 git vim make curl \
	&& wget https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-Linux-x86_64.sh -O mambaforge.sh \
	&& chmod +x mambaforge.sh\
	&& ./mambaforge.sh -b
ENV PATH /root/mambaforge/bin/:${PATH}

#
# Creation of the BODODEV environment
#
RUN mamba create -n BODODEV -y numpy scipy pandas=${BODO_PD_VERSION:-'1.4.*'} boost-cpp=1.74.0 cmake h5py mpich mpi 'gcc_linux-64>=9' 'gxx_linux-64>=9' python=3.9 -c conda-forge
RUN mamba install -n BODODEV -y numba=0.55.2 'hdf5=1.12.*=*mpich*' pyarrow=9.0.0 fsspec -c conda-forge
RUN mamba install -n BODODEV -y sqlalchemy pymysql xlrd openpyxl mpi4py cython hdfs3 ccache -c conda-forge
RUN mamba install -n BODODEV -y openjdk=11 pytest ipython
# RUN mamba install -n BODODEV scikit-learn='1.1.*' -c conda-forge

# installing hadoop and libhdfs (JNI)
ARG hdfs=3.3.2
ENV HADOOP_HOME=/opt/hadoop-${hdfs}
ENV HADOOP_YARN_HOME=$HADOOP_HOME
ENV HADOOP_MAPRED_HOME=$HADOOP_HOME
RUN wget -q -O - "https://www.apache.org/dyn/mirrors/mirrors.cgi?action=download&filename=hadoop/common/hadoop-${hdfs}/hadoop-${hdfs}.tar.gz" | tar -xzf - -C /opt

# copy hadoop configuration for pseudo-distributed
COPY core-site.xml $HADOOP_HOME/etc/hadoop/
COPY hdfs-site.xml $HADOOP_HOME/etc/hadoop/
COPY reset_hdfs.sh /root

# install ssh server
RUN apt-get update
RUN apt-get install -y openssh-server

# configure ssh
RUN ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
RUN cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
RUN chmod 0600 ~/.ssh/authorized_keys

#
# set up initial .bashrc for ssh
#

RUN echo "export PATH=$HOME/mambaforge/bin:$PATH" >> ~/.bashrc
RUN echo "source activate BODODEV" >> ~/.bashrc

# hadoop related enviroment variables
RUN echo "export HDFS_NAMENODE_USER=root" >> ~/.bashrc
RUN echo "export HDFS_DATANODE_USER=root" >> ~/.bashrc
RUN echo "export HDFS_SECONDARYNAMENODE_USER=root" >> ~/.bashrc
RUN echo "export JAVA_HOME=/root/mambaforge/envs/BODODEV" >> ${HADOOP_HOME}/etc/hadoop/hadoop-env.sh

# build bodo
RUN echo "cd /Bodo" >> ~/.bashrc
RUN echo "python setup.py develop" >> ~/.bashrc

# environment variables for arrow
RUN echo "export hdfs=3.3.2" >> ~/.bashrc
RUN echo "export HADOOP_HOME=/opt/hadoop-${hdfs}" >> ~/.bashrc
RUN echo "export ARROW_LIBHDFS_DIR=$HADOOP_HOME/lib/native" >> ~/.bashrc
RUN echo "export CLASSPATH=`$HADOOP_HOME/bin/hdfs classpath --glob`" >> ~/.bashrc
RUN echo "export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native" >> ~/.bashrc
RUN echo "export HADOOP_OPTS='-Djava.library.path=$HADOOP_HOME/lib'" >> ~/.bashrc
