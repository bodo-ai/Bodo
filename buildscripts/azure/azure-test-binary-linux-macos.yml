parameters:
  name: ''
  vmImage: ''
  caching_test: false
  PYTHON_VERSION: ''
  BODO_TESTING_HAS_MULTI_RANK_TEST: false
  matrix: []

jobs:
- job: ${{ parameters.name }}
  timeoutInMinutes: 360
  variables:
    - group: SnowflakeCredentials
  pool: ScalingVMSet
  strategy:
    matrix:
      ${{ insert }}: ${{ parameters.matrix }}

  steps:

  - task: UsePythonVersion@0
    inputs:
      versionSpec: '3.8'
      #Github Token used to download python from the GitHub registry if it doesn't already exist locally
      githubToken: $(GITHUB_REGISTRY_DL_TOKEN)
    displayName: 'Use Python 3.8'

  - script: |
      set -eo pipefail
      unamestr=`uname`
      if [[ "$unamestr" == 'Linux' ]]; then
        wget https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-Linux-x86_64.sh -O mambaforge.sh
      else
        wget https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-MacOSX-x86_64.sh -O mambaforge.sh
      fi
      chmod +x mambaforge.sh
      ./mambaforge.sh -b
      export PATH=$HOME/mambaforge/bin:${PATH}
      mamba create -y -n $CONDA_ENV python=$PYTHON_VERSION -c conda-forge
      source activate $CONDA_ENV
    env:
      CONDA_ENV:  ${{ parameters.CONDA_ENV }}
      PYTHON_VERSION: ${{ parameters.PYTHON_VERSION }}
    displayName: 'Download Mambaforge and Create Mamba Env'

  - script: |
      set -eo pipefail
      export PATH=$HOME/mambaforge/bin:${PATH}
      source activate $CONDA_ENV
      mamba install -y numba -c numba/label/dev -c conda-forge
    displayName: 'Install Numba-Dev'
    condition: and(succeeded(), eq('${{ parameters.useNumbaDev }}', 'true'))

  - task: DownloadSecureFile@1
    name: secret_file
    inputs:
      secureFile: 'publish_binary_secrets'
    displayName: 'Download Secrets File'

  - script: |
      set -eo pipefail
      sudo chmod a+r $(secret_file.secureFilePath)
      sudo cp $(secret_file.secureFilePath) $HOME/secret_file
      export PATH=$HOME/mambaforge/bin:${PATH}
      source activate $CONDA_ENV
      export CHECK_LICENSE_PLATFORM=$(CHECK_LICENSE_PLATFORM)
      export CHECK_LICENSE_EXPIRED=$(CHECK_LICENSE_EXPIRED)
      export OBFUSCATE=$(OBFUSCATE)
      if [[ "${{ parameters.platformBuild }}" == "true" ]]; then
        export PLATFORM_DEV_RELEASE=$(PLATFORM_DEV_RELEASE)
      else
        export PLATFORM_DEV_RELEASE="false"
      fi
      export BODO_VERSION=`python -c "import versioneer; print(versioneer.get_version())"`
      cd $(System.DefaultWorkingDirectory)
      ./buildscripts/azure/install_bodo.sh $BODO_VERSION $PLATFORM_DEV_RELEASE
    displayName: 'Install Bodo from Mamba'

  - script: |
      set -eo pipefail
      export PATH=$HOME/mambaforge/bin:${PATH}
      source activate $CONDA_ENV
      conda list -f numba
    displayName: 'Check Numba Version'

  - script: |
      set -eo pipefail
      mkdir -p $HOME/bodo-inc
      cd $HOME/bodo-inc
      mkdir bodo
      unamestr=`uname`
      if [[ "$unamestr" == 'Linux' ]]; then
        cp -avr $(System.DefaultWorkingDirectory)/bodo/tests bodo
      else
        cp -r $(System.DefaultWorkingDirectory)/bodo/tests bodo
      fi
    displayName: 'Copy Test Data'

  - script: |
      buildscripts/setup_minio.sh
    displayName: 'Setup Minio'

  - script: |
      set -eo pipefail
      export PATH=$HOME/mambaforge/bin:$PATH
      source activate $CONDA_ENV
      # s3fs is required by pandas for S3 IO
      # Cap the botocore version at 1.20.105 because 1.20.106 is incompatable
      # with fsspec.
      mamba install -y -c conda-forge fsspec>=2021.09 boto3 botocore=1.20.105 s3fs
    displayName: 'Setup S3 Testing'

  - script: |
      set -eo pipefail
      export PATH=$HOME/mambaforge/bin:$PATH
      source activate $CONDA_ENV
      mamba install -y -c conda-forge 'gcsfs>=2022.1'
    displayName: 'Setup GCS Testing'

  - script: |
      set -eo pipefail
      export PATH=$HOME/mambaforge/bin:$PATH
      source activate $CONDA_ENV
      pip install deltalake
    displayName: 'Setup Deltalake Testing'

  - script: |
      set -eo pipefail
      export PATH=$HOME/mambaforge/bin:$PATH
      source activate $CONDA_ENV
      mamba install -y -c conda-forge pymysql sqlalchemy snowflake-sqlalchemy
      mamba install -y -c conda-forge snowflake-connector-python --force --no-deps
    displayName: 'Setup MySQL + Snowflake Testing'

  - script: |
      set -eo pipefail
      export PATH=$HOME/mambaforge/bin:$PATH
      source activate $CONDA_ENV
      mamba install -y -c conda-forge scikit-learn='1.1.*'
    displayName: 'Setup Scikit-Learn Testing'

  - script: |
      set -eo pipefail
      export PATH=$HOME/mambaforge/bin:$PATH
      source activate $CONDA_ENV
      mamba install -y -c conda-forge openjdk=11
      unamestr=`uname`
      if [[ "$unamestr" == 'Linux' ]]; then
        wget -q -O - "https://www.apache.org/dyn/mirrors/mirrors.cgi?action=download&filename=hadoop/common/hadoop-3.3.2/hadoop-3.3.2.tar.gz" | sudo tar -xzf - -C /opt
      else
        echo "Skipping..."
      fi
    displayName: 'Download Hadoop for ADLS Testing (only Linux)'

  - script: |
      set -eo pipefail
      export PATH=$HOME/mambaforge/bin:$PATH
      source activate $CONDA_ENV
      unamestr=`uname`
      if [[ "$unamestr" == 'Linux' ]]; then
        mamba install -y -c conda-forge 'openjdk=11' maven
        cd azurefs-sas-token-provider
        python setup.py develop
      else
        echo "Skipping..."
      fi
    displayName: "Setup Snowflake ADLS Testing (only Linux)"

  - script: |
      set -eo pipefail
      export PATH=$HOME/mambaforge/bin:$PATH
      source activate $CONDA_ENV
      mamba install -y -c conda-forge xlrd xlsxwriter openpyxl
    displayName: 'Setup Excel Testing'

  - task: DownloadSecureFile@1
    name: testLicense
    inputs:
      secureFile: 'bodo.lic'
    displayName: 'Download Test License'

  # - script: |
  #     set -eo pipefail
  #     export PATH=$HOME/mambaforge/bin:$PATH
  #     source activate $CONDA_ENV
  #     mamba install -y 'matplotlib<=3.5.1' -c conda-forge
  #   displayName: 'Matplotlib installation'

  - script: |
      set -eo pipefail
      export PATH=$HOME/mambaforge/bin:$PATH
      source activate $CONDA_ENV
      mamba install -y 'openjdk=11' -c conda-forge
    displayName: 'Openjdk installation'

  - script: |
      set -eo pipefail
      export PATH=$HOME/mambaforge/bin:$PATH
      source activate $CONDA_ENV
      mamba install -y -c conda-forge 'openjdk=11' py4j=0.10.9.5 maven pyspark=3.2 mmh3=3.0
      cd iceberg
      python setup.py develop
    displayName: "Setup Iceberg Testing"

  # Note that we use $(which unzip), because the
  # mambaforge's unzip is not on SUDO's path, because SUDO uses a different PATH
  - script: |
      set -eo pipefail
      export PATH=$HOME/mambaforge/bin:$PATH
      source activate $CONDA_ENV
      mamba install -y -c conda-forge sqlalchemy cx_oracle unzip
      unamestr=`uname`
      if [[ "$unamestr" == 'Linux' ]]; then
        mamba install -y -c conda-forge  libaio
        wget https://download.oracle.com/otn_software/linux/instantclient/215000/instantclient-basic-linux.x64-21.5.0.0.0dbru.zip
        sudo $(which unzip) instantclient-basic-linux.x64-21.5.0.0.0dbru.zip -d /usr/local/lib
      else
        wget https://download.oracle.com/otn_software/mac/instantclient/198000/instantclient-basic-macos.x64-19.8.0.0.0dbru.zip
        sudo $(which unzip) instantclient-basic-macos.x64-19.8.0.0.0dbru.zip -d /usr/local/lib
      fi
    displayName: 'Setup Oracle Database Testing'

  # TODO: Re-enable (https://bodo.atlassian.net/browse/BE-4122)
  # - script: |
  #     set -eo pipefail
  #     export PATH=$HOME/mambaforge/bin:$PATH
  #     source activate $CONDA_ENV
  #     mamba install -y -c conda-forge psycopg2
  #   displayName: 'Setup PostgreSQL Testing'

  - script: |
      set -eo pipefail
      export PATH=$HOME/mambaforge/bin:$PATH
      source activate $CONDA_ENV
      mamba install -y pyspark=3.2 'openjdk=11' -c conda-forge
    displayName: 'PySpark'

  - script: |
      set -eo pipefail
      export PATH=$HOME/mambaforge/bin:$PATH
      source activate $CONDA_ENV

      mkdir env
      mamba env export | tee env/environment.yml
      mamba list --explicit > env/package-list.txt
      pip list | tee env/requirements.txt
    continueOnError: true
    displayName: Export Environment Spec

  - publish: $(System.DefaultWorkingDirectory)/env
    artifact: TestEnv $(Agent.JobName)
    continueOnError: true

  - script: |
      set -eo pipefail
      sudo chmod a+r $(testLicense.secureFilePath)
      sudo cp $(testLicense.secureFilePath) $HOME/bodo-inc
      export PATH=$HOME/mambaforge/bin:${PATH}
      source activate $CONDA_ENV
      pip install pytest pytest-azurepipelines pytest-mock
      unamestr=`uname`
      if [[ "$unamestr" == 'Linux' ]]; then
        export LD_LIBRARY_PATH=/usr/local/lib/instantclient_21_5:$LD_LIBRARY_PATH
      else
        export LD_LIBRARY_PATH=/usr/local/lib/instantclient_19_8:$LD_LIBRARY_PATH
      fi

      if [[ "$unamestr" == 'Linux' ]]; then
        echo "Setting up Hadoop (and Arrow) environment variables"
        export HADOOP_HOME=/opt/hadoop-3.3.2
        export HADOOP_INSTALL=$HADOOP_HOME
        export HADOOP_MAPRED_HOME=$HADOOP_HOME
        export HADOOP_COMMON_HOME=$HADOOP_HOME
        export HADOOP_HDFS_HOME=$HADOOP_HOME
        export YARN_HOME=$HADOOP_HOME
        export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
        export HADOOP_OPTS='-Djava.library.path=$HADOOP_HOME/lib'
        export HADOOP_OPTIONAL_TOOLS=hadoop-azure
        export ARROW_LIBHDFS_DIR=$HADOOP_HOME/lib/native
        export CLASSPATH=`$HADOOP_HOME/bin/hdfs classpath --glob`
      else
        echo "Skipping hadoop/arrow env var setup"
      fi

      # For debugging purposes
      export BODO_SF_WRITE_DEBUG=1

      cd $HOME/bodo-inc
      cp `python -c "import bodo; print(bodo.__file__[:-11])"`pytest.ini .
      # For caching tests we need to update the location of the decryption file.
      # We set the absolute path as an environment variable.
      export BODO_TRACING_DECRYPTION_FILE_PATH=`echo "$(System.DefaultWorkingDirectory)/obfuscation/decompress_traces.py"`
      if [[ "${{ parameters.caching_test }}" == "true" ]]; then
        python -m bodo.runtests_caching "${{ parameters.name }}" "$NP" bodo/tests/caching_tests
      else
        python -m bodo.runtests "${{ parameters.name }}" "$NP" --pyargs bodo -s -v -m "$(PYTEST_MARKER)"
      fi
    env:
      SF_USERNAME: $(SNOWFLAKE_USER)
      SF_PASSWORD: $(SNOWFLAKE_PASSWORD)
      SF_USER2: $(SNOWFLAKE_USER2)
      SF_PASSWORD2: $(SNOWFLAKE_PASSWORD2)
      SF_AZURE_USER: $(SF_AZURE_USER)
      SF_AZURE_PASSWORD: $(SF_AZURE_PASSWORD)
      BODO_TESTING_HAS_MULTI_RANK_TEST: ${{ parameters.BODO_TESTING_HAS_MULTI_RANK_TEST }}
    displayName: 'Test Bodo'

  - script: |
      set -eo pipefail
      export IS_RELEASE=`git tag --points-at HEAD`
      if [[ -n "$IS_RELEASE" ]]; then
        export IS_MAJOR_RELEASE=`python -c "import os; print(int(len(os.environ[\"IS_RELEASE\"].split(\".\")) < 3))"`
      fi
      if [[ "$IS_MAJOR_RELEASE" == 1 ]]; then
        export PATH=$HOME/mambaforge/bin:${PATH}
        source activate $CONDA_ENV
        git clone https://github.com/Bodo-inc/Bodo-examples.git
        cd Bodo-examples/examples/tpch/
        # Invalid env variables for AWS credentials in the pipeline, s3 access is denied unless we run it by resetting them
        AWS_ACCESS_KEY_ID="" AWS_SECRET_ACCESS_KEY="" mpiexec -n 4 python bodo_queries.py --folder s3://bodo-example-data/tpch/SF1
      fi
    displayName: 'Run Bodo Examples for Major Release'
