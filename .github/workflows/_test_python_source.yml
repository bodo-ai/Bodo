name: Run Python Tests (Linux)
on:
  workflow_call:
    inputs:
      batch:
        description: 'Test Batch to Run'
        required: true
        type: number
      total-batches:
        description: 'Total Number of Batches Running'
        required: true
        type: number
      pytest-marker:
        description: 'Pytest Marker to Run Subset of Tests'
        required: true
        type: string
      collect-coverage:
        description: 'Collect Coverage'
        required: true
        type: boolean
      os:
        description: 'The OS of the runners.'
        required: false
        default: 'ubuntu-latest'
        type: string

jobs:
  run:
    permissions:
      id-token: write
      contents: read
    name: Build and Run Tests Helper
    runs-on: ${{ inputs.os }}
    steps:
        # Setup
        - uses: actions/checkout@v4
        - name: Build from Source
          uses: ./.github/actions/build-source
          with:
            build-all: true
        - name: Load Hadoop from Cache
          if: runner.os != 'Windows'
          uses: actions/cache/restore@v4
          with:
            path: hadoop.tar.gz
            key: hadoop-3.3.2-${{ runner.os }}
        - name: Clean Cache
          run: |
            # Clean Maven and Spark Ivy Cache
            rm -rf "$HOME"/.ivy2/cache "$HOME"/.ivy2/jars "$HOME"/.m2/repository
          shell: bash
        - name: Configure AWS Credentials
          uses: aws-actions/configure-aws-credentials@v4
          with:
            aws-region: us-east-2
            role-to-assume: arn:aws:iam::427443013497:role/BodoEngineNightlyRole
            role-session-name: BodoEnginePrCiSession
            role-skip-session-tagging: true
            role-duration-seconds: 10800
        - name: Install Extra Test dependencies
          # This isn't published on pypi so no good way to list it as a dependency
          run: pip install 'git+https://github.com/apache/polaris.git#subdirectory=client/python'

        # Run Tests
        - name: Run Tests
          run: |
            if [[ "$RUNNER_OS" == "Windows" ]]; then
              # On Windows we set HADOOP_HOME to a dummy directory.
              # Spark needs to verify HADOOP_HOME exists at initialization even if it is not used.
              export HADOOP_HOME="$(pwd)/buildscripts/local_utils/hadoop_dummy"
              export PATH=$HADOOP_HOME/bin:$PATH
              # Visual Studio 2010 DLLs are needed for winutils.exe
              curl -LO https://download.microsoft.com/download/1/6/5/165255E7-1014-4D0A-B094-B6A430A6BFFC/vcredist_x64.exe
              ./vcredist_x64.exe -passive
            fi

            set +eo pipefail
            # Bodo Tests: Coverage is collected
            pytest -s -v -Wignore \
              --cov-report= --cov=bodo \
              --splits=${{ inputs.total-batches }} --group=${{ inputs.batch }} \
              --store-durations --clean-durations \
              --durations-path=buildscripts/github/test_dur_bodo.json \
              -m "$PYTEST_MARKER" bodo/tests/

            # Save Exit Code for Later
            python_test_exit_code=$?

            # BodoSQL Tests
            cd BodoSQL
            pytest -s -v -Wignore \
              --splits=${{ inputs.total-batches }} --group=${{ inputs.batch }} \
              --store-durations --clean-durations \
              --durations-path=../buildscripts/github/test_dur_bodosql.json \
              -m "$PYTEST_MARKER" bodosql/tests/
            sql_test_exit_code=$?

            # Pytest exits code 5 if no tests are run. Some markers are only in python or sql
            # so we suppress this.
            if [ "$python_test_exit_code" -eq 5 ]; then
              python_test_exit_code=0
            fi
            if [ "$sql_test_exit_code" -eq 5 ]; then
              sql_test_exit_code=0
            fi

            # Merge Exit Codes.
            # If neither Bodo nor BodoSQL fails, the exit code will be 0
            # If one fails, the exit code will be 1
            # If both fail, the exit code will be 2
            exit $((python_test_exit_code + sql_test_exit_code))
          shell: bash
          env:
            BODO_TESTING_ONLY_RUN_1D_VAR: true
            PYTEST_MARKER: ${{ inputs.pytest-marker }}
            BODO_TEST_SPAWN_MODE: ${{ inputs.pytest-marker == 'spawn_mode' && '1' || '0' }}
            BODO_ENABLE_DATAFRAME_LIBRARY: ${{ inputs.pytest-marker == 'df_lib' && '1' || '0' }}
            BODO_ENABLE_TEST_DATAFRAME_LIBRARY: ${{ inputs.pytest-marker == 'df_lib' && '1' || '0' }}
            BODOSQL_PY4J_GATEWAY_PORT: "auto"
            BODO_SPAWN_MODE: "0"
            BODO_BUFFER_POOL_REMOTE_MODE: "1"
            BODO_BUFFER_POOL_DEBUG_MODE: "1"
            # Testing Credentials
            SF_USERNAME: ${{ secrets.SF_USERNAME }}
            SF_PASSWORD: ${{ secrets.SF_PASSWORD }}
            SF_ACCOUNT: ${{ secrets.SF_ACCOUNT }}
            SF_AZURE_USER: ${{ secrets.SF_AZURE_USER }}
            SF_AZURE_PASSWORD: ${{ secrets.SF_AZURE_PASSWORD }}
            SF_AZURE_ACCOUNT: ${{ secrets.SF_AZURE_ACCOUNT }}
            AZURE_STORAGE_ACCOUNT_NAME: ${{ secrets.AZURE_STORAGE_ACCOUNT_NAME }}
            AZURE_STORAGE_ACCOUNT_KEY: ${{ secrets.AZURE_STORAGE_ACCOUNT_KEY }}
            BODO_TEST_SQL_DB_CREDENTIAL: ${{ secrets.BODO_TEST_SQL_DB_CREDENTIAL }}
            BODO_TEST_ORACLE_DB_CREDENTIAL: ${{ secrets.BODO_TEST_ORACLE_DB_CREDENTIAL }}
            AZURE_CLIENT_ID:  ${{ secrets.AZURE_CLIENT_ID }}
            AZURE_CLIENT_SECRET: ${{ secrets.AZURE_CLIENT_SECRET }}

        # Upload
        - name: Prepare Outputs
          if: inputs.collect-coverage && (success() || failure())
          run: |
            mkdir -p outputs
            mv buildscripts/github/test_dur_bodo.json outputs/test_dur_bodo_${{ inputs.batch }}.json
            mv .coverage outputs/.coverage_${{ inputs.batch }}
            mv buildscripts/github/test_dur_bodosql.json outputs/test_dur_bodosql_${{ inputs.batch }}.json
          shell: bash
        - name: Upload Timings and Coverage
          uses: actions/upload-artifact@v4
          if: inputs.collect-coverage && (success() || failure())
          with:
            name: output-${{ inputs.batch }}
            path: outputs/
            include-hidden-files: true
